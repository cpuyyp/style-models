I have a software that generates transactions and executes them. I would like to asynchronously inspect about the transaction progress in term of the simple proportion of queries executed over total number of queries. I'm able to read both and generated by , so I was thinking that a solution could be printing to some custom messages like "Progress: 3/8" (or another custom text string). I've thought about executing a "logging query" which stores in a proper table the informations about query progress, but this table wouldn't be available until the transaction completes, making it unuseful for me to inspect transaction progress. At the moment I tried the following (suppose to have 3 queries in the transaction which do some stuff): 

The problem is that I can't real-time access the content of variable. I can instead access the content of and , so the usage of doesn't make sense at all because it doesn't appear in both and but only in . Should I stick to parse or in order to find the output value from the function (removing the statement in that function because of it's uselessness) or there's an alternative method? Am I missing something? Thank you 

It's clear that the issue is related to . If you have control over the dump process, a possible solution is to do not execute the file from . To do so, you simply have to run the following two queries: 

where and are 50% and 75% of total RAM size respectively. should lay between and for your use case.Test it and give us a feedback. There are also two other moves you should make: 

The function is documented here: $URL$ ATTENTION Be aware that those two queries can give different results for periods that are exactly . The following returns : 

I'm running SQL Server 2008 R2 SP1, on a Windows Server 2008 box. I have a .NET script running from Visual Studio 2010 that does the following: 

Upgradability - SQL Server will rapidly test the limits of your hardware if you let it, so try to anticipate that Affordability - SQL Server licensing in 2014 is core-based, so this should be a consideration. 

The total number of times it will iterate is 150, however it is stopping at 100 connections and I can't figure out why. I could adjust my script to just use a single thread, but I'd prefer to know where I'm missing a max connection setting as that will be more useful to know for future reference. Here's where I've checked so far: 

That exception usually doesn't refer to the SQL Server itself running out of memory, but instead the client workstation that is processing the results running out of memory. You will generally see this if you are outputting a very large result set into the Output window. To troubleshoot the issue (and possibly resolve it) allow SQL to write the results to a file rather than trying to put it all in the output window. 

The IP reported is the SQL Server. Since this is ongoing, is there a way I could figure out what is trying to pass this credential? If I could get an application name or anything I could probably fix the problem. 

However I can't figure out how exactly I need to escape the quotes. It always wants to treat the as a separate column. How can I escape the comma properly? 

I have 2 instances of SQL Server installed on one server: SQL002. One instance is a default instance, SQL2008 R2, and the SQL service is generally not running except for specific tests. The other instance is a named instance, SQL 2014 (so SQL002/SQL2014). This is generally running all the time. Today I just had a developer tell me that when they connect to SQL002 in SQL Server Management Studio it will connect successfully. I replicated this from my machine and also see a successful connection, however when I look at the properties of the connection it is reporting that it connected to the named instance. What is going on here? Is there a redirect I'm not aware of? 

Are you sure about the "Trustworthy" setting? I know that is required for many scenarios using EXECUTE As between databases on the same server but I did not know it had an affect on Linked Servers. Perhaps you are referring to the A/D setting "Trust For Delegation" which must be set for on the server computer(s) 

You should look at Red Gate's tool set. They have a SQL unit testing tool called SQL Test. It might help you with a more comprehensive approach. 

IMO if you are going to the effort to migrate then you should go all the way to 2014 even if you run it in 10.0 compatibility mode. You are going to pay for the license anyway. Also the regression testing effort and developer/DBA learning curve will be significant in either case. If you stop at 2008R2 now you will just have to repeat the exercise again in a couple of years. 2008R2 has already seen its last Service Pack and in a few months (weeks) will be 3 full versions behind the current version. I am recommending my organization move from 2008R2 directly to 2016 for the same reasons. I expect we will start a testing effort as soon as 2016 hits RTM. BTW, I agree that a Side-By-Side upgrade is preferred. When I last did this exercise we ran the "Pre-Production" version in a Dev environment for about a month. 

I think you may be experiencing TCP Port Exhaustion on the Web Server. Avoiding TCP/IP Port Exhaustion is a good starting place for understanding the issue. This is generally an application design/implementation issue. $URL$ 

Is the granularity "transaction" or "current balance". Based on your description it seems that there is mix of the two in this fact. If the granularity is "transaction" then you should calculate balance and correct any "transactions" entered erroneously. If the granularity is "current balance" then you have to deal with the difference between correcting an error and updating the value based on a transaction. 

Execute this from the original database: Execute this from the destination database (the one where you have the out of memory issue): . 

I'm currently running a OS X Lion Server system which ships with a built-in and not-upgradable PostgreSQL version. After years of usage I've finnaly decided to leave the built-in version and install an indipendent version. I disabled the built-in installation and downloaded the installer from EDB and followed the wizard. After many issues reguarding encoding and locales, I've finally managed how to setup a DB with no locale and UTF8 encoding. I issued the following command: 

It subtracts 12 months from and checks if the resulting date is greater or equal to . This query works too: 

What I get from a transaction like the one above using the previous bash command are three outputs: , and bash variable. I'll post some extract of them to make it clear what's their content. plog.log 

I hope to have fully understood your request. With this query you get a concatenation of tables (a UNION) with all records. 

Remember that must be owned by user, so run . This way you can use wathever to analyze the table (if you need to). 

I've searched through the Internet but found nothing that solves my problem (for example issuing and adding to ). returns: 

That time is spent by pgAdmin to pack and render data and is not the time spent by Postgres to complete the query execution. Why are you fetching 250.000 rows into pgAdmin? If you need to export the table to a plain-text file (like a CSV with header) you can execute this query: 

PART1 - INSERTING You don't have to use but and add square brackets to the JSON data structure. I sugget you using a JSON validator website like JSONlint to test the correctness of your JSON data. This codes inserts 3 new records in : 

Sometimes our developers will write a query that uses cursors, but doesn't close them out explicitly. I'm trying to generate a list of active objects in my production database that use cursors but don't explicitly close/deallocate them. To do this I've written a simple statement that does the job, but is extremely slow: 

I'm not sure where else to check, I know I have a lot of moving parts here but I'm getting the feeling I'm just missing a max pool setting somewhere. 

I have the need to restart Microsoft SQL Server's group of services on a given computer, remotely, through some sort of programmatic method I can insert into a workflow. I'm looking for the best way to do this, I've seen a few different ways and I'm wondering if there's anything I'm missing: 

So the first thing I did was to make sure that the instance is accessible via SSMS (it is), and that my CMD prompt is Administrator (it is). Then I checked to make sure the instance has TCP enabled (it does) and allows remote connections (it does). What am I missing? The commend I use, minus the script, is: 

However I would like to have that integer replaced with a variable that is the RunID of the row updated (which is causing the trigger to fire). How can I do that? 

I'm gathering wait types on a load test environment, and the second biggest wait type is . The stats are coming from sys.dm_os_wait_stats, but I can't find any documentation that explains what that particular type means. I'm running SQL Server 2014, SP1 on a physical Windows 2008 R2 instance (no VM involved). 

I am trying to use SQLCMD to remotely detach a database but for some reason it can't find the server. From the workstation, I can connect to the database instance (which is the default instance) using the Host Name through SSMS successfully. The error is: