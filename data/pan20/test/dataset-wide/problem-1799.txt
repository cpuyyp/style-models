This behavior is common if you have a memory leak in a plugin. This results in memory starvation, and the server threads start paging in and out of memory. It can also happen if you allow too many threads as Apache will spawn new threads as load goes up. There are a number of settings that can be used to work around the issue. 

If you want to verify that the destination is valid, you can use callouts. However, Gmail may end up blocking you if you do so. The following code from the standard configuration does recipient callouts. 

Where are you testing from? If you are testing from your local server, the connection has likely been accepted before reaching your warn statement. The recipient ACL starts with some accept statements intended to short-circuit tests designed for incoming mail from the internet. Is the mail being delivered to the destination handling the mail? This likely requires an alias in . If not, it may be really bounced before it gets to your warn statement. Try using . This should show detail of each request where noreply was logged. Delivery messages should contain . Systems using a address normally set a Reply-To address to which replies are sent. addresses are typically used by automated system rather than individual users. Personal mail should be sent after authenticating as the user sending the mail. Testing addresses normally requires generating your own mail to the address. Other than bounce messages, these addresses should see little or no traffic. If you send to well behaved servers, bounces will occur before the delivery has completed, and will appear as a failed delivery. Other serves may accept the message and silently discard messages to invalid addresses. 

I ran a quick test of my IPad with TLS1 disabled, and was unable to connect to my mail server. My first question would be why is your e-mail server in your PCI-DSS protected zone. You shouldn't be emailing credit card numbers and other protected data in a form that requires PCI compliance. Sending such data by email will break your compliance. Move the email server outside the zone. TLS1 includes ciphers which don't meet the security requirements, but works fine with those ciphers removed. This likely may not pass compliance, but provides the same level of encryption. It is likely that here will clients that don't support TLS1.1 and up for a long time. 

The first two items can be handled by ownership and groups with or without LDAP. Changing access is should be easier if you use ACLs which can use userid and groups. Having a user be root on on server will make them root on all servers. To be root the UID must be 0. Allowing any user to login as root is bad security practice. which is the normal method for granting root access to users has full capabilities to restrict access by host and/or hostgroups. The usual host group is ALL. Changing the content of will not kill any running processes. You may want to implement , , or a similar tool to roll out your changes. This will ease planned access changes, and provide some documentation to what you have done. Changes can be done quickly if required, but I would be very concerned if frequent fast changes were required. The groups a user has are set a login, so revoking groups will not modify the access of logged in users. Changes in file access will have immediate effect for new accesses. I haven't verified the impact on open files, but expect the original access will apply. Look at the options in for some of the options that can be used with LDAP and pam. 

Exim used to be the default install on Debian. Ubuntu seems to default to postfix now. I install Exim, as it is easy to configure. My email server run exim with ACL additions to deal with incoming spam. (Very little makes it as far as SpamAssassin.) In your case I would install either Exim or Postfix. If you aren't going to relay via your ISPs server or another server, you have some DNS configuration which will need to be done. Check the RFCs and Best Practices. 

Both SPF and DKIM are entirely optional, but they do help distinguish your server from a spambot. I recommend using SPF for all domains. This can be as simple as for domains sending email, for mail servers, and for all other domains. 

You DNS server can be authoritative for as many zones as you wish. If you are us*ing just create a new zone file for each zone and add it to your configuration. My server is authoritative for two second level domains, and a few sub domains. I run a split configuration. Locally it is also authoritative for ip-addr lookups for the private IP address ranges, 10.0.0.0/8, 172.16.0.0/12, and 192.168.0.0 as well as localhost. EDIT: Pointing multiple NS records to the same IP address puts you in violation of the requirement to have redundant name servers. While some registrars might allow you to configure this, they are not doing you any service. I am not sure why you would want to do so. There are providers who will provide secondary name servers for free or low cost. If you are small enough not to have your own secondary server, it is likely your registrar's DNS service will support your needs. 

Many if not most users currently connected to IPv6 are connected this way. For IPv6 there are 6in4 and 6to4 tunnels. These encapsulate the IPv6 packet in an IPv4 packet and send it over the IPv4 network. The IPv6 packet is the payload of the IPv4 packet. There is an overhead of 20 bytes per packet for the IPv4 header resulting in a smaller MTU for packers routed this way. The IPv4 option would likely be a VPN running over IPv6. I would expect that the same techniques used for IPv6 over IPv4 could be used for IPv4 over IPv6 although I am not aware of any. IPv6 also has addressing schemes for IPv4 so IPv6 addresses can be used in an IPv6 network. However, the IPv4 headers handle options differently requiring header translation for certain header options. There are significant issues in routing IPv4 addresses in an IPv6 network, to encapsulation would be the preferred method of transport. 

This will give you an idea how well ntp is working. You should see it stabilize over time. There are a number of restrictions which can be set on to limit how much information about the server can be accessed remotely. It is possible you are restricted to only using the upstream server as a time source. Firewall rules restricting traffic to port 123 for both source and destination are possible. This provides a working ntp setup but limits access by other tools. Some tools allow you to use port 123 as the source port if it available. I am partial to using in debug mode. If you are correct about the of the upstream server being your IP address, it appears to be using your server as it's preferred timesource. Try adding to your configuration. It may be your upstream server is poorly configured. Try adding your router and/or nameservers as sources, I find they can be better sources than the official corporate server. 

As has been noted, your domain registrar likely can forward email for you. If you are sending email from your domain, you will want some basic email setup including an MX. Adding SPF, and DKIM signatures may increase your delivery success. You will want your MX to accept (and possibly forward) email sent to the sending address, as well as mail sent to postmaster of each sending domain (which you do want forwarded). You may want to use a address to get responses directly to your address. Although, if you have set up forwarding, you do have that option as well. If you already have setup an email server on one of your Linux servers, it can act as the MX for all your domains. You will need to update your configuration to include the additional domains. You have two options for aliasing addresses in this case (both can be active): 

NFS locks can survive a reboot. They should eventually timeout, but sometime you need to shutdown NFS and clear the lock directory manually. I believe I usually run into this issue when the export is not available when the system comes back up. If I remember right the locks are maintained in . 

Then allow access by service and/or network addresses. You can block by names returned by DNS record look-ups as well as by addresses ranges. The following allows access from the local network only, but blocks the router from access. 

From what I have seen Outlook is likely defaulting to attempt authentication. This will cause issues if you haven't set up an authentication mechanism. The other clients likely detected that you don't offer or require authentication. Outlook does offer an option to turn off authentication in its server configuration tabs. It may be difficult to change. For this kind of client, I require authentication over an encrypted connection. This is made available via startTLS on the submission port (587) as well as the regular SMTP port (25). This may solve your issue. Some versions of Outlook used an obsolete login dialog. There is an Exim authenticator that offers tje required dialog. You may want to set up a dummy authenticator for testing that always passes. 

If you are going to include the local clock fudge its level a fair bit. It looks like you have it set to 5. I generally set it to at least 8 (). If you don't fudge it, you can appear like an atomic clock to other hosts on your network. On one network I scanned, I found a lot of low strata servers announcing times which were usually incorrect by hours or days. Shane is correct about the value which indicates you have access to the server. The high and values for your time server indicates it may not be very reliable. They may be high, because your server is still synchronizing. The fact that the interval has increased to 128 indicates that your server is getting consistent results. It should gradually increase to 1024 seconds. Try running a loop like: 

Despite the fact the mail was from an external source, the accepted return path is internal. It also appears the external host used your domain in its HELO command. 

EDIT: If each LB has a public IP address then you really want an active/active configuration. Otherwise, you are likely to fail to respond to half your requests. Active/passive should be using a single IP address for incoming traffic. The passive node does an address takeover when the active node dies. In Active/Active mode, both LBs will have different public IPs. Normally, there would be one or more DNS names with both IPs listed in their entries. Simpler systems will use normal DNS round robin balancing between the two LBs. More complex systems will use short TTLs on the DNS entries and try to balance the load by handing out the address of the least busy LB as the first DNS entry. In Active/Passive mode, both LBs handle the same public IP address (with only the current active note passing traffic for that address). There are a variety of heartbeat monitoring techniques that can be used by the passive node to monitor the active node. 

Consider using Expires for your expiry information. In the absence of max-age in Cache-control, it provides the same functionality. Use Cache-Control for additional cache control information. If you configure the caching correctly, you should see fewer validation requests which pass through intermediate caches. This will reduce your bandwidth. Check RFC2616 section 14.9 for the cache values you might want to override. Cache-Control is mainly for overriding cache behavior of intermediate caches. However, there are directives for the browser cache as well. 

Configurration for DMARC with reporting. Until the reports indicate you don't have issues, I would not use a policy. You may want to start with as your policy. 

You would use the CA certificate if you want to automatically trust any certificates it has signed. This usually applies to clients like your web browser. Servers use the CA certificate for two purposes. 

The time servers you are using are synced to the same (possibly local) time server. I have seen servers claiming to be stratum 0 or 1 that had time services that were days off the correct time. Depending on where they get there time service they can be of by a few seconds. My ISPs public time server is current off bu 1.8 seconds. Setting the min poll to 36 hours will severely degrade the ability of NTP to correct your time. The fact your server is offset half a second from your time servers is the result. Try enabling one or two of the pool servers and see if you can connect. This will provide you better time service. 

Try filtering on referrer. Either mod-rewrite or mod-security can be used. See Debain Administration site for examples.