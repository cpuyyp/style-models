It's important to remember that the data you are loading may be 900mb outside of your RDBMS but may be even more in the database with out compression. You also have to accout for database growth if it does it in chunks and transaction log space. So always be sure you have ample disk space when doing that large of an import of data as it seems that code is a direct result of running out of disk space. 

I recently added a new modem (a plain ol consumer grade one) to a fax server thats been up and running for years running on Microsoft Server 2003 fax services. The server currently has two modems, the new one is identical to one of the existing. After installing the new modem it showed up in the Fax Server Manager as a device but was not doing outbound faxes. (The server by default does not handle incoming.) So after a reboot the server no loger sees the modem in the Fax Server Manager but is listed as a device in device manager. I've attempted to restart just the fax service and even the whole box again but to no avail. Any one have any ideas on this one? Or any one with good links to resources for the fax service? 

You're best bet would be to set something up like Squid as a transparent proxy to capture all of this traffic. There are a number of things you can do with pfSense like this to set it up as a sniffer or special purpose appliance if a proxy really just can't be configured in your network. But from the sounds of it you may want to look into tightening down that network a little more with a hardware or software firewall of some sort which will give you some of these functions. I have done this at a couple offices using Squid and it's worked out very well. 

I'd say set up one folder and have all your domains as folders inside, as I think you already have. So your folder structure will look like this 

I know you stated not putting them in a database, but I'm an advocate for this where appropriate and I'm thinking here it is. Any way you store files you are going to be taking on some amount of overhead, it’s just how much your will to take is the issue. By storing files in the database you can further limit who can see them by completely removing them from the file system. Under the right control and programming you can limit the files to have access by only your application, thus eliminating the need for another server and tons of file system security changes not to mention an additional backup plan for that additional “secure” server. Another added benefit of storing them like this is you can encrypt them and store them, as well as have a simplified backup plan. 

Not knowing your PC's specs it mgiht make a huge difference. I was running Win2003 Standard on a desktop box, Core 2 Duo e6400 (if I remember correctly) with 4gb of memory and a Raptor X 150gb drive. When I moved to 2008 Ent it decrease my boot time by about 20 seconds and overall performance of my app went way, way up due to the increase performance in the way is handles memory. Stability is about the same. I never really had a crash on the 2003 install, and have gone 136 days with no reboot on the 2008 install. Only reason it rebooted was due to a change in roles. I've not gotten the chance to install R2 on it yet, but am sure the new improvements will only add to the stability and responsiveness of the box. 

Well if it's just to do testing under IIS 7 you now have the option for using IIS Express and run on XP or better. Just a thought if your doing it for dev reasons. 

Since it's on the intranet doing it in IIS would be the only way to do it as far as I'm aware. If it was an internet facing site you could do it at the firewall level and leave the internal port what ever you wanted, just so long as the firewall knew what port it was. Also using host headers can help if you have multiple web sites inside IIS. But so you know, you can only change the port for the entire website in IIS. It's not possible to change the port for just an application or virtual directory under the root. So in other words you can change www.me.com to www.me.com:89. But not www.me.com/you/ to www.me.com:89/you/ and have it not affect your entire website in IIS. 

If your under windows you will need to edit the in your my.ini file. You can see the MySQL Ref Manual for help on this as well. 

I've been trying to really figure out what my IOPS are on my DB server array and see if it's just too much. The array is four 72.6gb 15k rpm drives in RAID 5. To calculate IOPS for RAID 5 the following formula is used: . The formula is from MSDN. I also want to calculate the Avg Queue Length but I'm not sure where they are getting the formula from, but i think it reads on that page as . To populate that formula I used the perfmon to gather the needed information. I came up with this, under normal production load: . Also the disk queue lengh of . So to the question, am I wrong in thinking this array has a very high disk IO? Edit I got the chance to review it again this morning under normal/high load. This time with even bigger numbers and IOPS in excess of 600 for about 5 minutes then it died down again. But I also took a look at the , , and . These number were taken when the reads/writes per sec were only 332.997/17.999 respectively. %Disk Time: 219.436 %Idle Time: 0.300 Avg Disk Queue Length: 2.194 Avg Disk sec/Transfer: 0.006 Pages/sec: 2927.802 % Processor Time: 21.877 Edit (again) Looks like I have that issue solved. Thanks for the help. Also for a pretty slick parser I found this: $URL$ It works pretty well for breaking down the data into something usable. 

If you are using an Antivirus scanner and trying to transfer large files it may be locking the file. You may want to see if you can exclude that folder from the scan. 

It sounds like you need to make the app be in the root of the site. So create a new directory outside of the inetput folder say C:\myweb. In C:\myweb add your wordpres application Open up the IIS management console and add a new website called www.mydomain.com and point the root of the web to C:\myweb. You can then use host headers to make it so www and any other subdoamin point to the same website in IIS. 

Then just create a new website and point it to the corresponding domain name. And again use host headers in your Bindings to specify the different domain names. There is no need to create a website pointed to the webRoot folder, or even have file in it as it's only used to house your different domain name folders that are application specfic. 

I'm trying to get a little more usefulness out of my MySQL backups. I'm wanting to gzip my backup when it's completed from a cron job. Here's the script I have so far to do the backup. 

Sucess!!! Since I'm using cheap-o hardware as the modem, I just borrowed another one from another computer in the office! I mean come on, like we still use modems, what is this 1999? Never the less, the new modem works correctly. Looks like it was just a hardware problem, still weird that it was seen in device manager as a working modem though.... 

Sounds like you need to set up SMTP on the server. I had some issues getting everything working on 2008 so I changed direction and went with hMailServer as my server of choice. It's failry flexable and is free. It's also dead simple to get in and configure. Not to mention lots of documentation to help guide you through the porcess. Once you have it installed you would need to open, and forward, the needed ports from your router to the mail server. Normally they are 25 (SMTP) and 110 (POP3) unless your using SSL then you would need to congifure the ports accordingly. You can also configure it to forward your out bound mail to a relay if desired/needed based on your ISP and their restrictions, if any. You of course also need to set up the proper MX record(s) in DNS and have it pointing to your domain/IP. 

I've used DoubleTake for the last year or so. This has allowed us to replicate 70 to 90 (count growing monthly) databases to a DR fairly quickly and with a high compression. As Farseeker stated it allows a block level replication which works quite well. It also allows for a queue for those times where there is a heavy transactional load. The only issue I really see for your instance is how heavy are these databases? I have at least 5 databases over the 10gb mark with a high volume of transactional data during peak hours and jobs, around 1 to 3gb per day per database. In all transferring upwards of 800+gb over the wire monthly (compressed is MUCH less of course). Since adding an additional 20+ databases in the past 15 months I've seen excessively high IO related to disk queueing. So it may be an issue trying to use something like this if most of your databases are very busy. You may end up with missing data or the receiving end if you have to much queued up and your link goes down. Of course this would only matter for a DR deployment. But keeping a close eye on it and tuning the bandwidth will help greatly with keeping the queue down.