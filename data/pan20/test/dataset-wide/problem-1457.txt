This line is not correct. An iterator over a vector might still be a random access iterator, but it very likely won't be of the same iterator type as the iterators passed in (e.g. iterators over a or a custom container). If insisting on proper static typing, this could be remedied as follows: 

However, this requires a strict memory mapping between the message struct and the serialized byte format (so in this case has to be a POD struct). Yes, this effectively bypasses the type system, but if used properly its the fastest way of parsing messages (and in case of embedded systems the reuse of the memory is a nice touch). 

MSVC still does produce some extra instructions (for the 's and the lambdas constructors and destructors), but those are never actually called. The final count for of MSVC would be 19 instructions (only 3 more than GCC because it does some stack pointer management, though that could probably be turned off with the right compiler switch). Link to godbolt with fixed macro (MSVC) 

Correctness sets you on the fast track for undefined behavior, as the value returned by might not be inside the same allocation as (e.g. in case of a linked-list based or an iterator returning a proxy object, as does ). Operations such as comparison, addition or subtraction of pointers are only defined if they both point into the same allocation (or the first element after it) and they are both of the same type! Implementation 

Compilation flags Please specify for which sets of compilation flags this code is expected to work (it will break if compiled with defined, as described below, and I'm not 100% sure on 64 bit support). Bugs / string handling If compiled with defined (e.g. by a compiler flag), a lot of stuff will break: 

Correctness Every returned by might be dangling. This can happen if the gets destroyed while there are still pointing to contained objects. This is a result of the not owning the pointer. If you can guarantee that there won't be any pointing into the when the is destroyed, this problem easily disappears. If this can't be guaranteed, there are two options: 

An old trick is to cast a pointer to an array of bytes to an pointer of a struct (POD) with the exact memory layout of the final message(s). 

Further reading I suggest you look for learning material about , and , as those will simplify memory management quite a lot (if used correctly). 

Algorithm You could actually skip looking up the maximum element in the range. This is because it gets cancelled anyways: $$y = {{e^{x - x_{max}}} \over {\Sigma e^{x - x_{max}}}} ={ {e^x \over e^{x_{max}}} \over {{{1} \over {e^{x_{max}}}}\Sigma e^x}} = {{e^x} \over {\Sigma e^x}} $$ Also, currently the results are stored in place, i.e. the original input data will be lost. This might not always be wanted, so maybe accept an iterator to write the results to? vs. SFINAE I personally like the SFINAE approach more in this case, because it's easier to introduce another overload if needed (e.g. for iterators over associative containers) and you get immediate error reporting. That said, if the decision is final that you won't ever need another overload, works fine. iterator Well, if the container is nicely conforming to standard library guidelines, you'll be fine with using . For custom containers, this might not be the case, though - for those cases you could use instead. 

Introducing your own smart pointer type that checks the for validity every time it's dereferenced, as the standard smart pointers (, and ) are not designed for this task. (Ab-)using the returned to keep the section alive. This can be done in the lamda init capture of the custom deleter. 

usage Normally, a is used to express "I own this". So a signature like says "Call me, and you become the new owner of whatever I return". Is this necessary in this case? No! After all, the caller just wants to access the existing object, and not acquire a new one. So, how can this be expressed? There are two variants: 

Optimization Your current code is not structured well enough for the optimizer. Why? If it could reason about it perfectly, it would remove all the code (as there are no observable side effects), running in near 0ms! Declaring all possible variables and moving them to the smallest scope possible helps quite a bit. Even better: Refactor the code into functions (and maybe classes) with proper annotations! Just this alone allowed MSVC and GCC to recognize that the whole calculations aren't needed (as they don't cause side effects by themselves), so they removed them and run-time went down to ~24 microseconds on my machine. To get relevant results, we now need to fool the compiler a bit: Adding a little side effect ( in the code below) and taking the number of loops to run as a command line argument were enough for MSVC and GCC (and clang, though not ICC). Now runtime (with all calculations!) went down from ~14 seconds (original) to ~12.5 seconds (again on my machine). 

Algorithm The encoding algorithm is fundamentally flawed (it cannot be reversed unambiguously in the general case). For an example, I have plotted the values for : 

Depends on whether your class already contains a vtable pointer or not. If it does, there will be no additional memory requirements per instance (just another entry in the vtable, which is shared by all instances). If it doesn't, each class will need an additional vtable pointer (that will be automatically inserted by the compiler to make virtual dispatch work). Also, a vtable will be generated, but those are one per class. However, since you are already using (and that includes possibly deleting) instances of derived classes via pointer to base class, the base classes destructor (in this case ) should already be marked so the derived classes destructor gets called correctly when deleting the . This means each class should already have a vtable anyways - so no additional per-instance overhead. 

Note: This might keep the section alive far longer than intended! (Some might also say that this is an ugly hack...) 

I won't repeat any of the excellent points @Loki Astari already mentioned. Asymmetric Interface The current implementation only allows for custom setters, but not for custom getters. This might be fine for trivial implementations of those, but will hinder reusability in more demanding cases. Unnecessary encapsulation breakage There's no need for a definition in the macro. Unnecessary convention introduction The implementation requires that each setter function is and a class method. Both requirements might be too restricting for all use cases. Naming I get it, naming is hard. might be borderline acceptable, but (as those from C#) or might be more fitting. Also, just looking at the name, what should do? Get a "setter"? Declare a "setter/getter" object? would be a far better fit IMHO, better conveying its intended purpose. User defined conversion problems If has its own user defined conversion operator, you might get into problems when "chaining" conversions. Example: 

Empty destructors The only empty destructor I'm worried about is . does acquire some resources (e.g. SDL handles), but never cleans them up properly. OTOH, the destructor of does some unnecessary stuff (could as well be empty). Comments Ideally, the best code is so clear in its naming and design that it doesn't need any comments. In practice, sometimes comments might be needed to explain why (not how!) something is done. In your current code, it feels like you wanted to label certain code sections to clarify what they do, there's a language feature for that: functions! Collision handling Other than the bug(s) mentioned above, it seems to be fine (regarding logic). Design While your current design works, there are some concerns: Many classes have multiple responsibilities. Ideally, every class has only one responsibility, i.e. only one reason to be changed. I don't feel like any of the classes in your current design adhere to this philosophy (only candidates are and maybe ). If I had to design this game, I'd probably use the following (public) interfaces: 

Doing so allows other threads to perform work on all unrelated elements. 3) Read/Write exclusivity What's the difference between reading and writing ? Reading can be done concurrently, writing can't. There is a lock that helps for this special case: allow multiple threads to read the related object(s), but only allows one thread to write to it (while no one else can access it). The catch? It's only available since C++17. Before that, there might be other libraries providing that functionality, though (e.g. boost), or you make do with a normal . Small problem In the current version, every changes to an element of is done in one transaction - no thread can see any partial state. If this property is required, this can be implemented with some special considerations. How do you change a object in one transaction? 

As you can see, most y-values have either 0 or 2 corresponding x-values. The exceptions are (1, 4), (14, 9) and (26, 23) corresponding to (, ), (, ) and (, ) - for this selection of , and . Why that? There are multiple reasons: 

Naming Many variable have very non-descriptive names. These could be improved for better readability (what tells you more: or ?). 

There are some nearly unique bidirectional mappings when is a multiple of and and are coprime and must be greater than 0 or lower than -26 - this is because how the modulo operator works and how you handle negative y-values. They would be unique if you reduced the number of possible input values to 26, e.g. by moving the values for to down to to . However, those mappings are basically linear (the contribution of gets "removed" by the modulo 26). For , this would be a cesar cipher. 

So the best we could get is an increase of by (by removing elements from the front and elements from the back, though that wasn't asked). Algorithm code In code (using arrays for consistency with existing code): 

Algorithm Your algorithm uses (as you correctly stated) \$O(K^2)\$ time by calculating all possible combinations. This can be reduced to \$O(K)\$ with a bit of cleverness: As far as I understand it, the problem basically boils down to: , maximize by removing up to <= total elements. This means to maximize , one needs to find how many elements to remove from each "end" of the array, because as you correctly deduced, only those matter. Now we can step from one end up to elements in, and for each step calculate the change in if we were to remove elements up to this point. If it's the best result so far, we note it for the current position, else we note the previous better result (after all, we always can take less elements away). We do this for both ends. Then we can add the noted values for taking elements from the front and elements from the back together (so up to elements total), and find the maximum for this value. This value is the highest increase possible for . Adding this value to the previously calculated original value of gives us then the maximum value for . Step by step Let's take your example: . Let be the map .