I am trying to understand lowest representations of loop groups as developed in Pressley and Segal's book. Specifically I want to be able to compute the weight spaces that appear in a lowest weight representation. I realize there is a formula for this -my question is along the lines of how to apply the formula correctly. I tried to do a small example with $LSL_3$ (actually $\mathbb{C}^\times_{\theta} \ltimes \tilde LSL_3$) and something fishy happened so I was hoping someone could point out my mistake. The maximal torus is $\mathbb{C}^\times_\theta \times T \times \mathbb{C}^\times$ where $\mathbb{C}^\times_\theta$ is the loop rotations and the other $\mathbb{C}^\times$ is central. The fundamental weights are $w_0 = (0,0,1)$, $w_1 = (0,-\omega_1,1)$, $w_2 = (0, -\omega_2,1)$. The positive roots are $(0,\alpha_1,0), (0,\alpha_2,0),(1,-\alpha_3,0)$. Where $\omega_i,\alpha_i$ are fundamental weights and positive roots of $SL_3$. Pressley and Segal normalize the Killing form so $\langle H_{\alpha_i},H_{\alpha_i}\rangle = 2$. Choosing coordinates $H_{\alpha_1} = [1\ \ 0]^T$, $H_{\alpha_2} = [0\ \ 1]^T$, $\alpha_1 = [2 \ \ -1]$, $\alpha_2 = [-1 \ \ 2]$, $\omega_1 = [1\ \ 0]$, $\omega_2 = [0\ \ 1]$ and the restriction of the Killing form to the torus is just the Cartan matrix $(B_{11} = B_{22} = 2, B_{12} = B_{21} = -1)$. I'm interested in the representation $V_{\tilde \lambda}$ of lowest weight $\tilde\lambda = (0, - \alpha_3,3) = w_0 + w_1 + w_2$. Let $\tilde \mu = (m,\mu, 3)$ be a weight of $V_{\tilde \lambda}$. According to Loop Groups (11.1.1) it is the case that $\tilde \mu - \tilde \lambda = (m,\mu +\alpha_3, 0)$ is a sum of positive roots. Viewing $B$ as a map from co-characters to characters and noting that $\alpha_i = BH_{\alpha_i}$ it follows that we can write $\mu = B[a\ \ b]^T$ for some $a,b$. According to (9.3.7) on pg 180 of Loop Groups the $\tilde\mu =(m, \mu,3)$ which satisfy $3\langle \mu,\mu\rangle - 6m = 6 = 3\langle -\alpha_3,-\alpha_3\rangle$ appear among the weight of $V_{\tilde \lambda}$. This says $m = {1 \over 2}\langle\mu,\mu\rangle-1 = {1\over 2}[a\ \ b]B[a\ \ b]^T - 1 = a^2 + b^2- ab -1$. Taking $a,b = 0$ produces the weight $\tilde \mu = (-1, 0, 3)$ but then $\tilde \mu - \tilde \lambda = -(1,-\alpha_3,0)$. Which is certainly not a sum of positive roots. So what gives? 

My favorite from the last few years is the proof by Hugo Duminil-Copin and Stanislav Smirnov that the connective constant of the honeycomb lattice is $\sqrt{2+\sqrt{2}}$: $URL$ 

Sure, multiplication is commutative, but there is more to it than that. While being reasonably easy, this puzzle suggests variations in ways that the equation $x\cdot y = y\cdot x$ doesn't. In his wonderful paper Games People Don't Play, $URL$ Peter Winkler describes essentially the same game as ``Next card color betting'' (a bit of googling also turns up $URL$ and $URL$ But there the player, Victor, wants to end up as far to the right as possible (increasing his bankroll). It turns out that there is a strategy that guarantees him to end up with $2^{10}/\binom{10}{5} = 256/63$ times his initial bankroll, or about 406 steps to the right of the origin. This is a game that children can understand, but if we pursue the analysis, it doesn't stop until we have developed, besides insights into hedging strategies, a good deal of nontrivial mathematics including information theory (the amount of information Victor has about the red-black sequence dictates exactly how much money he will ideally make by betting), the Wallis product formula (showing that his final bankroll is asymptotically $\sqrt{\pi n}$ for a deck of $n$ red and $n$ black cards), and even the central limit theorem. 

If $X$ is a complex manifold and $Z$ is a closed subset of codimension $\ge 2$ such that $X-Z$ has an algebraic structure, then is $X$ algebraic; i.e. a scheme? If not is $X$ an algebraic space? To clarify: is there a global algebraic structure on $X$ that restricts to a given algebraic structure on a analytic Zariski $U$ with complement codimension $\ge 2$? 

Not much is known about vector bundles on $\mathbb{P}^2$ but I wonder if the following is a tractable question: If $E,E'$ are non-isomorphic vector bundles on $\mathbb{P}^2$, then is there always a smooth curve $C \subset \mathbb{P}^2$ such that $E|_C$ and $E'|_C$ are still non isomorphic? A related and perhaps easier question: Can a vector bundle restrict to the trivial bundles on every curve without itself being trivial on $\mathbb{P}^2$? 

If I haven't missed something, this is the "ordinary" two-person zero-sum game, which is a linear programming problem, and solvable in polynomial time. Game theory is full of slight variations, and you might have read about one of those being NP-hard (for instance, there is a paper by Fortnow and Impagliazzo, $URL$ ) An excellent and concrete description of an algorithm for solving this sort of game is given in Section II 4 of Thomas S. Ferguson's electronic text on "Game Theory", $URL$ I don't know about the worst case complexity of that particular algorithm, but it probably works fine unless you cook up specifically hard games. And in the intermediate stages, the (sub-optimal) strategies of each player will give bounds on V(P) that successively improve. 

For $k$ alg. closed you can phrase the statement as $\Omega_{A/k}$ is loc. free iff Spec$(A)$ is smooth. 'Spec$(A)$ smooth iff $\Omega_{A/k}$ is loc free' should be true without requiring $k = \bar{k}$. But if $k \ne \bar{k}$ then the condition on the derivatives is not the same as smoothness. For example if $C$ is a curve defined over $\mathbb{R}$ with smooth $\mathbb{R}$ points but with singular $\mathbb{C}$ points then the condition on $f$ and its derivatives will be satisfied but there will be a maximal ideal of Spec$(A)$ with residue field $\mathbb{C}$ where $\Omega_{A/k}$ will have the wrong rank. You can try this with $y^2 = (x^2+1)^2$ and the maximal ideal $(y, x^2 + 1)$ in $\mathbb{R}[x,y]$. But if $A(k) = A(\bar{k})$ then the original statement should hold over $k$. 

This question was posed by my colleague Torbj√∂rn Lundh in his paper Which Ball is the Roundest? A Suggested Tournament Stability Index, Journal of Quantitative Analysis in Sports 2(3), 2006. We have discussed it a number of times without finding a solution. The context is a tournament, where $n$ players or teams meet pairwise in games. We assume for simplicity that each game results in one team winning and the other losing (no ties). Given the results of all $n \choose 2$ games, the task is to produce a ranking of the teams, that is, to order them from best to worst. This sort of problem goes back at least to the 19th century, and arises when a number of subjects are asked to rank for instance the taste of different wines. It's hard to directly produce an ordering of say ten glasses of wine based on tasting them. It's much easier to repeatedly make pairwise comparisons, is wine A better or worse than wine B? But the final answers need not be consistent, and we arrive at the problem of interpreting a series of such pairwise comparisons. One possibility is the method used in sports tournaments, where teams are ranked according to the number of won games (with various tiebreak rules when the scores are equal). But we might also be interested in the ranking that minimizes the number of inconsistencies, that is, minimizes the number of games that are won by the lower ranked team. 

Say $G$ is a reductive group over a field $k$. I usually take $k = \mathbb{C}$ so assume what you want about the field except maybe that its finite. If $X$ is a scheme over $k$ then a principal $G$ bundles over $X$ is a scheme $P$ together with a right action of $G$ and an equivariant projection to $X$ (with trivial action on $X$) such that $P$ is locally trivial in the etale topology. For some groups like $GL_n,SL_n$ and solvable groups principal bundles are locally trivial even in the Zariski topology. These are called special groups and Grothendieck classified them. I'm curious if $G',G''$ are special groups and $G$ fits into an exact sequence $1 \to G' \to G \to G'' \to 1$, then is it the case that $G$ is special? There is a paper by Serre that claims this at least for $G',G''$ commutative and its supposed to be a consequence of the exact sequence $\check H^1(X,G') \to \check H^1(X,G) \to \check H^1(X,G'')$. This is \check Cech cohomology in the etale topology. You have $\check H^1(X,G') \cong \check H^1(X_{zar}, G')$ and $\check H^1(X,G'') \cong \check H^1(X_{zar}, G'')$ and a map $\check H^1(X_{zar},G') \to \check H^1(X, G)$ but it seems you are still short of being able to use e.g. the 5-lemma. This can probably be deduced from Grothendieck's thm but I'm wondering if there is a direct argument. 

You should submit only one version of the paper. Think of the referee as a typical reader, not a judge providing a certificate of correctness. If the referee needs additional information, then other readers will need it too. Regarding putting a proof in an appendix: There are exceptional cases when this is necessary, but most often it is not, and it can even be annoying to the reader (or seen as a warning sign of a bogus paper!) when important arguments are removed from their context. Reading a math paper will always be time consuming, but I don't think there is a general convention that proofs should be sketchy. As an inexperienced writer, it is sometimes hard to know when something should be left out, and when leaving it out will be regarded as a gap. Feedback from teachers and supervisors on this matter can be contradictory and confusing. If you feel you still haven't got the knack for it, bear in mind that it is much easier for a referee to ask you to remove details than to figure out when they are missing. I would not endorse any general advice to write sketchy proofs in order to keep the paper short. 

If $X \xrightarrow{f} Y$ is a morphism of schemes then the scheme theoretic image of $f$ is the smallest closed subscheme $Z \subset Y$ through which $f$ factors through. Is this notion defined for algebraic stacks (at least under reasonable assumptions)? If so, can someone provide a reference? 

I don't know much about the theory of Hilbert spaces but a research project has me working with them a little bit. In particular requiring an operator to be Hilbert-Schmidt is a recurring condition. According to wikipedia one nice thing about H-S operators is that on a separable Hilbert space $H$ the set of H-S endomorphisms forms a Hilbert space that is naturally isomorphic to $H\otimes H^*$. So I'm wondering what else is nice about H-S operators. And what else works with H-S operators that wouldn't work for another class of operators. Fredholm operators also come up a lot. It $T$ is H-S and $S$ is Fredholm what can be said about the composition?