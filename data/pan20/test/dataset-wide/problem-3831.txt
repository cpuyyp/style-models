This is essentially a comment on user2097's excellent answer. One consequence of that answer was the construction of a graph with four non-isomorphic edges whose removals result in isomorphic graphs. The graph so constructed had 96 nodes and 293 edges. Without changing the idea of their construction, various tricks allow an improvement to a graph with the same property with 24 nodes and 47 edges. The tricks used are: 

At first I had hoped that I just had the "wrong" face maps and if I changed around my face maps $X_1\to X_2$ in a clever enough way that this would become a regular (semi)-cosimplicial Abelian group. But I don't see it. Another thought I had is that I have many other $d_\infty$ maps that I just haven't seen yet because I don't know the relations that they should satisfy and so am not looking in the right place. I also noticed that $d_\infty$ satisfies the relations I'd expect from the map $[1]=\lbrace 0,1\rbrace$ to $[2]=\lbrace 0,1,2\rbrace$ which is the constant map to $1$. But this seems not to lead anywhere because of the failure of the face identities at the bottom; i.e., the maps $X_0\to X_1$ and $X_1\to X_2$ don't act like regular injections of ordered sets. 

My favorite explanatory analogy for the first question, along the line of Leonid's answer, is that a power series in one variable with no constant term, $a_1x +a_2x^2 +\cdots$ has an inverse under composition if and only if $a_1$ has an inverse in the ground ring. 

The forgetful functors commute by inspection: $$ \require{AMScd} \begin{CD} Op@>>>ns\ Op\\ @VVV @VVV\\ \mathbb{S}\text{-}mod@>>>\mathbb{N}\text{-}mod \end{CD} $$ and so the left adjoint free functors commute $$ \require{AMScd} \begin{CD} Op@<{\otimes \mathbb{K}[\mathbb{S}_n]}<<ns\ Op\\ @A{F}AA @A{F_{ns}}AA\\ \mathbb{S}\text{-}mod@<{\otimes\mathbb{K}[\mathbb{S}_n]}<<\mathbb{N}\text{-}mod \end{CD} $$ and thus the free operad $F(M)$ for $M\cong N\otimes \mathbb{K}[\mathbb{S}_n]$ is canonically isomorphic to $F_{ns}(N)\otimes \mathbb{K}[\mathbb{S}_n]$. 

Well, the argument below proves much weaker statement that you've asked for: if $n$ is subexponential in $\sqrt{m}$ (more precisely -if I'm not mistaken,- if $n<\exp(c m/\sqrt{k})$, where $c$ is a constant). But it is clearly suboptimal, so quite probably one can improve it. The idea is to use a greedy algorithm. That is, assume that you are in a situation $(n,k,m)$, find a color that minimizes the number $n'$ of connected components using this color only. Pick this color and consider the connected components as new vertices (for instance, picking a vertex in each component and forgetting the rest); then, you are in a situation $(n',k-1,m-1)$. Now, if the passage from $n$ to $n'$ reduces the number of vertices sufficiently fast, you will be done (even though the $m-1:k-1$ ratio becomes less and less favorable). Next remark is that if you pick a color at random, the mean size of a connected component of a given vertex is sufficiently large: it is at least $1+\frac{n-1}{k}$, as this is the expectation of the size of the radius one neighborhood. And, if $n$ is large, it is a lot. So the least possible $n'$ should be noticeably smaller, than~$n$. If one can get the $n'<0.99n$ in the above argument (say, assuming $m>k/10$), that would lead to a positive answer to your initial question. The argument below leads to a weaker statement. That is: average size of the connected component of a given vertex is $1+\frac{n-1}{k}$. Hence, the sum of all such sizes over all the vertices, in average, is at least $n(1+\frac{n-1}{k})$. Hence, there exists a color, for which such a sum is at least $n(1+\frac{n-1}{k})$. On the other hand, this sum equals to $\sum s_i^2$, where $s_i$ are the sizes of the connected components (each component is counted as many times, as is its size). Hence, we have $$ \sum_i s_i^2 \ge n\left(1+\frac{n-1}{k}\right). $$ Let $n'$ be the number of connected components, and denote $\delta:=n-n'+1$. For a given $n'=n-(\delta-1)$ of positive integer summands $s_i$ with $\sum s_i=n$, the sum $\sum_i s_i^2$ is maximized if all of the components but one consist of one vertex, and the last one consists of $\delta$ vertices. In this case, this sum is equal to $\delta^2+(n-\delta)\cdot 1^2$. Hence, $$ n-\delta+ \delta^2\ge n+ \frac{n(n-1)}{k}, $$ and thus $$ \delta(\delta-1)\ge \frac{n(n-1)}{k}. $$ This leads to $\delta\ge \frac{n}{\sqrt{k}}$, and hence $$ n'= n-(\delta-1) = n\left(1-\frac{1}{\sqrt{k}}+\frac{1}{n}\right). $$ Well, the $1/n$ in the right hand side is almost neglectable, and taking $m$ iterations will reduce to $1$ the number of connected components, if we start with at most $$ \sim \exp \left(\sum_{j=k-m+1}^k \frac{1}{\sqrt{j}}\right)\ge \exp \left(\frac{m}{\sqrt{k}}\right). $$ 

Maybe this can be modified to show that in the case that one also drops the assumption that $\oplus$ have a unit, that and are the only other continuous options. I'll leave that to someone else. 

$M=S^2\times \mathbb{RP}^2\times\mathbb{RP}^2$. Since $Tor(\mathbb{Z}/2,\mathbb{Z}/2)=\mathbb{Z}/2$, the KÃ¼nneth formula tells you that the homology is: 

This is likely to be difficult. One feature of $As$ that makes it possible for an explicit small minimal model is a simple generators and relations picture; that is, there is one generator $\mu$ and one relation, which is quadratic in the generators. Of course, there are infinitely many colors, but that would be no big deal if the generators and relations were "locally small" in some sense. That is, if your operad were generated by operations like this: 

This is an answer to your second question. An element of consists of the equivalence class of a pair $(\tau,x)$. Here $\tau$ is a tree with $n$ leaves and $x$ is an element of $\tau(M)$. We'll unpack this in a second. The equivalence relation comes from isomorphisms of trees. There is an easy kind of tree and a hard kind of tree in terms of isomorphisms so let's start with the easy kind of tree first. The easy kind of tree is the kind with only the identity automorphism. An easy (and common) criterion that is sufficient (though not necessary) for a tree to have only the identity automorphism is that every vertex has at least one incoming edge. For example, these will be the only trees that contribute to the free operad if the $\Sigma_*$ module $M$ has $M_0=0$. In this easy case case, we can choose any representative tree (say that we choose one $\tau_0$ where the vertices are named $v_1,\ldots, v_r$ and the edges are named $e_1\,\ldots, e_{r+n}$). Then we can represent the equivalence class by an element $$ (\tau_0, x_0) $$ where $x_0$ is an element of $$M(I_{v_1})\otimes\cdots \otimes M(I_{v_r})$$ (recall that $I_i$ is the number of incoming edges of the vertex $v_i$) and each such pair is alone in its equivalence class. On the other hand, if a tree has automorphisms, then we must further mod out by these automorphisms. We can still pick a representative $(\tau_0,x_0)$ as above, but the pair is not necessarily alone in its equivalence class. The automorphism induces an automorphism $\phi$ on the vertices $V(\tau_0)$ and for each vertex $v_i$, an isomorphism $\phi_i:I_{v_i}\to I_{\phi(v_i)}$. Then $$m_1\otimes\cdots \otimes m_r \in M(I_{v_1})\otimes\cdots \otimes M(I_{v_r}) \sim \phi_1^{-1}(m_{\phi^{-1}(v_1)})\otimes\cdots\otimes \phi_r^{-1}(m_{\phi^{-1}(v_r)}) $$ The easiest example is the $0$-tree 

Well, I would say that at least for some (degenerate) $\alpha_0, \alpha_1$ there will be more solutions. Consider $f_2$ of the form $f_2(x)=\gamma_0+\gamma_1 \cos x + \gamma_2 \cos 2x$. If your equation to never has a solution of a form other than the two above, then the convolution $f_2* \log f_2$ would never be a degree one trigonometric polynomial. Though, this convolution is surely a degree at most two trigonometric polynomial, as $f_2$ is. Hence, to construct an example that becomes of degree one, you need only to eliminate the second degree term. To do so, you need $\log f_2$ to have zero $\cos 2x$-Fourrier coefficient. And it is just one relation on $\gamma_0$, $\gamma_1$ and $\gamma_2$. For instance, once you check that this coefficient can be (for different values of $\gamma_i$'s) both positive and negative, you are done. It seems to me that this is easy to be checked: for instance, taking $\gamma_0=1$, $\gamma_1$ to be small positive and $\gamma_2$ to be small negative, one gets $$ \log(1+\gamma_1\cos x +\gamma_2 \cos 2x)= \gamma_1 \cos x - \frac{1}{4} \gamma_1^2 (1+\cos 2x) + \gamma_2 \cos 2x + o(\gamma_1^2+|\gamma_2|).$$ So one can both ensure positivity and negativity of the $\cos 2x$-coefficient: the former by taking $\gamma_1=0$, $\gamma_2$ small, the latter by taking $\gamma_2=0, \gamma_1$ small. This leads, surely, to a degenerate example. But it shows that even if for generic $\alpha$'s your conjecture holds, it should be handled by more elaborate arguments. 

For the simply connected version of your question: yes, such an estimate exists. Namely: take a radius $R=R(E)$ (closed) "coloring" disk, and let us move its center along the boundary $\partial E$. Note that while the center of the disk makes a path of length $l=|\partial E|$, the disk "colors" the area that is at most $2\pi Rl + \pi R^2$. Indeed, you count the initial area $\pi R^2$ plus estimate the increase in area per $\Delta l$ displacement of the disk as its boundary length $2\pi R$ times the displacement $\Delta l$. (In fact, this upper bound can be improved to $2 R l$, but it requires a bit more words to be pronounced. Namely, you say that there are two disjoint discs, so you can count only increase terms -- area of difference between displaced and not displaced discs, -- and you estimate such an increase term more carefully as $2R\Delta l$. See also: analogous formulae in the theory of Minkowski sums/convex polyhedra, like the one for the area or the volume of $\varepsilon$-neighborhood.) On the other hand, by definition of $R$ any point of $E$ is at distance at most $R$ from the boundary $\partial E$. Thus, all the set $E$ will be colored. Hence, $$ |E|\le 2\pi Rl + \pi R^2 $$ and as $2\pi R\le l$, the $|E|\le (2\pi + \frac{1}{2}) R l$. So you can take $c=(2\pi + \frac{1}{2})^{-1}$. In fact, the improved estimate mentioned earlier tells us that you can even take $c=1/2$: $$ |E|\le 2Rl= 2 R(E) \cdot |\partial E|. $$ 

Richard Garner, MR 2506256 Understanding the small object argument, Appl. Categ. Structures 17 (2009), no. 3, 247--285. G. M. Kelly, MR 589937 A unified treatment of transfinite constructions for free algebras, free monoids, colimits, associated sheaves, and so on, Bull. Austral. Math. Soc. 22 (1980), no. 1, 1--83. 

Consider the nondecreasing vector $v=(1,1,\ldots,1)$. It's not too hard to show that two nondecreasing nonzero vectors orthogonal to $v$ must have a positive inner product. Here is a proof. Let $a=(a_1,\ldots, a_n)$ and $b=(b_1,\ldots, b_n)$ be orthogonal to $v$. Suppose that $a_j$ is the last negative entry of $a$ and $b_k$ is the last negative entry of $b$, for $k>j$. Then \begin{equation}\sum_{i=1}^j |a_ib_i| \ge \sum_{i=1}^j |a_i b_{j+1}| \ge \sum_{i=j+1}^k |a_ib_{j+1}|\ge \sum_{i=j+1}^k |a_ib_i|\end{equation} But the sum defining the inner product is \begin{equation}\sum_{i=1}^j |a_ib_i| - \sum_{i=j+1}^k |a_ib_i| + \sum_{i=k+1}^n |a_ib_i|\end{equation} So this is nonzero as long as $a_n$ and $b_n$ are nonzero; since $a$ and $b$ are orthogonal to $v$, $a_n$ is zero if and only if $a$ is zero, and likewise for $b.$ Now, a generic nondecreasing vector is of the form $av+u$ for $u$ nondecreasing and orthogonal to $v$. Assume we have three mutually orthogonal nonzero nondecreasing vectors $v_i= a_i v +u_i$ for $i\in\{1,2,3\}$. No more than one $u_i$ can be zero; suppose $u_1$ and $u_2$ are nonzero. Then $a_1$ and $a_2$ must have opposite signs for $v_1$ and $v_2$ to be orthogonal (in particular, neither can be zero). Now $u_3$ cannot be zero because then $v_3$ would not be orthogonal to $v_1$ or $v_2$. Then by the same argument, $a_3$ must have a sign opposite to both $a_1$ and $a_2$, a contradiction. 

I would say that the eigenvalues of $-\Delta+q$ stay within $\|q\|_{\infty}$ of eigenvalues of $-\Delta$ (and, as Noam Elkies says, note the multiplicity: the main term of asymptotics will be $\lambda_n\sim n$, as $l(l+1)\sim l^2$ is an eigenvalue of $-\Delta$ of multiplicity $2l+1$.) If I'm not mistaken, you can re-formulate the eigenvalues problem for $A$ being any of the (symmetric!) operators $-\Delta$, $-\Delta+q$ in the following way: Lemma. $\lambda_n(A)\le \lambda$ if and only if there exists an $n$-dimensional subspace $V$, on which $\langle f, Af\rangle \le \lambda \langle f,f\rangle$. Proof. For the "only if" part, take the space generated by the eigenvectors corresponding to $\lambda_1,\dots,\lambda_n$. For the "if", note that in the space $W$ that is a closure of the span of eigenvectors corresponding to $\lambda_n,\lambda_{n+1},\dots$, we have $\langle f, Af\rangle \ge \lambda_n \langle f,f\rangle$, and $W$ is a codimension $n-1$ subspace. Hence, if $\lambda_n$ was greater than $\lambda$, we would have a contradiction for a nonzero vector $f\in V \cap W$: $$ \lambda \langle f,f\rangle\ge \langle f, Af\rangle \ge \lambda_n \langle f,f\rangle. $$ (This proof mimics the standard proof from linear algebra, so I'm absolutely sure all of this should be known, but I do not know any references...) Now, when you add or subtract $q$, you change $\langle f, Af\rangle$ at most by $\|q\|_{\infty} \langle f,f \rangle$, and hence shift the eigenvalues at most by $\|q\|_{\infty}$. 

This is not exactly a solution, but what seems a good way to approach the problem. 1) Consider for each player $k$ the team $I(k)$ to which he brings a maximal value $$ v(k)=\max_i f_i(k) = f_{I(k)}(k). $$ BTW: note, that most probably for most of the players $v(k)$ is quite close to 1, as it is a maximum of $b\gg 1$ independent $R[0,1]$'s; to be more precise, the expectation of $v(k)$ is $1-\frac{1}{b+1}$. 2) Take a "greedy" way of forming the teams: put each player $k$ into the team $I(k)$ where he plays the best. Then, each player equiprobably goes to any of the teams, hence the number of players in any team is equal to the sum of $b^2$ expectation-$1/b$ Bernoulli variables, and thus is roughly normal with expectation and dispersion $\sim b$. In particular, the teams formed in this way are roughly equal, differing from $b$ by something like $\sqrt{b}$. If I'm not mistaken, this means that the product for this case differs (in average, most probably) from the theoretical maximum of $b^b$ by a factor of constant. (This could be surprising, as in the theoretical upper bound 1 is used instead of all the values, but in fact the greedy method almost gets 1 everywhere, and $(1-1/b)^b$ is $1/e$ -- a constant) 3) The idea now is that if you divide the players in a strongly non-equal way, you will get a value that will be lower than the ``greedy'' one. 4) Namely: imagine, that one of the teams is much smaller than the average, that it has less than $\epsilon b$ players (where, say, $\epsilon=\frac{1}{10}$). Then, you get an upper bound for the product by $\epsilon b$ times $(b+(1-\epsilon)b\cdot \frac{1}{b-1})^{b-1}$ (it is a bit rough: we're again setting all the players to values 1). But this is a theoretical maximum of $b^b$, multiplied by a constant, which is approximately equal to $\epsilon \cdot \exp(1-\epsilon)$, and the smaller is $\epsilon$, the smaller it becomes. In particular, for sufficiently small $\epsilon$ it becomes smaller, than the constant that we are getting in the greedy algorithm. The same applies if one of the teams is too large, larger than $Ab$. The upper bound is again $b^b$ times $A\cdot \exp(1-A)$, and the factor $A\cdot \exp(1-A)$ tends to zero as $A$ tends to infinity. 5) Finally, it looks quite plausible that one can make the above arguments work for $\epsilon$ and $A$ arbitrarily close to $1$, but for that one should improve the above arguments in two points: *) First, take $S=\sum_k v(k)$ to be maximal possible sum of values, and use $(S/b^2)^b$ as a reference point instead of $b^b$. *) Second, re-equilibrate the teams: for every player, consider the team which is second-best for him, and try moving $\sim \sqrt{b}$ players from large teams to smaller ones, which are second-best for them. It looks plausible that with this improvement of the greedy algorithm you get a product that is equivalent to our new maximum-reference point $(S/b^2)^b$, while any $\epsilon<1$ or $A>1$ reduce maximum possible value by a constant factor. 

The confusion between your desired statement and the statement from the nlab is arising because of the confusion between chain complexes and cochain complexes. The answer to your first questions is "yes." I'm not sure about the second question, but I would guess the answer is "no." 

On the other hand, another thing one could thing to do is to consider $(S,\eta)$ as generating a semicosimplicial functor $S_*$ where $S_n= S^n$ and the coface maps are given by $S^i\eta S^j$. Then one could consider the colimit of the diagram made up by coface maps up to a certain point: $$ S_0\to S_1\rightrightarrows S_2\to\cdots \to S_n $$ Call this colimit $Y_n$. Inductively it looks to me like $X_i\cong Y_i$ and so $X_\omega\cong Y_\omega$. Here are my questions. 

As I said in the comments, the answer to question 1 is that the two notions are equivalent (at least in characteristic zero, which I will assume throughout). Assume $\mathfrak{g}=(V,0,[\cdot,\cdot])$ is intrinsically formal. Now let $(V,l')=(V,0,l'_2=[\cdot,\cdot],l'_3,\ldots)$ be an $L_\infty$ algebra as in the definition of rigidity. Then the homology of $(V,0)$ is $(V,0)$ and so the induced truncated Lie algebra on $H(V,l')$ is precisely $\mathfrak{g}$. By intrinsic formality, there exists an $L_\infty$ quasi-isomorphism from $\mathfrak{g}$ to $(V,l')$. Any $L_\infty$ quasi-isomorphism between two $L_\infty$ algebras with zero differential is in fact an $L_\infty$ isomorphism, so $(V,l')$ is isomorphic to $\mathfrak{g}$. Thus $\mathfrak{g}$ is rigid. On the other hand, assume $\mathfrak{g}$ is rigid and let $(W,l)$ be an $L_\infty$ algebra with $$H(W)^{\text{trunc}}:=(H(W),0,(l_2)_*)$$ isomorphic to $\mathfrak{g}$ as in the definition of intrinsic formality. The homological perturbation lemma says that there exists an $L_\infty$ algebra $$H(W)^{\text{trans}}:=(H(W),0,(l_2)_*,l_3^{\text{trans}},\ldots)$$ equipped with a quasi-isomorphism to $(W,l)$. Note that the truncation of $H(W)^{\text{trans}}$ is $H(W)^{\text{trunc}}\cong \mathfrak{g}$. Then by rigidity, $H(W)^{\text{trans}}$ is isomorphic to $\mathfrak{g}$. Composing this with the quasi-isomorphism $H(W)^{\text{trans}}\to (W,l)$ gives a quasi-isomorphism so that $\mathfrak{g}$ is intrinsically formal.