? Don't use attributes with two double-underscores (). Use a single underscore. Two gives you name mangling, which you don't want. The funciton definition line should be formatted as 

Since is an expensive copy anyway, you can simplify the chain by just passing a value and deleting more trivially: 

You know that from reading the code so you don't need to repeat it. An example of a good comment would be 

Each pass of , one more element on the end of the array is already sorted. This means we can give a paramenter of how many elements to skip. 

is also weird; why not just ? It makes sense for to be an ABC, but by no means is this a requirement. It's worth noting that 

You should remove the many trailing spaces. You can replace slicing with unpacking and the double-brackets can be removed: 

This is safe against quoting errors (what if the IP contained ?). You also didn't need the s; strings automatically concatenate. You don't need to escape s inside or inside - but it doesn't matter with since you don't need to worry about quoting. You do: 

Put this logic in whatever framework you want. Personally I'd also throw in a test with a more compex object, but it shouldn't really matter. I would definitely try testing with another container, such as a , if you want to support them. You could easily get a stable sort, so you might want to add that and add associated tests. 

Your should be ; currently you are missing the last element. Change the loops to . Your would be faster on one line; CPython won't optimize out the intermediate for you. Since you only want to split the string into two, I recommend: 

Be careful not to ramp up the energy as well; annealing works as the states move slower towards the solution. When reaching a non-solution, instead of restarting one should consider finding the most displaced fraction of points and permuting their positions with their close neighbours. This will allow near-solutions to complete more quickly. The radius of permuted points should probably increase with the number of failed attempts. 

What matters isn't that your style is the same as mine or that it sticks strictly to line length guidelines but that it makes bugs look wrong. Whether this means you write things on loads of different lines: 

will always be True because of the first filter agains . I would short-circuit the instead of ing. It seems to me that you want to return on no result, but you default to . If you just default to this would be easier. 

as our heuristic. Now when outputting results, we can ignore any branches where the heuristic brings us above (or equal to) that. (If you want all of the best options, use strict inequality. If you only need one, use non-strict inequality.) Here is some code to try. It is not particularly pretty, but it works and is pretty fast. 

I'm not sure why you think the second one is "optimized"; the former at least looks faster to me. Don't name variables - it tells you nothing about the actual job of the variable. is also a bad name'; is clearer, and is not used so just use an underscore instead. Don't pre-initialize values, in this case . Assign to it only when you need to. Don't use - always use and explicit conversions. Then you have 

I was thinking about how to approach the problem safely, and it occurred to me that the best way to avoid building a parser would be too hook into Python's module. There is a convenient class that can let us do recursive evaluation of a tree. This is somewhat fiddly so I'll just give you what I came up with. 

The canonical response is to make an mapping to remove the inner loop. This has two cases. Firstly, if you just want to update with the values in , use 

Now, instead of getting deeper into how this could be improved, I'm going to express this as a matrix transformation. Consider the matrix X. 

Don't use names; just use names unless you really need name mangling (which you should try and avoid). Your is also misleading. If you wish to do something like this, just print directly. Otherwise a looks like a number, which is a pain for debugging. Your does a lot of work we're going to try and avoid, so lets work out a better way of doing this. 

This will error since has not been defined. No error actually needs to be raised at all, so an appropriate message would instead be 

Since these get hashed a fair bit and the class should be immutable, it seems sensible to make a tuple and simplify to just . is only called from , which can be merged to create 

is operating on Numpy arrays, typing these will not give you any speed improvements. Instead, you should look to either 

Note that this works for any number of iterations; one can trivially do friends-of-friends-of-friends-of-friends-of-friends. This is not optimal for full transitive closure, but it's fine for small iteration counts. It's should also be a fair bit faster. 

a lot; you should probably encapsulate this. It makes sense to move into the resource manager. and don't really need to be global; they would be fine as arguments to : 

I suppose you don't indent the debug lines to make them easier to spot. That's a sensible idea (although not one I've seen before). However, I treat Code Review answers as a "just before checkin" thing, so I'd suggest removing these by this point. You pre-declare your variables. Don't do this; write them as close to point-of-use as reasonable. Your op seems to be rather useless - you could just use instead. So remove it. Your 

You only use for , so import that directly. Names should be either , for functions and variables, or for classes. This means 

I'm using reverse since it seems to give more outputs than the other way around, which I assume is preferred. Now we can get useful timings. The first thing to try is how fast PyPy is: $$ \begin{array}{ll} \text{runtime} & \text{time}/s \\ \hline \text{CPython} & 3.1\\ \text{PyPy} & 110 \\ \end{array} $$ Well, it seems we're done making it faster. Let's fix some other things instead. Firstly, your code is mixing IO with logic. We can fix this by ing results out to the caller. This allows us to keep IO happening as soon as we already do, but let the caller do it. In , the needed values (there are two places). In , write 

It's strange you modify and then reverse the change; just use a different variable instead. Since the change is so simple, you can just stick with: 

This is written like C code; there are lots of things you're doing that would be much nicer using the tools C++ gives you. First, though, I'm not a fan of a global , so I removed it. You're using lots of s; it's best to replace them with s for consistency. Perhaps some s would work well, too, but it doesn't seem like an improvement to the API. You should also initialize them in the loops or as late as possible. Your should be replaced with a ; not only is it far easier but it's likely faster and takes less space. You don't need to . Your 

I hadn't realized that is only used with as the funciton; maybe you should move it into to make calling more convenient. You should split your s up: 

The new function is too condensed (I realize this does not reflect much on the original code). I would change it to: 

The key principle here is KISS. Note that I'm suppressing , not , since catching and is almost always a bad idea. If you want to make a default argument, just use another wrapper: 

then, but this is unfortunately way slower in this microbenchmark. I'll leave it as a hypothetical, then. The problem mostly revolves around having a really large number of inputs, so the overhead from is largely insignificant. Other people have explained this already, though, so there's not much point me repeating it. 

over the implicit one; logically you are checking for a sentinel and that's the canonical way to express it. Using would imply that you expect a could be falsy. doesn't need to be a property; just set it during initialization. Personally, though, writing the one time you use it seems more natural. The same goes for ; you aren't buying much per unit of work. is a property but entails a nontrivial amount of work. It's rarely a good idea to hide work like that under attribute access; I suggest making it a fully-fledged method. For some reason it also feels to me that it should be a standalone function. I'm not sure why. This gives 

You need to do as a second statement, but otherwise it's equivalent. The next function is actually three: 

Since you're using and , you should just consider a . This is flat in memory but much easier to use. Before I do that, though, let's consider some nicer ways to write . Firstly, your is disingenous. You never intend to loop in it. You use it here: 

An experienced Python programmer would probably be very averse to those lines; deleting variables should be done very sparingly. But in this context it's actually good; you have global data and you're clearing the mess up after yourself. The reason experienced programmers don't do this very much is because they know to encapsulate logic like this instead. The end result looks something like 

but the difference isn't vital. One last thing with - rename it to . Put the rest of the code in a function. If you write 

You don't need backslashes for line continuation inside any pair of brackets. Remove them. Further, this formatting IMHO is quite strange anyway. The second problem is that you are both modifying the sorted array and returning it. Note how modifies but doesn't return and returns but doesn't modify. Considering how slow your sort is, a copy at the start wouldn't hurt. Your docstring is also all wrong; docstrings should mention user-facing concerns, not implementation detail. A thorough one might say 

This way you can have multiple frames per draw if draws become the expensive part. Unfortunately, the slowest part is again despite the fast path. Let's look at its disassembly. It's long and scary, so hold on tight. First is the check. 

It's not markedly different, but I would argue that without using a declarative approach to layout there isn't much more you can do. 61 SLOC isn't a lot, and most are dedicated to declaring properties about the buttons, such as strings. 

You can solve all of these points of confusion by using . Install it and put at the top of your file: 

Consider the second method, . It's worth noting that for somthing called it seems to do worse. The first thing to do is to change capitalization to its cannonical form and even up spacing a bit. Also 

is a global; this is a really bad idea as it wrecks the ability to use this extensibly (say, have two boards). Speed-wise it's very problematic because you rebuild the whole grid each time; it would be better to mutate as you go and undo when backtracking. However, it is possible to improve. I tried something like 

In , there's another minor style point which is that should be . Personally, given that only uses and once, there's no great need to shorten them so much. YMMV. 

Note that is a poor naming choice since it refers to the type and not the value. Something like would be better. These: 

Why and ? You are using haphazard recursion to generate loops. Instead, define suitable functions to guide your loops and make functions self-contained where possible. For example, instead of using , have an outer loop that calls after the game has ended to allow it to restart. This should remove the need to call from the functions (you shouldn't be doing that). Because the game seems a bit underspecified, I wasn't able to bring all behaviours across: what exactly is meant to do? It seems to do nothing. has duplicated logic in the s. Move it outside of the s. This is also duplicated in , so extract it into a function. I would move to new-style formatting ( instead of ). In , you don't need since it's just . You shouldn't give a default to ; it just hides bugs. You don't need a argument to . In fact, I would write it as 

The calls are not part of this; only the looping and the slicing. This gives a cost of $$ 1(n)^2 + 2(n-1)^2 + 3(n-2)^2 + ... + (n-1)(2)^2 + n(1)^21 $$ or $$ \sum_{k=1}^n k (n-k+1)^2 = \frac{1}{12} n (n+1) (n^2+3 n+2) $$ which is \$\mathcal{O}(n^4)\$. So caching does improve this a lot from \$\mathcal{O}(2^n n!)\$... but not nearly enough. Note that we could prove that it's valid to ignore failed calls by moving the check into the caller and seeing that the cost is the same. Using range objects like Python 3's would give costs of \$\mathcal{O}(n)\$ each, not \$\mathcal{O}(n^2)\$, since slicing would be \$\mathcal{O}(1)\$. However, the check prevents this from mattering. You can see this by moving the check into the caller. If you changed this to using an \$\mathcal{O}(1)\$ hash, this would work and reduce the cost to \$\mathcal{O}(n^3)\$ overall. Math elided for brevity. 

One way of improving this is to early-out your s and s. I would also separate some of the longer lines. For example, I would try something like (untested): 

This is evidently too much, so some thought should go into fixing this. Perhaps caching some things might be better: 

You've got lots of stuff under . This is almost always bad; using a function normally works out nicer. You use rather than , FWIW, which is not great, and the call should go outside of . You do 

although it sounds dubious that such a call could have significant time implications â€” certainly not more than a few microseconds! 

It is best to just move it there, though you should use a tuple instead because, being immutable, those can be built once and then reused. 

Rather than pushing performance further here, I would suggest rewriting to a more optimal algorithm like a Sieve of Eratosthenes. 

so you should prefer it. Then, since you're doing command-line parsing I'd move to and hoist out dynamic aquiring of arguments: 

I am not going to mention using strings as comments again, but you do need to fix this everywhere. Remember that this does not apply to docstrings, where you should follow PEP 257. Inside the now-first block, we have an function 

The difference is obviously much less, but it exists. This is probably due to improvements in memory locality. It actually turns out that just terminating the range with gets you almost to this point, so the optimization, IMHO, isn't worth it. Sadly, CPython still trails the first version on PyPy. Janne Karila gave a good suggestion in the comments for speeding up CPython. The key part is to use (or ) to apply a filter and to do the counting. The large advantage comes from the iteration and counting being done inside C routines. I went with from Python 3.1 and Janne Karila's use of to get the wanted element: 

which gives . You add that to the number of values in front () and get . This means you only have to generate 2 values from instead of in order to get the appropriate length. 

is bad. Primarily this is because you're spreading out the checks where they don't belong and it should instead be 

instead. The inner type is better labelled and the outer types are and . This gives your API more flexibility, and since dereferences to a normal -reference, this does not prevent any prior use-cases. This code 

in , which doesn't seem to work since is packing any tuples it gets into another tuple. Another thing was the use of , which would be much simpler if you could just do - another advantage of composition. You can actually manage this with , though. Your returns another ring; this seems strange - a slice of a ring is rarely itself also a ring. If you have a ring of paper and cut a section out, that section has ends! Finally, your and are the default ones for , which is entirely misleading and very bad practice. Back to the point, looking at the abstract base classes in (later moved to ), the only interfaces it makes sense to support are and , since the class doesn't have a . Adding and on top of that would give something like