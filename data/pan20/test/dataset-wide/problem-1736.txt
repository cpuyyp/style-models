The plates can be removed, cleaned up and installed into another (new) hard drive. Cylinders that are fully outside the hole area should be readable no problem. This means, majority of the content, if there is only a single small hole. The plates may be re-balanced by drilling another hole of the same diameter in the opposite side. Some means must be taken to prevent heads running over the holes, but looks possible. 

If I put the entry into /etc/hosts.deny, would it block all requests from that IP address to my machine (like iptables do), or would it only block access for some applications like SSH? 

Also check if you have configured the RemoveIpValve on Tomcat properly. For the configuration like yours, conf/server.xml should contain something like 

I want to implement NAS solution for home usage, to keep data I care about. NAS offers RAID against disk failure, but what if the NAS box itself fails? Do I need two replicating NAS devices for a trustworthy storage? The amount of data is few Tb in size and while it is not many for a hard drive in these days, I think that much might be expensive to keep just in the cloud. An idea that comes to my head is to buy two small single drive NAS boxes replicating each other. Would you recommend better solution? 

It is my understanding that network address translation (NATing) goes away with IPv6. How do we isolate network resources to those that need them from the rest of the internet? I am specifically thinking about allowing access to internal network resources like file servers or VM hosts to remote users, such as those working from home. A similar scenario also comes up in IPv4 today. At many universities, including my own, each network device gets a publicly routable IP. I'd like to run a file server, but don't really want it publicly accessible. Ideally it too would have a public IP and VPN would not be necessary. Comments? 

How can I run an rsync backup/replication script in a user other than root while preserving permissions? This is a multi-user fileserver, where each user has a *nix account for permissions. Running with the root user poses obvious security risk - especially when you are using passwordless ssh keys to do it automatically. But running in a user other than root (like a backup user with full group permissions to the data directories), has problems setting permissions because only the owner or root can change permissions. In a perfect world, the production server user would only have read-only access. Thanks! 

It is possible to get more reliability by using hard drives that come from different batches and ideally manufacturers. Otherwise they may fail too close in time. The excellent answer of @Eliodorus explains this enough. Of course, it does not matter who shuffles the drives. If your provider confirms it does that for you already, no need to care about. However it seems not reasonable to do some forensic on maybe even different provider and conclude somebody does for you if you are not told directly. Providers usually are not lazy to advertise various measures they take to increase reliability of they drives. 

Your server stack may be buggy or outdated. On my server (3.19.0-41-generic 14.04.2-Ubuntu, xinetd 2.3.15 libwrap loadavg) xinetd does forward the needed header no problem. I would propose to upgrade the server stack. You can get the xinetd version with 

Place the root administration machine into the room locked with two keys, and give only one for each of the two admins. The admins will always work together, observing each other activities. It should be the only machine containing the private key to login as root. Some activities may need no root rights, so only part of the work would require to go to that room for "pair programming" You may also video record activities in that room mostly for making more sure that nobody works alone (that much is easily visible). Also, make sure the working place is such that screen is easily visible for both people (maybe large TV screen with the big fonts). 

How do cluster file systems avoid the myriad of possible race conditions? I'm trying to get a grip on using a cluster file system in a Master-Master architecture. I'm thinking specifically about GlusterFS, so implementation details for it are welcome, but I'm hoping for a general answer. 

I'm designing a file server based around ZFS and I'm considering using USB flash drives in RAID 1 as boot devices. It seems that few people do this, and I'm wondering why. From what I see, using USB flash drives have some benefits: 

Many servers have an internal USB port and can boot from the internal and external ports. Comments about how MLC flash is limited to 10k-100k write cycles and may not be reliable enough are sure to come. I'm not too concerned about this, but perhaps I should be. File servers don't write to the OS disk very often, only for logs and such. Super Talent's flash drives are rated for 100k write cycles. Having two in RAID 1 and perhaps replacing one of them 3 years after set-up is still cheaper than alternatives and I believe would be reliable enough. And with ZFS, write errors will be detected quickly. So why is this not more common?