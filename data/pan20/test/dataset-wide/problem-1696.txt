I'm running small Ubuntu devel virtual on VMware Fusion. 4GB disk and 512MB RAM is enough for development. Network of VM is in NAT mode, so I can access it even when not on Internet. I also configured AFPd so I can edit files directly mounting share. As far as I'm doing Django only that way setup is as following... Django app running under some user account I created, that user homedir is also a root (loaded on login), I use that user to login to AFP. When new project I just clone template machine and create new user account + . Installing to VMware Ubuntu chooses kernel that holds main virtualisation abilities... thus XEN, KVM, VMware. Deploymnet should then be DevOps way... just copying VM files to cloud and starting it online (maybe conversion of disk file or its growing to production size). 

If you have speedy lines between sites you want to mirror, I can imagine something like you export iSCSI volumes from sites storages and put them mirror and add some local disks for ARC, ZIL, cache to lower read/write peaks running over iSCSI. If your storage is mainly for backups, then it would be OK. Nevertheless SUN once had such product behaving like that on ZFS. 

May be your old mirror set was a hardware one, not the ZFS. Depends on your HW. Check partitions table with if something is there. ZFS can reconstruct its pools no matter what order are disks placed in. 

Note that means command has to start in user login shell loading user environment too. In case that login shell is something like for security reasons, there should be a problem. Try to change to and potentially do fine settings in for that command. 

Use , but also add per every network you want to route through VPN. Btw note that DNS setting on other interfaces will stop work, when that interface will not have route to its DNS servers. This is what happens when drops default gateway from your (W)LAN interface and adds host route to VPN server IP through original GW. Depends on your setup, may be there is no working setup and you'll have to change DNS naming to include some subdomain for internal networks. 

First one is pure software and second one is kernel accelerated provider accesible as PKCS11 token. Exactly those two on my old T1 Niagara are doing 8.4 sign/s versus 19740.0 sign/s. That's for sure huge difference. Modern x86 CPUs can accelerate AES for example and as far as I know it is used in software kernel provider. Check yourself what's the difference. More important is to have speedy asymmetric ciphers, because they are used during establishing a connection and are more CPU hungry... web applications close connection often. Btw KSSL is in fact just in kernel SSL encrypting proxy... a fact it happens in kernel contribute to speed too. Just to compare... on another machine, ~ same age as T1 noted above, but x86 in VMware is doing for me 42.1 signs/s versus 98.6 signs/s for rsa2048. So more than doubled speed. 

In this case you can play with and in SunOS . But best to block those attempts even before reaching with Solaris . Here you can find pretty often updated list of IPs to block: OpenBL I see attempts very rarely in logs, just using this blacklist. Then you can assemble cron job script to update FW rules or optionally there's formatted file available. 

What software needs to be installed to allow proper control or management of the fans/BMC etc on a DL160 Gen 6? I have tried to find SPP/SUM but I don't have entitlement as the server is from 2010. Surely there is legacy drivers/firmware that can be installed? We have installed a second CPU but struggling to understand why the CPU is running at ~90 degrees C and yet the fan RPM does not seem to be increasing. 

This works, the emails defined in the local_recipient_map are piped to the script, however I have a permissions issue. It seems as though the script (implantproc.py) does not have write permission to a file, which it will need to run. For example, an NDR showing the permission error. 

Our Remote Desktop server (2008 R2) is also hosting the IIS ADFS site. ADFS works beautifully for internal and external clients. Except, if I try to connect with a service that uses ADFS from the Remote Desktop session host server that also hosts IIS. When I do, transparent authentication does not work, and instead I get continual username/password prompts followed eventually by the obligatory IIS error: 

(Or approximately 40 seconds). This has happened two days in a row. Now I'm even more confused. Obviously the time never updates until I manually intervene. The issue seems to be related to virtualisation and veeam. Something may be occuring when veeam is backing up the PDCe. Any suggestions? UPDATE & SUMMARY msemack's excellent list of resources below (the accepted answer) provided enough information to correctly configure the time service in the domain. This should be the first port of call for any future people looking to verify their configuration. The final "40 second jump" issue I have resolved (there are no more warnings) through adjusting the VMware time sync settings as noted in the veeam knowledge base article here: $URL$ In any case, should any future reader use ESXi, veeam or not, the resources here are an excellent source of information on the time sync topic and msemack's answer is particularly invaluable. 

I am deploying Chrome through group policy. This is working fine. Obviously Chrome has a pretty regular update cycle. I am not allowing Domain Users to install Chrome updates. Having subscribed to the release blog, and downloaded/tested a new release MSI, what is the "correct" way to deploy a Chrome MSI? For example: do I use the built in Group Policy MSI update feature? Do I overwrite the MSI file with a new one? Do I delete the policy and make a new one, linked to the newer MSI? Or do I allow Domain Users to perform Chrome updates automatically? P.S. As a humorous aside, if this question gets down-voted, closed or voted to be closed as non-constructive, I will probably kill myself. You will have blood on your hands. 

Finally worked out the problem inadvertedly whilst installing ESXi instead and receiving an error regarding the partition tables. Solution: run gPartEd and manually init an MBR on the small logical disk and a GPT on the larger disk. ESXi installed then which led me to try Windows on bare metal again, and like clock work, it booted fine after install. You would think that Microsoft would correctly set up the partition tables on a new install...or perhaps it is a weird oddity after configuring arrays with the HP SSA. 

I have an Active Directory domain with two DCs. The first DC in the forest/domain is Server 2012, the second is 2008 R2. The first DC holds the PDC Emulator role. I sporadically receive a warning from the source, event ID 50: 

Note that x86 can get some accel for SSL from CPU. You can get listing of accelerators by running . Even kernel software provider has some optimizations. Those providers are the same ones running KSSL. To measure the difference run following for example: 

Try to import that certificate to some NSS store. For example to Firefox, which is using NSS. It's other implementation of SSL (in fact the 1st one) and you can see attributes of certificate... of course if you succeed with import. Otherwise you got some wrong certificate. 

I think it is more probably a DNS issue than GSSAPI. likes prompt DNS responses to work promptly during connection phase... cause of logging and access checks. 

Zabbix, when compiled with CURL support, can directly monitor web services including complex more steps scenarios. You can setup triggers on HTTP return code, returned data, response time... Documentation here. 

option - when you want to stay with FreeBSD, check FreeNAS to automate complexity you are afraid of. option - NexentaStor, it is Solaris based storage appliance SW with great management web gui. Up to 18TB setup is for free. Again there you can easily manage complex vs. a lot of datasets configuration. 

Configure status plugin and install collectd to collect system performance data. It's a very lightweight daemon in means of system resources it needs. There's plugin for nginx monitoring: Plugin:nginx and of course can monitor whole other system performance data. As far as is just collector of performance data (stores it in RRD DBs), a tool for displaying data is required. I'm pretty comfortable with CGP... git version is OK. is a PHP app thus it will eat you CPU just only when you will look at graphs. Example graph: Nginx_connections_and_requests.png Btw Amazon EC was always significantly slower than others and most notably for storage. That could be root of higher load. 

The most likely you forgot to enable forwarding. Add to , then or restart. Also try to add following to OpenVPN config: 

Zone virtual interface has some features limited... some states can't be setup, packet filter doesn't work in zone too. If I remember right, zone interface can't send ethernet broadcasts, so then no DHCP. Btw why you doing that bloat about setting up zone interface? What about this? 

I got many DMA errors on drives, when air condition issue in datacenter and ZFS was able to fix that mess. And it was just simple mirror. I do remember promo video issued by SUN when they introduced ZFS... they made RAIDZ on USB flash drives deployed to 8 port USB hub and then randomly changed position in hub for few of them while doing IO on that pool observing no outage. 

So you have to calculate values for those param to mimic behaviour you get by setting 4 params to Solaris net stack. Btw check in Linux. 

Is there any way to get network configuration of iLOM in Solaris SPARC? I want to get the IP address of iLOM console at least. It's pretty easy on x86 by , but for SPARC I can't find something that do the same. I found some mentions about and , but those are not available for systems with iLOM. 

Note that adding interface to bridge, sets promisc flag appropriately. Bridge interface need not to be in promisc mode. I got the same setup running, but on OpenSUSE, TAP interfaces are created during startup and OpenVPN just opens them - no start/stop script in OpenVPN.