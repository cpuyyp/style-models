Whether you are flooding your network depends entirely on the frequency and size of the broadcasts, the size of the subnet you are broadcasting to, your network topology, and the capabilities of your equipment. Without knowing that no one can answer your question for sure. However, DHCP is broadcast traffic, and in a large network can be quite chatty. Many networks won't take any special action to manage this DHCP traffic - the impact is not a concern. Estimate whether your broadcast will amount to significantly more than existing DHCP broadcast traffic on your network - if so, then maybe you need to worry and implement a different solution to whatever problem you are having. If not, then most likely you can move on to the next challenge. I'm intrigued as to what specifically you are trying to setup failover for. As other respondents have suggested, there are a bunch of options out there for redundancy you might use where you won't have to worry about this, and can tap into other people's experience. 

I have managed to fix this issue when running on Apache/Linux by creating a group (e.g. webserver) and adding the user apache runs as to that group. You can then change group for all files under your wordpress site as follows: 

SPF controls which servers can send mail on behalf of a particular domain name. The SPF record is a TXT type DNS record, and should be set up for the domain name you are sending email for, NOT the domain name of your mail server (unless they are the same). The Sender Policy Framework site is very helpful for reference, and includes an SPF calculator that will help you write your SPF entry, and links to an SPF record tester that will check any SPF entries for any domain. 

A local area network may be split into subnets and/or VLANs divided by routers and even firewalls. If the workstation that can telnet to the SQL server is in the same subnet/VLAN as the SQL server, and the one that doesn't work is in a different network location, then it is possible that it is a routing device that is preventing your traffic. The SQL server may also be preventing access based on network properties of the device trying to access it. There should be someone you can ask, but if you are the system administrator and don't know what is going on, you should be able to make some educated guesses after looking at the network settings (IP address, subnet, gateway) of the machines involved. 

It might be possible, but it will be much easier and more supportable if you generate a CSR from IIS on the Exchange Server and then use that to create a new certificate. Most Certificate Vendors will allow you to revoke a key and replace it with a new one that has the same expiry date, without incurring extra charges. Unless you have a very good reason to do otherwise, I recommend starting over. 

Unfortunately, this is our only site with an 800 series router connecting to the internet, so I am not very familiar with it, and I won't be able to test the configuration out properly until I get there. 

It would entirely depend on how confident you are about your PHP install. If you think it is rock solid, even if an attacker knows everything about your PHP install, then you could leave it in place. But really, why would you leave this in place on a production system anyway? There may be exploits you are not aware of in your version of PHP - people may now or in future scan for your version of PHP, or particular options you have enabled, because they know how to carry out these exploits. So by keeping this up publically, you added yourself to their hitlist. If you want to keep it up, you can put it in a password protected directory, or just switch it on when you need it. Given the small cost of these options, I wouldn't take the risk of keeping it public. 

Have you tested whether the account can send mail? There are a few ways of doing this, but the easiest is to telnet to port 25 (smtp) on your mailserver (try from the local console): 

If you had Sharepoint setup on your Windows Server 2003 server (which is available for free), you could create a document library, with content types for Quotes and Images. Both content types would have a column defined for the Client Name - you could make this a select list, and give a specific person the responsibility of updating this list. Client Name is set as required. Files are then saved into this document library, and must be assigned a content type, and then the Client Name selected. You can then create a view of the document library for each Client, and one for All Images and one for All Quotes. 

The latest release of the ASA software (8.4) appears to integrate with Active Directory and allow rules based on users, so if you use Active Directory you might be able to do what you want, although I suspect it isn't all that easy. Check out the release notes for ASA 8.4 for more info. 

If you are trying to keep your management traffic separate from other traffic, you will not achieve this simply by having your management leaving a different port on your server. You need to keep the traffic separate after it leaves the server too - which you will not achieve by having it travel on the same subnet. So to separate your traffic you really need to split your network up into multiple subnets, using separate switching, or VLANs, and use routing to route traffic between the different subnets. Then on your server you have a separate management interface that is only connected to the management subnet. Ideally you do your management tasks from hosts connected only to this subnet too. That will enable you to really get what you want, and will be simpler to configure and understand - although not necessarily cheaper to setup. I'm assuming you have a clear business case for separating your management traffic. If all you want to do is limit management tasks on your server to specific hosts on your network you would achieve this more simply by setting up iptables to only allow management type traffic (e.g. identified by port such as ssh) from those specific hosts IP addresses. 

You might be able to fudge it by writing a script in your CGI directory which sets environment variables, and then starts PHP, instead of invoking PHP directly. This is detailed at $URL$ and provides the following pointer for more info: 

Its a bit of a shopping question, but I'll answer anyway since its a useful sysadmin tool: Decaf Monitor does exactly what you are asking. There are plenty of hosted services which do this, and if monitoring a single server its often free. I've found Montastic good enough for casual monitoring. For one server where you aren't willing to invest much money, you are right about the irrationality of being averse to this kind of solution. Really though, if you are doing this in any sort of professional way (to be on topic on this site) then why would you host a single server yourself when you can rent rackspace or a VPS for around USD300 a year with massive redundancy and gigabit connection speeds? If you really want to host, and again assuming that this is a professional question, then any ISP you should consider will offer an enforceable service level agreement. If they offer this you can bet they are very unlikely to fail to meet it. 

The checks don't report the percentage of space remaining, but the percentage of space used. A close look at the screen shot above shows what is returned by the checks. Most Nagios checks return critical or warning results when something goes over a figure rather than under. It is a bit confusing. So you need to change your critical and warning levels to 80 and 95 or 90. E.g. 

You could use a CNAME to point abc.com (or a sub-domain, wildcard or @ record of abc.com) to the host abc.myapp.com. Or you could set up an A record for abc.com (or a sub-domain, wildcard or @ record of abc.com) to the IP address of the host abc.myapp.com. Of course you have to make sure that the host abc.myapp.com will handle requests made to abc.com once it start receiving them. 

10.6.89.200 is the address I configured for the ASA. It has the subnet mask 255.255.255.0. The ip address 10.10.0.0 corresponds to one of our subnets, but it certainly wouldn't have a subnet mask of 93.137.70.9. That looks more like a public IP address (and resolves to an ADSL connection somewhere). I am sure if we had such a subnet configured, that it would indeed overlap with 10.6.89.200. There is no reference to 93.137.70.9 in the config of this ASA or our head office ASA. Can anyone shed light on what is going on here? The sudden appearance of a strange subnet mask is a bit alarming. 

Microsoft provide their own Key Management Server for automatic product activation of Windows. Is this what you are asking about? 

Probably you should ask your Cisco vendor this - then you have someone properly accountable should it not turn out the way you hope. 

The best/only way of minimising downtime would be to maintain both IP addresses for 48 hours, preferably on the same server, if your supplier will allow this. 

netstat has options that just return numbers without translating them e.g. will return IP address, port, user as numbers; will translate everything but the IP address. My reading of the snoop man page suggests that it does capture the IP address, and you need to run a capture file through it with the -N flag to get hostname translation. This suggests that you may be using another tool reliant on snoop which is requesting the results use lookups to get hostnames. Perhaps your question is a bit leading in naming those two tools. Can you give a bit more information on what you are trying to achieve here? Maybe you need to string a bunch of commands together to get exactly what you want. I think most unix network tools have a flag to toggle lookups. 

You need to consider whether the spammer has sent the email from your address to a billion other addresses, or whether the spamming engine they used to send the email used the recipients own email address in an attempt to foil spam filters. If the former, you may have a big problem with reputation (unless you actually are a Viagra salesperson). But I think the latter is more likely, and the solution to that is to look at your own spam filtering solution. How can you tell which has happened? Are you (or your postmaster) also getting bounce messages containing the spam as an attachment or fragment in the body? If so, then your email address has definitely been used to send the message to many recipients. If you aren't getting bounces, it doesn't guarantee your address wasn't used, but it suggests it either wasn't, or the message didn't go to that many people. 

If you are sending messages out to multiple thousands of users on a regular basis a cron job technically should be able to do it, but is it right for you and your users? A mailing list manager app (e.g. MailMan) might be more appropriate. It may be configured to send the messages in a way that is less likely to fall foul of spam filters, will help you manage who gets sent the messages, and should allow recipients to opt out. You can still set up a cron job to trigger the sending of the message on a scheduled basis - I believe that is a more sustainable way of sending bulk messages. 

The only requirement for hostnames is that they should be unique on the network. The meaning doesn't have to only be to do with the servers function. Location can be very useful if you have to deal with physical devices. Knowing if a device is virtual or physical can also be useful. Being able to tell the difference between a network device, a linux server or a windows box can be very handy when it comes to figuring out what tool to use to login. The way we handle it is to try and put this information into the device name as follows: L or T - Live or Test P or V - Physical or Virtual S or N - Server or Network (we don't have any Linux servers) a sequential number to ensure uniqueness An ISO 3166-1 three letter country code indicating where the device is located. We then use CNAMES in DNS to map various service names through to the hostname. I have mixed feelings about this. It certainly saves time in having to look up where a certain device is located. On the other hand it is much harder to remember what a given server does when presented with its hostname, when compared to our previous system which used gemstones. The gemstones didn't imply any meaning at all, but they were easy to remember because each person could create their own connections. I guess the only advice would be to settle on one schema as the greatest confusion arose when we transitioned from one system to the other. 

URL Filtering on the ASA inspects http requests and checks them against a filtering server which could be internal or external. It is possible to set up cacheing of the response to reduce the number of lookups. WCCP (Web Cache Communication Protocol) can be configured on the ASA to force http requests to go via a cacheing server, and many web filtering servers are cache servers - so presumably they could serve up a forbidden page instead of banned sites.