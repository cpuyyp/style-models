The use of the "winning" condition is to ensure that the overall construction has the properties we want. For example, in the game in the original question, Player 1 chooses "left" or "right" at each stage. Thus Player I always has a possible move. But Player II is forced to lose if the play arrives at a neighborhood that contains only a single point. So the actual question is whether Player II can play in a way that avoids ever being backed into a corner like that. A winning strategy for Player II in that game actually encodes a complicated dependent-choice construction in which none of the neighborhoods played ever contains just one point. Such a construction is not possible in every Polish space. But we know that the construction is possible if and only if player II has a winning strategy in that game. So the game-theoretic language gives us a way to characterize topological properties of the space. 

The Stanford Encyclopedia of Philosophy has several articles on theories of truth, which may be helpful for getting acquainted with what is known in the area. Their top-level article is $URL$ There are several more specialized articles in the table of contents. 

The key idea Feferman is exploiting is that there can be two different enumerations of the axioms of a theory, so that the theory does not prove that the two enumerations give the same theory. Here is an example. Let $A$ be a set of the axioms defined by some formula $\phi(n)$ (that is, $\phi(x)$ holds for exactly those $x$ that are in $A$). Define a new formula $\psi(n)$ like so: $\psi(n) \equiv \phi(n) \land \text{Con}( \langle x \leq n : \phi(x)\rangle)$ Where Con(σ) is a formula which says that no contradiction is provable from the axioms listed in the sequence σ. In the case where $A$ is the set of axioms for a suitable consistent theory $T$ that satisfies the second incompleteness theorem, the following hold: (1) In the standard model, we have $\phi(n) \Leftrightarrow \psi(n)$ for all $n$, because $T$ really is consistent. (2) T does not prove that $\phi(n) \Leftrightarrow \psi(n)$ for all $n$, because this equivalence implies that T is consistent. (3) If we use $\psi$ to define a formula Conψ(T), then T will prove (under the assumption that the empty theory is consistent, if this is not provable in T) that the theory defined by ψ is consistent. However, T will not prove Conφ(T), which is the usual consistency sentence for T. This kind of example is presented in a more precise way in Feferman's 1960 paper that you mentioned, along with precise hypotheses on the theory and sharper results. My opinion is that we cannot regard a proof of Conψ(T) as a proof of the consistency of T, because although φ and ψ are extensionally identical, they do not intensionally represent the same theory. Feferman expresses a similar idea on his p. 69. Of course, this is a matter of philosophy or interpretation rather than a formal mathematical question. 

Addendum. It's impossible in general to construct a formula $J$ such that $J$ is literally the same formula as $F([J])$. Any typical Gödel numbering has the property that $n < [F(\underline n)]$ for every formula $F(x)$ and number $n$. But if $J = F([\underline J])$ then $[J] = [F(\underline {[J]})]$. So, if our proof method is going to work with an arbitrary Gödel numbering, is has to be more indirect. The proof gives a formula $H$ so that $H([H])$ is provably equivalent to $F([H([H])])$, but not literally the same formula. This may help explain why proof proceeds the way it does. 

I have a few comments that I hope are useful even if they don't clarify things completely. As Michael Blackmon says, different people have different ways of resolving things to their own satisfaction. In the end, attempts to resolve things by reasoning about $V$ in a natural-language set-based metatheory are always going to be complicated because of the set-theoretic paradoxes. If these didn't exist, we could define $V$ in the naive way and not worry about it. But the paradoxes tell us that the idea of "the collection of all pure well-founded sets" is not as simple as we might have hoped. 1) "How can a variable in a first-order language run over the elements of a collection that is not a set?" This question seems to relate to the fact that most set theory books do not work with a semantic metatheory in the way that model theory books do. The counter-question is: from what perspective are we handling an interpretation of the language? From the viewpoint of the object theory, quantifiers are no problem. By analogy, in Peano arithmetic we can quantify over all natural numbers even though we have no sets at all. The way that most set theory books treat things, you want to pretend you are working in a metatheory like PRA that performs only syntactic (uninterpreted) manipulations of formulas. From this metatheoretic point of view, the variables of a ZFC formula don't range over anything at all, because the metatheory does not attempt to interpret them. The advantage of this approach are that it side-steps many philosophical problems, and it gives extra oomph to relative consistency results. The disadvantage is that it is divorced from the semantic way that set theorists actually think about models of ZFC. It would be perfectly possible to work instead with an actual semantic metatheory that can handle models of ZFC as objects. In that situation, though, it wouldn't be the case that interpreted quantifiers would range over something that isn't a set, because now the interpretations are all sets; the variables under a certain interpretation would range over the object-sets of that interpretation, not over meta-sets. There is no reason, strictly speaking, that this metatheory would even have to be a set theory. For example, you could use something based on the multiverse axioms of Gitman and Hamkins, which is vaguely analogous to a category-theoretic axiomatization of the category of models of ZFC. In that case, it might not even be possible to directly quantify over meta-sets in the metatheory. 2) It isn't necessary to view "V" as a meta-theoretic definition. Instead, you can simply think of it as an object-theory definition, which stratifies the universe of discourse of a particular model into the levels of the cumulative hierarchy. Each interpretation has its own idea what $V$ denotes. In other words, there's no harm done if you just pretend you have fixed a particular model of ZFC and are working inside it. This is essentially what most set theory books do, even if they don't come out and say it. This means you can ignore any other models that might or might not exist; you've committed to just one of them. 3) The idea that the $V$ from any one model is always an initial segment of $V$ in another model was proposed by Zermelo (1930) "On boundary numbers and domains of sets", translation in From Kant to Hilbert v. 2. This proposal has echoes of the notion of "absolutely infinite" from Cantor. This idea of extending $V$ reappears as one of the multiverse axioms. 

That book does prove the unique readability (parsing) algorithm for propositional and first-order formulas. 

A decidable theory can certainly have noncomputable models. For example, consider a theory with an infinite set of 0-ary relation symbols $A_1, A_2, \ldots$; no other relation, function, or constant symbols; and no axioms. This theory is decidable - it is basically just propositional logic - and its countable models are in effective correspondence with the subsets of $\mathbb{N}$ in the obvious way. There is not an algorithm, in general, to tell whether a subset of $\mathbb{N}$ is computable. The class of computable subsets of $\mathbb{N}$ is $\Sigma^0_3$, strictly. 

Here we do not deduce $\phi(c)$ from $(\exists x) \phi(x)$, rather we assume $\phi(c)$ as a temporary hypothesis, for an appropriate $c$, knowing that we can later weaken that hypothesis to $(\exists x)\phi(x)$. But $\phi(c)$ does not appear on the right side of the turnstile in the metatheorem: it is never a conclusion, only a hypothesis. Also, Enderton does define $\vDash$ via your "simple definition": $\phi \vDash \psi$ means that for every structure $M$ and variable assignment $a$, if $M$ satisfies $\phi$ with $a$ then $M$ satisfies $\psi$ with $a$. In particular, he points out the example that $Q(x) \not\vDash (\forall z) Q(z)$, where $Q$ is a unary relation symbol, and in this sense free variables are indeed not "implicitly universally quantified" in his definition. He is still able to prove that $\Gamma \vdash \phi$ if and only if $\Gamma \vDash \phi$, with no restrictions on free variables, by being careful with the logical axioms he assumes in his Hilbert-style system. He does get universal generalization as a metatheorem: if $\Gamma \vdash \phi(x)$ and $\Gamma$ does not mention $x$ then $\Gamma \vdash (\forall x)\phi(x)$. This is quite different than the definition of $\vDash$ mentioned by Emil Jeřábek, in which $Q(x) \vDash (\forall z) Q(z)$. Let's call that "implicitly universally quantified". I have found in several cases that authors who are concerned with universal algebra or equational theories seem to prefer to use the definition in which free variables are implicitly universally quantified, while those who are concerned with model theory may not even define satisfaction or logical implication for formulas with free variables (instead they define what it means for a tuple of elements to satisfy a formula in a given structure, which is slightly different). All the definitions agree if we only consider sentences, of course. 

In computability theory, it is often necessary to prove some particular function is a "computable function". Until the 1960s, this was most commonly done by actually demonstrating a formal algorithm for the function in a kind of pseudocode, or giving a set of recursion equations. Needless to say this style of presentation was heavily symbolic and conveyed little intuition about why the function was defined the way it was. The more modern style of presentation relies instead on having a good sense of the closure properties of computable functions, and identifying a large class of basic computable functions (the "primitive recursive functions"). So one can simply explain how to obtain the function at hand from primitive recursive functions using operations that preserve computability. This style of proof allows for much more detailed exposition of the intuition behind the definition of a computable function. Everyone in the field understands how, in principle, to take this kind of proof and obtain a formal algorithm, if it is ever necessary. 

The number of meager sets needed to cover the real line is a "cardinal invariant of the continuum". It is one of the invariants in Cichoń's diagram. In particular, it is Cov(K) in Cichoń's diagram on Wikipedia. Looking at nowhere-dense sets instead of meager sets would not change this invariant, because of basic cardinal arithmetic. I am not certain, off the top of my head, if the invariants are the same for every uncountable complete separable metric space. 

There is a large family of systems that go by names such as $\text{E-}\widehat{\text{PRA}}^\omega$. These are all somewhat related to the "System T" introduced by Gödel as part of this Dialectica interpretation. These systems are function-based, rather than set-based, and they are typically axiomatized in all finite types, although it would be easy enough to limit the collection of types. But they have a "feel" very much like PRA, in that the rules for creating functions of higher types by recursion are generalizations of the primitive recursion scheme in PRA. Comprehension is usually replaced, in these function-based settings, by fragments of the axiom of choice. One aspect of this area is that, unlike reverse mathematics where there are five big systems that are each robust against minor changes, in the context of proof theory there are many different systems (e.g. $\text{PA}^\omega$, $\text{E-PA}^{\omega}$, $\text{E-}\widehat{\text{PA}}^{\omega}$, $\text{E-}\widehat{\text{PA}}^{\omega} \mathord{\upharpoonright}$ are different systems) and the fine details make a difference in the strengths. Moreover, different authors may use different notation for the same system. The best references I know of for these systems are the books Applied Proof Theory by Kohlenbach and Metamathematical Investigation by Troelstra. Kohlenbach's book, in particular, has one of the most clear developments I have seen. There are a few papers online that have some information, such as 

It may help to realize that $\mathsf{RCA}_0$ does prove $$ (\forall X)(\forall m)(\exists \sigma)[\sigma = X[m]]. $$ This is provable directly by $\Sigma^0_1$ induction. So if $X$ is any set in a model of $\mathsf{RCA}_0$, every initial segment of $X$ is coded by a number in the model. Perhaps (this is just speculation) the question is trying to apply the universal quantifier $(\forall X)$ to a set $X$ that is not actually going to appear in the model, because the existence of that set would force $\Sigma^0_1$ induction to fail? 

There's no such algorithm under at least one rigorous specification of the question. Consider a position in which there is a black king at (0,0) and no other black pieces; white rooks at $(1,5)$ and $(-1,5)$, and possibly a white queen at a position of the form (0,$n$) for some large $n$. Picture a king backed into a long tunnel. Then white can checkmate black (and does, from the start) if and only if the queen actually exists somewhere along the tunnel. If there are only two rooks, I believe that the king can stave off checkmate by moving off towards infinity indefinitely (see my explanation in the comments below). Using positions like that, given any r.e. set $K$ and any number $m$, I can make a chess position such that white can checkmate black if and only if $m \in K$: I put the queen at $(0,n+5)$ if and only if $m$ is enumerated in $K$ after exactly $n$ steps. So I can decide membership in $K$, relative to an oracle for your problem. Actually I only need an oracle that works for indices of computable positions. This shows that any solution to your problem is of degree at least $0'$. Note: I have taken a "position" to be a function from locations on the board to pieces. You could try to work around this solution by specifying something else as a "position". For example, you could make a position a function from a list of pieces to locations on the board, and that might lead to a different solution. However you need to require the list to explicitly say how many pieces there are from the beginning, or a variation of this solution will still apply. 

Now we are getting into the territory of a witness property for ZFC. The language of formulas consists of all second-order formulas with one free set variable; the term language consists of terms of the form $\{n : \psi(n)\}$ where $\psi(n)$ is a formula of second order arithmetic. There is one more subtlety. What about: $$ \phi(X) \equiv (\{0\} = X \land V = L ) \lor (\{1\} = X \land \lnot (V = L) ) $$ Note that $V = L$ here is an abbreviation for ``every real is constructible" which can be expressed as a formula of second-order arithmetic. In this case, we can find $\psi$; one possibility is: $$ \psi(n) \equiv (0 = n \land V = L ) \lor (1 = n \land \lnot (V = L )) $$ So we cannot hope for the interpretation of $\psi$ to be absolute, nor can we hope for some sort of extensionality with $\{n : \psi(n)\}$, as the wording of the question might suggest. The set defined by $\psi$ may (necessarily) change from one model to another even though $\psi$ itself stays the same. Thus our proof in ZFC has to see $\psi$ itself, not just a code for $\{ n : \psi(n)\}$. But we will show that the overall question has a negative answer anyway. Negative answer Using a construction similar to the answer by Emil Jeřábek, let $\phi(A)$ say: "If there is a nonconstructible real then $A$ is a nonconstructible real". Clearly $\text{ZFC}\vdash (\exists A)\phi(A)$. But there can be no $\psi$ such that $\text{ZFC} \vdash \phi(\{n :\psi(n)\})$, for the same reason as the negative answer in that other answer. If we look at the particular model of ZFC in which $V$ is a Cohen forcing extension of $L$, then no $\psi$ can define a nonconstructible real in that model. There is some restriction in the counterexample $\phi$ we could use here. Because of Shoenfield's absoluteness theorem, ZFC does have witness property in question for formulas that are sufficiently low in the analytical hierarchy. For such formulas, ZFC proves that if $(\exists A)\phi(A)$ then $(\exists X \in L)\phi(A)$ and then $\psi$ can be a formula which defines the least set, under the $\Delta^1_2$ well ordering of $L$, which satisfies $\phi$. 

So $H([H])$ asserts $F([H([H])])$. (For informal clarity, I have intensionally not used underlines here.) 

In Reverse Mathematics, we can study what happens if we use weak systems of second-arithmetic as metatheories. For example, we can study the strength of the completeness theorem and prove results such as "Gödel’s completeness theorem is equivalent to $\mathsf{WKL}_0$ over $\mathsf{RCA}_0$." That can be seen as a meta-meta-theorem: we are investigating which axioms are required in the metatheory for the completeness theorem to hold. This is not as trivial as it may sound; some results are genuinely unexpected. For example, one interesting fact is that every countable $\omega$-model $M$ of $\mathsf{WKL}_0$ contains a real $C$ that codes a countable $\omega$-model of $\mathsf{WKL}_0$. Due to other weaknesses of $\mathsf{WKL}_0$, this does not cause $\mathsf{WKL}_0$ to be inconsistent! We identify the coded $\omega$-model $C$ not within $M$, but at a level one step above $M$; the model $M$ will not, in general, recognize that $C$ satisfies $\mathsf{WKL}_0$. So we are viewing $\mathsf{WKL}_0$ as our metatheory and our object theory, but not as our meta-meta-theory - we cannot prove the desired result in $\mathsf{WKL}_0$ because of incompleteness phenomena.