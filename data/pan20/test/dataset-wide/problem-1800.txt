When adding a new drive, it took over /dev/sda1. Now my old drive is /dev/sda2 and it messes with the current fstab setup of the server. I know I can get away with using UUID or labels (what I just did), but I would still prefer having the primary drive take /dev/sda1... So, how do I force a disk to take a particular device number? 

Also, it should be noted that if an account is locked due to too many authentication attemps, you won't see that in /etc/shadow. You can find out the failed logins count of an account with 

Version Control Gold Server Directory/Authentication Servers Network File Servers Configuration/Application management Monitoring ... 

Most facilities I've seen just put the switches in the rear, and assume that they will find enough cool air to operate. Many switches are designed to operate in extended temps (they are often deployed in unconditioned wiring closets.) You may want to check with your vendor: Third party Vendors are addressing the switch issue for contained aisles. This product features plenums that provide cool air to the sides, and let hot air exit from the back of certain Cisco switches whether they are front or back mounted: $URL$ 

If the DNS server and the hosts are on the same subnet (192.168.1.0/24) it is extremely unlikely that the packets traverse the machine that you are setting IPtables rules on. Devices on the same subnet normally send packets directly without the use of a router. You will need to either set the IPtables output rule on all devices, or you will need to restructure the network by placing either the clients or the DNS server) on separate subnets with the iptables machine in between. Once you get the packets crossing the iptables machine this rule will work: 

I'm looking to transfer data across 2 lv of an HP-UX server. I have a couple of those transfers to do, some of which are mostly binary (Oracle tablespace...) and some others are more text files (logs...). Used data size of the volumes is between 100Gb and 1Tb. Also, I will be changing the block size from 1K to 8K on some of these partitions... Things I'm looking for: 

Of course, this is some really basic usage. Read the manual or online how-tos to get more advanced usage. Here's a little how-to about reliable forwarding with rsyslog. To tell your servers to receive logs: 

We have a spare Integrity blade (2x Tukwila quad-core + 16Gb RAM) laying around which I would like to use has a Virtual Host for a couple of Linux VMs. I am having some concerns finding the best solutions for our situation (if a solution is possible at all?). Here's what I'm dealing with: 

Check the logs for hints. Do a "netstat -lvtn" on the mail server as root, see if the postfix process is attached to port 25. From the local server: "telnet localhost 25" Verify that you get a 250 reply after a few seconds. From a remote server elsewhere on the Internet and/or one on the same network: "telnet myserver.com 25" look for identical results If either step fails something is blocking the port, or postfix is failing. 

If you are building quite a few of them you might find designing your own case using something like $URL$ might be the way to go. I believe this is the route BackBlaze took: $URL$ Find a consumer or low end server motherboard with your needs and wrap a case around it. If your cards are short enough you might be able to get them into 2U. (I don't think I've seen right angle adapters for PCI-e). You might also talk to your vendor, if you are a good customer and you need a few of these thing you might be able to get a custom option setup, especially if the vendor decides other customers will want something similar. 

If you really want to use , you need to first select a window with , but be aware this configuration does not configure logging for all windows... 

Right now, I've thought about dd, cp and rsync, but I'm not sure on the best one to use and the best way to use them... 

Use Process accounting Write a shell wrapper based on script or similar and make it the default shell Or use snoopy which uses LD_PRELOAD to wrap around exec system calls and logs it to syslog 

Vim has vimdiff mode which is quite good. It obviously works in console mode too. It give you color highlighting of differences and the possibility to edit the diffed files efficiently. Vim is also installable or even installed on most *nix system these days... It is better if you already know Vim though... 

I made it work with Kickstart. If you create a kickstart config file you can exclude base from the packages definition and get a really minimal install. I think it was so minimal it didn't even have yum and a few others, and I had to add those packages back in. 

How about creating a DNS entry for "expenses.mycompany.com" that sends to a webserver with a redirect rule of expenses.mycompany.com -> mycompany.com/expenses? As long as clients have a DNS suffix of "mycompany.com" set they will convert "expenses" into expenses.mycompany.com, and hit that webserver. It means a few extra DNS entries, and some virtual hosts on the webserver that do nothing but redirect to the "real" URLs? 

Infrastructures.org has a good checklist of best practices and general guidelines. The information looks a little bit outdated, but most of the things they suggest are still to be considered when setting up a large data center environment. Some of the topics covered: 

So, to sum up my question, how would you guys go about virtualising x86_64 guests on an Itanium server? 

What I generally do is seperate static content and process it in another location directive. Something like: 

Elinks which originates from links. It has support for Javascript, tabs, frames, tables... I also like w3m, but I don't think it supports Javascript. 

I personally prefer using process accounting for this kind of activity monitoring. It is also the one that is the most similar to what you are looking for (commands summary, login summary...). 

Harddrive errors tend to be caught by the kernel. Does your server have ECC RAM (it should)... without it memory errors can be missed. Same with any cache RAM on RAID adapters and the like. Pull the DIMMs, clean the contacts and try again, or try running Memtest. Checking for SMART errors on the drives can be helpful. Drives can fail without SMART errors, but usually marginal drives will have them. "smartctl -a /dev/sd[x]" or smartctl --test=long /dev/sd[x] should give some more information. 

If you just want reliable file sharing for a few machines with limited admin support I would consider one of the inexpensive network NAS devices from a major vendor. The WD Sharespace devices $URL$ from Western Digital have worked quite well for me. 

I have a mounted NTFS partition under Windows (2003) and Linux (RHEL 5.7) at the same time. The LUN resides on SAN and is presented to both servers at the same time. At first, the setup looks ok as I initially can see files from both Windows and Linux. Writes are only initiated from Windows and I mounted the partition under Linux with read only (ro) and no access time (noatime) options. But when I add files from Windows, I can't see them under Linux. Is there anything I'm missing? Is it even possible at all? I would like to achieve this in order to avoid copying from the network for a data migration of > 1Tb. Do you see any other way to do it?