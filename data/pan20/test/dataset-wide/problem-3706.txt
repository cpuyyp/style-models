I'm looking for a method to efficiently compute a numerical approximation of $$F^n_D(x_1,\ldots,x_n) = \sum_{m=0}^{\infty} \sum_{i_1 +\ldots+i_n=m}\frac{(a)_{m}(b_1)_{i_1}\ldots (b_n)_{i_n}}{(c)_{m}i_1!\ldots i_n!}x_1^{i_1}\ldots x_n^{i_n}$$ I'm restricted to the cases where $$\left\{\begin{array}{c} (x_1,\ldots,x_n) \in (-1,1)^{n}\\\\ (b_1,\ldots,b_n) \in \mathbb{R}^{+}\\\\ c=\sum_{i=0}^n b_i \\\\ a=\sum_{i=0}^{p<n} b_i \end{array}\right. $$ which may help speed up the computation. Also, typically $n \sim 6$. Since $c > a > 0$, I'm aware of the integral representation $$F^n_D(x_1,\ldots,x_n)=\frac{\Gamma(c)}{\Gamma(a)\Gamma(c-a)}\int_0^1 \frac{t^{a-1}t^{a-c-1}}{(1-x_1t)^{b_1}\ldots (1-x_nt)^{b_n}}\mathrm{dt}$$ Currently, that is the fastest way I know of computing the series is to evaluate the integral directly by quadrature. The series under its current form converges very slowly due to the combinatorial explosion of terms. Writing the terms of the series as a graph, I tried to explore the graph with a heap, adding the largest terms first, but even that is much slower than the integral. This article introduces an alternate expression of the series, but my understanding is that it hides a sum over the partition number, which grows exponentially with $m$ rather than polynomially as in the original expression. Is there any fast method to approximate the series when all parameters and variables are real? 

Let $G$ be a semisimple group over $Q$ and $K$ a maximal compact subgroup of $G(R)^+$. I am assuming that $G(R)^+/K$ has a structure of a non-compact Hermitian symmetric domain. Let $g= p + k$ be corresponding Cartan decomposition of $g = Lie(G(R)^+)$. Now let $F$ be a semisimple subgroup of $G$ (hence defined over $Q$ !) and let $K_F = K \cap F(R)^+$. Let $f = p_F + k_F$ be the Cartan decomposition of $Lie(F(R)^+)$ with $k_F = Lie(K_F)$. I would like to know if it is always the case that $F(R)^+/K_F$ inherits a Hermitian symmetric structure. I understand that this comes down to showing that $p_F$ inherits a complex structure from that of $p$... This may be naive or trivial but I am not familiar with this theory and literature.. 

Assume a directed graph $G = (V,E)$ is drawn from a random graph distribution, for instance Erdős–Rényi's $G(n,p)$ (but with directed edges). Let $S:V\rightarrow\mathcal{P}(V)$ be the direct successors function, that is $S(u) = (\left\{u\right\} \times V) \cap E$ Let $f_0: V\rightarrow\left\{0,1\right\}$ be an initial, arbitrary, labeling of vertices with $0$'s and $1$'s Define $$n_t(u,x) = \left|\left(\{u\} \cup S(u)\right) \cap f_{t}^{-1}(x)\right|$$ $n_t(u,.)$ is simply the number of vertices labelled one or zero among $u$ and its direct successors. Now define recursively: $$f_t(u) = \left\{ \begin{array}{cc} 0 & \textrm{if} & n_{t-1}(0) > n_{t-1}(1)\\ 1 & \textrm{if} & n_{t-1}(1) > n_{t-1}(0)\\ f_{t-1}(u) & \textrm{otherwise} & \end{array} \right.$$ Simply speaking, at each step $t$, a vertex's label is changed to reflect the majority among itself and its direct successors, or is unchanged in case of a tie. I am interested in the convergence of the sequence $f_t$, and in particular convergence to a limit that is constant over $V$ (all $1$'s or all $0$'s) for all initial conditions. How is the probability of convergence affected by the statistics of the graph? I'm sure the problem has been studied and I'd happily take some references on the topic. 

Let $G$ be a semi-simple algebraic group over $Q_p$ and $K$ in $G(Q_p)$ a maximal compact open subgroup. Let $\tilde{\pi}\colon \tilde{G}\rightarrow G$ be the simply connected cover. Then $\tilde{\pi}^{-1}(K)$ is a compact open subgroup of $\tilde{G}(Q_p)$. Is it necessarily maximal? 

Suppose I have an entire function $f : \mathbb{C} \longrightarrow \mathbb{C}^n$ for $n \geq 1$. Let $C$ be the curve $f(\mathbb{C})$ in $\mathbb{C}^n$. Let $\Lambda$ be a lattice in $\mathbb{C}^n$ (free $\mathbb{Z}$-submodule of rank $2n$) and assume that $\mathbb{C}^n/\Lambda$ is algebraic - it is an abelian variety. Suppose that $C$ is stable by $\Lambda$ i.e. $C + \lambda = C$ for all $\lambda$ in $\Lambda$. What conditions that imposes on $f$? I think it should impose that $f$ is a linear function but I have no proof. This question is probably trivial to an expert in complex analysis.. 

I'm looking for the following limit $$\lim_{x\rightarrow 0} \frac{\sqrt{\frac{\text{BesselK}^{(2,0)}(0,x)}{\text{BesselK}(0,x)}}}{\log (x)}$$ I believe the limit is finite, and is near -0.578. However, it is hard to get more digits numerically, and I'm interested in knowing if there is a closed form behind this constant. $\text{BesselK}^{(2,0)}$ is the second derivative of the Bessel K function with respect to its first variable. 

You're looking at distributions with rotational symmetry. The answer is, any distribution that depends only on the norm of ${\bf x}$. You can get such distributions by taking a symmetric distribution $p$ over $\mathbb{R}$ and letting $P({\bf x}) \sim p(||{\bf x}||)$ 

The motivation for this question has to do with neural networks, but it is essentially a purely mathematical question. Suppose you have a perceptron with one hidden layer, a bias, and a logistic activation function. That is a parametric function of the form $$f(X) = \mathbf{B}\cdot\sigma\left(\mathbf{A}\mathbf{x}+\mathbf{b}\right)$$ where $\mathbf{x} \in \mathbb{R}^{n}$, $\mathbf{b} \in \mathbb{R}^{p}$, $\mathbf{A} \in \mathbb{R}^{n \times p}$, $\mathbf{B} \in \mathbb{R}^{p \times n}$, and $\sigma(x) = \frac{1}{1+e^{-x}}$ is the logistic function and is applied to vectors elementwise. If $n = p$ and $\mathbf{A}$ and $\mathbf{B}$ are full rank, then $f$ is injective. Question: if $p>n$, what conditions on $A$ and $B$ are sufficient for $f$ to be injective. 

Let $B$ be an indefinite quaternion algebra over the rationals, let $G$ be the reductive algebraic group defined by $G(A) = (B\otimes A)^*$ for ${\bf Q}$-algebras $A$; hence $G({\bf R}) = GL_2({\bf R})$ in particular. Then $(G, {\bf H}^{\pm})$ is a Shimura datum (${\bf H}^{\pm}$ is a the union of lower and upper half planes) and it embeds into $(GSp_4, {\bf H_2}^{\pm})$ (Shimura datum defining $A_2$, the moduli space of principally polarized abelian varieties of dimension 2). This induces an embedding of the Shimura curve defined by $(G, {\bf H}^{\pm})$ into $A_2$. On the modular level, this map is just forgetting quaternioninc multiplication. I am aware that there is a slight issue of connected components but this seems irrelevant for what I am going to ask... My question is what the centralizer of $G$ in $GSp_{2g}$ would be. This is what I am confused about... Logically, this should be $B^*$ because this centralizer represents endomorphisms of the corresponding abelianb surface, which in this case case is $B$. However, this is not possible since this centralizer must be compact over ${\rm R}$ (modulo centre) which of course $B^*$ is not... This is really confsing, I am clearly missing something.... can anyone help? Many thanks in advance! 

One road is for Alice and Bob to generate vectors $\epsilon$ and $\eta$ where every entry is a random normal number with a very large variance $\nu$. Alice sends $u+\epsilon$ to Bob who computes and publishes $u.v + \epsilon.v$ Bob sends $v+\eta$ to Alice who computes and publishes $u.v + \eta.v$ They also compute $(u+\epsilon).(v+\eta)$. With all that, they can compute $(u.v - \epsilon.\eta)/N$. There remains an error term, $\langle \epsilon.\eta \rangle/N$ which has standard deviation about $\nu/\sqrt{N}$ The problem is that there is a tradeoff here. If the $\nu$ is too small, too much about the vector is divulged, if it's too big there is too much noise in the result. Another idea would be for Alice and Bob to agree on a random base of $\mathbf{R}^N$. Alice could then pick $\epsilon$ as a random linear combination of the first $N/2$ vectors, and Bob could pick $\eta$ as a linear combination of the last $N/2$ base vectors. This guarantees $\epsilon$ and $\eta$ will be orthogonal, but now Bob would know the projection of $u$ over a very large subspace. Not that good. Thougths? 

Let $f : \mathbb{C} \rightarrow \mathbb{C}^n$, $n>1$ be an entire function. Assume for simplicity that $f(0)=0$. Let $B$ be the closed ball of centre $O$ and radius $R$. Is there an upper bound for the number of points of intersection $f(\mathbb{C})\cap B \cap H$ where $H$ is a hyperplane in $\mathbb{C}^n$ (not containing $f(\mathbb{C})$), independent of $H$ (depending only on $f$ and $R$)? I know that there is no general analogue of Bezout's theorem for analytic sets, but I am asking for something much weaker - I do not care about the dependence on $R$... 

There are countably many special subvarieties because they are defined over $\overline{Q}$ but I do not see how this is relevant to your question? I understand you want to know whether any Shimura curve is contained in a special subvariety; I think the answer is yes, it should be contained in an appropriate Hilbert modular variety. 

Let $x$ be a binary random variable and $z$ be an arbitrary random variable. $x$ and $z$ are, in general, not independent. Let $y_1, \ldots y_n$ be $n$ identically distributed binary random variables conditionally independent given $z$. A graphical model would have $x$ at the root, pointing to $z$, and $z$ pointing to each of the $y_i$. Consider random variable $c = \sum y_i$ and function $f(k) = p(x=1|c=k)$ defined from $k=0$ to $n$. How many local extrema can $f$ have, at most? That is, points where $(f(k)-f(k-1))(f(k+1)-f(k)) < 0$ 

Suppose I have a random variable $X_0$ with a p.d.f $f_0$ supported on the real interval $[a_0, b_0]$. $X_1$ is the restriction to $[a_1, b_1]$ of the sum $X_0 + g$, where $g$ is normally distributed $g \sim \mathcal{N}(0,1)$ $$f_1(y) = \frac{\int_{x=a_0}^{x=b_0} f_0(x) e^{-(y-x)^2/2}~dx }{\int_{x'=a_1}^{x'=b_1}\int_{x=a_0}^{x=b_0} f_0(x) e^{-(x'-x)^2/2}~dx~dx'}$$ or $$f_1 = \frac{1}{Z} L( f_0, (a_0,b_0,a_1,b_1))$$ Where $Z$ is a normalizing factor. $$Z = \int_{a_1}^{b_1}L( f_0,(a_0,b_0,a_1,b_1))(x')~dx'$$ $L$ is a linear operator over functions in $\mathcal{L}^2$ What are its eigenvectors? What happens when I replace the interval with a $n$ dimensional box and the normal distribution with a multivariate normal? Thanks! Clarification: I'm looking at f in $\mathcal{L}^2(\mathbf{R})$, not $\mathcal{L}^2([a_0,b_0])$ otherwise $L$ is obviously not an endomorphism.