This begs quite a lot of questions. First, was Marx right in his analysis of the relationship between workers and capitalists? More importantly, is Marx still right? Capitalism has moved on substantially and in multiple ways: it would be hard to argue that the US model and the Scandinavian model are the same, for example. Implied in your version of UBI is that workers are free to exercise their freedom. For instance, it implies at most very limited notice periods (at least enforceable ones). It implies that any exploitation/restriction is primarily financial. It also implies that the UBI generosity is sufficient to make the decision to not work trivial. In other words that one can relatively seamlessly move between a state of employment/unemployment. Given all that, and assuming all other things are equal, then it would be fair to assume that the relationship of those with wages near or below the UBI level would have a substantial change to their work relationship. The further one moves from that level though, the less this is likely to be true. Now, all other things are equal is a nice catch all. A bit like sufficiently generous. If the UBI level is sufficiently high then the economy is likely to be significantly changed. It is very hard to determine in what ways. What is probably fair to assume though is that, as with all other panacea, things may not be all that rosy once this is tried at scale. 

This argument is based on an assumption that science deals in eternal absolutes. That luxury is generally the preserve of, well, philosophy. Science deals with hypotheses and experiments. I can test the hypothesis that there exists black swans. And, by luck, I can confirm it readily (as I did last weekend). Now, if I try to confirm the hypothesis that there exist green swans, I cannot do so so readily. However, assuming my grant money comes through, I can set out on a series of expeditions to look for this elusive creature. As my fruitless search expands, I may not be able to prove categorically that no green swan exists anywhere (my grant money doesn't stretch to searching Jupiter). I can, though, make strong statements about their existence within the bounds of my experimental scope. And it's this latter point that is key. It's why, for example, people say that Einstein proved Newton wrong. He didn't. He showed the bounds within which Newtonian mechanics apply and the adjustments one need to make to extend the bounds. And it's why, even when my best seller There are no green swans is reaching its 30th edition, one is discovered in the depths of the Amazon jungle, I will rejoice. Apart from making a great sequel, our knowledge has progressed. Our original understanding was limited and we can now correct our hypothesis. Some people find this lack of absolutes unsatisfying. Personally, I think it's a swanderful. 

It really doesn't. The religions you mention are very well developed and absolutely are not talking about energy in the thermodynamic sense. There are, of course, some points of crossover but it's generally superficial. 

If god is missing one of these traits then they could still exist but not be able to prevent suffering. Now, whether or not it makes sense to worship a being that is missing one or all of these traits is a somewhat different question. BTW this is often dealt with using the concepts of omniscience, omnipresence, omnipotence and benevolence. However, a god doesn't need these in order to end suffering. For example, I'm aware of the suffering but don't have omniscience. 

Cheating genetics? Yes, absolutely. In precisely the same way that wearing clothing cheats genetics. Cheating evolution? Definitely not, at least not evolution by natural selection. That's exactly what's going on here. Our hero is adapting to his environment to ensure genetic success. 

It's not a new idea. Haileybury School in England was set up by the East India Company to train civil servants to administer India. By its standards it was very successful, the school still exists but obviously not for this purpose. Note, though, that it's not at all clear that the people administered by the alumni of Haileybury necessarily agreed that they did a great job. This, I think, hints at the flaw in the idea. By necessity, if you train all your civil servants in one school/college, they'll have an outlook that reflects that training. That's presumably the point of doing it. This requires, however, that the curriculum and ethos of the college instills the right outlook. But what is right in this regard? Is there one true way to govern? Would we not be better with various viewpoints and outlooks? I don't think the answer is at all clear cut. 

Objectivity and neutrality aren't necessarily the same. Objectivity refers to taking a view or position on the available evidence. Neutrality refers to taking a view or position that is even handed. They are effectively synonymous if and only if the subject under question has valid positions both for and against. As an extreme example, take the Ickian position that the British Royal Family are lizards. Looking at this objectively is not going to be the same as taking a neutral view on it i.e. a neutral position would balance the pros and cons on either side. An objective position would naturally conclude that they are, of course, lizards /s. Somewhat more controversially, an objective reading of man-made climate change would not conclude the same as a neutral view given the preponderance of evidence. 

Scientific theories are intended to describe events that occur in our universe. They generally have the form of a model, sometimes mathematical, that can be used to describe a class of events. We don't currently have a (useful) theory that encompasses everything so we make do with a diverse set of models. As such, each of those models has a field of applicability. For example, it might cover gravitational events or electromagnetic radiation or atomic events etc. Necessarily that field of applicability has bounds i.e. there are only so many events that it applies to. For example, Maxwell's equations only apply to electromagnetic radiation. What we consider a "good" scientific theory is one that gives an accurate description of a large number of events. Ideally, it would also be useful for accurately predicting future events. To that end, Newton's theories of motion and gravity are great theories. Why? Because they describe and predict a vast number of events. Pretty much everything that we can see without specialist equipment, that involves stuff with mass, can be adequately described. Now, around the turn of the 20C, some people started to notice that the models we had for various events didn't really join up. Primarily between Newtonian mechanics and Maxwell's equations. Also, improvements in technology meant that they were starting to see discrepancies between what the models predicted would happen and what was actually observed. This wasn't really an indication that the existing models were wrong. It was that we were starting to see the edges of their fields of applicability. Eventually, the Newtonian models were superseded by quantum electrodynamics and general relativity. The key requirements of these theories were that a) they gave identical descriptions to Newtonian and Maxwell models within the field of applicability of those models and b) they better described the events outside of that field. Effectively extended the field of applicability that our models now describe. Fast forward to the 21C and we're in a similar position to the one we were in 100 years or so ago. Our current models do a very good job of describing almost everything that we know about (quantum chromodynamics was added in the '70s). However, there are some discrepancies between what they predict and what we see. Dark energy and dark matter are "placeholders" that are used to help us accumulate information about some of those discrepancies. Also, our main models: general relativity and the standard model of quantum mechanics don't join up. As such, scientists are researching newer models that describe events as well as these models do in their field of applicability. But with the intent that they will adequately describe the dark areas, and hopefully new phenomena, as well. 

I think this is the crux of the confusion. Even in science, it is not irrational to believe without empirical evidence. Future predictions are common in science and, more or less by definition, they cannot have empirical evidence (having not yet occurred). As such, scientists tend to believe in things that are consistent with empirical evidence. An established theory is simply one that has been shown to be consistent in a significant number of scenarios over an extended period of time. Now, as we're talking about God, I would rephrase this first sentence as follows: 

we have an incomplete understanding of the laws of physics (almost definitely true) we aren't aware of every event ever (definitely true) there have been violations that we haven't witnessed (not unreasonable) the gods exist but haven't bothered to do anything (both scientifically and theologically tricky) 

This is dangerous. Logic says nothing at all about the real world by itself. At best, if your input statements are consistent with the real world then logic can produce other statements that are consistent with the real world. This can be valuable, for sure, and can help to gain insight but is limited by its inputs. For example, let's reword your initial problem a little: 

Whatever Solomonoff's theory of inductive inference is proving, it's not that. Firstly, if all other things are equal i.e. both theories have identical pre- and post- diction power then it's impossible to distinguish the level of truth between them. Regardless of how convoluted they are. At best, one may argue that the simpler one is more elegant but that is orthogonal to truth. Secondly, if we don't really mean all then "because fairies" has precisely one assumption so is hard to beat in the "least assumptions" stakes. More boldly, Occam's Razor can tell you little about the truth of a theory when comparing to a theory of equivalent power. Where Occam's Razor has proved valuable is in the utility of a theory. In other words, a theory that fits the facts with less assumptions is more likely, in practice, to afford useful predictions. This may be because of overfitting or overconstraining of the convoluted theory. Or it may be because the extraneous features are incorrect but the current facts aren't sensitive to them. Or to put another way, Occam's Razor can be a useful predictor of relative theoretical predictive power between theories that have equivalent postdictive power. But that's not very catchy. 

According to the first amendment, the US Congress does not have the right to abridge freedom of speech. It explicitly does not say that individuals have the right to say what they want. Also, it has never been taken to mean that and a number of exemptions have been determined by the US Supreme Court over the years. 

With our present understanding of the universe, the answer is very probably. Any god that exists has only ever acted within the laws of physics. More precisely, regardless of your definition of a god, there is no extant evidence that the laws of physics have ever been violated. Now, there are a number of reasons why we may find that this isn't true: 

Obviously I can't speak for everyone but I'm going to push the boat out a bit and say, no, many people who do have a passion for life will probably lose it. Again though, as there's absolutely not a shred of evidence for pre-destination, we're good for now. 

The problem of suffering is somewhat separate from the problem of existence. For a god to end suffering that god would need to: 

Something is necessary if, without it, it is impossible to arrive at the outcome. Something is sufficient if you can arrive at the outcome with only that thing or things. Unfortunately, your example isn't great because there are so many varieties of bread and breadmaking is a relatively complex process. For example, it's perfectly possible (and quite common) to make bread without wheat or salt so neither are necessary. Also, imagine you plonked water, wheat and salt on a plate and put it in the oven for 3 days. It would be a stretch to call the resulting concoction bread. As such, it cannot be correct that these inputs are sufficient. 

Nice try but there are, at least, two major flaws in your logic. Firstly, if the program became sentient then it is absolutely ethical for it to follow its conscience. Further, it would not be ethical for its creator to make it act against its conscience. Secondly, we are not programmed to reproduce. Some, but not all, of us are able to reproduce and evolution makes use of that fact to evolve. There's an argument that, if we all reproduced equally, evolution would be stuffed (not the technical term). But evolution is not individually directed, it's just improving the species for environmental fitness. So in no sense can it be said to have a singular purpose for us and, as such, there's no sense that we can fail to meet that purpose. Edit: I'm assuming that your ethical system does not consider mental slavery as ethical. If it does then there's no problem. Edit: I'm assuming you meant evolution in the scientific sense. If you do allow for evolutionary direction e.g because we all should be doing god's will, then whether or not we should be reproducing depends on the rules that said god has mandated.