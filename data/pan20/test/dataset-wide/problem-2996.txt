That said, it is also important to stipulate what information we have to answer the question? Do we have perfect knowledge? If so, then you know how much energy each person would use developing a given proof, control for the energy consumed at rest and thinking about the proof. The difference multiplied by the time spent thinking about the proof and only about the proof will be the energy used to create the proof. Consider the amount of energy each person consumed in formulating the proof, select the lowest value, and you have the minimum figure for all extant people. 

I recently read about encoding and exemplifying. From what I understand - Detective Smith (a real person) exemplifies detectiveness, but Sherlock Homes does not. Sherlock Homes isn't real - and if, upon first learning of the character, I was told 'Sherlock Homes is a detective' - that information (that he's a detective) wouldn't tell me much about detectives - it wouldn't 'exemplify' detectives very well. However, if someone first told me everything about Sherlock Homes, but did not tell me that he is a detective - and then revealed to me that he was. When I learned that Sherlock Homes is a detective, now knowing everything about him (especially, now that I know about his work routine) - I'd have to say I have an exemplification of a detective. So, why do fictional characters not exemplify properties? 

What is the difference between an 'idea' and a 'concept'? Has a distinction between the two terms been settled and accepted by most modern philosophers? 

If we ever learn that they exist, it will not be philosophers who ascertain that fact. It will be astronomers, astrophysicists (who recently looked at 100,00 galaxies for signs of civilizations [link]) or people who work in electronic signalling. In so much as philosophy is a principally rational discipline, there aren't many questions related to extra-terrestrials that we ought to properly consider best answered by modern philosophy. The Drake equation is a popular formula (link) for calculating the likelihood that intelligent life exists. Biology, astrophysics and astronomy, history, and other disciplines inform us of the best values to substitute the variables of the equation. There is the question of why we seem to be alone in the universe. There are explanations other than ones that appeal to the distances between stars. Plausible answers to that question are the sort of things that philosophers contemplate. For example, is it plausible that we could be so different from other intelligent life that we wouldn't even notice the signs of each other's existence? Many of those questions (link) relate to attempts to solve Fermi's paradox. However, there are few plausible solutions to the paradox, and those solutions do not evoke any profound philosophical questions. 

That point of conversion from amoral agent to moral agent is not clearly defined, and may be intrinsically vague. You might start by asking, "does moral agency have clear existential borders, or can it exist as a matter of degree?" It's been pointed out before that we should not seek to do philosophy here on Philosophy.SE, so rather than engage in a conversation on the topic I'll just refer you to the sources on the subject. Jean Piaget is probably the best person to start with on the subject of childhood development and morality. If you can dig up any of his papers, many of them begin with this very topic. For a general review of childhood as a philosophical status, try the Stanford Encyclopedia of Philosophy. 

If by "superposition" you mean that experience supervenes directly on quantum states, I've been told explicitly by David Albert and others with no small amount of knowledge on the subject that this cannot be the case. Superpositions of quanta cannot be sustained over that large a set of eigenvalues - or something like that. The point is that your perceptual apparatus is just too large and too complex. On the other hand, if you're using "superposition" here in a looser sense to describe a set of potential end states, then you're in new territory. That notion appears to describe the underlying idea behind Integrated Information Theory as put forth by Giulio Tononi. He even goes so far as to use a Hamiltonian in his description of experience, which he builds out of something he calls "q-space" (q for qualia, in the philosophic sense). You can read his paper on the subject, and if you find it all compelling, please email me! 

I'm very familiar with the argument John makes with his Chinese Room argument, and he's extremely consistent about what he means it to portray: that our concept of what it means to understand language is mistaken when we try to apply the term to any machine which operates only syntactically. It's primarily a refutation of the notion that a Turing Test is sufficient to claim that a conscious understanding is present. As a system administrator by day, and an aspiring philosophy student by night, I can with full confidence tell you that yes, John Searle is correct when he claims that computers operate purely syntactically. All they do is manipulate symbols, and we still require a human agent to imbue those symbols with meaning. Still, the realization that syntax alone can have such incredible power is the great lesson of our age. The problem with the example you gave above is that it sidesteps the very point of the reductio that the Chinese Room makes. In the original example, Mai would submit her answer to a great big box, and receives intelligible responses from this box (whose occupant she's agnostic of) in a reasonably rapid amount of time. From Mai's perspective then, the box has passed the Turing Test- Mai believes she's been understood by a conscious being. On John's side of it, he has a set of drawers which contain all sorts of responses and phrases for different questions, and the guidebook he carries simply directs him to an appropriate drawer based on the Chinese message he receives. The intuition Searle latches on to here is that John doesn't understand Chinese, so Mai's belief that her words are being understood by a conscious being must be wrong. Trying to replay the thought experiment with Lao playing the role of the conscious, understanding responder thus just circumvents the whole argument without addressing the problem it presents. There's plenty of deep disgreements to be had at this point: we could defend Mai by claiming that John+Box+guidebook together make a system which understands Chinese, for instance. Searle himself denies this position is coherent, but not everyone buys his opinion. There's also the issue Daniel Dennett raises, that Searle makes a category mistake when using the word "understanding". In Dennett's view, semantics are unnecessary to understanding language, and syntactic operations are all that there is to explain consciousness. You could also try leveling the charge that Searle's mistake is in thinking that there could even be a set of rules which a living language such as Chinese could be reduced to. This argument however has the consequence that it denies any possibility that a Turing Test could ever succeed. As a result, leveling this charge requires that you already agree with the results of the thought experiment: that rule-following alone cannot account for our normative understanding of what constitutes "understanding". 

I have a small-claims matter pending with the courts in my state. Here, self-represented parties are required to attend an information session, which I attended today. During this session the presenter talked about mandatory settlement conferences, in which the parties both present summaries of their cases to the deputy-judge, who then tells the parties how he would rule if he were the trial judge for the matter. The courts operate these conferences to encourage settlement and reduce the number of cases that proceed to trial. I asked one of the two presenters, "I heard that the settlement-conference deputy-judges usually press the guy with the most money to make the larger concession; is that true?" She replied, "Well. Hm. Maybe my colleague should answer that." Her colleague answered, "Let's take that to an extreme. If that were the case, then the settlement conference deputy-judges would just look at each person's net-worth and tell the richer person that he expects him to prevail if the matter proceeds to trial." (I accepted his answer, but ultimately, the first speaker conceded that what I heard wasn't entirely inaccurate.) I thought the second speaker misused reduction to the extreme in a manner analogous to countering the claim that there are aliens living on earth by arguing that if that were true, then there would be so many of them that we would have to stack them face-to-face toward the sky in order to fit them all on our planet. But if I claimed that relish is a vegetable, one might argue that if that were the case then one could get half a day's worth of vegetables from several packets of relish and ketchup. That example seems to succeed, but the prior example seems to fail. Why? 

The problem I understood the definitions of 'a priori' and 'analytic' to be extensionally identical. The definitions of 'synthetic' and 'a posteriori' that I used here may be different, but I'm doubtful - as it seems to me that there are only two ways of verifying a statement: deduction, and induction. From what I (probably, incorrectly) understand, 'A priori' and 'analytic' refer to 'deduction'; this leaves 'synthetic' and 'a posteriori' to share 'induction'. Yet, people who know more about philosophy than I know about it, and who have thought about these terms more than I have thought about them, seem to be able to distinguish between the two sets of terms. The question What distinguishes 'A priori' from 'analytic'? What distinguishes 'synthetic' from 'a posterior'? Thank you 

Keep in mind that opinions on what constitutes a synthetic judgment are strongly divided. Kant himself had a very clear idea of what he meant, but may have failed to communicate an exact-enough definition. Julian Baggini points this out in his Toolkit, noting that a way to view the distinction between synthetic and analytic judgments is in whether or not a judgment "adds something to the subject" (§4.3). What this means for Kant is that in any judgment, there is some experience which is being had. Providing evidence for any proposition requires that an experience of the evidence be possible in the first place. Kant's deduction then unfolds from the argument that categories are a necessary feature of such an experience. It may appear that Kant has thus plucked his categories out of thin air, but the details of his argument for why experience would be impossible without categories is compelling. 

From the perspective of a basic philosophical education, that kind of division looks familiar, but strikes me as a little weird. I believe the problem you might be having is that the lecture series, by presenting those "categories" of claims, is conflating a few basic ideas about knowledge, beliefs, and epistemology with philosophy of mind. Let me try a brief explanation of what I hear when you use the word "claim" in these various ways. 

To be perfectly honest, your question's a little offensive. I could equally well ask you: where can I find an exhaustive list of the different sciences that exist? How would such a question be reasonably answered? Not to mention that "schools of thought" are so varied that its unclear what you really mean by it. To be charitable, I'll assume that you're looking for the branches of philosophy, which is answerable. All that said, it's still useful to know what the broad strokes of philosophy are, and for that there's a recent, decent book by Simon Blackburn you could read through in few hours. In it, he teases out eight major branches of philosophy which cover most of the spectrum. I've rewritten his chapter titles to be more specific. Epistemology What do we know, and how can we know it? What is the nature of knowledge? What's the difference between true statements such as "3 + 2 = 5" and "The Statue of Liberty stands on Liberty Island"? Consciousness What is the phenomenon of being awake and aware? How is it different or similar to dreaming? What is pain? Is it possible to be certain that anyone else suffers the same phenomena I do? Freedom If the ability exists for all actions to be predicted, what does it mean to say that I am the agent responsible for my own actions? Is it meaningful at all, or just a hallucination? Identity Are you the same person you were yesterday? Will you be the same person fifty years from now? If I take some other object, and replace its parts one at a time, at what point does it ever cease to be the same object? Ontology Is there a Creator? If not, how did the the world (i.e., the universe) come to exist in the first place? Is causality a real relationship between events or just one we impose on the universe to make it sensible? Where do our beliefs about these things come from? Logic What is the difference between a good and a bad argument? What series of rules will always produce correct results? How can we describe the things we say or write in a way that allows them to be evaluated by these rules? What beliefs can we evaluate in this way? Perception Are the qualities of objects in the world produced by those objects, or are they imposed on those objects by our mind? By what means can we judge the things we see, hear, smell, etc., to be facts about the world and not imaginative hallucinations or clever illusions? Ethics Are beliefs sufficient to motivate certain actions? What are those qualities of an event, object, or person which makes it good? 

Philosophers seem to use more neologisms than most other academics. Novel permutations of morphemes seem especially prevalent. I suspect most people apprehend the meanings of words like mathematizability, cousinhood or cousindom, and intelligentness. One can use words like that instead of using lengthier phrases like the quality of being able to be restated mathematically, the quality of being a cousin, and the quality of being intelligent. None of those are words, but they seem useful. Does increased brevity, generally, justify the use of neologisms like the aforementioned? 

Among humans? Or among mating organisms in general? Also, in what circumstances? Economically Suppose a couple who value what most people value, and who value those things about as much as most people value them. If they share fixed costs (shelter, utilities, and furnishings), then the arrangement will effect more value for each of them; presuming, living with another person doesn't offset the added value. Otherwise, parasitism better characterizes the arrangement than symbiosis does. Reproductively Whether we ought to regard cohabitating as symbiotic, or regard it as parasitic, depends on the circumstances: Can either party force the other to mate with it? How would doing so affect either party's absolute reproductive success (the number of organisms at an arbitrary future time that will have descended from the ancestor in question)? Game theory explicates this intertesselation well. The game proceeds as follows. First note the following game parameters. 

The sentence, The Current King of France is ill, presupposes the existence of an extant French king. That sentence translates to, ∃!x(Kx ⋀ Ix), which is false. Similarly, the sentence, The Wolverine has an Adamantium Skeleton, translates to ∃!x(Wx ⋀ Ax), which is true. Similarly, the sentence, Socrates had a beard, translates to ∃!x(Sx ⋀ Bx), which is true. However, for all I know , Socrates could also reference a fiction. How does logic reference fictional characters? 

1.12. "Then, the totality of all facts determines what the case is and also, what isn't the case." 1.13. "The facts in scope of logic are the world." 

Not quite. It's a little easier to read if we make the sets explicit. Let curly braces denote any set, where the name of that set is inside the braces. For instance, set x is {x}. The set's name, followed by a colon, indicates the set's members (separated by commas). Hence if a, b, c are members of set x, we can show this as {x: a,b,c}. Subsets are members of a set. Hence if a law of nature is "any set of worlds that has a subset ", then this is {x: {}}. Let's say that a law of nature at the actual world can be denoted by Li. Then the set of all laws that hold in the actual world (i.e., the world we currently live in) is { L: L1, L2 .., Ln }. Let {} be the set of worlds in which the laws in L and only the laws in L are true. By Van Inwagen's definition, a law of nature just is the set of worlds {Wa} for which is a subset, or {Wa: {}}. That's all. It may still be possible that a different law not in L holds for some other possible world, but then that law would not be a natural one. For instance, say {} is some set of possible worlds for which { S: S1, S2 .., Sn } are not in the actual world. Then S can still be in the set of possible worlds {Wb}. All this means is that if { Wb: {}, {} }, then Wb would still count as a law of nature just like Wa would. { Wc: {} } would be excluded as a law of nature, even if it overlaps with some members from . That is, say a is the actual world, b is a possible world for which all and only L hold true, and c is a possible world where all L and some S holds true. Then any W with members a, b, and c can have the subsets { X: a, b }, { Y: b, c }, and { Z: a, c }. If these were all the possible worlds that exist, then W and X would be natural laws, but Y and Z would not. 

Philosophers often describe one thing as consisting in some other things. However, I've never seen a rigorous definition of the 'consists in' relation. Does such a definition exist? 

The third formulation: Act that your will can regard itself at the same time as making universal law through its maxim. 

For what it's worth - you could probably quite easily store the schematics for the 100 most powerful super computers on one USB stick. Furthermore, its not the complexity of a thing that makes it powerful, its the sophistication of its design (if you will). An example to support the point: The schematics for a medieval repeating-crossbow (yes they existed) were probably as complicated as the schematics for a modern revolver, yet the revolver is more powerful. 

By Kant, you may treat people as means; however, you must not treat them only as means. In other words, you must also treat them as ends in themselves. Presumably, almost all retailers retail as a means to an end. When you buy from them, you conduce their attainment of those ends. As such, when you buy from them, you do not treat them only as a means to your ends. If you were to steal from them, you would have treated them only as means to your ends. 

Background I enrolled in a class, The Philosophy of Human Rights. The authors of the course readings never use 'duty' and 'obligation' interchangeably, so I suspect that the terms may have distinct meanings. Question Do the terms 'duty' and 'obligation' represent different concepts to philosophers? If so, what do the terms mean? My attempt to answer the question I thought that a duty might be an obligation that entails action, and that an obligation is a more general term that may or may not entail action. However, one author, Henry Shue, mentions a 'negative duty', such as a duty to respect a person's right to liberty: In essence, a duty to do nothing to someone. I don't consider actions to include 'doing nothing' (that's 'inaction'), so I don't believe that my definition of 'duty', as 'an obligation that entails action', is correct. What's the difference between 'duty' and 'obligation'? Thank you.