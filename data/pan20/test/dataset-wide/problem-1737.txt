have you verified your results with a tool like wget? Are you using ISA as a proxy, or a transparent proxy? Sometimes clients have issues if proxy auto-detection is set up in IE. If you turn this off, or hard configure it to use your ISA proxy, then things get a lot better. I had this same problem at startup at one of my clients, but not quite as reliable or prevalent as you seem to have it. 

Over a gigabit ethernet connection, you're only going to get a maximum of 120MB/sec. And that's best-case, you'll probably top out at 100, and that's even if the Drobo can keep up with that (though I've heard it can). I've used iSCSI from an EMC Celerra over the same transport - it did relatively well for 10 or so low-usage hosts, 1 SQL server doing maybe 250-500tps and a Clearcase server doing probably triple that. 

That said, you should treat your backup servers disks with the same sort of redundancy you treat your database server. Say your database server fails at noon, you can rollback to the backup servers ondisk copy from last night and do your restore, where you tapes might already be a $250 emergency return from your offsite vendor. You should put RAID on every server you run, IMHO, and not that non RAID RAID-0 crap. :-) 

Today there are multiple levels of backup, nearline and offsite. Nearline is where you back up to disk. Here you can keep multiple backup sets of highly important data near, while a copy gets made from the backup servers disks to tape and then the tape gets sent offsite. This has several benefits: 

I generally use Standard Edition, because that's what the vast majority of my customers use. When I need clustering or the advanced features of the other products, I install those. There's probably a small size/memory footprint difference between them all, but I'm not 100% on that. I also typically stick to 32bit images unless I KNOW I'll need to utilize higher quantities of memory. 

A buddy was experimenting with some weird extents-based MD+LVM on Linux, and Linux apparently has a hard 63 partition limit on any disk. I'm not sure if that's filesystems per extended partition, or what. I'd like to think that in today's day and age, it's relatively irrelevant. 

My boss tells an amusing anecdote about one of my coworkers, a Chinese man with a thick accent. Smart guy, but hard to understand on the phone sometimes (I'm an expert in Engrish). So one day he gets a tech-support call from an Indian guy, and is having a hard time getting the guys name and problem description. After about 5 minutes of listening to the Chinese guy on the phone, my boss, native English speaker, offers to help. He gets on the phone "Can I help you?" to which the poor Indian goes, "Oh thank God!" 

JBoss has maturity, whereas Glassfish is striving to be THE reference J2EE stack. A year from now, there'll be almost no difference to your production deployments. 

Having run numerous virtualization farms, both for big business and personal use, I'm of one singular camp. VMware. The VMware tools support is currently unparalleled, between Lab Manager, LifeCycle manager, etc. Citrix XenServer is coming up, but it has 10 years of makeup work to do to catch up with the mature VMware products. And as a general rule I've found that even though you start at a dozen or so, you need to plan for 50. Once you start virtualizing, you never stop. At the moment, though the Citrix offerings are promising, VMware is your best choice for the near future. If you're willing to live with the growing pains Citrix offers (immature tools support), I don't think you could lose with either open. And both have Free-as-in-beer versions you can try-before-you-buy. 

I keep track of my notes with a combination of pNotes portable, and Evernote. If I ever need to REMEMBER something that I've just worked on, I write an article about what I did, what problem I solved, and how I did it, almost as if I was publishing it (even if I never do). 

your SQL server doesn't know how to route to the gateway device (not likely if you can browse the web from it). Your virtual server on the firewall is a proxying device for web traffic, and doesn't understand your SQL traffic. You want "port-forwarding" 

Even a bulk "insert ..." shouldn't take too long. I took a new JIRA database export of 200MB and loaded into a virgin database in approximately 30 seconds. 

www.opengoo.org is a project striving to recreate much of the Google Docs experience (including mail integration). I'm not sure about the importing of XLS documents. I haven't quite made it that deep into the demo. 

Okay, you've gotten really great answers here, but I'll illuminate why I love VMware & it's brethren. 

Utilization - in a room full of servers, of which maybe a dozen are doing anything near 50% utilization, I can instead consolidate those servers onto one or two single larger servers and have room to growth. Capacity planning - becomes less of a concern as you can buy with resources to grow, and $5000 worth of a server gives you lots of flexibility in deploying new services Real-estate - I'm running a 200 machine test lab on three ESX servers (2xquad core). That's 197 servers that aren't sucking 1-300 watts of power sitting idle 90% of the time, and wasting disk, memory and CPU. Flexible deployment - I need 15 Windows servers for a new project. With tools like lab manager, I can have this in an instant. Simplified upgrades - I want to test an upgrade to a product. I can simply clone the entire machine, put it on it's own network, and run an upgrade test without impacting the existing service. Backup - I can take snapshots of the entire machine's running state. No more need for special backup clients that can't lock files. (not entirely true for application state, however). Mananagement - I can remote manage every single on the machines from one unified tool. Cost-center/utilization billing - there are tools coming on the market now where you can bill by utilization, and help tailor your budgets to ensure groups aren't spending more than their fair share. Disaster recovery - if your big ESX server crashes, it CAN transition the workload to a backup server designated to recover for it. Sometimes without the VM even knowing it crashed. 

backup to disk is usually faster You have an effectively unlimited # of disk devices, where backing up to tape is usually constrained in the number of heads you have to write at a time. 

Exposing a SQL server to the Internet at large? Eh, I wouldn't do it if I'm storing Credit Card or Personally identifiable information. 

In datacenter-grade equipment, you're looking at at least $1000/core currently, with large memories. Which is a pretty damn good price, IMHO. But the problem is that of capitalization. A lot of that is underutilized, even using tools like Surgient or VMware/LabManager. So you move to the cloud on-demand. Have a huge process that needs to run for 3 days at the end of every month? Deploy it to the cloud. $10. Versus $10,000 for having a server sitting around doing nothing for 25-28 days a month losing money. The time-value of money is what drives people to the Cloud. It may cost more in the long run, but can you get more for the dollar you have now, versus the dollar you MIGHT have then? 

I'm currently running snv_129 (EON NAS image). I think I have somehow shorted one of my PHYs and I'm trying to debug the issue. /etc/hostname.rge0 192.168.250.20 /etc/hostname.rge1 192.168.250.21 Router: 192.168.250.1 Network 192.168.250.0/24 I'm trying to switch the active/primary NIC from rge0 to rge1 and am unsure how to go about doing this (I really should have stayed with Linux, which I know a whole lot better). Anyhow, netstat -rn gives me this: Dest: default GW: 192.168.250.1 flags: UG 127.0.0.1 127.0.0.1 192.168.250.0 192.168.250.20 Interface: rge0 I cannot ping anything when using rge0 as the primary interface. I don't really have the skills with Solaris to know how to debug this issue. svcs -a says everything is online, and I can ping 192.168.250.20 whether it's plugged in or not. Any help would be appreciated, and I'm happy to add more information if necessary EDIT: My eventual goal was to do link aggregation. At this point, all I want is to return one of the two interfaces to functioning order - just one. I've followed some of the advice below. Here is what I've done since last update: Disable interface 1 in the BIOS. (only one interface detected) dladm show-phys: LINK: rge0 MEDIA: ethernet STATE: down SPEED: 1000 DUPLEX: full DEVICE: rge0 ifconfig rge0: flags: UP BROADCAST MULTICAST IPv4 (RUNNING is not present) inet: 192.168.250.20 netmask ffffff00 broadcast 192.168.250.255 ether ff:7f:7f:7f:7f:7f Anybody have any ideas on next steps? 

What virtualization platform are you using? VMware's Lab Manager product is working wonders at my workplace for setting up test-clusters and customer environments. 

I have a 6TB RaidZ ZFS array configured on my nv129 based OpenSolaris filer, and I want to upgrade to FreeNAS as painlessly as possible. I remember betas had warnings that they did not support existing ZFS pools - has this changed? I can't seem to find any official statement that this is possible, and I'd rather not risk my array if possible. I have backups, so I could start from scratch, I suppose, but I'd rather not. Thoughts?