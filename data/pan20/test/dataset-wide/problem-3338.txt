Perhaps because words that begin with 'I' or 'V' in Latin are statistically more likely to use those as the semivowels /j/ and /w/, rather that the vowels /i/ and /u/ which are more common in the middle of words, eventually — but well after Roman times, and partly after the Middle Ages — 'J' and 'V' established themselves as semivocalic forms, while 'I' and 'U' remained for the vowels, and since the informal cursive distinction in "glyph length" became systematized as swashes in printing, this was no longer just restricted to handwriting. In the meanwhile, the phoneme /w/ had since long mutated into /β/ or /v/ in Latin and its successors, so 'V' is rarely used as a semivowel in today's languages that employ the Latin script, instead representing [v] or related fricatives or approximants. In some languages, /j/ stopped being a semivowel too, becoming [ʒ] in French for instance. So, the way 'V' and 'J' are used today varies with languages, and additionally, Germanic languages that still had a separate semivocalic /w/ created a convention of using a double 'U' or 'V' (which were not yet generally distinguished at that stage) to reduce the ambiguity with both /u/ and /v/. A tangentially related point is the origin of the dot on both 'i' and 'j' in modern non-capital scripts: this can be traced back to the apex diacritic mentioned above, which eventually became the acute accent used in many modern languages to mark either word stress or vowel quality resulting from ancestral length distinction, although some languages still use it to mark length. Because 'ı' and 'ȷ' were thin letters which often caused confusion (especially with 'm' when they were next to 'n') in minuscule handwriting, the apex or acute accent, then known as a tittle, started being systematically used regardless of length, quality or stress, merely to make those letters stand out as separate from the adjoining ones. 

Learn some formal language theory via Sipser's Intro to the Theory of Computation. Having the background will be useful when dealing with Minimalist Grammars and their parsers. 

So it would seem that after [DP where/who/what all] merges in its theta position, wh-extraction can target only the wh-pronoun. Turning to long-distance wh-extraction, the following are all grammatical. 

Successive cyclic wh-movement is motivated by theoretical principles of minimal computation, as well as empirical data. There's nothing inherently wrong with the 'one fell swoop' analysis, but cyclic wh-movement is preferable. Minimal computation: At any point in the derivation, the range of visible syntactic objects available for computations (e.g. Agreement) is restricted. Remember, SMT assumes that derivations form interface-interpretable objects as efficiently and lazily as possible. Thus, we assume visibility is restricted to phase (CP and vP) edges, which rules out one fell swoop movement. This is known as the Phase Impenetrability Condition. Data: The following data comes from McCloskey 2000. In a dialect of English spoken in Ulster, the quantifier all can attach to wh-pronouns. 

Merge is more useful as a structure building operation than traditional phrase structure rules or X-bar theory, because unlike the latter, it can freely intersperse with movement. If you require structure building to precede all movement processes, you're in some sense postulating at least two different levels of representation. Economy of derivation principles say that one or zero levels is always preferable to two. Furthermore, once we adopt Merge, movement does not need to be a separate, primitive operation, since any instance of movement is equivalent to copying the relevant object and Merging it. This is known as the copy theory of movement. Note that syntactic computation begins once we select items from the lexicon and form a numeration (i.e a set of ordered 2-tuples consisting of the lexical item and the number of times it was chosen (Lexical Item, n)). Since n can be as large as we wish, it follows that the copy theory of movement does not introduce a new operation into the system. Economy principles are observed. There's much more to be said about our Lord and Savior, Merge. We are humbled by His Recursiveness. 

However, saying it was "spelled with an I instead of a J" may be misleading, because 'J' as a later innovation did not arise from thin air: while 'I' and 'J' were not distinguished in Roman times, they existed as graphically distinct variants of the same letter, which always looked more like 'I' in capitals, but could sometimes look more like a (dotless) 'ȷ' in everyday cursive script. The distinction was originally just a matter of natural variation within people's handwriting, but in time, a habit tended to form where the first and/or last letters in a word may come to stand out more, resulting in 'ȷ' being used more often than 'ı' in those contexts, just like a better-defined 'v' would stand out more than a more fluidly-written 'u'. I think this pattern can be observed in a few of the Vindolanda tablets for example. I consider it somewhat natural for the first bit of handwriting to be written more carefully or incisively than what follows. In the case of 'ȷ' (often called the equivalent of "long I" in several modern languages), the distinction may also have been influenced by the standardized classical Roman habit of writing a longer 'I' to indicate that it was a long vowel, something they routinely did in inscription too, and which was unique to 'I' as the same indication was given for other vowel letters by writing an apex above them, at least when useful to reduce ambiguity. This use, in any case, is distinct from the specific shape and use that 'J' later evolved into. Another letter that often underwent shape/length changes depending on position in Roman cursive was 's', and this distinction also survived into modern times as the long ſ, this time used within words whereas 's' would be used at the extremities. Since this also appears in Caesar's name in both word positions, we can reconstruct the way his name would typically have been written in Roman cursive by approximating it, at least in concept, with the modern lowercase form 

Assuming the copy theory of movement, cyclic wh-movement is further supported by languages in which multiple wh-copies are pronounced. Consider the following Afrikaans data from du Plessis 1977 

Your analysis is not correct. It is well known that wh-extraction out of adjuncts is impossible. See Huang 1982. Thankfully, the derivation of your sentence involves neither wh-extraction nor adjunction. Notice that it involves the passive construction The plot was discovered by the authorities, in which case the plot and the authorities are both assigned theta roles by discovered. Ignoring the technical details of passive constructions, the derivation involves building up [TP the plot was discovered by the authorities] And in the usual manner, we merge in an interrogative C bearing a wh-feature that needs checking [C [TP the plot was discovered by the authorities]] The subject inverts with the auxiliary, and then how gets merged into the tree to yield [how [[C+was] [TP the plot was discovered by the authorities]]] 

The three projections of X'-bar theory namely X, X', and XP exist to establish the Head-Complement, Specifer-Head, and Adjunct relations. If intermediate projections were also XPs, then there would be no way to distinguish adjuncts from (multiple) specifiers. 

Thus, it is possible to strand the quantifier in intermediate Spec, CP. This lends support to the cyclicity of wh-movement shown here. Angled brackets indicate lower copies. 

Many aspects of cognition lack neurobiological evidence - consciousness for instance. Now if Cartesian duality is correct (and given its formidable presence in the history of philosophy, it's not a totally insane possibility), it follows that human cognition will never be completely understood within any biological framework. The language faculty can then be one of the 'magical' aspects of cognition, in which case, biological inquiry will be useless. However, this does not preclude the notion that the language faculty employs computational mechanisms like Merge. In light of such possibilities, the computational approach to the language faculty, namely that sentences are formed via Merge, is correct to the extent that we can successfully account for natural language syntax with Merge along with the other assumptions of the minimalist program (e.g. The Strong Minimalist Thesis). I would say that Merge has been very successful in this regard. On the other hand, it's possible that neurolinguistic research will one day provide a more illuminating account of the language faculty. For instance, perhaps Merge can be localized to Broca's or Wernicke's area. Or as an extreme case, perhaps the language faculty doesn't exist at all, and by extension neither does Merge. That language is nothing more than the result of domain general cognitive processes is a view held by many (e.g. Lakoff and most functionalists). My personal view is that the current generative approach will be vindicated when generative ideas are used to solve the central problem of AI. Once we create robots that speak indistinguishably from humans, using such hated principles of Universal Grammar, generativism's detractors will be at a loss of words.