If the normalised filter response function is $R_{\nu}$ then the measured flux is $$ F = \int f_{\nu} R_{\nu}\ d\nu $$ The integration is done over the frequency range of the filter. If you measure a flux through a filter then the process cannot be inverted exactly. However the average flux density can be found by dividing the total flux by the effective frequency range $$\langle f_{\nu} \rangle = F/ \int R_{\nu} d\nu $$ 

The best prospect from the ground now appears to be NGTS, which will probably have the precision to get down to the sub-Neptune sized planets, but which will be limited to the southern hemisphere. NGTS started last year, so as long as it can get results out very soon, then it will steal a march on TESS. 

We lack the precision to say that there aren't regions where there is matter without dark matter or vice-versa. But what is clear is that the ratio of dark matter to normal matter, which is (or needs to be) around 5 on average to explain the flatness of the universe, varies by orders of magnitude from place to place. The reason for this is that matter interacts with matter in a completely different way to that in which dark matter interacts (weakly) with normal matter or itself by any other means than gravity. Gravitational interactions between normal/dark matter are not dissipative. By that I mean that the sum of gravitational and kinetic energy is preserved. When normal matter interacts with itself there are normally dissipative consequences. For example, interacting matter may become hot and radiate away energy. That is why the normal matter in our Milky Way galaxy is concentrated into a plane. Dissipative interactions during the gravitational collapse of our Galaxy, combined with the requirement for conservation of angular momentum result in disc formation. The same is not true for the dark matter associated with the Milky Way, which is expected to have a much more spherical distribution. Likewise, when we look at the required density profiles of normal and dark matter in order to explain the kinematics of stars and gas in our Milky Way, we see that the normal matter is much more centrally concentrated than is the dark matter - hence we talk about a "dark halo". Again, dissipative interactions in normal matter are the reason. Another famous example of the separation between dark and normal matter is the bullet cluster. The image below shows where the hot gas is (normal matter, observed by an X-ray telescope) compared to where it is inferred that the dark matter is (shown by contours) on the basis of gravitational lensing. This pair of galaxy clusters have recently interacted, passing through each other. The hot, intracluster gas has been stripped out of the pair and shock-heated, so that it appears concentrated between the two galaxy clusters. The dark matter content of each cluster has sailed on oblivious and remains concentrated around the visible cluster galaxies. 

The main tool to measure the diameter of a star is interferometry combined with a parallax-based distance measurement - a brief review by Kervella (2008) might be useful. The principles behind interferometry are described here. Interferometry involves measuring the light from a star using two (or more) telescopes that are separated by some distance. Together, the signals from these telescopes can be combined to give an angular resolution that can be (in the best circumstances) equivalent to a telescope with a diameter equal to the telescope separation. These measurements give the angular size of the star, which must then be multiplied by their distances to get a physical diameter. One of the most successful experiments is the Chara array, which has yielded diameters for many nearby stars. Precisions can be as good as a few percent, but more usually 10% and of order 100 (predominantly nearby) stars have had their radii measured in this way. A second main direct technique is to use eclipsing binary systems. The measured light curve can be used in an almost model-independent way to estimate the radii of the two stars involved. Of course most eclipsing binaries are close pairs with short orbital periods and with orbital inclinations that allow us to see the eclipse. They are therefore highly prized objects. Radii can be measured with precisions of 1%. A reasonably complete catalogue of the $\sim 100$ known eclipsing binaries with precise radii can be found here. Another technique is lunar occultation. The passage of a star behind the limb of the moon results in a changing diffraction pattern that can be used to estimate the angular size of the star. Again a distance is required to convert this into an actual diameter. More distant stars are inaccessible - their angular diameters are simply too small. At the moment only indirect estimates of their radii are possible. For example, if we were to assume that a star radiates as a blackbody, then its luminosity ($L$), radius ($R$) and temperature ($T$) are related by Stefan's law. $$ L = 4\pi R^2 \sigma T^4,$$ where $\sigma$ is the Stefan constant. If the star has a measured flux at the Earth and we know how far away it is, then $L$ can be estimated. If we take a spectrum and estimate its temperature, then the equation above can be rearranged to give the radius in terms of the measured luminosity and temperature. Real stars are more complicated than blackbodies, but the principle is the same. Neither of the above techniques can work for black holes, and the sizes (event horizon or Schwarzschild radius) of black holes have not yet been directly measured. The physics of a black hole is relatively simple(!) and so there is a direct relationship between their Schwarzschild radii and their masses (modified somewhat by rotation). Basically it is 3 km multiplied by the mass in solar units. Therefore a measurement of the black hole mass gives its "radius". The masses of black holes are measured by looking at the motions of stars and gas around them and applying our knowledge of how gravity works. 

Yes, there is a limit. Anything with a mass larger than about 13 times that of Jupiter would be called a brown dwarf (a failed star), though whether such an object would consist entirely of gas, or had a rocky/icy core as is probable for most giant planets, is not presently observable. Any larger than about 75 Jupiter masses and we would just call it a star. The exact definition of what a planet is (especially, the 13 Jupiter mass boundary) is still disputed. Of the bonafide planets that have been detected and confirmed, the catalogue at exoplanets.org lists Kepler-435b as the one with the largest measured radius (although its radius error bar overlaps with that of other planets). The quoted radius is $1.99 \pm 0.18$ times that of Jupiter. Most giant planets have very similar radii for masses between about 0.5 and 10 times that of Jupiter. The reason for this is that they are largely supported by electron degeneracy pressure. The diversity in the radii (between about 0.7 and 2 times that of Jupiter) of such planets is not yet fully understood. The plot below shows mass vs radius for "planets". The smaller (probably rocky/icy) planets do show a trend of increasing radius with mass (the solid line is where a theoretical relationship for rocky/icy planets has been used to estimate the mass from the radius). The gas giants above about 0.5 Jupiter masses show no trend and a small scatter. 

The raison d'etre for TESS is to do a precise and complete survey for exoplanets, that are smaller than Jupiter, around bright stars in a short period of time. The main reason to go to space, is to do more precise photometry than is possible (in an efficient way) from the ground looking through the Earth's atmosphere. This allows the detection of Neptune and even Earth-sized planets, which are currently not detected by the all-sky ground-based experiments like WASP and HATnet. The predicted yield and improvement is shown below (from the NASA TESS site.) 

Brown dwarfs are born moderately hot and luminous and then they contract and cool. Thanks to electron degeneracy in their cores, they never become hot enough to ignite hydrogen (though there is a brief deuterium burning phase) and as a result their fate is to cool and fade. The plot below (from Burrows et al. 1997) shows how the luminosity behaves as a function of time since birth (age) for objects of various mass. The brown dwarfs are the green and red tracks (some would call the red tracks giant planets). The curves are labelled in Jupiter masses. The highest mass brown dwarf is 73 Jupiter masses, the next one down is 70$M_J$ and then the green curves count down in steps of 5$M_J$ to 15$M_J$, then the first red curve is at 13$M_J$ and the red curves count down in steps of 1$M_J$. The axes are logarithmic (to base 10). Thus when the y-axis says -2, it means the brown dwarf is one hundredth the luminosity of the Sun, -3 = one thousandth etc. The x-axis is logarithmic in units of billions of years. Most brown dwarfs observed in the Galaxy will be in the range 1-10 billion years (i.e. between 0 and 1 on this x-axis). The flux received by a planet in orbit around a star/brown dwarf will be proportional to the its luminosity divided by orbital radius squared. From this we can write that the orbital radius where a similar flux to that of the Earth around the Sun will be received is $$ R = \left( \frac{L_{BD}}{L_{\odot}} \right)^{1/2}\ {\rm au} $$ $$ \log\left(\frac{R}{1\ {\rm au}}\right) = 0.5 \log \left(\frac{L}{L_{\odot}}\right)$$ This you can get you answer immediately from the graph below. Choose the mass of your brown dwarf and its age. Find the log luminosity on the y-axis and halve this value. That is the the log of the orbital radius in astronomical units where a planet would receive the same amount of flux as the Earth from the Sun. e.g. Consider a 50$M_J$ brown dwarf that is a billion years old. Find the appropriate green curve and see that the y-axis value for x=0 (1 billion years) is -4.2. The log of the orbital radius (in au) at which a planet would receive the same amount of flux from the brown dwarf as does the Earth from the Sun would be -2.1. In linear units, this is $10^{-2.1} = 0.0079$ au, or 1.19 million km. 

The rate of detected gravitational waves of this amplitude or detections of gravitational waves due to the merger of black hole binaries are both unknown quantities for the moment. Measuring these is partly the purpose of the experiment. The rates of detection can be converted into a rate of mergers per unit volume in space and these can be compared with models and predictions. The aLIGO collaboration have released their first post-detection paper on that very topic - Abbott et al. (2016). The high mass of the discovered black holes implies that they either formed in a metal-poor environment from the core-collapse of massive stars or that they formed from the merger of smaller black holes in dense clusters. The range of rates previously predicted for the mergers of such objects covered a huge range because of the massive uncertainties in the production rate and mechanisms for binary formation of these objects, and lay in the range from 0 to about 1000 per year per cubic Gigaparsec. The rate actually implied by the single detection of a BH binary merger (from only 16 days of data) at $z=0.09$ is somewhere between 2 and 400 per year per cubic Gigaparsec. So at present, this doesn't really rule out a lot, but it is expected that with a few further detections in the coming months the uncertainty on this number will come down rapidly. 

"Clean the image", how apt, because most of what you can see is caused by dust. It is a bit difficult to comment specifically because I think you have chosen an example which is a combination of images and not all the images are in the visible part of the spectrum and so have had a "false colour" applied. In fact it is a combination of optical, X-ray and sub-mm images. In general terms red is present in false colour astronomical images, usually used to representing the coolest or longest wavelength light in the image. Red is also present in true-colour images of nebulae and is caused by light emitted due to transitions of atoms and ions between excited states separated by particular energies. Red light is predominantly due to Hydrogen alpha and ionised nitrogen emission. The coolest stars are also red in true colour images, simply because their pseudo-blackbody radiation spectra peak in the red part of the spectrum for temperatures lower than 5000 K. The integrated light from old stellar populations (predominantly cool main sequence stars and red giants) would therefore have a reddish tinge - for example in elliptical galaxies. As I said, it is hard to say in the case of this particular composite image, but the band across the centre of the galaxy is dust. It obscures (makes dark), the optical image, but warm dust glows in the sub-mm image. The structures coming out of the galaxy at right angles are jets from the active galactic nucleus traced in the X-ray. 

There are more stars and galaxies but not necessarily more information. You might choose to measure the information content in terms of photons received, in which case, for a given star/galaxy, this decreases as the inverse square of the distance, so the two effects cancel out. Astronomy is a constant struggle with the tension between these two competing dependencies. As we look further, not only do we see more of particular types of object, but we also get to see examples of rare objects - i.e. the tails of the distributions. On the other hand as we expand our horizons, so our grasp of what is going on becomes increasingly blurred in terms of spatial, spectral and temporal resolution. It is for that reason that bigger and bigger telescopes are built! The issue you raise concerning redshift is interesting. The co-moving volume versus look back time in any direction will not be a simple function (i.e. doesn't just go as the square of the lookback time) and depends critically on the adopted cosmological parameters. There is of course a limit in any case. Once we get back to the microwave background at $z=1100$, then further probing backwards with electromagnetic radiation is stymied by the optically thick nature of the universe at early times. 

There can be no such thing as a "supermassive neutron star". The theoretical upper mass limit for a neutron star is somewhere between 2 and 3 solar masses. Any more massive and they inevitably form black holes. So I am not clear what kind of "neutron objects" you were thinking of? Nor is it clear what you mean by "non-stellar" objects that will have the densities required to make neutron-degenerate matter? There aren't any apart from (I) the cores of massive stars at the ends of their lives. (II) Massive white dwarfs if they accrete matter over and above their Chandrasekhar limit. It is true if you could arrange to compress any matter to densities above $\sim 10^{15}$ kg/m$^3$ it would form neutron-degenerate material. But this requires (as far as we know) the conditions I listed above.