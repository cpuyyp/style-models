I'm not very experienced in test-driven development (TDD), but I'm trying to get into the groove. Here I am making a console app that creates records in a database. I bootstrapped by creating a console app and then let MSTest make a unit test for . I know I'm doing at least something right, because the tests didn't pass until I did the development -- they "drove" me to "develop". But I feel like maybe I'm still missing the point, as I didn't really test my code - I tested the database the code acted on. How would an experienced TDDer approach this? 

Is this useful or is there an obvious other way? The context is solving the problem of bubbling events in an asp.net site built with user controls and nested user controls. I found myself writing a ton of events. So instead of events, i'm using a technique to allow any client to watch an arbitrary session value. A shared context class for Page and UserControl. Updates to session values go through here as well as registrations for session value changes. 

I had this same issue today. I already had a table of the databases, so I wrote a program. It could be done with dynamic sql in the same way. That said, I have huge regrets that my original design used multiple databases in the first place and maybe the reality is that the reason its not something readily doable is related to the fact that its not something that ideally needs to be done (just a thought). 

I just wrote some code that is very representative of a recurring theme (in my coding world lately): repeated logic leads to an instinct to eliminate duplication which results in something that is more complex the tradeoff seems wrong to me (the examples of the negative side aren't worth posting - but this is probably the 20th console utility I've written in the past 12 months). I'm curious if I'm missing some techniques or if this is really just on of those "experience tells you when to do what" type of issues. Here's the code... I'm tempted to leave it as is, even though there will be about 20 of those if-blocks when I'm done. 

Feedback #6: You have no error handling around your request, but on an app this simplistic that may be by design. 

I am attempting to create a stored procedure that looks at one table and imports changes in that table to another. This stored procedure is going to be preformed on multiple source tables and will dump out into multiple log tables. The way the data in the log table is stored looks like this: 

Feedback #2: Angular provides a filter for formatting numbers, $number, so no need to write your own. Feedback #3: Use proper camelCase for function names (i.e. instead of ). As well as don't mix your snake_case and camelCase. Use snake_case for CONSTANTS (of which you have none) (i.e. instead of ). Feedback #4: Remove unused properties. You never set nor call , so get rid of it. Feedback #5: You're making a request without having all of your . If I change the value of the first select, but haven't changed the value of the second you are firing the promise each time. This can easily be fixed with a simple statement: 

I have one entity that depends on another however in my API service class I would like to just deal with the dependent entity. Am I doing this correctly and is there a better way to go about this? Post Entity 

Can someone please show me the light. I would preferably like to be able to update singular elements within the class without destroying and rewriting the file every time I have to update it. 

Feedback #1: Angular can actually build the select for you without the repeat via the ng-options attribute directive: 

The idea being that if a record changes the log table would indicate all the fields that changed with their new values but leave fields that didn't change for the record null. In order for this to work I need to grab a copy of what the record looked like in the most recent log version vs the current source version (the problem being that some of the values in the most recent log will be null) In order to accomplish that I am using the current query inside my stored procedure: 

Next, don't try to return every type of Object from the one Switch statement, it will always be ugly. In order to work out the next step maybe you could elaborate on what is happening outside the blackbox, e.g. if the calling code wants a Double you could add that into your enum: 

On the whole it's not at all bad, I find it readable and I'm sure that it does the job (one caveat to this is how does it handle cases where you have multiple instances of the same point e.g. {{1,1},{1,1},{1,2},{2,1}}), a few things that you could do to improve it.. 

Then onwards. Arguably this is borderline procedural but with these few steps I think that is acceptable. Edit: Less readable, more old school 

Firstly, underneath everything Javascript is an event driven language so I do not think that there is anything wrong with using an event driven design pattern if you are comfortable with it. Events are a great way to be able to interlink different components of your system without exposing the inner workings of them (loose coupling) and they add queuing by default. However they are more complex, they make it hard to trace behavior which in turn can make them hard to debug. I think that you would get a cleaner interface by developing using something called the revealing module pattern, there is an excellent resource on various design patterns by a guy called Addy Osmani at adyosmanio.com and the revealing module pattern specifically here. This (or a flavor of it) is commonly used in jQuery plugin development which you can see on the jQuery advanced plugin development page (see Keep private functions private). By following these principles you can keep the private stuff private and only expose the functions that you want the calling code to have access to. You mentioned specifically , and so a quick example of how that might look. 

I am creating user profile logic for a blogging platform. I have the model and then two separate models, and to control the user's various social media contacts (i.e. Facebook, Twitter, Google+, etc...). I am looking for feed back on the execution of the methods used to new . Is this the way you would handle it? Is there a better way? What are some of the issues you see with my methods (specifically in the service class)? The Models 

The stored procedure requires you to pass it the log table, the source table and the primary key that ties the two tables together (usually the source PK). And is a temp table created before this is executed in the stored procedure that simply stores column names that match between the source table and the log table (not all fields from the source are being logged). Now this code behaves as intended, the problem is the query takes about 10-20min to complete (just this part of the stored procedure). The heaviest query this is used on is looking at 48 fields in a table that only stores 300K records. There has got to be a way I can make this query faster. 

I have a service class called , the service class is called using an interface . The service class simply does CRUD methods for the in my context class. In my service class constructor I have: 

I am writing an application that either mirrors a file/directory into another location or creates a zip file "snap shot" of a file or directory and stores it in another location. The user is able to create "rules" where they define the source file/directory, the destination file/directory and if they are archiving how many archives to keep. The user is also able to exclude files/directories if they so choose. Now this service class is a lot of code and I am wondering if there is a better way to do this. Of course all of the methods that can be called by the interface are called with a BackgroundWorker.RunAsync() method. Any feed back on how to make this more efficient would be super appreciated. 

The main difference here is that you have deferred the creation of the random value to the callers end. The calling code will also be required to either use generics too: 

Now what you really want to do of course is collapse down that loop. I found that if you have LINQ (which I see you do not) you can use the operator, very simple e.g: 

So, if you're clever about getting an index in there you could write the algorithm (without validation) in just 3 lines and you'd have done a bit of functional programming which sets you up nicely for playing with a new language. 

Finally, you say you have read about the factory pattern, that is ultimately what you are playing with here. Note. I think Enum naming should use the singular (Type) rather than the plural (Types), you are not selecting an Object of type Types as your Object (Types.DOUBLE) represents just one type. 

Modify this to render just the first three links, then your ellipses (...) separator and then the final page number. EDIT to add pseudo code This is messy but hopefully gives you the idea, create your function, make it work and then post a new question asking how to make it prettier (for example tidy up the ifs, add logic to only render a single set of ellipses, don't repeat any rendering code). 

Caveat: I've never written a line of C#, nor do I know anything about its compiler. I think that the approach taken in your code could be considered the more modern approach. It is definitely more suitable for human consumption, and it makes it more easy to test individual parts of the algorithm. With luck it will compile down to very similar byte code too. But, your code is inelegant in that you loop twice skipping alternate elements. You also have a bit of smell where you have the code . I'm not sure what the accepted usage of Tuples is in C# but for internal use I'd have thought a single function that returns you an (insides, outsides) would be acceptable - if not a little helper class with two elements. This would modify you code to begin (pseudo-ish):