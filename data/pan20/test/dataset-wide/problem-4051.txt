Are there algorithms for finding $\omega_1\dots,\omega_n$, so that $\omega_i+\omega_j\le \|e_{ij}\|\ \forall i,j\quad\wedge\quad\sum{\omega_i}=max$ that are not based on linear programing, e.g. graph theoretic algorithms? 

I want to model the following situation: there is one production site (modelled by the source), a collection of depots (modelled by nodes without demand) and, of course many more customers (modelled by sinks). The production equals the demand and the transport of goods costs money; the costs are proportional to the amount of goods transported, but the factor may be different for different roads. Now comes the twist: a depot may only be visited if also a specific customer nearby will be served from that depot. The way I intend to model that requirement is by demanding that the flow from the depot to that customer shall be the maximum of all outflows from that depot. The question is now, as to whether such a maximum restriction upon the outflows of a node will preserve integrality of the solution. 

leave the sides of the hexagons unaltered, but for each hexagon, choose one of the diagonals at random, or leave it empty. Especially the case of the honeycomb in the plane is very easy to implement: the honeycomb can be squeezed to resemble a brickwall pattern of which the presence or absence of vertical edges can be decided via the parity of the row index of the 'higher' of its adjacent vertices. Whether a diagonal of a hexagon is present and, its orientation in case of presence, can be encoded by two bits. Honeycombs on cylinders come in two basic variants: either spiraling or not. Fullerene graphs $URL$ would be an example of planar graphs, that are bipartite with the exception of twelve pentagons and would thus require some preprocessing to make them bipartite. 

Under the assumption, that the quadrilateral is convex, the edges constituting to the matching with maximal edge-weight sum, are the diagonals. There is also a wiki page dedicated to quadrialterals ($URL$ which also discusses, how to calculate the are of convex quadrilaterals in various ways; among it the remarkable Bretschneider's formula. 

The Riemann mapping theorem (cf e.g. $URL$ essentially guarantees the existence of a biholomorphic mapping of a simply connected, open subset of the complex plane onto the unit disk. Questions: 

Besides in the calculation of distances, square roots appear naturally as the lower bound on the length of the boundary of planar regions of given area. 

The optimal solution of the original problem can then be derived from the shortest path in the vertex-split graph by contracting edges resembling a transition between edges. 

In a nutshell, the Moler and Morrison algorithm is a fast method for calculating euclidean distances in a numerically stable way by using reflections instead of the pythagorean theorem. In order to reflect a point $(x,y), 0\le y\le x,$ towards the $x$-axis in a norm-preserving way, Moler and Morrison use the line through $(0,0)$ and $(x,\frac{y}{2})$ as an approximate angle-bisector for the reflection of $(x,y)$; the convergence rate is cubic, as can be seen from the taylor series of $$\arctan\left(\frac{\tan(x)}{2}\right) = \frac{x}{2} + \frac{x^3}{8} + \frac{x^5}{32} + \frac{11 x^7}{1920} + \frac{25 x^9}{96768} - \frac{3443 x^{11}}{9676800} + O(x^{12})$$ Now, out of curiosity, I checked, what would happen, if the angle-bisector were approximated by the line through $(0,0)$ and $(x+\frac{y}{2}\frac{y}{x},\frac{y}{2})$, i.e. the line through the origin and the midpoint on the normal to $(x,y)$; well, somewhat surprising to me, the taylor series of $$\arctan\left(\frac{\frac{\sin(x)}{2}}{\cos(x)+\frac{\sin(x)}{2}\tan(x)}\right) = \frac{x}{2} - \frac{x^3}{8} - \frac{x^5}{32} - \frac{11 x^7}{1920} - \frac{25 x^9}{96768} + \frac{3443 x^{11}}{9676800} + O(x^{13})$$ and, investigating the obvious idea of taking as the $x$-coordinate of the point, through which the approximate angle-bisector should pass, the arithmetic mean of those two points, one gets $$\arctan\left(\frac{\frac{\sin(x)}{2}}{2\frac{\cos(x)}{2}+\frac{\sin(x)}{4}\tan(x)}\right) = \frac{x}{2} - \frac{x^5}{32} - \frac{5 x^7}{384} - \frac{x^9}{288} - \frac{289 x^{11}}{387072} + O(x^{13})$$ so the error of approximating the angle-bisector has reduced from $O(x^3)$ to $O(x^5)$. 

The 1979 publication Combinatorial Optimization with Rational Objective Functions of Nimrod Megiddo answers my question sufficiently well. 

I am asking because I haven't seen the Minkowski metric being mentioned or used in any article dealing with clustering of spatio-temporal data, especially not in training neural networks to classify motion patterns and I wonder how tolerable it is to use a wrong mathematical model for physical reality. 

as the all to all shortest paths can be calculated in polynomial time, it is also possible to determine all nodes, whose distance to some other node is not above some bound. That observation is not restricted to planar or geometric graphs. Now, provided that a geometric dominating set of nodes exists, an idea for at least approximately determining a minimal covering set could be to iteratively add the vertex that maximizes the number of shortest paths it is on, to the cover, remove it from the graph and determine the next vertex to add to the cover. Edit: An argument that just occured to me, is that the decision variant of the problem (i.e. the existence of a geometric cover) can be solved via an all shortest paths table, but it is not clear to me, whether and how the optimization variant is related to the existence variant. 

Meanwhile I found that the paper "Algorithm Engineering for Optimal Graph Bipartization" by Falk Hüffner is exactly what I was looking for. The key term that is related to the problem is that of an odd cycle transversal 

This is a followup question to Unconstrained Rational Combinatorial Optimization, where I asked for a solution of $$\min_{\alpha \in \lbrace0,1\rbrace^n}\frac{\alpha^T w}{\alpha^T m},\quad w \in \mathbb{R}^n, \ m\in\mathbb{N}^n,\ \|\alpha\|\ne 0 $$ I had accepted the Nimrod Megiddo's publication regarding combinatorial optimization with rational objective function; there is however a little difference in the kind of problem that is solved, namely that w.l.o.g.: $\ \alpha_0 = 1\ $is known. In my problem I don't however know à priori, which of the $\alpha_i$ can assumed to be $1$. 

Is there already name for the generalization of Clothoids to curves on smooth manifolds, i.e. where the curve's curvature depends linearly on the curve's length-parameter? In the euclidean plane Clothoids are a suitable idealized model for the trajectory of vehicles moving at constant speed while the steering wheel is also rotated at constant speed and I wonder if there are also idealized models for that kind of driving on smooth surfaces. 

Background of the question: The reason, why I am interested in the truth of the conjecture is related to the TSP problem. If the conjecture could be proven in the affirmative way, then it would be possible to identify quadruplets of vertices, that appear in the optimal tour through all points in the same order as in the shortest tour through that quadruplet of vertices, namely if those 4 vertices are adjacent to two crossing generalized diagonals of $G$; that in turn would reduce the number of candidate permutations, that could represent the optimal tour, by a constant factor, because then provably only one of the three possible tours through the quadruplet of vertices can resemble their relative order in the optimal tour. 

I am looking for a simple way of calculating minimum-weight perfect matchings in complete graphs with an even number of vertices. I know that there are implementations that are based on Edmond's celebrated Blossom algorithm available, but they come with some installation over/head/aches I currently don't want to invest. So, I was wondering, if the Bellman-Ford algorithm couldn't be tweaked to find such optimal matchings. Surely others may have had the same or a similar idea prior to the publication of Edmond's Blossom algorithm, but had to learn that that doesn't work. Now I would like to know what the obstructions against using Bellman-Ford for matching problems are; any pointers to articles or counter examples will be highly appreciated. An idea for preventing odd negative cycles from the answer of user36212 I conclude that the appearing of odd negative cycles is the reason why the "ordinary" Bellman-Ford algorithm can fail to report a minimum-weight perfect matching. Now my idea to rule out negative odd cycles would be to tweak the edge weights prior to applying the Bellman-Ford algorithm to solve the matching problem as described in the addendum. The tweak would be to incorporate edge-counting into shortest-path calculations, which can be done e.g. by adding to each edge-weight a sufficiently large value that is the same for each edge; the effect would be, that a cycle containing $m$ matching edges and $k$ non-matching edges will have non-negative length, whenever $k\ge m$. If $k=m$ then the added constants are canceled out and it depends only on the original edge weights, whether the sum is negative or not; if the sum is negative, the weight of the matching can be improved by exchanging the roles of the edges on the cycle. addendum the way I would use the Bellman-Ford algorithm would be to start with an arbitrary perfect matching and then, repeat to negate the weights of the matching-edges, check for negative cycles, exchange on such negative cycles the matching-edges with the non-matching edges, until no more negative cycles are detected. The question is now, what can go wrong with such an algorithm, whether negative cycles with an odd number of vertices could be reported and/or the running time could be exponential. 

Depending on space-dimension, kind of objects and, the number of runtime queries, different algorithms and datastructures may be advisable and thus welcome answers. My problem is however tied to the Euclidean plane and the objects are either convex polygons defined by a mesh or, their enclosing circles for reasons of speedup and, the cost of runtime queries outweighs that of preprocessing; the size of the datastructure plays however a role. 

for explaining, what is conjectured, further notation is introduced: $P_{uv}^E$, $L_{uv}^E$ and $C_{uv}^E$ shall be the set of edges, its sum of weights and its cardinality of a path between $u$ and $v$ consisting of edges from the entire edge-set $E$ of $G$, whereas for $P_{uv}^{MST}$, $L_{uv}^{MST}$ and $C_{uv}^{MST}$ the set of edges shall be restricted to $G$'s minimum spanning tree MST. Conjecture: $$\frac{L_{uv}^{MST}}{C_{uv}^{MST}}\ \le\ \frac{L_{uv}^E}{C_{uv}^E}\ \forall u,v\in G$$ 

What is the complexity of the following task: given a sequence $p_1, ..., p_n, p_1$ that defines a closed polyline in the euclidean plane, what is the complexity of finding a reordering of the points, that resembles a simple polygon? To clarify: the task is to find a suitable reordering as fast as possible; it is not the task to find a reordering that resembles a simple polygon that is optimal in some respect. The measure of complexity shall be the number of vertex-swaps. Edit: I am looking for algorithms (and their complexities) that transform any closed polyline into a simple polygon by a minimal number of vertex-swaps, using no extra memory and only the ability to detect and remove edge-intersection via vertex-swaps. The task is somehow related to sorting if one interpretes intersections as inversions and it would be interesting to see, whether the analogy allows the successful adaptation of sorting algorithms. 

Caveat: this is a pure idea and would thus need some checking of e.g. complexity and/or numerical stability. Due to their limited support (i.e. arguments, for which they are non-zero), B-Splines do not allow the technique of principal component analysis. 

As can be seen from the construction of the dual parabola as described here it is clear, that the astroid like curves inside convex polygons are actually composed of pieces of parabolas. A simple proof for the claimed parabolic segments is, that the perimeter-halfings, whenever they intersect a pair of edges in inner points, resemble the construction of a quadratic Beziér curve. To see that, simply elongate the two intersected edges to their intersection point and to a length, that equals half the perimeter of the convex polygon. The end points of the elongated edges are then the control points of a quadratic Beziér curve, along with the fact that as one endpoint of a perimeter-halfing slides towards the common intersection, the other end slides away from the intersection by the same distance, which is the same as the convex combination to obtain intermediate points on the control polygon of a Beziér curve that define the tanget to the parabolic arc. These quadratic Beziér curves also appear in String Art In case of a regular triangle the curve collapses to a point. 

This question is inspired by a lossy compression technique for polylines, namely to identify a subset of the points of polyline $\mathcal{P}$, whose removal yields a polyline $\mathcal{Q}$ within a given Hausdorff distance of $\mathcal{P}$. The primary objective of this "weeding" is to obtain $\mathcal{Q}$ with minimal number of points. The most prominent heuristic is the Ramer-Douglas-Peucker algorithm and I do not know of any exact algorithm. Question: given a polyline $\mathcal{P}$ with $n>2$ points, is there an algorithm or formulation of the optimization problem, that yields among all polylines $\mathcal{Q}$ with $d_H\left(\mathcal{P},\mathcal{Q}\right)\le c$ one of those with a minimal number of points? 

Being able to calculating the ordinal number of integer sets would to me be an important building block for calculating more elaborate ordinal numbers for use in graph theoretic algorithms, as indicated above. 

Meanwhile I found a simple counterexample: the least average edge-length of a path from node A to node D would be A$\mapsto$B$\mapsto$C$\mapsto$D with an average edge length of $\frac{1+1+2}{3}=\frac{4}{3}$, whereas in the MST (bold lines) the only path from A to D is A$\mapsto$D with a length of $\frac{2}{1}=2$ 

Let $G(V,E,\omega),\ card(V)=n,\ E=\lbrace\lbrace i,j\rbrace\ |\ i,j\in V\rbrace ,\ 0\ \lt\ \omega(\lbrace i,j\rbrace)\lt \infty\ \ \wedge\ \omega(\lbrace i,j\rbrace)+\omega(\lbrace j,k\rbrace)\ge\omega(\lbrace i,k\rbrace)\ \forall i,j,k\in V$ be a weighted, symmetric graph, where the weights satisfy the triangle inequality (i.e. the graph is metric). Let further $\Omega_i = \sum_{j\ne i}\omega\left(\lbrace i,j\rbrace\right)$ denote the summed weights of edges, that are adjacent to $v_i \in V$ Then one can formally associate two triangles $t_{i,j,k}$ and $T_{i,j,k}$ with each triplet of vertices and define the respective sets side lengths as $L(t_{i,j,k})=\lbrace\ \omega(\lbrace i,j\rbrace),\omega(\lbrace j,k\rbrace),\omega(\lbrace i,k\rbrace)\ \rbrace$ and $L(T_{i,j,k})=\lbrace\ \|\left(\omega\left(\lbrace i,j\rbrace\right),\Omega_j-\Omega_i\right)\|,\ \|\left(\omega\left(\lbrace j,k\rbrace\right),\Omega_k-\Omega_j\right)\|,\ \|\left(\omega\left(\lbrace i,k\rbrace\right),\Omega_k-\Omega_i\right)\|\ \rbrace$ Additionally we can formally calculate an area (resp. volume) from the side length via the Heron's formula (resp. via the Cayley-Menger determinant ). The quotient $\frac{vol(T_{i,j,k})}{vol(t_{i,j,k})}$ may be used as a measure for the slope of the $T_{i,j,k}$ 

Under the assumption, that $n$ points in random order are given, the best algorithm seems to be to construct the generalization of the Delaunay Triangulation to $d$-dimensional Euclidean space; that yields a collection of empty hyper-balls that are defined via $d+1$ of the points; the number of those hyper-balls is $O(n^{\lceil d/2 \rceil})$. The bound on the number of empty hyper-balls proves that the convex hull of $n$ points can't have an exponential number of faces like e.g. $O(2^n)$. From that collection of hyperballs the ones, whose center is outside the convex hull of their defining $k>=d+1$ points, are not inside the convex hull of the $n$ points and are not considered further. Then one has to check, whether the radius of any of the remaining hyper-balls is at least $1$. From the efficient construction of the Delaunay Triangulation in higher dimensions, it follows, that the answer to the question is yes. The situation doesn't change, if only the points on the convex hull shall be taken into account; this is so, because the points on the convex hull can also be efficiently determined via a generalized gift-wrapping algorithm and then the generalized Delaunay Triangulation can be constructed for those points and finally the largest empty hyper-ball can be determined as described before. If the unit ball is centered at the origin, then one has to check, whether distance of the the faces of the convex hull that were reported by the gift-wrapping algorithm, is not less than $1$. 

Where can I find example and counter examples to seemingly plausible assumption about the properties of optimal solutions of planar euclidean TSP instances? The reason for asking is that the problem instances, that one finds on the internet, seem to almost exclusively come from some real-world problems and are lacking theoretical motivation; the only open problem being to find the optimal solution. I would however like to have exemplary instances, that for e.g. demonstrate that an optimal tour may simultaneously contain the shortest and the longest edge, or, the longer diagonal of an empty, narrow rhombic region defined by four points of an TSP instance. Question: have there ever been attempts to collect optimal solutions of (small) planar euclidean TSP instances with unusual properties and, where could such collections be found?