Also, a lot of research funded by the military or DARPA or the OSD in the United States has a Final Report as its ultimate end-result and the means of disseminating the findings and recommendations, rather than a peer-reviewed journal article. It is a shame that have an educational e-mail address for affiliation gets you a bye for submitting to arxiv; perhaps even academics should need an endorsement prior to being allowed to commit an article to arxiv. The seed recommenders would have to have been planted earlier, anyway. 

I've played with this problem in real life with a TiVo, wanting it to go to sleep (a low power consumption state) without having to turn on the monitor to watch as its states changed. The TiVo, or any remote, uses an alphabet size of at least as many buttons as there are on the remote control. However, a little hunting on wikipedia shows that "Synchronizing Word" is where "reset sequence" leads to. For $n$-state DFAs over a $k$-letter input alphabet in which all state transitions preserve the cyclic order of the states, an algorithm by David Eppstein finds a synchronizing word in $O(n^3+kn^2)$ time and $O(n^2)$ space. The name of that paper is "Reset Sequences for Monotonic Automata" . Finding and estimating the length of the "reset sequence" for a Deterministic Finite Automaton has been studied since the 1960's. The Černý conjecture posits $(n-1)^2$ as the upper bound of for the length of the shortest synchronizing word, for any $n$-state complete DFA (a DFA with complete state transition graph). The way you've posed your question sets $k=2$, since the transitions can only be labeled by the two buttons as input, thus the Deterministic Finite Automaton underlying your question will have a directed graph with at most two outbound arcs at each state. 

The question as proposed is more like a random walk on a $C_{n+1}$, the cycle graph of size $n+1$, rather than a 1-dimensional random walk on $\mathbb{Z}^1$. This is because of the wrap-around conditions imposed by the way the problem is defined. This is a biased random walk on a graph, with the graph being $C_{n+1}$. For simplicity, label all of the vertices of this cycle graph clockwise from $0,1,...,n-1,n$. Start the random walk at the node labeled $0$ and proceed in the negative direction (CCW, counterclockwise) with the probability $1-p$ and proceed in the positive direction (CW, clockwise) with the probability $p$. If $p=1$ or $p=0$, then you have a deterministic process that will hit the boundary at $t=kn, k\in \mathbb{Z}$. It can also be seen that is $p = 0.5$, you can expect to hit the wrap-around boundary at a distance of $n$ on average at time $t=n^2$, or you can come back to the center "boundary" with the standard expectation of an unbiased random walk returning to $0$ before it hits distance $-n$ or $+n$. If $p\ne 0.5$, then there is a drift. If $p>0.5$ then there is a drift in the clockwise direction, if $p<0.5$ then there is a drift in the counterclockwise direction. Now try to find the expected hitting time for the clockwise boundary, or counterclockwise boundary, or for returning to $0$. The drift is $p-(1-p)=2p-1$. Define the transitions of this system as the tri-diagonal stochastic matrix $T$ with $n+1$ rows and $n+1$ columns, where each element $T_{i,j}$ is 

This might be a way to start going about proving it: Conway's Game of Life is Turing complete: it is possible to simulate a universal turing machine within the Game of Life. Deciding whether a Turing machine will halt or continue infinitely for an input is the "Halting Problem". It is not possible to have a general algorithm that decides the Halting Problem for all possible inputs to a Turing machine simulated on the Game of Life. Thus the Halting Problem is also undecidable for arbitrary inputs on particular subsets of initial patterns on the Game of Life: specifically those which implement a Turing machine simulation. It should be a small step from there to being able to say that there is no general pattern or algorithm for deciding the ultimate outcome of running Conway's Life on any arbitrary pattern, except by actually simulating the running of Conway's Life on that particular arbitrary pattern. Thus there is no general algorithm for deciding the ultimate result of Life on an initial pattern or for deciding the halting pattern on an initial pattern, except for actually running the simulation. And since there is no short-cut to simulating Conway's Life on a pattern, there is no algorithmic way to predict the outcome of Life on an initial pattern, thus it is not possible to decide the halting problem for Life. 

Iterated multiple times, this generates a Sierpinski triangle with a few extra points thrown in at the beginning. If your initial point is definitely on the Sierpinski triangle (say you start with one of the vertices as your initial point $P_0$), then all of the subsequent points are definitely in the Sierpinski triangle. The Sierpinski triangle has Hausdorff dimension $log(3)/log(2)$ ≈ $1.585$ (copied from wikipedia) I remember writing this as a program in BASIC on the Apple ][, but I cannot recall the source of the question that led me to the program. Most likely it was an article in Byte or Creative Computing. This is similar to your selecting a new point defined as the circumcenter of your three points, and then using that new point along with two of the vertices of your current triangle to generate then next triangle to find the circumcenter of. Your iterated method leads to points outside of the triangle, leading to a wandering triangle in most cases, leading to your second question, in which cases of initial triangles do you end up with convergence or divergence, which seems to have been addressed with some of the earlier answers. I'll think about that a bit more before commenting on that. This "iterated line-segment midpoint" technique definitely does not converge. It leads to selecting points within the set of points contained within the Sierpinski Triangle. The new points also do not diverge away; the points always stay within the confines of the triangle $ABC$, and if the initial point is in the Sierpinski triangle, then the set of points generated are all also within the set of points in Sierpinski triangle. 

The question as you have it formulated currently has "no" for an answer. If the loss of coherent information means you cannot correct the errors, then obviously the loss of coherent information means you cannot correct any errors. @unknown (yahoo) question asker, I think I follow the gist of what you are asking, however. In non-quantum coding, it is possible to generate error correcting codes that are capable of correcting $a$-bit errors per $n$ bits (obviously, $a \lt n$), and of detecting $b$-bit errors per $n$ bits, ($a \lt b \lt n$), while greater than $b$ erroneous bits would be a catastrophic undetectable and uncorrectable error. These error-correcting codes depend on sending redundant information, decreasing the information content or the information content below the maximal Shannon information density possible on that communication stream. There is no way around having to reduce information density to increase the quality of the transmission. Hamming codes allow for 1-bit error correction, 2-bit detection; Reed-Solomon codes are used to perform error correction on audio compact-discs. While your comment says you "meant not PERFECT error correction", your question still says "to provide for perfect error correction". Perhaps you could edit your question to provide more rigorous mathematical definitions and ask explicitly exactly what you mean.