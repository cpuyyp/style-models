Logical positivism is sort of self contradictory in a different way. It rejects assumptions about the existence of an underlying (observer independent objective) reality, but uncritically accepts the existence of empirical data. But often empirical data can only be collected, if there is at least some theory of an underlying reality. It is a bit like saying "the statistics says ..." without realising how much what the statistics say is influenced by how you asked the questions and how you interpreted the answers. Edit Maybe the downvote is justified. I now tried to track down references for the critique of logical positivism expressed above. So far, the best source seems to be the critique of Ernst Mach's idea that a physical theory should only contain quantities which can be observed. The problem here is that it is unclear to which extend logical positivism subscribes to Ernst Mach's idea. Werner Heisenberg was confronted with that critique in 1926 by Albert Einstein (see Werner Heisenberg "Der Teil und das Ganze" Kapitel 5), but that doesn't mean that Einstein is the original author of that critique. Interestingly enough though, that critique cannot be applied to the original Copenhagen interpretation of quantum mechanics, since it explicitly accepts and uses classical physics as the mean to describe observations, i.e. empirical data. (Not sure whether this means that the original Copenhagen interpretation is not positivistic.) 

The special relativity theory teaches us that simultaneity is relative to the motion of our reference frame. This seems to contradict the intuitive notion of the present to be instantaneous. Some additional paradoxes from quantum mechanics and general relativity seem to question our intuitive notion of time and present even more so that a static deterministic universe seems to be the only consistent solution compatible with these experimentally well confirmed paradoxes. However, assume that we are convinced that the universe is dynamic and non-deterministic. Are there any specific properties of the present, like being instantaneous, that are necessarily implied by this? Even if we say that the present is the interface between the past and the future, does it really follow that this interface must be infinitely sharp? At least for computer simulations of hyperbolic partial differential equations, it can sometimes be convenient to use a multistep scheme, or to use a position dependent time shift (for simulating oblique incidence on a periodic structure). However, this computer simulation is effectively analogous to the static deterministic universe, hence it is unclear what we can really conclude from this for the dynamic non-deterministic case. 

If we acknowledge the existence of the real thing, it is often possible to produce an emulation of it. Often, this emulation is better than the real thing for all practical purposes. The purpose of an emulation is to reproduce all relevant features of the external measurable behavior of the real thing. The advantage (and disadvantage) of the notion of emulation is that its intention and meaning is more restricted than the intention and meaning of the notion of simulation. A simulation related to some real thing can have many different purposes. The perfect reproduction of the external measurable behavior of some real thing is normally not among these purposes. In fact, simulation is often used in situations where there is considerable uncertainty about the actual behavior of the real thing. Simulation is sometimes used to enable observation of internal states which would otherwise be unobservable. In the context of Searle's Chinese room, we have a computer program related to the understanding of Chinese. The Chinese room is assumed to emulate the operation of this computer program. Now we ask ourself the question whether the Chinese room understands Chinese. Questions 

If you invent an algorithm, the empirical approach to prove that you have not left out any important detail is to implement it in an actual programming language. Depending on the used programming language, this can look quite ugly and contingent. However, the deeper problem is that even if your program compiles and works correctly for all problems on which you test it, what does this prove? Well, it forces you to lay down all your cards, so if later something turns out to miss, you can't just claim that it had been there all along and was only not understood correctly. My point here is that even if ZFC should turn out to correspond to an ugly programming language, it still serves the purpose of a certain kind of rigor good enough, even if this kind of rigor might not be the last word regarding rigor. Conclusion: Rigor in mathematics has something to do with playing with open cards and not withholding boring details. 

From all your suggestions, only "the set of interpretations" is related to "semantics". For some given (formal) language, its "semantics" is what it can mean. There may be more than one way to interpret a given sentence (from a formal language). I'm mostly thinking about different compilers for a fixed programming language here, but the same is true in most other contexts as well. 

In first-order logic, I can essentially just ignore issues related to nonexistence and invalid formulas, without losing much. There is also free logic, in case I'm not happy with simply ignoring these issues. While trying to make sense of a description and discussion of the Barcan formula, I started to wonder whether ignoring these issues also for modal logic could "work". Of course, I would want to have a predicate which tells me whether an object is nonexistent in a given world, but such a predicate in itself doesn't create much inconvenience. Ignoring also seems to imply that formulas which are only invalid in some worlds must be forbidden, hence I can't declare formulas which contain a nonexistent object in an "inconvenient" place as invalid. However, this would be a small price to pay if it would "work". I have not yet read a systematic introduction to modal logic, but only SEP and wikipedia articles on modal logic (and Kripke semantics). So my question is just whether ignoring issues related to nonexistence and invalid formulas is a reasonable option for (quantified) modal logic, in the same sense as I typically ignore these issues for first-order logic. 

I find the description of the interaction between state, transition and time (past, present and future) in Kierkegaard's book intriguing. It also reminds me of the wave particle dualism of quantum mechanics, where the wave nature corresponds more to the state (which normally cannot be measured directly), and the particle nature corresponds more to the transitions (which often have observable side effects). I also ask myself how much other authors after Kierkegaard have used these concepts in similar ways. 

What does this 63%, i.e. the number 0.63 means in this context? It means they are man hunting again in Germany, which always feels strange to me when I see the havoc caused by people like Silvio Berlusconi at the same time. But back to your question about the meaning of such numbers, this a number automatically generated by some more or less carefully designed procedure. The same is probably also true for probabilities reported by the weather forecast. The point about such automatically generated numbers is that you can try to calibrate the translation of these numbers into probabilities such that the deviation from actual frequentist probabilities is minimized. As such a calibration doesn't really modify the underlying procedure, the reported numbers can't be true testable frequentist probabilities. All we have done by the calibration is to convert the output of the procedure into a "measurement scale" which we know how to interpret (more or less intuitively). 

As long as a (specific) QM interpretation still contains physical misunderstandings, it should stay firmly in the realm of physics. So if David Deutsch would claim that the many world interpretation is the only possible interpretation of QM, and that a quantum computer proves his point, because it gets its strength by computing in all those many worlds simultaneously, then it is the job of other physicists to point out that he is perpetuating physical misunderstandings. Or if Gerard't Hooft would claim that Feynmann diagrams represent pathes of virtual particles, then physicists must decide whether this can be a valid interpretation at all from a physical point of view. And if Dieter Zeh would claim that the density matrix is just an auxiliary mathematical construction which should under no circumstances be used a part of an interpretation of QM, then this is again a question which can be answered by physicists without the help of a philosopher. On the other hand, what about discussing whether the currently used pragmatic interpretation of QM still has anything to do with Niels Bohr's interpretation of QM, or whether those interpretation disagree with the Copenhagen interpretation? Since neither the methods used to investagate such question, nor the answers themselves are of any interest to physics, one could say that they belong to philosophy (or maybe sociology). 

1. Complex numbers are nevertheless named correctly, according to the red herring principle in mathematics. It stresses that a “red herring” need not, in general, be either red or a herring. Don't laugh. Look it up and think about it, then you will understand why. 

If I remember correctly, mathematics originally meant "the knowledge which is teachable", in contrast to the knowledge which can only be gained by experience. The emergence of formal logical systems like ZFC didn't worry mathematicians much in this respect. However, the computer proof of the four color theorem did really worry them, in exactly the way you suggest. Both facts are easy to understand historically. (1) When ZFC emerged, physical computers where much weaker in their computational power than a skilled mathematician, so the computer only served as a logical tool for making the notion of "decidability" precise: "a statement is decidable, if and only if it can be proved or disproved in a finite amount of time by an idealized computer". (2) When the four color theorem was first published, it could be understood neither by a computer nor by a human alone. So it clearly was experimentation in exactly the way excluded by the original meaning of mathematics. In a certain sense, the proof was simply not written down correctly, even so it was clear that it should be possible to write it down correctly, and find out whether it is correct or not. This has been done later, the original proof turned out to be incomplete, but it was possible to fill the holes. So the initial controversy was both justified and unjustified in a certain sense. But today, physical computers have more computational power than a skilled mathematician, and the proof of the four color theorem has been formalized such that it can be understood and verified by a computer. Progress on the Riemann hypothesis has been in the form of computers checking that it holds for the first few millions zeros of the zeta function. The thing with the fully formal proof is debatable, but the computerized experimental verification of the Riemann hypothesis is clearly impure experimentation. For technical reasons, we have to accept that the computerized experimental verification of the Riemann hypothesis is mathematics, so mathematics is indeed not as pure as originally thought. 

The connection between the law of excluded middle and partially defined operations is probably hard to appreciate without some background. Sadly, this background might be slightly too mathematical for a philosophy site, but let me add it nevertheless. A Boolean algebra is a distributive lattice with an involutive negate operation. A lattice is a partially ordered set where any two elements have a greatest lower bound (meet) a least upper bound (join). A semilattice has only one of these two operations guaranteed to be defined everywhere. A semilattice can also be defined as an idempotent commutative inverse semigroup. And an inverse semigroup can be represented as a subsemigroup of the partial one-one transformations of a set. The connection to the law of excluded middle is that often the structure of a complete semilattice (among propositions, formulas or sentences) arises naturally, but a complete semilattice is nearly indistinguishable from a complete lattice. But you can define an implication operation ("from A follows B" for a Heyting algebra, but in general rather "from A, B, C, ... follows Z") which allows to distinguish "and" and "or" (or "meet" and "join") properly. This is important, because the symmetry between "and" and "or" so typical for classical logic is often just an illusion caused by the fact that complete semilattices are so hard to distinguish from complete lattices. But if the maximal element (infinity) is removed from the complete semilattice, then it becomes much easier to distinguish it from a complete lattice. 

After reading "In Defense of the Simplest Quantified Modal Logic", I wonder how to add functions to the language of the simplest quantified modal logic (QML for short). The simplest model of QML has a "global" non-empty domain of individuals that all worlds share. Hence, I think one can interpret it as a kind of many-valued logic, especially with respect to the problem of how to add functions to the language. I haven't seen any reference that explains how to add functions to quantified modal logic or many-valued logic. My question is how to do it for QML or many-valued logic. I would also like to know whether adding functions extends the language in a non-trivial way that can't be emulated by the same language without functions. See my explanations below why I'm worried about this possibility. 

The complex numbers form a complete algebraically closed field, but treating them as numbers makes it difficult to define what numbers are1. As other answers indicated, should we consider quaternions, octonions or sedenions as numbers? What about p-adic numbers? What immediately comes to my mind is that you can't tell "i" from "-i", even if you would find a real world manifestation of complex numbers. For quaternions, you can't tell "i" from any unreal quaternion of length one. Is there a similar problem for p-adic numbers? I don't know, but I could check. However, I wrote an answer to this question, because nobody has mentioned the surreal numbers yet. They are the largest possible ordered field, and being an ordered field should be sufficient for the label "number". 

At least the English translation talks about bodies and matter as if they were identical. It leaves me wondering how to make sense of his explanations for a block ice, which first get heated until it melts, and then get heated further until it evaporates. Is it still impenetrable after it has evaporated? Or do Euler's arguments only apply to solid bodies? But if they only apply to solid bodies, then do they also apply to solid bodies which contain fluids (or freely moving electrons)? Or what about elaborate mechanical mechanisms with suitable hinges to allow certain internal movements? None of the criticisms voiced above relies on new knowledge not yet available to Euler. How should a conclusion be valid, if we don't even know what the conclusion is supposed to mean? 

Three nice answers and not a single upvote, I certainly won't put much effort into my answer under these circumstances. Frank P. Ramsey in 

How about Alfred Teitelbaum or Alfred Horn? (These are not philosophers, I know.) Seriously, I think the notions of standard and non-standard model arouse out of necessity, and are not directly related to metaphysical questions. On the other hand, many theories have distinguished models: 

I don't know whether the untyped lambda calculus and first-order logic can be compared directly, but the Simple Type Theory is a typed lambda calculus and at the same time a formalization of higher-order logic. According to wikipedia: