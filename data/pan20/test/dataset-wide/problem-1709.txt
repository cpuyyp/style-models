My ESX hosts each have 8 NICS. I have set up 2 NICs for our iSCSI SAN - each is connected to a different SAN switch. 2 NICs are set up for vMotion and Service Console - these are each connected to a different core switch (ports are trunked with VLANs dedicated to vMotion and Management) I now have four ports left over. Currently we have these set up each going into our default VLAN. Two NICs are connected to one core-switch and two are connected to the other. We decided to aggregate the connections to each switch - so they are teamed at the vswitch end, and port channelled at the physical switch end. I am now reading that port channelling these connections is not particularly useful, perhaps even over complicating things. Is there a particular problem with using port channels for VMware? What method provides the best balance between redundancy and performance? 

What am I missing here? The same account can log in to other Windows Server 2008 R2 Domain Controllers fine. Update: found this technet article which discusses various error messages to do with login and why they appear. Looking at the settings for RDP-Listener I see that there is a local group called Remote Desktop Users on the server, but the domain group is not listed. A local Administrators group still exists too. On other Domain Controllers the Domain version of the group is listed. 

As you can see, with spanning tree enabled everywhere, Switch A's port-channel goes into discarding state. If I disable spanning tree on Switch A communication between two switches works. 

Drawing on Chapter 4 of IPsec Virtual Private Network Fundamentals the following architectural issues can disrupt IPsec traffic: 

We have had some issues with accessing certain things through the ISP used by one of our branch offices. They have asked us to allow them SNMP polling access to our Cisco ASA 5505 in order to check bandwidth use there. I am not sure exactly what they expect to get from this, but I want to help them solve our problem without being disruptive. So my question is, what is the risk of allowing our ISP SNMP polling access to our ASA? 

Implementing Network Security in CentOS/RedHat Servers is a great introduction to Linux network security - it isn't a walkthrough - it explains things in depth, and well worth a read. Despite the title, it doesn't just apply to CentOS/RedHat. 

A physical to virtual conversion isn't quite what you asked for, but is a pretty effective backup - VMWare Converter Standalone will do this (you need to specify the source as RHEL). You could then trim down the spec and run it in VMware player or on an ESX server. 

We use Cisco ASA for our IPSEC VPNs, using the EZVPN method. From time to time we encounter problems where an ISP has made a change to their network and our VPN stops working. Nine times out of ten the ISP denies that their change could have stopped this working - I suspect because they don't understand exactly what might have caused the problem. Rather than just bashing heads with them I want to try and point them in a direction that might get a speedier resolution. In my current incident, I can ssh onto the external interface of the ASA and do a little poking around: 

Unless you have good reason, don't put your SQL server on the edge of your network. I see that you think you need SQL on the internet because developers need access. That isn't a good reason to make SQL available to the internet. You have a number of options for allowing your developers to access the server without making SQL server accessible. They could SSH to the server and run SQL commands via command line. They could use a VPN to connect to the server, and run any app. You could even lock down at the firewall to only allow access from your developers. Many options that are more secure are available to you. Just for the record, my favourite would be SSH access using keys for authentication. That allows you more security options, and your developers can use SSH to tunnel to the server if necessary, with command line access when it isn't. You can secure the server against the developers using chroot, jail or just plain old permissions 

Look at the error messages in TMG relating to internal traffic (172.16.x.x ones are a good place to start). Figure out what hosts those relate to, and whether or not these are appropriate actions for the firewall to take for the traffic on those hosts. Never assume that a firewall comes with appropriate configuration out of the box especially if that firewall is to be deployed internally. I'd also suggest using separate switches for your iSCSI Storage Network, rather than trying to segregate the traffic with VLANs. A lot easier to get your head around, and you really need to get your iSCSI traffic right if you are using it for VM hard drives! 

I've been challenged to "improve Skype performance" for calls within my organisation. Having read the Skype IT Administrators Guide I am wondering whether we might have a performance issue where the Skype Clients in a call are all on our WAN. The call is initiated by a Skype Client at our head office, and terminated on a Skype Client in a remote office connected via IPSEC VPN. Where this happens, I assume the trafficfrom Client A (encrypted by Skype) goes to our ASA 5510, where it is furtehr encrypted, sent to the remote ASA 5505 decrypted, then passed to Client B which decrypts the Skype encryption. Would the call quality benefit if the traffic didn't go over the VPN, but instead only relied on Skype's encryption? I imagine I could achieve this by setting up a SOCKS5 proxy in our HQ DMZ for Skype traffic. Then the traffic goes from Client A to Proxy, over the Skype relay network, then arrives at Cisco ASA 5505 as any other internet traffic, and then to Client B. Is there likely to be any performance benefit in doing this? If so, is there a way to do it that doesn't require a proxy? Has anyone else tackled this? 

I found a blog post detailing this problem and how someone resolved it. Don't know how this will affect log analysis, but noting it here as I found it useful. 

Should I be setting up connections from each Remote DC to all 3 of our HQ DCs, from each Remote DC to only one of the HQ DCs, or manually spreading the load? Is there a way I can "reset" the configuration so that AD automatically generates the most appropriate connections? 

Whatever list system you use, there will be a bulk subscribe function which allows you to shove in a bunch of email addresses. If it is a really large list with commercial value, you might also look at a professional mailing list service like MailChimp. They are free for up to 2000 subscribers, so I'd consider looking at that option anyway. 

Many monitoring applications will include a network discovery tool which can query snmp on all devices it discovers. Some will even allow you to enter multiple SNMP community strings and it will try each of them. 

If these are going to be critical tools for your users, then you need to build something resilient. A single SBS 2003 Server isn't going to be either resilient or powerful enough, so you are looking at something that clusters. You have a lot of choice. But before you start down this route, with only 25 clients and running SBS you seem like a fairly small shop. Think long and hard about whether you should go down this route. What is really wrong with what you are already doing? Have you got any budget? Because while maybe getting cheaper hardware for user, you will have additional server costs, licensing issues and a learning curve to breach. Is this of value to your employers, yourself and your users? 

You can then download the captures from each device at and analyse it in Wireshark. My packet captures showed that ISAKMP traffic outlined above was getting fragmented - since those packets are encrypted, once they are fragmented it is hard to put them back together and things break. Giving this information to the ISP meant they could do their own focussed checking, and resulted in them making some changes to a firewall. Turns out the ISP was blocking all ICMP traffic on their edge router, which meant that Path MTU Discovery was broken, resulting in fragmented ISAKMP packets. Once they stopped blanket blocking ICMP the VPN came up (and I expect all their customers started getting better service in general). 

Someone must have registered that in public DNS with an A record of 127.0.0.1. I am seeing this too when I do an nslookup for dp.000.in. whois for 000.in doesn't reveal much. Poking around with some similar fqdns (do.000.in and dq.ooo.in) brings up the IP address 64.74.223.36, but there aren't any websites there. That doesn't really answer the question. 

I work on Sharepoint 2007 intranet with 500+Gb of documents. Running a full crawl takes over 48 hours. When we first set Sharepoint up, and it was much smaller, we ran Full crawl jobs on a weekly basis, and incrementals each night. Is there any benefit to running full crawls? Or should I reduce the frequency to monthly - or even do it less frequently than that? 

Given that only the root of each site will change (e.g. $URL$ becomes $URL$ it should be possible to do smart redirection for the rest of the URL which actually points at the documents, pages etc. I know this would be possible with Apache at least. However, the combination of Sharepoint 2007 and IIS6 is making it hard to track down the best way of achieving a friendly solution that keeps the user happy. 

If you can save a file into the folder through Samba then you can examine the properties of the file to see which user and group own it - that should be your answer. 

You may need to run the above as root, in case the user doesn't have permission to access the directory ethtool is in. Once you have found ethtool, and made sure its directory is in the users path, you can then check the permissions on the folder and ethtool itself. 

I know this may be an obvious question, but have you verified that you are using the correct IP address to access the ASA? Are you connecting via a VLAN that has management access? Check the config for changes to these. 

Our AD is a basic hub/spoke design. We have a headquarters in London, and remote offices. The remote offices are connected via VPN to HQ. We have 3 domain controllers at HQ, and one in each remote office. We have had Windows 2000, Windows 2003 and Windows 2008 R2 domain controllers in place. Over the years, any automatic configuration put in place by AD itself has been eroded, and we now have a situation where the NTDS settings for each server has been manually set. I see that some remote servers are connected to all 3 of our HQ Domain Controllers, some are connected to 2 and some to only 1. Looking at the connections back from the HQ Domain Controllers, these are similarly variable. Here is a picture of how some offices are setup: 

You may find that during testing of this, web caching may result in you seeing the wrong page. Your browser/OS probably has a local cache, which you can usually bypass by pressing CTRL+F5 to refresh the page. It isn't that likely that a cache outside you control (e.g. your place of work, or your ISP) has cached content for the URL, but not impossible. You can also fall foul of DNS cacheing. You can clear your local DNS cache in Windows by typing and then see whether re-loading the page results in the content you expect. Again, there may be DNS cache in between you and the nameservers for this domain, and they can cause problems too based on the TTL for the record. Finally, it can take some time for DNS changes to be reflected globally (up to 48 hours) so there is a chance that you won't see the results of your change for some time. From what I can see your settings are correct, so probably you just need to wait a while - generally it is a lot less than 48 hours.