I have written a paper, which includes an appendix discussing how to obtain numerical evidence for the result of the paper. Now the computation essentially works as follows: 

Operators of the form $$ H = -\frac{d^2}{dx^2} + F x,\quad \text{on } L^2((-\infty,\infty)) $$ are discussed in Cycon--Froese--Kirsch--Simon "Schroedinger Operators". In example 3 at the end of Section 4.1. I know them by the name of Stark Operator. But googling didn't yield any good reference. You'll have to dig through the references to see how the eigenfunctions of $H$ behave. At least at 0 energy, you can solve the problem explicitly with Airy functions, and you'll see that the behavior is very different than for the free case $H_0 = -\frac{d^2}{dx^2}$. This is to be expected since their spectra satisfy $$ \sigma(H) = (-\infty,\infty) \neq \sigma(H_0) = [0, \infty). $$ 

Hi. First, I suppose that the Lyapunov exponent is given by $$ \lim_{n\to\infty} \frac{1}{n} \int \log\|A(x,n)\| d\mu(x), $$ where $\mu$ is an appropriate ergodic measure. (You have some base dynamics for the cocycle, i.e. $A(x,n + m ) = A(T^n x, m) A(x,n)$ and $T$ is $\mu$ ergodic. Then $$ \lim_{n\to\infty} \frac{1}{n} \log\|A(x,n)\|, $$ for almost every $x$, not for every. This follows from the subadditive ergodic theorem. The inequality is very rarely strict. For the simplest example, consider a dynamic over a one-point space given by $A(x,n) = A^n$ for $$ A = B \begin{pmatrix} 2 & 0 \\\ 0 & \frac{1}{2} \end{pmatrix} B^{-1}. $$ It is easy to check that the Lyapunov exponent will be $2$, but using an appropriate choice of $B$, one can make $\|A\|$ arbitrarily large. 

Let me just sketch some thing else. If $U(t_0) V = V$ for some subspace $V$ of the base Hilbert space, then we know that there exists an orthonormal basis of $V$ consisting of eigenvectors of $H$. This is the commutation result, I mentioned in the comments. So, it clearly suffices to consider $H$ restricted to that subspace. The question that remains is how can it happen that $U(t_0)$ maps $n$ vectors into themselves, when $V$ is an $n$ dimensional space. If I am not totally mistaken this implies that $U(t_0)$ when restricted to $V$ is the identity. Continuing my example. If the eigenvalues $E_1$ and $E_2$ satisfy $n E_1 = m E_2$ for some integers $n,m$, then we have that for any $$ v_1 = a_1 \psi_1 + b_1 \psi_2,\quad v_2 = a_2 \psi_1 + b_2 \psi_2 $$ the claimed property holds. Although not all eigenvalues are rational. 

Just, a basic property one establish, when one assumes that $$ w^*(x) \leq C w(x) $$ is that $w(x)$ grows subexponentially, if furthermore $w(x)$ is continuous. Define $A = C \cdot \sup_{|x| \leq 1} |w(x)|$. Then $$ |w(x)| \leq A^{|x|}. $$ Proof: Let $n = \lfloor |x| \rfloor$. Then we can write $x = n y + z$, where $y = \frac{x}{|x|}$ so $|y|, |z| \leq 1$. By assumption, we have for $|u| \leq 1$ that $C w(x) \geq w(x+u)/ w(u)$ so that $$ w(x+u) \leq C w(x) w(u) \leq A w(x). $$ Applying this $n$ times yields the claim. q.e.d. 

There is first Polya's estimate that if $f$ is a monic polynomial, then $$ |\{x\in \mathbb{R}:\quad |f(x)|\leq 2\}| \leq 4. $$ A proof can be found in the book "Proofs from the book". One can obtain inequalities for non-monic polynomials by rescaling. Second there is Cartan's lemma or estimate. It can for example be found in Levin's book on entire functions. The estimate even holds for analytic functions. The basic statement is: Let $f: G \to \mathbb{C}$ be analytic and assume that $f$ is bounded by $1$ on a disc of radius $2$. Then there are constant $C, c > 0$ such that $$ |\{z\in \mathbb{C}:\quad |z| < 1, | f(z)| \leq e^{-s}\}| \leq C \exp\left( - \frac{c}{\log(\varepsilon^{-1})} s \right) $$ where $\varepsilon = |f(0)|$. In fact, this is sharper, since it provides some information on how the set looks. For a polynomial it's just the union of its degree many disks. (For analytic functions countably many). 

Here's how to carry out direct proof: By Weyl's criterion it suffices to show $$ S_N = \frac{1}{N} \sum_{n=1}^{N} e(k n^{\rho}) \to 0 $$ for $k \in \mathbb{Z} \setminus \{0\}$ and $\rho \in (1,2)$. Now $$ |S_N|^2 = \frac{1}{N^2} \sum_{m=1}^{N} \sum_{n=1}^{N} e(k (n^{\rho} - m^{\rho})) $$ Write $n = m + h$. Then by Taylor's theorem $(m+h)^{\rho} - m^{\rho} = \rho h \cdot m^{\rho - 1} + \frac{\rho(\rho - 1)h^2 }{2 (m + \xi)^{2 - \rho}}$ for some $|\xi| \leq h$. Hence $$ |S_N|^2 \leq \frac{1}{N^2} \sum_{m=1}^{N} \left|\sum_{h} e(k \rho h \cdot m^{\rho - 1} + \dots) \right| $$ here one needs to figure out the limit of $h$ and how to get rid of the $\dots$ term. This trick is called Weyl differencing (e.g. how you show the claim for the sequence $\alpha n^2$). The conclusion is that $|S_N|^2 \leq N$, which suffices to deduce the claim. 

I believe the following argument works for $d = 2$: $A = f^{-1}((-\infty, t))$ and $B= f^{-1}((t,\infty))$ are two open sets whose complement is contained in $C$. If the Hausdorff dimension of $C$ was $< 1$, then $C$ would be totally disconnected. Hence, $\mathbb{R}^2 \setminus C$ would be disconnected, which is implossible. 

This is off-topic: But powerful techniques to show that gap exist, can be found in the following papers: $URL$ $URL$ of course. The setting is somewhat different, since they consider discrete Schroedinger operators ... 

Falling under "Wouldn't it be nice if there's somewhere where I could look up X": Typos, mistakes, and expanded calculation for published papers. Of course, this is more or less wishful thinking since I have no idea how to deal with potential correctness issues, etc... 

To the second question: You can check that your condition is equivalent to $$ \limsup_{n \to \infty} \|A^n \| \leq 1. $$ If there is an eigenvalue > 1, it is clear that the above fails. If an eigenvalue = 1 has non-trivial Jordan block, you have $\|A^n\| \gtrsim n$, so the condition is violated. As for a name, in my opinion "subunitary" would seem appropriate. But that is just a guess and not based on knowledge. 

Ok, I rethought my old comment. I believe it is better with $Af (x) = f(x+a)$ and $B f(x) = f(x+b)$ to think about $$ T^n = \frac{1}{2^n} (A + B)^n = \frac{1}{2^{n}} \sum_{k=0}^{n} \binom{n}{k} A^{k} B^{n-k} = \frac{1}{2^{n}} B^{n} \sum_{k=0}^{n} \binom{n}{k} C^{k}, $$ where $C = AB^{-1}$ so that $Cf(x) = f(x + a - b)$. It think that one should be able to show that this converges relatively easily ... (one somehow needs to deal with the weights). 

So you will now need to do something smarter. This is possible in many particular cases, for example for Toeplitz operators. The first property allows one to reduce the computation of the index to the computation of the winding number of a polynomial. Or the Atiyah--Singer index theorems reduces computing the index to some topological information ... So to get a more meaningful answer, you will need to be more specific about the problem. 

Just to elaborate on my comment: It is clear that your operator $\varphi$ is symmetric, in the sense that for $f,g$ smooth and compactly supported functions, one has $$ \langle f, \varphi g\rangle = \langle \varphi f, g\rangle. $$ However, this does not imply self-adjointness. Furthermore, the usual arguments fail why your sum should be well defined. In particular $Q_k$ and $P_k$ both are operators, whose spectrum is $\mathbb{R}$, so quadratic form methods are not available. Coming to the question: I would say there is no such description. It is well known that the operators $- \frac{d^2}{dx^2}$ and multiplication by $x^2$ both have spectrum $[0, \infty)$, but there sum has spectrum $2n + 1$ (if I remember correctly). Furthermore, the eigenvalues of this sum, the harmonic oscillator, are the Hermite polynomials, and not simple combinations of $\delta_x$ or $x \mapsto \sin(k x)$, which are the generalized eigenfunctions of $x^2$ respectively $-\frac{d^2}{dx^2}$. However, if your operator is self-adjoint you should be able to write down the spectral projections. First your problem factors into problems on $L^2(\mathbb{R})$. Second, I think one can explicitly solve the ODE $u' + a xu = z$, which should allow one to write down the spectral projections ... Update, July 5th: So I make fewer typos, denote by $H$ some self-adjoint operator. Define $$ R(z) = (H - z)^{-1} , \quad im(z) > 0 $$ Then one can write the spectral projection $E(a,b)$ of the interval $(a,b)$ as $$ E(a,b) = \lim_{\varepsilon\to 0} \frac{1}{\pi} \int_{a}^{b} im( R(t + i \varepsilon)) dt $$ with some subtelitties because of point mases, I choose to ignore. So in order to understand $E(a,b) f$, one can now try to understand $$ \lim_{\varepsilon\to 0} \frac{1}{\pi} \int_{a}^{b} im( R(t + i \varepsilon) f) dt $$ Since, we can write down what $R(t + i \varepsilon) f$ using the ODE, we can compute this (with some effort). However, one first need to write down the domain of $H$ so, one knows what $R$ is. Further Update Let $f$ be compactly supported and smooth. Introduce $$ K_{a, z}(x) = \exp\left(\frac{ia}{2} x^2 + z x\right). $$ A direct computation shows that $i K_{a,z}'(x) + (a x - z) K_{a,z}(x) = 0$. So if we define for $f$ compactly supported and smooth $$ R_{z} f (x) = K_{a,z}(x) \cdot \left(\int_{-\infty}^{x} K_{a,z}(t) f(t) dt + C\right), $$ then we have $i R_{z} f'(x) + (ax -z) R_{z} f(x) = f(x)$. Now, if we want to have $R_{z} f \in L^2(R)$, we must have $C \equiv 0$ by looking at $x \to - \infty$ asymptotics and also $$ \int_{-\infty}^{\infty} K_{a,z}(t) f(t) dt =0 $$ by looking at the $x \to \infty$ asymptotic. This worries me, since $R_{z}$ should be defined for all $f \in L^2$. Does anybody see my mistake? 

The answer is no, and the main reason is that $\{x^n\}_{n = 0}^{\infty}$ form a total set in $L^2([0,1])$ so the set of their finite linear combinations is dense. But $\int x^n dx > 0$ for $n \geq 0$. I believe, the best one can do is apply Gram--Schmidt to $x^n$ and obtain a sequence of polynomials $p_n$ (the orthogonal polynomials) of degree $n$ such that $$ p_n \perp x^m,\quad m > n. $$ Here $f \perp g$ means $\int f(x) g(x) dx= 0$. However, the notion of "best" here is not well-defined. It's just the usual choice. 

I guess the only non-trivial thing about the problem is that: $$ x f(0) \geq \int_0^{x} f(t) dt \geq x f(x). $$ So you start by computing the integral $$ r_1 = \int_0^{y_1} f(t) dt,\quad y_1 = \frac{r}{f(0)}. $$ Then replace $r$ by $r - r_1$. I think under reasonable assumptions this should converge pretty quickly (and always lower bound). It should be noted that I only use one of the inqualities, one can probably optimize it by using the other one. 

Let me elaborate a little bit on my idea. Denote by $\lambda_j$ the eigenvalues of the operator $A$. Then Weyl-asymptotics means that $$ N(E) = \\#(j: \lambda_j < E) < C \cdot E^\alpha. $$ Consider now the operator $(A)^{-1}$ with eigenvalues $\lambda^{-1}$ ... and consider its Schatten $p$ norm $$ \|A^{-1} \|_p = \sum _{j} \lambda_j^{- p} = p \int_0^{\infty} \frac{N(E) dE}{E^{p-1}}. $$ This is finite for $p >\alpha + 1$, so it suffices to investigate stability of the $p$ norm of the resolvent, which is standard. 

I suppose you order your eigenvalues by $\lambda_{k} > \lambda_{k+1}$ and that it should be clear that they are positive. If yes, using the mini-max principle one should be able to get lower bounds on the eigenvalues. Of course, this would require having some idea what the correct test functions look like, but one should be able to obtain this from the Sturm--Liouville operator picture. Of course, this is just what I would do having no idea on the background of the problem. There might be a smarter solution available. 

I commented earlier, without finishing reading google's reply: $URL$ shows the answer is no if you replace $\mathbb{R}$ by a compact manifold. Key is googling for "Is every diffeomorphism a time one map?". I'm not sure what the answer for $\mathbb{R}$ is, and if it has been looked at. 

Of course there is: For example: this paper by Lubinsky describes universality for a special class of tridiginal matrices. For example the condition off-diagonals $\equiv 1$ and entries on the diagonal are in $\ell^1(\mathbb{Z})$ would suffice. So the matrices are $$ H_N = \begin{pmatrix} b_1 & 1 & \\\ 1 & b_2 & 1 & \\\ & 1 & b_3 &1 & \\\ & & \ddots & \ddots & \ddots \\\ & & & 1 & b_N \end{pmatrix} $$ with $\sum_{n=1}^{\infty} |b_n| < \infty$. This can be further generalized see: Avila--Last--Simon. Of course all these results are for special tridiagonal matrices (Jacobi operators). Last, there is also the work by Deift et al. See the book. 

Actually, I think one can answer the thing quite easily. At least in dimension 2. Step 1: Call $P_1(N)$ the probability that none of the points $x_1, \dots, x_N$ lies in the sector $(0,\infty)^2$. So we have that all points lie in $((0,\infty)^2)^c$, which has probability $\left(\frac{3}{4}\right)^N$. Step 2: Call $P_2(N)$ the probability that each sector contains at least $1$ point. By independance this is just $P_2(N) = 4 \left(\frac{3}{4}\right)^N$. So, we have that the probability that $0$ does not lie in the convex hull of $N$ points is $\leq 4 \left(\frac{3}{4}\right)^N$. To get a similar bound in the other direction, observe that the probability that all points lie in one sector is just $(3/4)^N$ as mentioned above. So the two bounds are within constants. However, I believe that improving on the number $4$ above would be kind of tedious ... 

Simple answer: bounded operators are simpler than unbounded ones, so it's better to study them. Discretized models lead to bounded operators. For example consider the discrete Laplacian $\Delta$ on $\mathbb{Z}^d$ given by $$ \Delta u(n) = \sum_{| m - n|_1 = 1} u(m), $$ where $u:\mathbb{Z}^d\to \mathbb{C}$. Boundedness just follows from the triangle inequality. Furthermore, if one considers the time evolution operator $U(t)$ (for example in quantum mechanics $U(t) = e^{- i tH}$). Then $U(t)$ is a bounded even unitary operator. ($H$ might not be). Edit: Another important example is if $A$ is a (possibly unbounded) operator with non-trivial essential spectrum, then the resolvents $$ (A - z)^{-1} $$ are bounded but not compact.