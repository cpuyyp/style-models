I think this depends on the load you anticipate to get but the models chosen by both systems are architecturally different. Firstly, nginx uses an event based model to handle requests whereas Varnish uses a thread based model. Varnish places its cached content in a very efficient critbit tree. I couldnt find out what implementation that is used by nginx. nginx should be more efficient because it uses a non-blocking event based model to spread load evenly with as little contention as possible, however if lookup times from the cache is much slower you could argue it cancels things out. Varnish creates thread pools (normally of many threads, 500 or so) to handle multi processing. The cost here is in context switching especially if you have many requests to process. The way I see it -- varnish will perform better as you scale up the number of cores you have to battle with the contention, plus its really very good caching algorithm makes its lookups and responses very fast. Use varnish if you have lots of cores and have very high traffic/content to deliver. Nginx on the other hand takes a much less sledgehammer approach with managing resources and I reckon on small/medium caches on low-powered systems will probably work out better value in terms of efficiency and requests per second. Overall, varnish works best on a dedicated system with at least 2 cpus/cores. It will linearly scale as you add cpus. Nginx probably works best on a smaller multi-roled system where the cache pressure is not as hot. It will also scale linearly but I suspect its caching algorithm and implementation is not as good as the varnish one which could end up being a performance bottleneck as you reach high levels of traffic. 

Then run to compile and insert the policy. Providing you ensure that the boolean is on this should (potentially) fix your issue. Also make sure you set to a permission which allows read both from the parent directory tree and in the directory itself. If you want to permit read/write you'll need to use the label instead of . 

As a guess as it currently lacks useful info, I reckon your de-queueing this packet from netfilter too late -- after a routing decision has been made and thrown the packet into the local route table. Try putting your NFQUEUE rule in iptables in the mangle tables PREROUTING chain. 

This is an selinux problem. When you run it starts as , when you run it starts nginx as . By initially starting with just sudo it creates a bunch of files and initializes its state as . For example the pid file will be the wrong context. Thus when using to terminate it there is insufficient privileges for to read files written by the . You should really always start using which will avoid this problem. To correct it you will need to relabel stateful files that exist in the filesystem, for example running will correct the incorrect label set on that pid file. I am not sure if there are any more files that get written out when the service is created which will also need correcting. You can get a list of which files that these might be doing . 

Your picking up ipv6 network connections which often have a number of colons in them. The command doesnt take this into account when snipping the colons out from the IP address. Might be more suitable to use instead of cut in that case I guess. 

Sure, remember that for all intents and purposes, both are doing the same thing. Organizing namespaces, cgroups and mount points. All the primitives are dealt with by the kernel itself. Both implementations just offer a mechanism for interfacing with the kernel options available. 

This comes with the territory. Desktops might work shifts but servers do not and may be expected to be operating 24/7. I would imagine some shift work or unsociable hours in any job like that. Salaries vary greatly depending on business, ability and what you would be responsible for managing. 

In Fedora 17 they moved a lot of unused (in common usage I guess) modules for the kernel into the package kernel-modules-extra. Install that and your problem will go away. 

So, it checks the real UID of the caller and enforces the change or not depending on whether the the real UID is 0. So, you should simply be able to setuid your binary and make sure root owns it, then it will be able to change password and enforce the cracklib decision. setuid'ing your binaries only sets the effective uid to 0, not the real one. 

Well, its not quite that simple, because it depends who you are when you try to run the binary! Fortunately, the utility is incredibly handy for inspecting what the policy might be in this case. We can ask it to tell us what all the transitions are that might occur when running the object labeled . Which yields 

I suspect your problem is in tomcat not apache, from the logs you have shown anyway. When you get 'error 110' trying to connect back into tomcat it indicates you've got a queue of connections waiting to be served that no more can fit into the listening backlog setup for the listening socket in tomcat. 

The following SELinux policy will be needed to set this up. NOTE: I assume here that the ajp_port_t type does not actually exist on the system currently. 

Whilst I cant say to have ever heard of the rule, static content has advantages that database servers are unable to provide as easily. SATA drives usually have lower mean times to failure, are slower and perform less well at random I/O. The upshot is their cost per GB is cheaper. When you store media such as static content, the system typically will cache the content so its not normally read much from disk, this negates the need to have a high speed disk so much. This is especially true for websites where 90% of the data presented makes up 99% of the requests. Databases on the other hand typically have an IO profile that is a lot more random. Databases also usually dont rely on the caching subsystem of the kernel to manage its content, so it can benefit to using faster disks. They also tend to perform many more writes than static content which is where the SAS drives can really help. Bear in mind, there are so many shades of grey that its not as simple or as straight forward as that. 

Theoretically, the journal would save you from filesystem corruption due to a sudden loss of power because metadata will be guaranteed to be well-ordered. 

If you used the certificate to perform mutual authentication. Its a wildcard certificate or a certificate which hosts multiple domains (the losses double, or triple or whatever many hosts can be used for it) The certificate is multi-purpose in some other fashion. The certificates purpose is to ensure the integrity high value data (medical records, financial transactions and the like). The other end expects a high degree of trust and/or is reliant on the integrity of your system to make operational decisions. 

Insert equal or greater sized new USB disk. Using vgextend add the said disk to the existing volume group. Using pvmove switch the extents from the old root partition over to the new USB disk. Using vgreduce remove old old USB disk from the volume group. Remove old drive. 

I expanded the policy given its a bug. Install the RPM if not already present and then paste this content into a file called . 

You are going about this in the wrong direction. You can use filesystem semantics to enforce consistency. 

This is meant as a display parameter. So in EL6 if you setup a quota, pass some packets through, then do you'll notice the quota value decrements. In F20 doing the same thing the value doesn't decrement. I guess the designers believe its probably a better thing to make sure people know what quota was set rather than what the quota really is (seeing as packet counts make it clear what is left). However, this has an unintended effect. When you run you save the quota value as read via . In EL6, if this value reaches 0 it displays 0 to . Thus, when you restore, you restore the 0 back into the iptables chain. With them removing it, this value never decrements and thus you never actually save the quota. What really needs to happen is the module needs redesigning. There should be a entry and a entry. Remaining should decrement like in EL6 and be what is used to enforce the quota, whereas "quota" should be the actual set value like in F20. This way you get the best of both worlds. A saved state of the quota and a actual description of what quota is set. You should probably report this to the netfilter team. 

Is the most concise way to do this. Edit: Found a more concise way. This will not confuse stray "$:" that exist in GECOS fields, for example. 

If you remove the IP from the local routing table, (this is possible and it will send out of eth0) then on its way back (debatable it will ever make its way back) Linux will consider it a packet to be forwarded and not locally delivered. You'll never process the packets you get back but try and forward them. If you want to add network problems to a device. Try looking at the qdisc. For example. 

You can set it yourself to anything you want by putting the file /etc/hostid in place with the value you want (presumably thats the same as what comes out of the 'hostid' program on your donating box). To set it is a little tricker though.. the file required a packed binary representation of the hostid. I used python but you can do whatever.. (pretty sure someone knows an easier means to print packed bytes). 

No. You should setup all allow/denies in your filter chain only. Mangle is meant for altering packets in some way. You could use mangle to setup a fwmark on the traffic if it matches a series of IP addresses and then permit the traffic via a fwmark instead. 

The big downside to barriers is they have a tendency to slow I/O down, sometimes dramatically (around 30%) which is why they arent enabled by default. In addition to this, things become doubleplusungood when you start to add logical layering on top of standard disks like LVM or Raid. LVM (relatively recently) added barrier support for most LV configurations and mdadm seems to have had it for a little while.