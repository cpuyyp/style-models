In SQL Server 2012 AlwaysOn has something for you here that works potentially. Availability Groups are an answer here with the concept of an Active Secondary for reading purposes. But there are licensing concerns - you need to be in Enterprise on both the primary and the read only/active secondary. With the replication approach you still need to be licensed on both ends, but this is a good option for sure. It, too, has overhead associated and some administrative concerns that you should learn about - but it makes a great option. 

"How bad is it?" depends on the degree to which you are suffering now or could suffer with increased workload in the future. One major point of suffering with plan cache pollution could be too many single use plans bloating your plan cache leading to inefficient cache usage. Another point of suffering could be high compilations/second - so in an environment with a heavy workload and a lot of activity, there is a cost associated with compiling over and over. You can see the impact of compilations/sec in perfmon (SQL Server Statistics:Compilations/sec). This can look like CPU pressure. To your performance/applications, this can look like increased query duration waiting for needless compiles each time it runs. You can see the impact to the plan cache from the memory bloat by this query borrowed from Glenn Berry's Diagnostic scripts. How big is your SQLCP plan cache? 

What is the significance of DB CPU paramater in Automatic Workload Repository? Say in my case it's always above 100. Does it have benchmark metric as such to say that so and so number is the right value? How does it work? 

Should the service-name mentioned in TNS and the service which I create for TAF using srvctl be the same so that client need not make any changes in tns at their end? 

I'm running a master-master replication with read-only second master. Now since my binary logs are not getting replicated in my passive master. 

As per compatibility matrix, the target and the RMAN client version has to be the same. The workaround is connect to the catalog database from the target database ( whose version is lower than that of the RMAN client) and register the database in the catalog. Thanks! 

Say, if a recoverable error occurs on the single instance, where does it replay the transaction? Can someone help me understand this? 

I have set the file size for the user mysql as unlimited in /etc/security/limits.conf. Timeout values: 

Added info:: I will be moving from OEL 5 to 6 or above. Downtime I will get over an weekend. No change in character set or licensing features. Database size is approx 50 GB. This is only development instance and not prod. Should I install 12c database and then import everything from 11g to 12c database or run DBUA? Best.! 

That weird padding during comparison thing is the ANSI-SQL standard at work. You would have to do a workaround of some sort. Either replace the spaces with some unique character that you wouldn't have in your data set and remove the characters at display time or use a computed column, etc. What you are trying to do is sort of against how the ANSI standard handles these things. As far as I know the only operator to really consider those trailing spaces is the LIKE operator. I wonder if you could do something with computed columns and some guaranteed escape character per space (Tilde, Pipe, etc) for storage, or rethink what you are trying to make as your primary key. Could your primary key be more of a surrogate key like an identity column which makes inserts and updates happier potentially? Could it be more of a composite key with two columns that are unique together? 

2.) What are some reasons TempDB could be higher? So TempDB is a database and it can have IO stalls like any other database as I just discussed. But what are some reasons TempDB can have higher reads? (not exhaustive, I welcome additions or thoughts in edits, other answers or comments) - 

Okay first things first, this is probably a common issue which gets resolved going through all those questions and googling it but still I face this issue: 

Is it good to reclaim space using resizing datafiles? What are the things to be taken care before resizing the datafile? 

I have 4 servers running MySQL 5.6. A,B,C and D. A and B are Master and slave whose default port is 3306. C and D are running in non-default ports 3360. A and C are in Master-Master replication mode. C and D are in Master-Slave setup. Now I need to change the ports on A and B from 3306 to 3360, what commands I need to run and in what order to have B,C and D back in replication? Is the below steps right? 

I have a Percona MySQL database 5.6 running in a linux machine. I have created new users called test1 and test2. What I did was I imported mysql database from my test setup to this new setup. After which when I run the query 

I have two servers. One is DB server another is RMAN Catalog DB server. From my RMAN Catalog, I connect to my remote DB server and I run the backup. Where will the backup files be stored? Will it be in my RMAN catalog db server or the source db? 

Short Answer: Yes. There are many reasons but the few that stick to mind: 1.) Trust but verify - SQL cares a lot about its environment, the hardware or virtualized system it is on. When I help a company with SQL on VM issues it is normally a misconfigured VM. In many cases the idea of SQL on VM is about to be thrown away. 2.) DBAs should look at memory reservations, alerts and performance conditions, how overcrowded a physical host is ( or isn't) and understand how it works. 3.) DBAs are learning more and more about virtualization. Through excellent blog posts and SQL events, the VMware knowledge in the SQL dba community is rising. An extra set of eyes may help ensure things are well tuned and future proofed. 4.) Prove yourself... If you've done everything right and built a great environment, show it off. Read access to center isn't going to destroy your system and you can show those pesky DBAa everything is up to snuff. And if it isn't? Don't you want to know? ;-) 

The answer here is "it depends" - While actually blocked? A session should not use any resources. It is in a state basically saying "I sure would like to do my work, hey SQL Server may I have a lock on such and such a resource" so while that resource is locked - the session is basically not able to do anything except wait for resource availability. Once that has been cleared it can then start running or join the runnable queue waiting for its scheduler time. Now you could still see IO and CPU increasing on a session with many queries or steps that is blocked in different spots. So you could look and see it is currently blocked, but see the CPU increased or IO - that would be because it got past a block did some work for a statement but was then blocked again. I'll often diagnose blocking with a tool that shows query duration and CPU/IO metrics for a session but maybe missed tracking blocks if an execution of a query is higher than normal duration wise but remains within its normal limits for CPU and IO. It isn't only blocking that will present that way but it often is - so it becomes a tool to say "hey let's look and see if we see any blocking". I might also suggest you have a look at sp_whoisactive. A great script which will be much more informative than SP_Who2. 

How to start a non-rac single instance with ASM file system. As in the case of RAC after reboot of server, the ASM and CRS resources startup automatically.. but with non-RAC but with ASM storage, what is the right way to start the database? Is there anything specific that should be given attention to start the database? Start the ASM instance and mount all the diskgroups and then start the database? Correct me/add if i'm wrong. Server- RHEL Database - 12c 

I have 11.2.0.3 database. I need to upgrade to a higher version either 11.2.0.4 or 12.1.0.2. Which one I should upgrade it to? Im not going to upgrade on the same server. I will have to do it in a new server. So how can I proceed with the upgrade? Export/import? DBCA? Manual upgrade? What is the procedure to do this? Same as above question except that this is another database but 10g. Which version I should upgrade it to and how to? 

I have an Oracle 11.2.0.3 about 700GB in size running in noarchivelog mode in a pretty slow storage setup. It barely gives IOPS and there is resource crunch in terms of hardware resources. The transactions hitting the database is heavily read/write intensive and redo generation is quite high (near to 8MB/Sec) and naturally it is finding difficult to write to the disk. What can be done in such a scenario? Can nologging in certain tables boost the performance? Data corruption because of nologging is a concern, I understand that and can be taken care of. But can someone give insight of how truly enabling nologging helps in this situation? or if it doesn't help, what are the other options I have? 

You can see more about the commands and options for backup here. There are many other options you should look into - such as verify, checksum, etc. A couple notes also - 1.) The is necessary the first time I execute this here since this mirrored set is not yet formatted/created. So the backup doesn't operate like a traditional backup in that regard - because you are effectively creating a new mirrored backup set. The link above will help explain that a bit more. And seeing you ask this does lead me to ask the question of "What is the goal?" - This is a feature for a reason and it may just be a requirement you have. But it could also be that you are trying to handle something that may be better handled in other ways. For instance backing up to a device with redundancies built in, backing up to a network drive, backing up to a SAN that has proper SAN replication in place, grabbing a copy of a backup right after you take it, etc. 

Well so I see there is a vote to close afoot here, and it makes sense - this is an opinion based question. There is no right or wrong answer here. But before the close votes come in - a few things for you to consider: 

What is the difference between having a master-slave replication and having a master-master( where in the second master acting as hot-standby - active-passive) replication? Also, what are the issues that I could face having a master master replication where both the masters are writable. I have read here that experts have said it is very dangerous to have both masters writable. Without Percona/NDB/DRBD, what are my options for setting up HA for my databases? What is the best replication that I can have? 

I'm thinking of configuring Application Continuity for my 2 node RAC (12c) database where my application is running on Weblogic server. Before I proceed with the setup of AC, I need to clarify/confirm few things regarding AC: 

I recently was going through Application Continuity in Oracle 12c. As I read through the Oracle link which I understand when used in RAC, will be able to replay the transaction (DDL/DML) in the event the node goes down. In the link, it also mentions creating a service for non-RAC (standalone) instances as well. How does Application continuity work in case of single instance. 

I need to make log-bin-trust-function-creators persistent so that I need not make it to true everytime on instance restart.