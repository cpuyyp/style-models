Luther's realization that faith is a necessary part of religion, which implies proof is counterproductive, Jung's observation that some version of God generally turns up in the psychology of anyone, if only to be forcefully denied, and Hume's argument that faith in the regularity of cause and effect is in effect faith and nothing more 

Neither trumps the other, in fact, falsifiability is only relevant as a specific approach to induction. Popper was dissatisfied that various other supposedly empirical theories failed to converge over time, and yet continued to elaborate themselves. Forcing risk via demanding attempted expansion as a critical criterion instead of respecting a steady state of simple continual consistency is meant to force out theories that won't converge. Continually seeing what you expect is not a good enough basis for a theory, because of confirmation biases, which ultimately make simple induction unconvincing. Deploying falsifiability as the basis for induction is often called 'statistical inference' -- the 'statistical' reference is to Bayesian statistics, which vaguely apply even in the absence of the use of statistical methods. If something is genuinely falsifiable, there must be a nonzero chance that it is false -- it makes a definite claim that may not be true. Then by Bayesian reasoning, if the claim is not falsified by a few direct attacks, you can divide out the odds of its falsehood from the odds of the system from which it derives being nonsense. Requiring future statements to assume it is true theoretically increases the overall reliability of the system to which it is adjoined, if only by a tiny degree. The first few men you see die each reduce the odds that any other similarly-constructed man will be immortal, but after that, repeating it hundreds of times won't help much, the products of odds quite close to 1 stay quite close to 1. Of course, this only applies if you think the interpretation of the theory as a whole is clear enough to have given chance of being false. Kuhn would discount that entirely -- no paradigm is so water-tight that you can actually use Bayesian statistics on it. On the other hand, the odds of a given sub-theory being better than another, when they presume the same overall theory, might be close enough to matter. The basis they have in common puts bounds on the space of distributions to some degree. So Popperism is a good tool for what Kuhn calls normal science. 

But it remains an open question whether all science should be approached in this way, even when it can. Many folks after Popper have contested the power of this method when things are less stable. Kuhn, for example has suggested that science regularly moves into 'revolutionary' periods, when determining falsifiability is not always possible, and therefore it cannot be required. (Feyerabend goes even further, claiming that science is constantly at least partially in such a state, and should attempt to remain so.) When a science is trading out older paradigms whose creative energy has been spent, and deriving new paradigms, the old and the new can be incommensurable in a way that obscures our ability to know what exactly 'falsified' means in the context of the science in flux. When a science is close to a revolutionary boundary, just descending into or just getting out of a paradigm switch, demanding falsifiability it is not always the best choice. It may shoot down new ideas based on habits and older ideas that are about to be shot down, themselves. Potential new paradigms need slack to establish a footing, and preserving parts of the old paradigm that still happen to remain clear in the new interpretation may undermine cohesiveness in the new foundation coming into practice, which will make for a complicated mess in the future. If, like Feyerabend, we prefer every science should always have competing sets of underlying assumptions, and avoid 'hegemonizing', then falsifiability becomes something optional, if still very convenient, in a theory. 

Leibniz answer is that even a perfect, benevolent God can only make the best possible world. There are several different ways of looking at this: 

From the viewpoint of Jung, complexes are not necessarily abnormal, they are what makes for stereotyped behavior, and the vast majority of social behavior seems stereotyped, so we must all have a lot of them. Complexes serve a purpose, in allowing you to behave without deep consideration of each individual action. They become problematic only when they do not suit your current situation, or when they are so overdeveloped that they bar deeper consideration too completely. So if jealousy is just an inferiority complex, what are the developmental advantages of inferiority complexes? We all start as children. And they encourage one to subject oneself to other's judgement, which is a useful thing for a child to do in a complex society that takes a long time to adapt to. So, then why do they create resentment of those who presume to be superior? Even though your parents are 'better than you' for most of your childhood, they will not always be. If this resentment were not a natural part of an inferiority complex, the new generation would never come into its own by overpowering the status quo. So, is retaining this behavior past adolescence adaptive? It certainly creates rituals that enforce conformity when necessary. To me this seems practical. We allow people to 'parent' us in domains where we acknowledge their status. The resentment may seem more problematic, but if its purpose is to shatter the ritual when it has run its course, then it serves as a foil against, for instance, military dictatorship, or technocracy. So, to my mind, basic jealousy is perfectly logical. The particular jealousy of future generations is more ambiguous. Perhaps you could leverage it to encourage yourself to live longer, or to think futuristically in a way that might encourage invention or other kinds of imagination useful to the culture. So I do not see it as a totally pointless complex. 

Popper would say that is exactly what happens. And it is surely what happens short-term in sciences. Folks compare results based upon known theories and the most logical fit wins. Over the longer term, it seems to be overly simple, given certain historical examples. For example, in the case of Copernicus, people chose to abandon a more effective theory in favor of a simpler one, because the more effective one became so complex that it felt ad-hoc. They kept the known results of the old theory around for daily use, and it still affects our vocabulary and conventions. But they stopped developing it, and study went primarily to the new one, which eventually outstripped it. To cover such cases, Kuhn proposes that all sciences occasionally decide they are wrong and rewrite their basic principles, he calls these paradigm shifts or 'revolutions'. But he also still believes that science gets more and more powerful in its predictive efficiency and therefore closer in some sense to the truth, even if it does not 'converge' in the sense that yesterday's truth is related to tomorrow's. Even though contending paradigms cannot necessarily be compared to each other directly, each time we choose a new paradigm, we include more preconditions for taking it seriously. So we can expect all of the next round of candidates to be stronger than most of the rejected options. We would never simply move backward in time and return to a failed paradigm, as the dissatisfaction that caused it to fail is documented. We might choose a paradigm that was in the running last time around and lost out. But overall, there is still a process of elimination taking place. It is possible for forward progress to be forestalled by the apparent strength of the current paradigm, even though it fails consistently at some things. In particular, if we look at fields like Alchemy or Chinese Medicine, which unified fields too broadly across natural boundaries and lost traction, we can see centuries or millennia of stagnation or asymptotic circling. But in the end, something has always confronted them from outside and set the process of increasing power over time back on track. So whether you can expect new explanations to be better than old ones depends upon what is going on in the 'paradigmatic tectonics' of the sciences involved. But on a grand scale, you can expect progress. 

You can look at this through the lens of "Mathematical fictionalism" $URL$ and the related sort of bounded dialethianism that results, allowing contradiction to harmlessly exist all over the place, even in something like Classical Logic. The issue is not whether there is a consistent model of the universe. You can assume from the start that there just isn't. The question is how large your universe of discourse can get before it degenerates, instead. Something like Russell's paradox is a real contradiction inside Classical logic, but it is seldom entailed by anything, so it can just stay there, and other parts of the universe can still be useful. The resulting universe is huge and such large parts of it 'conserve truth', that it is worth having on hand as a tool. If you take this notion of separate fictional universes seriously, but deny their fictionality from a Meinongian point of view, then yes, these things exist, but they cause the universes in which they would/do exist to be quite small, since they run into contradiction very quickly. Very little can be said that conserves the truth of its premises, unless none of the subjects involved have shapes. 

postfix PQ+, P Q+ or P,Q+ prefix +(P,Q) with the parentheses signifying the reversed order infix P + Q the notation everyone else in the world prefers 

You might consider work like 'No Boundary' by Ken Wilbur to lie in this vein. It follows down the Jungian layered Self based ultimately upon a Collective Unconcious, in detail. Of you can go straight to Jung's writings on the subject. And you can surely find evidence that we share mental content in a more pedestrian way in modern interpretations of psychoanalytic intersubjectivity in therapeutic and other contexts. Kurt Lewin models mental space as "field", with the same sort of action-at-a-distance common to other field theories, and this perspective pays off in the understanding of group and other political action. Active psychoanalytic group approaches like Tavistock-style group therapy trace how common issues and conditions coalesce and create shared difficulties and potential solutions (q.v. Bion). Kleinian notions like projective identification are played out particularly in the treatment of Borderline conditions (q.v. any basic course on psychoanalysis, e.g. McWilliams). Self-psychologists observe reflected impressions from transference onto shared self-objects (q.v. Kohut and Kernberg). In a more direct way, out-of-body experiences near death or under DMT, LSD or mescaline, where people see rooms, etc from the perspectives other than their own can be taken as evidence that there is a shared constructed world from which we get information that properly only belongs to other people. Even if we get this kind of information by reading others in some subtle way, they are unconsciously communicating it clearly enough that we can experience it as if we were living it out ourselves when we are suggestible enough. And even when we are fully aware, groups do easily manipulate us into acting on motivations that are not natively our own, without openly communicating them to us. I am unsure how much you consider literature on these subjects to be 'philosophical work'. Hard-core psychoanalysis is surely closer to philosophy than science, but philosophers are not keen on it for the last several decades. Folks tend to admit folks like Lacan as having philosophical content, but not generally modern Transpersonalists, Jungians or Group Therapists. 

Kant argues that being does not have being -- it is not a property or state, it is simply the reality of a thing having properties and states. His argument is narrower than yours, but basically the same, and it goes farther. If existence were a state, then nonexistence would be a state. Yet what can nonexistence be the state of? Such a thing would not exist... Instead, non-existence is only really the state of an idea, and not of a thing, and it does not really mean non-existence, it means not describing anything. To think of it as a property of things is just a grammatical error of omitting 'quotes'. The idea of non-existence is applied, in reality to a sort of 'quoted' object, a description of a potential object, and determines whether that description has instances. Existence is the opposite of non-existence, so it must also be a property of potential descriptions, and not of actual things. We want to think of time as the continuum along which all things exist. But if being is not really something that things 'do', then time is just an elaborate convention, not a real thing. He calls this a 'form of intuition', a necessary part of every description, which is necessary because of the structure of animal minds, and not a real aspect of anything other than potential descriptions. Space is likewise not real, but only a mental model. Things have relationships 'in time and space' because humans need to experience many things that are all combined into a single, inseparable reality as separate objects in order to comprehend them. But he theorizes that the separation is not necessary for more advanced forms of intelligence, or would not be the same for alien beings. Every being with a mind has a nature dictated by its forms of intuition, its 'autonomy' which allows it to know when its judgments will serve it well. So Kant agrees that everything that is ultimately real must be eternal and absolute, but that we cannot address the eternal and absolute until we are able to put aside time and space, which we cannot do in the form we take. We can only interpret the correlations that phenomenal (spatio-temporal) reality has with the underlying 'noumenal' reality, and we cannot build or rely on an understanding of those relationships themselves because they are in fact relationships between things that we experience, and things that we cannot comprehend. Instead, we are limited to recognizing patterns and combining them according to the forms of intuition that are built into us, like space and time, logic and judgment. 

I might suggest civil rights in general as a historical example. In the U.S. Antebellum South, the greatest number of people may well have been made happier by the system with slaves. Relatively fewer people are enslaved (about an eighth), and those people generally came from conditions that were not that good to begin with. So their lives may even be improved materially. The Confederate argument is Utilitarian. But the intrinsic inequality is just wrong, especially when slavery extends across generations. The right action was to free the slaves, even if that threw the South into immediate and quite intractable poverty. The caste system in India has similarities, but they are not as clear-cut. Gay marriage is a similar thing. It upsets economic fine-tuning meant to favor reproducing couples without saying so. So its overall effects for everyone may not be positive. And it offends a lot of people in a very visceral way, which makes them less happy. But the arbitrariness of having non-reproducing straight couples treated like reproducing ones, and gay couples treated as not being couples at all, is significantly bad for a small part of the population. The nuclear weapons trade generalizes out to the whole military-industrial complex with privileged countries supplying weapons for continual third-world wars, of both ours and their own. We like making money of other people's wars. And we like the stimulus that wars of our own give to our economy. And those other people somehow feel better having their wars than not having them, or they would just stop. So everybody may be happier with a huge weapons trade. But in the end, encouraging violence is wasteful of life and resources in a way that is just wrong. 

As compressive notation: We can define the real numbers as distances along a chosen line. This is, in the end, completely circular and does not define anything. We already had the notion of the real numbers, or we would not be measuring things, but it makes a new way of saying things that is more compact when we are focussed on points rather than measures. An example from outside math of this kind of definition is defining "work" as the product of force and distance, just so we can refer to it efficiently. Via distinction and equivalence: We can define the real numbers as the equivalence classes of convergent sequences of rational numbers the unions of which still converge. This brings up background questions. We have to establish that the condition on the equivalence satisfies the requirements of an equivalence relation. That can be work. If it failed, we would not have a definition. We would not have accidentally defined something else, other than the ordinary reals, we would in fact have a statement that if treated as a definition, would give us false proofs. An example from outside of math is the definition of "species". What defines the word is the ability to describe how to tell whether two animals are of the same species, and just that. (I don't mean the standards for each species, but the idea that those standards exist generally.) It is important that the distinguishing criterion not get too vague or become ambivalent about a too many pairs of animals, or we have to start questioning the concept of species itself. Via models of axioms: We can define real numbers as the minimal ordered field with consistent least upper bounds. Besides being oddly abstruse, this also pushes a horde of assumptions. It is the minimal model of this set of axioms, there are not thousands of unrelated models that all behave differently -- they all contain this one, and that takes a lot of proving. An example of this kind of definition from outside math is that of 'the alpha of a troupe'. It picks out a specific kind of animal from a group by its behavior and that of those around it. The individual models an archetype or a stereotype made up of general rules. If we find different applications of the same checklist of features leads to disagreement too often, we have to discard the definition, and perhaps question the applicability of the concept itself.