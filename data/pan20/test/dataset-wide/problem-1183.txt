Seems like I am failing to find in online MSDN the illustration of the sense (or points) of an SQL Server Central Management Server. Can you provide me with some? 

while executing a rebuild from mentioned article and observe that it is being delayed until index rebuild finished What is blocking and how to avoid it? Update: Microsoft SQL Server 2012 (SP1) - 11.0.3128.0 (X64) Enterprise Evaluation Edition (64-bit) on Windows NT 6.1 (Build 7601: Service Pack 1) 

Though, I removed any CMS (Central Management Server) instance and still getting the same results over multiple SQL Servers on 2 differing machines 

Check your server bit if it is 32 bit and if you try to install 64bit package percona's xtrabackup . It would end up throwing such error messages. 

Lets say reboot is on Slave. Which I suspect a lot. Then start tuning queries to pick indexes or create indexes if required. Any changes in schema should be performed on Master so the schema can be consistent. When you are sure you have tuned queries on slave. You may put back to Master in smaller query sets week by week. And remove slave if you don't want to. 

4) Enlist 'Target-Server-Name' into 'Master-Server-Name' (if Success here, then error in 3) or both in 3) and 4)) 

Fig.1.1. On launching SQL Server 2012 (i.e. VS2010 Shell)) Data Tools --> New Project and on pressing OK button 

After installing Download SSDT for Visual Studio 2010 then Download SSDT for Visual Studio 2012 from Download SQL Server Data Tools - October 2013, everething seems started to work but I am eager to understand whether VS2012 setup damages SQL Server 2012 (i.e. VS2010 Shell) Data Tools for everybody or just me? 

If this works, try to take a mysqldump and keep it safe side. And recreate a fresh installation with correct settings and remember to remove the entry innodb_force_recovery. If this doesn't work, increase the value and see if it works. Since I'm not sure about the history of this server. You may need to verify your innodb_log_file_size set correctly as per recommended values. 

Here is my opinion. As long as you are going to use innodb engine it doesn't matter which one are you in. Provided Maria gives you the option of multiple writes to master-master architecture using Galera-cache. But as your TPS goes beyond a particular point, you might face issues in getting writes paused due to flow-control. Hence you may use innodb engine let there be 2Nodes using MariaDB using GaleraCache Cluster or simple Master&Slave. But have your applications writing to one node only either case. For my.cnf you may use percona tool wizard to generate as per your requirement. 

I've tried to set Mater and Target Servers on various cobinations of SQL Servers 2012 R2 on Window Server 2008 R2 and Windows 7 machines but always getting one or 2 of the following errors during setting either target or master server: * 

ADDITIONAL INFORMATION: An exception occurred while executing a Transact-SQL statement or batch. (Microsoft.SqlServer.ConnectionInfo) 

In all cases I was using a domainUser login with sysadmin role for setting SQL Server Agent service and owner of an SQL Server Agent job (or, in the latter, tried also ), Windows Authentication to in used by them maintenance plans. The used domainUser is part of (local) Administrators group in each of the Windows (machines). The SQL Server Management Studio is run . How can I troubleshoot these errors? What should I check and look for? Specifically, I do not quite understand: 

The only biggest benifit of switching to Mysql 5.6.5< is due to the feature that supports automatic failover utility which is default in Mysql 5.9.1 in a Mysql replication topology, this requires GTID level replication. Unless or until you don't really need an automatic failover within Mysql itself, we can work with the legacy features of Mysql 5.5 which is recognized most. But also I would like to highlight some cons of using GTID: A nontransactional storage engine (Myisam) mixed with updates to tables that use a transactional storage engine (Innodb) within the same transaction can result in multiple GTIDs being assigned to the same transaction. Thish might break sync between Master/Slave replication. In a nut shell: If your environment is stable in performance, High-availability and Security in your existing version it is better to keep untouched. If there is a necessity in any of the above then go for it. Management audit says a lot to keep latest version according to standards but they don't see technology wise what is standard? For this we need not spend time and effort to upgrade and sustain the same setup when it is feasible and effecient in current versions. 

On Windows 7 Prof I have installed SQL Server 2012 R2 with, as I am pretty well remember, client tools. Then, I tried to install Visual Studio 2013 Ultimate but failed. Then I've installed VS2012 Prof (30-day trial). Now, on launching SQL Server 2012 (i.e. VS2010 Shell)) Data Tools --> New Project I am getting: 

that is, update (but not read) operations require space for row versioning should have IMO failed due to lack of space. And why do read ops fail if they do not require version storage in tempdb ? 

But looking at your table definition you have secondary indexes almost on all. You might want to verify on performance of all your selects. Or tune them inorder to add the partition name or partition key as a mandate clause in where clause. So its better you take perf against selects and updates you use and then think whether is it feasible to go for partitioning or archiving the table. Also if you are anyway going for partition, you need to define the partition in such a way older partition can be removed. So I would suggest to go for 

Invalid class (System.Management) 3) Ensure the agent startup account for 'Master-Server-Name' has rights to login as a target server (if Success here, then 4) is error or both 3) and 4) are errors) 

The rebuild of indexes takes appr. the same 55 min. with both "Do not rebuild indexes and "Rebuild indexes offline" "For index types that do not support index rebuilds" with "Keep index online while reindexing" checked 

In SQL Server 2012 Enterprise Ed., which index types do not support online index rebuilds? and why? and which activity-operations can prevent online index rebuilds? 

Why do you think you need to compare the data? Anyways it has to go to DB I guess. You can have a current_timestamp as one of the columns to DB and value can be derived when the Device generates its local data using device NTP. 

Note: I have used SPLIT_STR function to exactly cut for the said occurence position by said delimiter value. In unix it is like -> Returns "Dick". Try it on your application requirement and see if this suits, I guess I dragged it long. I wish you to get someone with a decent fix. Use my fiddle -> $URL$ for quick testing purposes. All the best!!