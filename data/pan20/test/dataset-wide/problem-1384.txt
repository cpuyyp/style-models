doesn't really check if you've won; rename it to, say, . should really be renamed by this point. I would go with . can just be: 

you're conflating "returns 0" with "not cached", which means you can't cache the many returned zero values. A quick fix is to use a better sentinel 

Note that there are simple optimizations you can apply. For instance, you can easily iterate over only those values for which is a palindrome by construction - this reduces the values to iterate over from \$10^6\$ to \$10^3\$. 

This isn't as nice as the Julia code, but it's giving you a lot of opportunities to be a lot more efficient, and it's catching a lot more errors. It's true that locking feels like a chore on 50-line examples, but it fits Rust's macro-goals of faster, safer APIs. 

Fundamentally this is also inappropriate. Your first question gives reasons that normal arguments might not be appropriate, but Nizam Mohamed points out some flaws in your understanding. In fact, having a lot of parameters in a signature is fine. Objects to hold options exist for several reasons: 

Then you have at most two partial minutes left over, which means there are at most a further 118 specific timestamps. You can do a full check on these fairly quickly, but it is easy enough to skip it if the minute cache says the full minute never beats the current maximum. 

I'm not a fan of this design. @TheBlackCat is right. Don't do this. If you are to do this, rethink your design. A more sensible one might look like 

Depending on how much startup costs affect you, this could either be better or worse than the original strategy. I'll stick with the second of these, since it's less problematic in the face of Unicode. The test suite seems to ignore anything but lowercase ASCII, but I'm not willing to make such a horrible assumption. So, first we want a bunch of lists indexed by character. This will be easiest as a , since they all start out empty: 

firstly has a very strange comment, since should almost never involve . I could understand logging, but not if it throws away the error. Secondly, it'd be nicer to write as 

Unfortunately, the above is no faster than the naïve method. However, you can do merge sort with and in \$\mathcal{O}(n \log n)\$ time, so you can instead have 

let me choose First things first; your code is ing to and opening . This is woefully inflexible. The simplest fix is to accept an argument on the command line, as . (Don't use .) numpy What you're doing looks a lil' bit crazy. To deal with highly-dimensional data, Numpy is often a good candidate. A first-pass would look something like 

Your function should really avoid the globals by using lexical scoping. This strikes me as a good comromise: 

I'm going to leave this here for now, since I only have so much time to cover changes, though you can continue a lot of these cleanups in the same way. Other major untouched issues are around clearer high-level explanations, building the program out of separated functions, removing hardcoded paths, and moving to a matrix representation rather than a dictionary approach. 

This does mean there's more boilerplate, since it exists for each piece of functionality you add, but the logic itself is an order of magnitude simpler. 

This is based off of the fact $$ (a - b)^2 = a^2 + b^2 - 2ab $$ and so, ignoring the fudging with indices, $$ \sum(a - b)^2 = \sum a^2 + \sum b^2 - 2\sum ab $$ The squared terms are just 

I don't like that you're reusing for two things and haven't explained why they can't interfere. Heck, when dealing with locks very little matters except for the explanation of why you think things should work. I don't get 

Alternatively, roll your own. It also has a somewhat poor name (just , eh). I would just put the fields in there: 

You want the first in the text, so you can either also use Ashwini Chaudhary's method or something like 

You can change the inner loop to start at . You can also cache the value to halve the number of s you make. 

Note that I say this as someone who has never touched this kind of stuff; mathematicians are far ahead of any naïve implementations and if you want to take this seriously you'd probably want to look at the literature first. 

is a very strange special case; you deal with but not or . I suggest removing the special-case and using . Now we have 

I don't know Kivy, so here are a few general style tips. First, order you imports. Don't also import everything directly; it's OK to use namespaces. I would probably import as so: 

This also works on Python 2. Unfortunately PyPy doesn't (yet) have an easy Numpy port. Even so, the times: 

will already be sorted, so don't call . Use over as well. More efficient than sorting \$\left(\mathcal{O}(n \log n)\right)\$ is to use a . However, to produce output one would have to loop over a range. This can be done with: 

Addition of strings in loops is always almost bad, because it may reallocate the string on every addition. Instead, one should do a join: 

By using a well-defined API you can avoid such strange results and give better errors messages. Even better would be building a parser yourself, but that sounds a touch harder. I would also consider doing substitutions and finding all name tokens at the token level simply because it allows supporting things like 

but the speed improvement from unrolling matters after the next step: You spend a lot of time calling and on squares that haven't updated. Strangely, you also draw before updating. If one cached the old board, one could do 

This is as direct a mapping as possible; instead of changing the comparison I just shifted the index when indexing. This isn't idiomatic, but it's direct. It's largely the same as your code, but it's correct. This matters when we go to larger N, where your code fails. It's also Python 3 compatible simply by using with brackets. Let's time them: 

Surely the in the can only hold for . You might as well add that as another case in the loop instead: 

There are some other minor style points: , and are terrible names, and and are poor. Most variables are temporary, so tells you nothing in a lot of space. could refer to solving any problem. is silly - obviously it's "your" list and you don't even care if it's a list - you just want a sequence. There are other improvements, too. Instead of giving a bounded iterator, produce an unbounded iterator and call . If took a reversed iterator directly, it could be 

should not be part of . This is not what the function claims to do! Let do that, since it's responsible for output. The whole function can be simplified to 

You also don't need the argument - it's default. Don't put brackets around conditions in loops of s. It's just and . A more fancy example might use, say, Python's library - but this is fine for what it does. 

to find the \$\pt nn\$ matrix of distances. The problem with the current technique is the quick invalidation of these generated distances. When you call or anything that emulates it, you can not further involve it in movements until a new call to . This means that \$\mathcal{O}(n^2)\$ work must be done to move at most \$n\$ points once each. The alternative is what you have done: calculate distances and directions independently with each . A faster algorithm (in Python) would require vectorized calls to move the points. The sensible thing to me would be a pseudo-physical simulation; each point has two forces it applies to every other point according to some potential. One should fall off exponentially (or at \$1/d\$) whereas the other should rise exponentially. Where the distance, \$d\$, is between the limits the forces should (approximately) cancel. The equations can be alike to 

This is very similar to your version, except the macro dealt with formatting for me in a simple way. I also wrapped my lines, which is important for readability. Note that I used , not . Using skips the first index. Here's the full code: 

A slightly more robust technique than volcano's, but still less-so than ferada's, is to capture the evaluation in a fake "scope" and avoid messing with strings: 

doesn't work is just a fact of life right now, although that will eventually get fixed with non-lexical lifetimes. These imports 

Note that this is again going to have problems with duplicates, so that needs to be handled once again if it can arise. 

Your timing is also slightly worsened by the cost of a list comprehension. Removing that would be more honest: 

Since the first and last options share quite a lot of logic, reshape the control flow to accomodate: 

I don't get your justification for running . I suggest you make sure this is really the right thing to do, because it looks wrong. You have 

This actually helps PyPy a lot more than CPython, getting PyPy to a full 20x the speed of the original CPython here. 

We want to do a binary search to find the counts. This is just and , depending on whether you want to be inclusive: 

That about finishes it. There are much faster ways to solve this, but they'd all involve larger core changes. Here's the updated code: 

(I am not personally a fan of dropping brackets on or , but it's somewhat wordy in this bracket style without doing so.) Consider using zero initializer for : 

Your doctest is misformatted; fix that. Also, don't add a space before the docstring and don't give it a useless header like "Doctest": give it real documentation. Beware of PEP-8 spacing, too. Your parameter is misnamed; you don't take an but a . Best call it just , which is good for duck-typing. You default and to ... but ! This means that if the user passes in as or it would be ignored. You should default unknown values to, say, . I would also rename these to and . You do 

We check the and that for every in the words which must not be in . If this matches, we return , otherwise we go to the next iteration of the loop. This can be simplified: 

First thing first - PEP 8 is the de-facto style guide for Python. It's a good idea to just stick to it, and for the most part everyone else will too. This would look like 

This creates a heap of length-element pairs (equivalent to your list), only with the length inverted so it acts as a max heap and not a min heap. It will yield the most common element that isn't the previous element at any given time, maximizing the chance that the most repeated element will be used up by the end. This is not as brilliant as Antti Haapala's solution, though. 

This took some care, but it works OK. Then we can remove the by using a single cumulative sum outside the loop: 

Note that this is a somewhat silly way to do things, though. First of all, takes s! I'd rather avoid that if possible. Further, this is more work than needs to be done. Instead, one can do this: 

Preferably, it should also be fleshed out with useful information. Many of your other comments are mostly useless: 

This also lets you add a default if wanted with . It might be a better idea to catch the error explicitly, since can interfere with generators: 

in that you don't care about the branch, so avoids mentioning it. You'd want to make generic over writers, and start it like 

to store . An alternative is doing away with those altogether and storing strings of the form where the is a not a character but an end-of-string marker. This would give: 

One could use a run-length encoded data structure for instead, but I don't see any particular benefit. 

instead. I'd also rename this to . In fact, you only use this once, so I'd remove the function here too. You only use in , so inline it, giving: 

This finds the unique genes to fold the values into, along with the mapping and the number of repeated values that map to the same index: 

since you're checking against a sentinel. You also call ; this seems pretty superfluous. You don't need to call and I'd avoid it unless it serves a purpose. I can kind'a get why you'd want a property for - to keep it read only. However, there's no reason to have or as a property. Don't, it doesn't buy you anything (and does have costs). But this puts into question why you have the ABCs at all... why do you? If you had multiple classes, sure. You might want something to guide it. But as it stands, you're using it once and it's just overhead. Don't, it doesn't buy you anything significant (and does have costs). Similar applies to ... but why not just use ? Not only does do everything that can do, it's better tested and supports more functionality. Further, everyone knows how to use (I hope). Don't build abstractions for the sake of abstractions. Build abstractions in order to simplify common functionality or allow extensibility where you plan to extend things. Abstractions are meant to make code simpler to understand, but if you build too many layers you drown out the intent that you're trying to express. 

This can only do as many s as there are elements in , so all the calls added together can't be much slower than generating the list in the first place. The resulting code is much faster; for it went from 2.6s to 0.026s, a 100x improvement. There's also a bug! should be ; else will include two consecutive numbers (eg. instead of ). 

However, this is not advisable. There is nothing wrong with inner functions. But let's consider what you've done by using recursion. Hopefully you're aware that as you recurse a stack is built up: 

should be . You should name thing better; is both the wrong case and far too short. You should short-ciruit the error case. In fact, you should throw an error. If you're on Python 3, you don't need to , and if not you should just to get Python 3's behaviour. If you really don't want to, you should still use a call instead. You should use to find the mean. If you're on Python 2, this isn't an option without a backport. This will throw a good error for you, so you could remove that check. You should use over . Since you only want the index, you can just do