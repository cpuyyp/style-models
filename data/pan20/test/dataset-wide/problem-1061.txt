Great question! Here is an approach using super/sub-typing in the barker-ellis notation style. In this approach super and sub-types are used only for classifying based upon a single, un-changing, fundamental characteristic possessed by all the entities of a given entity type. This is similar to the taxonomy of biological organisms. Using this style, we only sub-type based on who you are, not on the role you play. 

Distinct un-ordered rows Uniquely named un-ordered columns Single Value Columns (SVCs) No missing column values 

Aside: One thing I will gloss over in the interest of space but that is extremely important is truly understanding all of the candidate keys. In this example we have RESPONDENT_ID as the PK. Are there other data elements that uniquely identify a respondent? Just designating a surrogate key upon which we declare all the other now "non-key" columns functionally dependent does not change the functional dependencies of those non-key columns on some other column or set of columns which also form a candidate key. Another Aside: There is a CURRENT_IND column. That makes the PK of RESPONDENT_ID very suspicious. If this means what it usually means, then the table could potentially have multiple rows per RESPONDENT_ID, many of which are not current, and one of which is. Then the real candidate key is something like RESPONDENT_ID plus CREATE_DATE. This makes the example too complex to analyze though so I will ignore it. But in reality this is a real problem that implies you really have two types of things here - current respondents and former respondents. This gets into temporal concerns which are complicated to address. Let us assume the following functional dependencies for the second table: 

Your question really is not about normalization. Instead it is about specialization vs. generalization with respect to design. Let me give some background to show why this is the case. Background A table is a relational (R-Table) table, and thus normalized (meaning in 1NF by definition) if in its design a discipline is followed that ensures: 

No, simply because determining if the table is or is not in 3NF has nothing to do with how many candidate keys it has. It instead has everything to do with ensuring all the non-key columns are fully functionally dependent on those candidate keys. But this does bring up an interesting point. Note that a unique key when defined as a constraint in a DBMS is not the same as a unique identifier defined as a business rule in a conceptual business model. Perhaps in our world we always know the person's SSN and thus it serves as a candidate key for a person, and perhaps we also introduce a surrogate key in the logical schema we call Person Id. Our business model includes the rule stating that SSN is a unique identifier for a person in our world. This implies a functional dependency of all the descriptive attributes on this identity attribute. This rule does not change just because we either forgot to or chose not to inform the DBMS. This is precisely why it is vital the constraint be declared - so that the DBMS can ensure the data stored is consistent with the rules of the business model! If we didn't create that unique constraint on SSN we can now inadvertently create more than one row for the same person with the same SSN; each row having a different Person Id! An excellent primer on these topics is Fabian Pascal's Practical Database Foundation Series and Chris Date's Database Design and Relational Theory, from which this answer is derived. While each paper of Fabian's is a must read, paper #1 (which clearly defines the difference between the conceptual, logical, and physical levels) and paper #4 (which clearly defines the various kinds of keys) specifically address this question. Likewise, Chris' entire book is a must read while Part II is the section devoted to normalization with respect to functional dependency. 

The short answer here is none. Normalization, more formally called Projection-Join Normalization, is a scientific process in which one can remove redundancies in R-tables due specifically to join dependencies which are not implied by the candidate keys. The join dependencies are exploited by taking projections based on them to create two or more tables from the original table which removes the redundancy. It is important to note that normalization cannot remove all redundancy. Instead, it can remove only redundancies caused by join dependencies not being implied by the primary key. 

Following is an ERD in Barker-Ellis notation created using Oracle SQL Developer Data Modeler showing these rules: 

What I do at this point is list out the entities and relationships identified and place the attributes identified with the entity type it belongs to: 

The best way to implement this is to create a new table that represents the links between the parent and dependent work packages while leaving the work package table to represent the work packages themselves regardless of dependency. This design does not mix work packages dependent on other work packages with work packages that are not dependent on others. A key advantage of the relational approach is that a single structure with a single set of operators - relational tables and relational algebra - can easily represent a hierarchy or a network. Network DBMS's require two types - a node and a link - with two distinct sets of operators, and thus twice the complexity. A hierarchical DBMS can't represent a network correctly at all. This is a key reason why the NoSQL systems available today can only address a narrow set of use cases. Fabian Pascal's book Practical Issues in Database Management, Chapter 7, gives an excellent overview of data hierarchies using SQL and I highly recommend it. 

Have unique unordered rows Have uniquely labeled unordered columns Have a single value of whatever domain the column is defined upon in cell 

Then if you insert a new step - say between UUID3 and UUID4, you perform more of a linked list operation which will update UUID3|UUID1's NextId to UUID5 and then just insert the new UUID5 with a NextId of UUID4. This will reduce the UPDATEs to 1 in most cases, but it will make querying the process more difficult as now you have to walk the list from top to bottom to list out step by step. You need to decide which process you want to favor - inserting and updating or retrieving. If you favor retrieval (which you might if changes are infrequent and reporting is frequent, and the lists are short), then go with your original design. If you favor insert and update (which you might if changes are happening all the time and reporting is infrequent, or lists are really really long), then go with the linked list approach. I hope this helps. Interested in what other solutions the community might come up with as I'd love to broaden my knowledge around this! 

Fabian Pascal's Practical Database Foundation Series (as referenced above). The remaining paper's in this series provide a concise and easy to understand introduction to the various parts of logical database design. Fabian's gift is his ability to distill very complex topics correctly into language the rest of us can understand. Toon Koppelaars and Lex deHaan's Applied Mathematics for Database Professionals. This wonderful book lays out a sound methodology for logical database design rooted in set theory and logic. It presents the fundamentals and then also presents how to apply them to create a fully functional database in Oracle. CJ Date's Relational Theory for Computing Professionals. CJ Date's body of work is enormous and one can benefit from any and all of it. This particular book is a recent (2013) revision superseding earlier works that really lays out the basics of the relational database model. 

This handles the need to associate the email address with the users as well as the persons, but eliminates the redundancy of using the actual email address text to instantiate the relationship. It has the additional benefit also of ensuring you understand who is actually using a given email address, as you can place an alternate unique index on the email address text as a given email address in unique. I think this kind of solution would eliminate the cons while still retaining all of the pros. 

This gives you a good deal of DDL to start with. A good reference on data modeling is David Hay's Enterprise Model Patterns. I hope this answer helps you move forward with completing your design! 

Not only could it be, it must be if we want to ensure the data stored in the database remains consistent with the rules we have identified in the real world! 

Background I am working on the database design for an application that tracks information about database development projects at my company. The project management office (PMO) assigns a psued-number to each project based on if the project's cost is counted toward merger integration or not. To illustrate, the number assigned will either start with INT (for a project contributing to merger integration) or NINT (for a project not contributing to merger integration). Then a sequential number is assigned. For example, INT175 would be 175'th project identified contributing to merger integration. An additional wrinkle is the PMO sometimes wants to create multiple projects with the same number as they are "related". So for example there could be an INT175a project, an INT175b project, and so on. While the PMO considers this number to be the identifier for a project, in the database I will only use the column as an alternate unique key both to ensure duplicate projects are not created and as a search key for users. I want to implement a check constraint on that column to ensure only a valid number matching the rules I gave above can be entered. What I've Tried - Regular Expressions My first thought was to use a regular expression. In Oracle, my target DBMS, we have the REGEX_LIKE function that can be used. I researched the documentation (here, here, here, here, and here ) on regular expressions and found the options to be dizzying! For whatever reason my brain gets tangled up trying to take the list of all the various pattern matching options and apply it to my specific example. I'm one of those people who work best with examples. Unfortunately, I haven't found many examples out there. What I have found have either been too simple, or so complex I couldn't grasp them. What I have tried thus far is something like this: 

When a transaction against Jim Brown is to be processed, it will come from the source using the source key. Say its system A with source key 12345 with an update to one of the other fields. The ETL looks up the source key in the key map and finds it, and knows to apply that transaction to the row on Person with a surrogate key of 1. If you only had 1 source system life would be easy. But you have 3. This is where the natural key comes in as you know you can identify Jim in any system by using these 2 characteristics that never change and are true about him. Now, say you integrate System D. The first transaction comes in for Jim Brown in system D, and system D's source key is AB2945. Now when the ETL looks in the key map, it doesn't find it. But since you know you have multiple systems that may contain a person, the ETL also does a lookup on the Person table for the natural key and voila - a match. Now the ETL inserts a new row to the key map for System D also for Jim Brown. So in summary you always want to use a surrogate key as the PK in the BI database table when doing data integration of the same logical entity among many sources. You'll map it to the source key using a key map table, and prevent duplicates by looking up on the natural key in the BI table (along with an alternate unique key on the natural key to ensure no duplicates). Now there are many other details to work out - like is your natural key really unique, do you want to store it in your key map to prevent look ups on Person, do you have to handle composite source keys, do you keep a history of source key changes, do you track a system of record and systems of reference, how do you handle source key reuse (a potentially very sticky issue in its own right), etc. But this short summary gives you and idea of the differences between natural, surrogate, and source keys and where to use each in the BI scenario. I hope this helps... 

This indicates that each department will be associated to one or more locations, and thus necessitates breaking this out to its own entity type. A second reason to elevate it is that we can think of a location as a place and as such would have its own attributes such as name, address, city, state, zip, and so on. A third reason to elevate it is that the location is referenced by more than one entity type - the department and the project. If you find the element in question is referenced by more than one already identified entity, you should consider it an entity in its own right that is related to the others, and not simply an attribute of the others. There is no science to this however - its purely a judgment call. This is why ER diagramming is at the conceptual level as its subjective to individual perspectives. One person's entity is another person's attribute depending on their perspective into the domain of interest. Regarding the relationships, here is a list of what I highlighted in pink: 

Oracle is a SQL DBMS not a truly relational database. It implements as its logical model of data a variant of SQL. Its architecture was developed in the late 1970s along the same lines as IBM's System R which was an initial implementation of a DBMS based on the relational model using SQL as the data sub-language. This short background is necessary to understand that SQL and Oracle are not the same as relational. The relational model, as defined by Codd and further developed by researchers like Date, is a purely logical model of data where data is to be presented as relations, with a relational algebra defined to manipulate the relations, and a data integrity component to make it possible for the DBMS to maintain data consistent with its real world intent. The relational model is mute on implementation by the DBMS. Therefore, when identifying a use-case that a given SQL DBMS does not handle well purely due to performance reasons, the issue lies with the implementation, not the relational model. Given this, I suspect NoSQL solutions are sometimes recommended over SQL DBMS' for time series analysis as time series analysis is a very narrow use case and the SQL DBMS architecture was aimed at more generalized online transaction processing use cases. I know little about time series analysis but do recognize that it is purely analytical and not OLTP, and so transaction support - which is a mainstay of SQL DBMS' but orthogonal to the relational model - is pure overhead in such a use case. I recall seeing Michael Stonebraker a few years ago discuss time series analysis and argue the solution was to store data in arrays not rows. Since all the SQL DBMS's are row-stores, that may be another reason why other solutions are recommended. I would caution against diving right into a NoSQL solution. These systems are much less mature than traditional DBMS'. Secondly, time series analysis I believe is pretty heavy statistics and you will likely have to add that yourself with a NoSQL solution. A mature SQL DBMS like Oracle may have some built in statistical features that are much easier to use. Third, SQL is, despite its flaws, a complete query language giving you the power to write queries of arbitrary complexity. Most NoSQL solutions require you to write programs to perform the analysis you want. Finally, and perhaps most importantly, it is likely that to get any useful information out of your time series data you need to "enrich" it with other related data. For example, I work for an electric utility and in this business just having a huge amount of time series data on how much power was used for an interval of time isn't very useful unless you can correlate it to weather, demographics, and so on. A SQL DBMS, precisely because it is a generalized data management solution, makes that easy. You can place the time series data in the same database as the enriching data and have the full power of SQL to join and analyze it. With a NoSQL solution you will have to perform the enrichment yourself as an additional step - potentially extracting, transforming, and loading the data from the very SQL DBMS that wasn't used to store the time series data in the first place! It will be a lot of extra work to write the ETL programs, and you have to decide at the time you write them what data will be useful for analysis. If later you decide you didn't have everything useful, you now have to write more programs. If instead you placed the time series data in Oracle right along with all your other data it is already in place and ready for analysis once you discover a need. Bottom line I would say that unless can prove you have so much data coming in so fast as to exceed the capacity of your existing SQL DBMS installation, and you have the time and the skill sets necessary to write the additional infrastructure on top of a NoSQL solution (assuming of course the NoSQL solution you choose does have the capability to scale to the data volume and velocity), you are better off sticking with the SQL DBMS.