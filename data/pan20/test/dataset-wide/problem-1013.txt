Thanks in advance for the help! This has been wracking my brain. Note that I am re-writing the original query, which had HORRENDOUS performance due to lots of joins on the main table (which is also large). Oh yeah, there should be another couple of columns in the index, but I'm more concerned with getting the correct result set first and THEN I'll consider the performance next. 

I'm not sure what to think about this plan, other than I noticed that 80% on that clustered index scan. Hopefully this is what was being asked for, if not, I can repost. Thanks again! 

Currently by design, there is only ever ONE record in the INSERTED table (we are only updating one record at a time from a UI). What we have discovered is that, as the number of records increase in TABLE_B, trigger performance degrades rapidly. For example, with around 12000 or so records in TABLE_B, this update statement takes around 40 seconds (we established a timeout of 30 seconds). As I remove records from TABLE_B, performance gradually improves. As this was an unacceptable solution, I had to find ways to improve this update statement. Through testing/profiling, I found that the problem was with the second update statement (update TABLE_B). The first update statement works without problem; if I change the second update statement to its equivalent SELECT statement, it also runs fast. The solution that I found was to shove the singular record in the INSERTED table into a #TEMP table and join on that instead. I was also able to do this with a table variable as well, but performance was terrible until I created an index on it. This immediately resolved the problem and the update now runs almost instantaneously. My question is this - why did this solve the performance problem? Perhaps I am looking at this in the wrong way, but I can't imagine why I would need an index on a one record table. I have read that the INSERTED table isn't created with an index on it, but it still seems odd to me that I should need one. Thanks in advance! EDIT: As pointed out, I forgot to mention some other relevant table structure tidbits. TABLE_B indeed has a compound primary key/index created as follows: 

An easy way to get job to execute only on primary node is to put simple check for the job to verify which node is at the time job is being executed. It can be done with simple sql statement: 

I used the following query that I got from EXCHANGE SPILL, but slightly modified it to convert time from UTC to local. 

In SQL Server it is best to store DataTime as one field. If you create an index on DataTime column it can be used as Date search and as DateTime search. Therefore if you need to limit all records that exist for the specific date, you can still use the index without having to do anything special. If you need to query for time portion you will not be able to use the same index and therefore if you have a business case where you care more about the time of the day than DateTime, you should store it separately as you will need to create an index on it and improve performance. 

This questions came from a developer friend who is working with SQL Azure Database. Scenario: There are two Azure DB servers, one in North America, USA region and another one in South East Asia region. One way replication has been setup for a read-only replica to enable a local client to get data faster. The issue is whenever the client has to write data to the database, they need to write to North America, which incurs large latency issue. As a solution, they want to setup bi-directional replication between two servers to keep them in sync and thus allowing a client to read and write from a server located in their region. I'm more of SQL Developer than DBA, thus, I'm not familiar with different options that could be available for bi-direction in SQL Azure DB. I have told him about SQL Broker and how I saw it used for near real-time replication and with some effort it could be set up for bi-directional messages, though not sure if it can be implemented in SQL Azure DB. 

So here's what I'm trying to do: I am trying to write a query that returns an XML formatted document that represents an 'Audit' of any particular date range. That means that the user will enter a date range and a report will be produced that includes all records from the MAIN table in that range and their history (description/explanation fields only) from the AUDIT table, as well as the current state of the record and the very original state of the record. Note that the 'current' record will always be found as the highest UNIQUE_ID in the audit table for a given combination of TABLE_UNIQUE_ID and TABLE_USER_ID. So basically, from the given picture, I should have XML similar to the following: 

However, I am running into problems where I don't capture all the history OR original records (because the DATE_INDEX on the historical records don't necessarily fall in the date range defined by the user). My question is - what might be the best way to produce output, for a given date range (which will be queried in the date_index column), that selects the following: 

This table represents records and associated actions from other tables, where the TABLE_UNIQUE_ID and TABLE_USER_ID are a composite key from the table they originated, XML is the XML representation of the data, and the DATE_INDEX a date the user defines for record (which doesn't necessarily equal the timestamp). This table is large, ranging from 1-10 million records. The main table that records are inserted from is generally in the thousands to hundreds of thousands range. In short, each set of TABLE_UNIQUE_ID and TABLE_USER_ID combined (and TABLE_NAME, but I'm not worried about that right now) represents one record in the main table and everything that ever occurred to this record (they are uniquely identified by the UNIQUE_ID) For example, here's a set of records from this table that represents ONE record and its history in our 'main' table: 

Just asked a Microsoft Certified Trainer during a developer course for SQL Server. He suggested using a single catalog, and having the two indexes, "title" and "body" in the same catalog. The only thing to watch is with too many indexes in the same catalog, there is a greater chance for fragmentation within the catalog. With two columns though, this should not be a concern. 

I'm using SQL Server 2005. I have two tables that contain aggregate information. The information is constantly being updated, generating almost 5GB of log data a day. (That's larger than the entire database!) I'd like to disable logging on these tables, as rolling back is not really necessary. I would however like to keep logging on the other tables in the database. Is it possible to disable logging on certain tables within the database? If not, can I place the two tables in the same schema, then disable logging on the schema? Is the only option to move the two tables to a separate database, and disable logging there? Update: I guess I'll explain why I really don't need to log the activity on these tables. The two tables are filled with GPS data, so they get quite large. The first table is capturing raw locations from six Android tables in the field. New data from each of the tablets comes in every 5-10 seconds. That information is then aggregated as locationA, locationB, travelTime. The goal is to ultimately have the shortest travel times between all locations, based on actual driving data. The data is only for a small city, and only accurate to four decimal places, so it is manageable. However, as new raw data comes in, there are slower travel times that need to be updated, and new ones that need to be inserted. Once the raw data is aggregated, it is purged. We're not going backwards to longer travel times, so that is why rolling back does not matter so much in these tables. 

I saw it once during a presentation when someone showed a query to get a count of how many times views have queried in a SQL server. I don't remember if it was from DMV or a combination of some other statistics, but I clearly remember when they ran a query that selects from a view and after it would show that count going up by one. Another interesting fact that I recall about the presentation was selecting from a CTE increased the count by two because SQL Server has to create a "temporary view" and later select from it. Does anyone know how this can be demonstrated? 

which made no sense as it is self-join back to the table. After carefully looking at your plan I realized that you are bringing back data from a view and then joining it back to the base tables that are present in the view. It is a known issue that nested views will always produce estimated row count of 1 no matter how much you update statistics. My recommendation is to rewrite query without use of which just hinders performance. Remember: Views are not for performance, they are for simplicity and easy of access of information. 

When I look at messages, the command does not return row every loop but shows up as multiple rows at ones. I have added one line and now it shows up 1 line at the time and the the whole process is much faster. 

Is it possible in the foreign key definition to restrict the categories that can be referenced based on another column in the table? For example, say there is a column in the table. I'd like the foreign key constraint to be restricted to those categories where . 

Setting history is not really important to me, so I wouldn't need to see if the active flag was ever used. Is it best to use a smaller table and insert, delete, insert, delete, etc., or is it best to add that extra bit, and insert, update, update, update? I'm running SQL Server 2005. 

When creating the index, it is possible to specify a "LANGUAGE" argument. Within the description of the "LANGUAGE" argument is the following: 

Each user can choose to apply the settings, or not. The interface allows them to quickly toggle the settings on or off. The setting is by default off. I'm looking for best practice on the table. Should it be designed such that only active settings are included in the table? This would involve a lot of inserts and deletes on the table. 

Then, when doing a search using FREETEXT or FREETEXTTABLE, once again use the "LANGUAGE" argument. Microsoft defines the "LANGUAGE" argument as follows: 

So, I will use one catalog and one index on the multi-lingual table using a neutral language resource. Then I'll use the appropriate language setting when searching so everything is parsed correctly.