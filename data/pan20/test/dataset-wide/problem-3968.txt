I would like to find a good reference for the following or a similar, probably well-known, approximation error result: Let $\Omega\subset \mathbb{R}^d$ be bounded, $p\in [1,\infty]$, $l, m\in \mathbb{N}$ with $l\leq m$ and $(Q^h)_{h>0} \colon W^{m,p}(\Omega) \rightarrow W^{l,p}(\Omega)$ a family of operators such that for $u\in W^{m,p}(\Omega)$, $x\in \Omega$ and $h>0$ the value $Q^hu(x)$ only depends on $u$ in the ball $B_h(x)=\{y\in \Omega| |y-x|<h\}$. Furthermore we assume that $Q^h$ is exact for all polynomials of degree smaller than $m$ and that there exist a constants $K,C_1>0$ such that for all $x\in \Omega$ and $h>0$ we have $$ |Q^hu|_{W^{l,p}(B_h(x))}\leq C_1 |u|_{W^{l,p}(B_{Kh}(x))}. $$ Then there exist $C_2>0$ such that we have $$ \left|u-Q^hu\right|_{W^{l,p}}\leq C_2h^{m-l}|u|_{W^{m,p}} \text{ for all } u\in W^{m,p} \text{ and } h>0. $$ The estimate can be proven using the Bramble-Hilbert lemma. In finite element books one can find similar estimates but not in this full generality. Jackson's inequality is also similar to this but there it is with trigonometric polynomials. If it helps in my case one has to additionally assume $m>d/p$ because my operator is defined only for continuous functions. 

Found a proof for the half sphere by showing that the functional is convex at every critical point and using poincare-hopf theorem. 

As explained in the comments the smallest solution (if it exists) must be between $\sqrt[16]{100801956}$ and $\sqrt[16]{100801957}$. The first few digits are $3.16385673$. 

Edit: Original proof was wrong and I couldn't fix it. The algorithm does not work in general. For $S\subset [n]$ let $a_S=\sum_{i\in S} a_i$, $b_S=\prod_{i\in S} b_i$ and $c_S=a_S/b_S$. If $S$ is optimal, $i \in S$ and $j\in [n]\backslash S$ we have $$\frac{a_S}{b_S}=c_{S}\geq c_{(S\backslash i)\cup j}=\frac{a_S-a_i+a_j}{b_Sb_j/b_i}$$ Hence $a_S(b_j-b_i)\geq b_i(a_j-a_i)$ and therefore $$\begin{cases} a_S\geq \frac{(a_j-a_i)b_i}{b_j-b_i} & \text{if } b_i>b_j\\ a_S\leq\frac{(a_j-a_i)b_i}{b_j-b_i} & \text{if } b_i<b_j\\ a_j\leq a_i & \text{if }b_i=b_j\end{cases}.$$ The values $\frac{(a_j-a_i)b_i}{b_j-b_i}$ for all pairs $(i,j)\in [n]^2$ divide $\mathbb{R}$ into maximal $2\binom{n}{2}+1$ many intervals. We loop through all these intervals and assume each time that $a_S$ lies in the corresponding interval. If an inequality above is violated we get that $i\in S \Rightarrow j \in S$. We consider a directed graphs with vertex set $[n]/\sim$ with $i\sim j$ iff $(a_i,b_i)=(a_j,b_j)$ and a edge from $i$ to $j$ iff $i\in S \Rightarrow j \in S$. Originally I presented a wrong proof where the graph had an edge between any two vertices and one could continue with that. 

Supposing the pair $f(\cdot)$ and $\phi(s,\cdot)$ don't have to map $\mathbb{C}$ to itself, that $\mathbb{C}$ is weakened to the unit disk $\mathbb{D}$, and $f(0) = 0$ with $|f'(0)| \neq 0,1$, then there always exists a $\phi$ satisfying $f$. It seems though, as soon as we lift from $\mathbb{D}$ (or any simply connected domain biholomorphic to $\mathbb{D}$) to $\mathbb{C}$ it fails. I can show the result in a restricted form, which I also think is interesting 

This question has been bogging me down lately. I'm not sure how to come up with an approach to tackle the proof exactly. I'm without a proof, butI think the result I'm searching for is true. Similarly, I do believe I'm not the only person to consider this question and I expect it is already answered somewhere in the vestibule of the internet. The $n$'th super root is defined as the inverse to the function $$^n x = F_n(x)=x^{x^{...n\,times...^x}}$$ so that if $\Psi_n(x)$ is the function in question then $$^n \Psi_n(x) = F_n(\Psi_n(x)) = x$$ Now $F_n(x)$ depends on the branch of the logarithm chosen to define it, and therefore it is multivalued. We will stick to the principal branch of the logarithm as it simplifies the question (and I assume solving for other branches only requires a modification of the proof). It is obvious $F_n(x) : \mathbb{C}/ (0,-\infty) \to \mathbb{C}^{\times}$. It also follows that for $\Re(y) > 1$ there exists $x \in \mathbb{C}$ such that $y = F_n(x)$. Now we can define an inverse through the analytic implicit function theorem granted that $\frac{d}{dx} F_n(x) \neq 0$ when $\Re(F_n(x)) > 1$--but showing this is rather daunting. It invovles showing when $\Re(F_n(x)) > 1$ we have $$\frac{F_{n-1}(x)}{x} + \log(x)F'_{n-1}(x) \neq 0$$ which is rather daunting to say the least. This brings me to my question which is more of a reference request than anything. Unless I'm completely missing something and the answer is right on my nose. 

Well, this problem can be handled exactly as the last one was handled. Let me give you a rough reasoning as to why. I won't elaborate in detail as quite literally my last answer handles this case with little generalization. Any bounded function $\phi(z)$ in the right half plane $\Re(z) > -\delta$ for some $\delta > 0$ can be written as $$\phi(z) = \sum_{n=0}^\infty \dbinom{z}{n}\sum_{m=0}^n (-1)^{n-m}\dbinom{n}{m} \phi(m)$$ and $\phi(pz+s)$ for $p,s \in \mathbb{R}^+$ is equally so bounded, so that $$\phi(pz+s) = \sum_{n=0}^\infty\dbinom{z}{n}\sum_{m=0}^n (-1)^{n-m}\dbinom{n}{m} \phi(pm+s)$$ The sampling data can be spread out, and shrunk with no effect when $\phi$ is bounded. (This result can be stated much more generally, but I'll stick with this version.) The essential point I'm making is that the sampling data doesn't matter, as long as its a linear function and it's evenly spaced. Now what you are essentially doing is the same thing you did before, except you are working with $(^{zp+s}a)$ in stead of $(^z a)$. The sampling data will not matter because the function you are interpolating is bounded. Therefore watch carefully my reasoning $$\phi(z) = \sum_{n=0}^\infty \sum_{k=0}^n (-1)^{n-k} \, q^{p \binom {n-k} 2} {z \brack n}_{q^{p}} {n \brack k}_{q^{p}} ({^{p\,k+s} a})$$ This function has imaginary period $2\pi i /\log(q)p$ (just like $^{zp+s}a$). This function tends to a constant as its real argument grows, therefore it is bounded. Now, assuming that $\phi(n) = (^{pn+s}a)$ then $\phi(z) = (^{pz+s}a)$. I didn't see you state that it agrees on the naturals, but I'm assuming that is why you asked this. This result follows for the exact same reason as it did in your last question. The functions agree on the naturals $\phi\Big{|}_{\mathbb{N}} = (^{pz+s}a)\Big{|}_{\mathbb{N}}$ and both functions are bounded on the right half plane, therefore $\phi(z) = (^{pz+s}a)$. 

Let $\Omega\subset \mathbb{R}^d$ be open and bounded with $C^\infty$ boundary $\partial\Omega$, $\phi\colon \partial\Omega \rightarrow \mathbb{R}$ continuous and $u^\phi$ the solution to Laplace's equation $\Delta u^\phi=0$ on $\Omega$ with Dirichlet boundary conditions $u^\phi|_{\partial\Omega}=\phi$. Is it true that there exists $C>0$ independent of $\phi$ such that $$ |u^\phi|_{H^1(\Omega)}:=\|\nabla u^\phi\|_{L^2(\Omega)}\leq C\|\phi\|_{L^\infty(\partial\Omega)}? $$ More generally, if $M\subset \mathbb{R}^n$ is a Riemannian submanifold of $\mathbb{R}^n$ and $$ u^\phi:=\mathop{argmin}_{\substack{v \in H^1(\Omega,M)\\v|_{\partial\Omega}=\phi} } |v|_{H^1(\Omega,\mathbb{R}^n)}, $$ is it true that $$ |u^{\phi_1}-u^{\phi_2}|_{H^1(\Omega,\mathbb{R}^n)}\leq C\|\phi_1-\phi_2\|_{L^\infty(\partial\Omega,\mathbb{R}^n)}? $$ I am trying to derive a discretization error estimate for a numerical scheme. Since the boundary condition can in general not be implemented exactly I would like to estimate the error due to errors in the boundary data. 

By the generalization of HÃ¶lder's inequality, i.e. $$ (u_1v_1w_1z_1+u_2v_2w_2z_2)^4\leq (u_1^4+u_2^4)\dots(z_1^4+z_2^4) $$ and $ab+(1-a)(1-b)\leq 1$ we have $$ \begin{eqnarray*} &&(abx+(1-a)(1-b)y)^4\\ &\leq&\left(a^2b^2x^4+(1-a)^2(1-b)^2y^4\right) (a+(1-a))(b+(1-b))(ab+(1-a)(1-b))\\ &\leq& a^2b^2x^4+(1-a)^2(1-b)^2y^4. \end{eqnarray*} $$ 

By MassiveJack's comment it follow that $$f(z^{\frac{p}{q}})=(f(z))^{\frac{p}{q}}$$ for all $p,q \in \mathbb{N}$ and $0<z<1$ and by continuity $$f(z^\alpha)=(f(z))^\alpha$$ for all $0<z<1,\alpha>0$. Now put $z=e^{-1}$ and $\alpha=-\log(x)$ then $$f(x)=f(e^{-1})^{-\log(x)}=x^{-\log(f(e^{-1}))}$$ hence $f$ is of the form $f(x)=x^a$ on $(0,1)$. As $f(z)^2=f(z^2)$ and $f$ is continuous we have $f(-z)=f(z)$ or $f(-z)=-f(z)$ for all $-1<z<0$. Now it is easy to answer the three questions: 

Let $X$ be a hadamard space and $\gamma_1, \gamma_2 \colon \mathbb{R}\rightarrow X$ be two geodesics. Part 2 of Coroallary 2.5 in $URL$ states that $f(t):=d(\gamma_1(t),\gamma_2(t))$ is convex. I wonder under what conditions $f$ is even strictly convex. My conjecture is that if $f>0$ then $f$ is strictly convex or constant. However I dont know how to prove nor where to find such a result. My motivation is that I want to prove uniqueness of a minimizer of a functional $J\colon X^n\rightarrow \mathbb{R}$ of the following form $$J(u)=\sum_{i=1}^m d^2(a_i,u_i)+\sum_{(i,j)\in E} d(u_i,u_j),$$ where $1\leq m<n$, $a_1,\dots,a_m \in X$, , $E\subset \{1,\dots,n\}^2$. I want to prove that if the graph corresponding to $E$ is connected and $a_1,\dots,a_m$ do not lie on the same geodesic then there exist a unique minimizer. Edit::The conjecture about $J$ is wrong, just assume that $i$ is a node with exactly two neighbours $j_1$, $j_2$. Then $u_i$ can be choosen anywhere on the geodesic between $u_{j_1}$ and $u_{j_2}$ without changing the value of $J$. 

I can think of two good examples. The first is rather straight forward. The hyper-operators. Namely, $$a \uparrow^n b : \mathbb{N}^3 \to \mathbb{N}$$ $$a \uparrow^0 b = a \cdot b$$ $$a \uparrow^n 1 = a$$ $$a \uparrow^{n} (a \uparrow^{n+1} b) = a \uparrow^{n+1} (b+1)$$ $$a \uparrow^{n+1} b = a \uparrow^n a \uparrow^n ...(b\,times)... \uparrow^n a$$ It is a rather interesting open problem to construct the same object in analysis. Namely, replace the $\mathbb{N}$'s with some domain in $\mathbb{C}$. Pivotally, tetration, or $e \uparrow^2 z$, is somewhat solved (though controversy exists as to which solution is the right solution). You can perceive the problem better with tetration. It's very easy to get $$e \uparrow^2 k = e^{e^{...k\,times...^e}}$$ which satisfies $$e^{e \uparrow^2 k} = e \uparrow^2 (k+1)$$ but how do we get holomorphic $e \uparrow^2 z$? Surely in this scenario the discrete instance inspired the continuous instance. Another one would be indefinite summation. Everyone knows that $$\sum_{j=1}^n f(j) = a(n)$$ is well defined, and satisfies $a(n) + f(n+1) = a(n+1)$, but how do we get holomorphic $$\sum_{j=1}^z f(j) = a(z)$$ where $a(z) + f(z+1) = a(z+1)$. Surely the discrete instance inspired the continuous instance, again. In fact, the whole field of study dedicating itself to extending recursive relationships defined on the naturals to the complex plane fits the bill of discrete before continuous very well. 

I mean to ask if $G(\xi(x,y))$ satisfies the Cauchy-Riemann equations for $(x,y) \in A \subset \mathbb{R}^2$ almost everywhere under the $\mathbb{R}^2$ Lebesgue measure, and if $\frac{\partial G}{\partial x} = \text{Constant}$ and $ \frac{\partial G}{\partial y} = \text{Constant}$ almost everywhere. This would imply that $G(\xi)$ is a weird triangle wave in its own right. Sadly though, comparing the situation to $\sin$ again, the discontinuities of the derivative of $T(x)$ are at the critical points of $\sin(x)$. This makes things a bit easier to classify. $T'(x)$ is discontinuous when $\sin'(x) = 0$. Unfortunately $f(x)$ has no critical points, $f'(x) \neq 0$, so we don't get something as simple. Forcing us to ask, if $G$ is continuous and differentiable outside a set of measure zero with no limit points, 

What do you need your transformation for? One possible transformation would be $f(t)=A^{1/2}(A^{-1/2}BA^{-1/2})^tA^{1/2}.$ It satisfies $f(0)=A, f(1)=B$ and is the geodesic w.r.t. to the metric $d(A,B)=\|\log(A^{-1/2}BA^{-1/2})\|_{tr}$ where $tr$ denotes the trace norm, i.e. $\|A\|_{tr}=\sqrt{trace(AA')}$, see also "The Riemannian Geometry of the Space of Positive-Definite Matrices and Its Application to the Regularization". Regarding the transformations (1) and (2): First note that the operations permute. Second note that if all eigenvalues have multiplicity one then the function which assigns the eigenvalues and the functions which assigns the eigenvectors are continuous. Hence in this case the conjecture holds true. If a function has multiplicity more than 1 it gets more complicated... 

Let $M$ be a compact Riemannian submanifold of $\mathbb{R}^K$, $U\subset \mathbb{R}^K$ an open neighboorhood of $M$ such that the shortest point Projection $P_M\colon U\rightarrow M$ is well-defined and smooth, $\Omega \subset \mathbb{R}^d$ open and bounded, $m \in \mathbb{N}$, $p\in [1,\infty]$ such that $m>\frac{d}{p}$ and $f \in W^{m,p}(\Omega,\mathbb{R}^K)$ with $f(x)\in M$ a.e.. I want to prove that there exist $C,h>0$ such that $$|P_M(g_1)-P_M(g_2)|_{W^{l,p}}\leq C|g_1-g_2|_{W^{l,p}}$$ for all $0\leq l\leq m$ and $g_1,g_2 \in W^{m,p}(\Omega,\mathbb{R}^K)$ with $\max(\|g_1-f\|_{W^{m,p}},\|g_2-f\|_{W^{m,p}})\leq h$. Here $P_M(g_1) \colon \Omega \rightarrow \mathbb{R}^K$ is defined by $P_M(g_1)(x):=P_M(g_1(x))$ for all $x\in \Omega$. I could find similar results, but not the one I need, in Section 5.5.2 of Sobolev Spaces of Fractional Order, Nemytskij Operators, and Nonlinear Partial Differential Equation by Thomas Runst and Winfried Sickel My goal is to extend error estimates for an operator $Q$ to error estimates of the operator $P_M \circ Q$ for functions with values in $M$. 

Your conjecture is true. Assume that $n$ is the smallest integer such that these polynomials are linearly dependent. Then there exist $a_0,\dots,a_{n-1}$ with $$f(x):=\sum_{i=0}^{n-1} a_i N_n(x+i)=0$$ for all $x\in [0,1]$. Let $$g(x):=\sum_{i=0}^{n-1} a_i N_{n-1}(x+i).$$ By the definition of the splines we have $$f(x)=(N_1*g)(x)=0$$ for all $x\in [0,1]$. It follows that $$\int_0^1 g(y)dy=0 \quad \text{and} \int_0^x g(y)dy=\int_1^{1+x} g(y)dy$$ for all $x\in [0,1]$. It follows that $$g(1+x)=g(x) \text{ for all } x\in [0,1]$$ and $$g^{(i)}(0)=g^{(i)}(1) \text{ for all } i\in \{0,\dots,n-3\}$$ Let $p$ be the smooth extension of $g|_{[0,1]}$. Assume that $p\neq 0$ and let $a_kx^k$ be the leading term of $p$. Then $0=g^{(k-1)}(1)-g^{(k-1)}(0)=k!a_k$ which is a contradiction. Hence $g(x)=0$ for all $x\in [0,1]$. As $N_n|_{[n-1,n]}\neq 0$ at least one of the coefficient $a_0,\dots,a_{n-2}$ is nonzero. It follows that $$\{ N_{n-1}|_{[i,i+1]}|i\in \{0,\dots,n-2\}\}$$ are linear dependent which is a contradiction to the choice of $n$ being minimal.