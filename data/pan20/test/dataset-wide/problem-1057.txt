Aaron already pointed out and I am going to emphasize on that, starting from SQL Server 2012 the SQL Server express database engine can consume more than 1G of memory. The BOL information is not updated one it still says memory is which is incorrect. As per this support article 

Yes this is doable. For your scenario if you want to remove the database from availability replica you must do that from secondary replica. So you have to login into secondary replica from which you need to remove database. Expand availability database, right click on it and select . You can choose multiple databases to remove at one go. More information in BOL document If you want to do using TSQL which I prefer just login into secondary replica from which you want to remove the database and run 

So basically it does page movement and frees empty space from the pages. This movement of page is logged in transaction log file. Due to this movement the logical ordering of pages changes and hence logical fragmentation comes in. The point to note here is this is not an atomic operation. If you stop the shrinking operation in between the changes done so far is not lost it is maintained and when you start next time it will continue from where it left. See this Blog from Paul Randal for data file size management if you are worried about growing data file size. 

There was surely something happened in database . The first thing you should do is change autogrowth setting you have set autogrowth in percentage(10 %) for both data and log files this IMO would have forced database to grow unnecessarily. You can refer to Autogrowth settings and how to configure it and configure optimum value for this preferably in MB. 

Changing recovery model to bulk logged and doing bulk logged operation would make you loose point in time(PIT) recovery so if you are concerned about PIT recovery dont do that. Instead rebuild index through intelligent script which only rebuild fragmented index like one Is Ola Hallengren index rebuild solution please note that if Index is rebuild with full scan for that index stats is already updated with rebuild process. If you do heavy DML please break it into batches so as not to explode log files. 

NO, this is where Availability Groups are so nice. No matter on which secondary replica you take transaction log backup it would work. What happens is when you take backup on secondary replica and after it finishes the secondary replica will give all information related to log backup to primary replica like LSN and VLF's that can be marked as truncated and accordingly primary replica does the changes. Bottom line is you can take log backup on any replica and the changes would be reflected on primary. I would suggest you read Active Secondaries: Backup on Secondary Replicas (AlwaysOn Availability Groups). From the BOL I quote 

Not necessarily, a single MSDTC can work for multiple instances. But if you want to know what all queries need MSDTC I would direct you to Cindy Gross Blog Do I Need MSDTC for SQL Server Cluster. Quoting 

I can only say please leave it to default, I am not sure how recovery time has anything to do with log file and its configuration Regarding Tempdb make sure you have Data files equal to number of physical cores. Paul has more to say about how many files you can have as per cores IMHO you can start with 4 tempdb files but keep monitoring for contention. Make sure that all tempdb data files have SAME INITIAL SIZE and SAME AUTOGROWTH setting. You can also enable TF 1118 to avoid contention To check contention you can run below query 

You need to first update your script to point to new location. Then you need to make sure SQL Server service account has read write permission on the new NAS where you would be taking backup. You also need to make sure that SQL Server can see the NAS otherwise if there is no connectivity you would not be able to backup there. A simple test can be done, create a test database on SQL Server and try taking backup using TSQL command, you were using to backup on previous NAS, if you succeed well and good if not resolve the error. 

let us see how many databases have auto shrink enabled Yes you an kill backup operation (SPID 186 here) but you would loose all the time spent in taking backup and you would have to start all over again. Before doing that let us see how much backup has finished, what is output 

Yes if database is in full recovery mode and NO proper transaction log backup is in place or no transaction log backup is taken at all the log file can grow huge and can grow greater than data file. In full recovery mode ONLY transaction log backup can truncate the logs and make them reusable. This is how circular nature of transaction Log works. The working of transaction log is quite nicely explained in Logging And Recovery In SQL Server. Full recovery model is ONLY suggested when point in time recovery is required. If you don't need point in time recovery and you are OK with some data loss change the recovery model to simple. In simple recovery model log truncation happen automatically after checkpoint hapens or when log file grows 70% of its size, only exception is if long running transaction requires a portion of log file then it wont be truncated. So you can see in simple recovery log truncation is managed by database engine. You cannot take transaction log backup in simple recovery mode. 

On SQL Server VM committed can become equal to VM Reserved, it's not necessarily an issue. And please don't develop a habit of restarting SQL Server IMO this is worst you can do. Now what I think is you are facing performance issue in SQL Server and you need to find out first what actually is causing your Server slow. To get started with you can refer to How to analyze SQL Server Performance This would actually help you to find out where the problem is. Believe me from what you posted it does not seems to me like its a memory issue, again you gave limited information about SQL Server version so my answer is limited. Please add output of below in your question 

Leave 2 G memory straight away for Windows OS. Of course system would have antivirus running. Please leave 1.5G for Antivirus. Please note Mcafee and SQL Server do not go hand in hand so make sure you leave enough for it. You can also check perfmon counter to monitor memory usage by AV and other small applications running on SQL Server box 

No whole table might or might not be kept into buffer cache depending on size and whether SQL Server finds all such pages during read ahead reads. SQL Server would try to bring as much page as possible which it can do with read ahead reads. The amount of read ahead pages SQL Server can read in enterprise edition is much more and efficient than standard edition. So its quite possible that SQL Server would read not only page that holds row but more such pages so it might not do any but since most pages which belong to table are bought into memory (by read ahead) and since index is not present SQL Server will do some good amount of logical reads to find the row Example: I run a query like below on Developer edition which is same like Enterprise edition. Table T1 has no index 

I suppose you are referring to This support article. The purpose of this support article is if you are trying to install Service pack on cluster without disturbing the current cluster configuration(active nodes) and you want to keep things online. I suggest take application downtime and apply service pack in that case you don't have to remove any possible owners from the list. I always consider this better way of applying SP, although MS provides you way to update the passive node of cluster without disturbing active node. This article also helps you when you add node to cluster with RTM version while cluster is on higher SP level, then you have to apply SP on passive node in that case after adding node make sure the added node is not in possible owner list and go ahead and apply patch on passive nodes added so as to make it identical to all nodes. 

I just took backup of Adventureworks database on my local machine and provided media name below screenshot will show you the result. 

First of all please note initial size is not actually what it means. Yes you can do it but make sure you don't use SSMS GUI. 

To see all column names which fn_dblog would produce Example: I would show what all things are logged when simple update command is fired 

To further understand the problem I would require you to add output of below queries into your question. I would also like you to add output of Paul Randal Wait stats query. The source of query is This Blog, I suggest you to read the blog. 

If database files are on multiple disks backup operation would initiate on thread per device drive to read the data. In same way if restore is done on multiple drives/mount points backup operation would initiate one thread per drive/mount point Even if you are dumping multiple copies of backup on same drive we would have one thread per backup file dumped. The parallelism associated with backup is related to the stripes. Each stripe gets its own worker thread and that is really the only part of backup/restore that one should consider as parallel operations. The max degree of parallelism has no affect on backup operation. 

There are other methods as well. Perhaps you can use two DMV's. Please note that both will only work for SQL Server 2008 and above A non zero value for locked pages allocation KB would tell that SQL Server account has Locked pages in memory privilege 

Can you please add the output of above query in question and lets see how much memory AWE API is allocating. 

This was just a small demo. Remus Rusanu has explained how to read transaction log in details in This article please read it 

Index reorganize does not touches statistics so there is no chance for causing recompilation. Since when index is rebuilt with full scan stats are also updated for the column this can trigger recompilation as statistics change. 

If you believe this is the case and you want SQL Server not be be victim of such issues you must make sure SQl Server service account has Locked Pages in Memory Privielge (LPIM). This will not let OS to force SQL Server page out its memory. If account running SQL Service is local system by default SQL Server will have this privilege in SQL Server 2012. Note: