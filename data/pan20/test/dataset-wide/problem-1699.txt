As Khaled said, you can use check_snmp to monitor the printers - you'll need to check the docs for your printers to see what OIDs to check for the things you want to monitor. I expect that most of the things you are looking for will be snmp trap alerts rather than exposed through passive checks (checks initiated from Nagios) - I always struggled to get traps working with Nagios. Alternatively, a lot of printers that support snmp also support email alerts for the same events. That may do all you need without requiring Nagios. Also note that if you want to monitor other printer counters, you may actually want to monitor the print queue on your server if you are using windows print queues. 

Currently using Groundworks Open Source Community Edition 5.3 - although support has fallen by the wayside on that version now. May upgrade to GWOS 6 or perhaps jump ship to Zabbix or similar Open Source system. I tend to favour those based on Nagios, but wouldn't go for vanilla Nagios due to the nightmare of managing all those interdependent config files. Groundworks' WMI Monitoring plugins for NRPE work pretty well. Nagios triggers a WMI service check on a windows box using NRPE, which then does the WMI querying of your other windows boxes. This gets around the requirement to have NRPE agents on your windows boxes, and also the nightmare of trying to get Nagios running on *Nix to authenticate on Windows. Another nice option is to set up SNMP on your windows boxes as part of your base build. There are some options out there to expose WMI checks via SNMP (SNMPTools) (although you need to install this on each Windows box, making it not agentless). There are a number of Windows tools which can monitor Windows logs and send an SNMP trap when certain events occur. 

In a perfect world, you would have network drops to all machines possible, and a good wireless access point for the few people who cant use a network cable. You can connect as many routers/switches into a network that you want to (there is a limit with old 15 year old hubs but not new switches), but each one introduces more failure points and potential quirks when dealing with consumer equipment. 

Well, we eventually couldnt figure it out and ended up to making someone drive 9 hours to get last known backup tapes :p Not fun at all. Moral of story: 1.) have more than 1 DC at all times 2.) back the systemstate up constantly and verify! 

Unfortunately that's a bit vague to start with. Define "performance drops a lot". This is one of those situation wheres there's about 20 different things to check, both hardware and software. Hardware: - do you have a good decent nic on both ends? (intel/broadcom), not realtek - do you have a managed switch? - Is the managed switch maybe unavailable to do all the process switching if small packets? - have you tried swapping network cables - confirmed it's gigabit? - perhaps your harddisks can't keep up with the data streams? generic basic harddrives can be maxed out on gigabit. - do have a network card that does TOE? Software: - are you using mtu 9000 aka jumbo buffers in card? - have you looked at tuning receive windows or buffers? - What OS? - If windows, do you have av/firewall software running? Applicationlevel/Data: - is it being encrypted? (tunneled over ssh?) - What protocol? ftp/cifs/rsync/http/nfs - what are the size of files? thousands of small files or one really large one? There's so many places to start, but those are some questions you need to answer to yourself. Once you get to the software level, I would recommend using iperf between the 2 machines and seeing what the maximum of raw data you get. That will tell you the highest possible speeds. Then you can compare it to what your application is giving you. 

I am seeing the 1030 and 1058 errors for a remote Windows Server 2003 domain controller. Specifically the 1058 error says: 

How the hell do Sharepoint Permissions Work? You should also make sure you look at the permission levels you have set at the site level and the pages/document library level - make sure Contribute includes the abilities you require. 

I don't think there is any difference in the ping part of it. When you run pathping, it does a traceroute, then pings each of the devices in the route, and reports the results of ping. You could do this manually, and I guess at some point someone who had to do that got bored and wrote pathping to do it in a single step. 

It isn't uncommon to find the device in each location that is making the VPN connection is also capable of acting as a DHCP server - e.g. Cisco ASA, Linux server, pfsense, m0n0wall. Depending on the capacity of the device and number of clients at the site, this might be worth taking advantage of. This is particularly useful where there may be site specific configuration you want to push out via DHCP. For example, you might want to include a public DNS server in the list of DNS servers assigned, so in case the VPN fails, but the Internet is up, people at the remote site can access public resources even if your central DNS is unreachable. It is also a lot easier to visualise/explain this way. 

I'm trying to migrate a dns server that has several thousand zones loaded on it. The named.conf file has about 17 different includes, and some of those files also has includes in them, and lots of commented out etc. It's a fricking mess! I'm wanting to get a list of all the zones currently loaded into BIND. I looked at rndc dumpdb but it doesn't show me just the zones. Instead of following the messy include files, is there an easier way to get a list of the authorative zones inside BIND? Thanks! 

Confirmed rndc dumpdb is the best method. In my case, i discovered that there was 2 seperate bind instances running on the same server (don't ask), one doing forward dns and one doing reverse dns. Without specifying the PID, it attached to the one only doing reverse dns and only showed me that. 

Unfortunately this is a vague issue and it needs to be narrowed down. One of the first things that needs to be done is to make a chart clarifying what the problem is, and for whom. Chances are fixing the wireless network will improve your network greatly, but that might not be the real problem. One of the main questions would be , are the people who are physically wired in experiencing problems? If so, then that shifts the focus from the wireless issue to a server/application level issue, perhaps upgrade from older switches to gigabit etc. Wireless is not as good as a physical cable. Especially with consumer wireless routers/access points. They're designed for a few people to surf the internet, not a business network. Chances are the wireless network isn't operating as well as it should be. Few options: 

You can probably do it via an advanced search, where you specify the column with your doc number in it as a search field your users can use. You may also find that searching for the number in the regular search works - if this returns too many documents because your numbers are low (e.g. 1 would probably return a lot of docs that have 1 in the body) you might look at adding a prefix to your numbering system to avoid this. 

This article on taming oom-killer looks particularly useful. Seems you can set priorities to prevent oom-killer killing certain processes (sshd would be a good start for a VPS!) 

I have a number of Cisco ASA 5505 and PIX 506e around the world acting as VPN endpoints. They connect to a Cisco VPN Concentrator 3000 at HQ. I am using Easy VPN to set up the VPN (i.e. most of the config is central on the VPN Concentrator) The majority of endpoints work absolutely fine. However, there are three that do not. 2 ASAs and 1 PIX get disconnected from one of the VLANs on our network. This is the VLAN that my monitoring server runs on - so those endpoints look as if they have gone down. However, I can still ping the endpoints from our user VLAN. If I then SSH onto the endpoint, and do a ping to my monitoring server, the connection comes back. Then after about 10 minutes it stops working again. I've looked at the configuration of my endpoints, and I can't see any significant differences. One common feature is that the affected endpoints are connecting to the internet via retail quality routers. However, I don't see how this could affect traffic within a VPN tunnel. Any ideas or suggestions? I've also got a thread on Cisco's forums at $URL$ One other person has reported the same problem. 

So... was trying to add in a 2008 DC to a single 2003/exchange 2007 setup. ran adprep and updated schema, and joined the new DC to the AD... then 6 hours later noticed everything was not working. Restore tapes are offsite and not available for a few days so no easy option. The gist is the GC is not locatable and the sysvol isn't being shared. If you connect directly to the DC you can query all objects inside the AD properly, but nothing that queries the root domain itself works. went through the dns tree and eveyrthing seems proper. the server is pointing to itself for dns. dcdiag shows: Starting test: FsmoCheck Warning: DcGetDcName(GC_SERVER_REQUIRED) call failed, error 1355 A Global Catalog Server could not be located - All GC's are down. Warning: DcGetDcName(TIME_SERVER) call failed, error 1355 A Time Server could not be located. The server holding the PDC role is down. Warning: DcGetDcName(GOOD_TIME_SERVER_PREFERRED) call failed, error 1355 A Good Time Server could not be located. Warning: DcGetDcName(KDC_REQUIRED) call failed, error 1355 A KDC could not be located - All the KDCs are down. i have done ntdsutil and seized all roles anyway, confirmed under sites that the DC is a GC. it should work...google doesnt show what i want.... i'm good with AD but not good enough ;) Where do i go from here? 

Cisco ASA 5505 in remote site, connecting as Easy VPN client to ASA 5510 at HQ. VPN light is green, and shows active security association. However connectivity to some of our subnets is not working. Running shows IPSEC SAs exist for most of our subnets, but not all. Not surprisingly, for subnets where there is no SA, there is no connectivity possible. When this happens, running or power cycling the remote ASA restores the IPSEC tunnels, and access to all the subnets is possible again. When this occurs it is intermittent. No config changes have happened with the devices affected. Here are my questions: 

So you are trying to block all IPs that try to login as root? I would imagine most non-targeted hacking attempts will first try logging in as root then try enough non-existent accounts to get the IP banned. If this isn't the case maybe you should change your approach. I think a better option than locking root altogether would be to disable external login as root through sshd's config. That may result in attempts to login as root triggering a security message that fail2ban can use. 

you can remove i386 directory with the caveat that if you need to install new services you need the windows cd handy, or if corrupt files or if you install new hardware. it's not critical to the operation of windows itself. 

Not sure if I understand the question but you wont be able to have high availabilty of your virtual machines running on a host system. If you're already running an OS, then you need to add on a virtual machine service to windows. this would include: - virtualbox (free) - vmware server (free but being discontinued) - vmware player (free) - vmware workstation (paid) You can run VMs on each desktop, however you WILL notice a slowdown of the host system even if the VM isnt doing anything. CPU is only one concern - HD activity, network activity, ram, and most endusers will notice if you "sneak" a vm onto their workstation. If you're looking for high availability - to move vm around from machine to machine seamlessly - you're looking at commercial software from vmare/xen/microsoft. Using existing workstations is a bad idea as it will be slow and hassle to admin. What you're asking about isnt done in the real world. If you're wanting to play sure go for it, but if this is for a business/school/nonpersonal network it's bad idea to try to harness the "spare" cpu power, cannot stress that enough. It doesnt scale. 

Chances are that the other company gets as much of your email as you get of theirs (or more, since they have the .com which people are more likely to use in error), so you should probably get in touch with their postmaster, as you may be able to come up with a solution between you - e.g. an autoresponder that notifies senders of the distinction. Longer term though, you probably want a more distinct domain name, especially if the other company does something similar to you. That is more of a branding/management decision. At least if you talk to the other people you may be able to inform those responsible for branding how much potential business you might be using. 

I want to set up various infrastructure in MS Azure that will then be available to multiple locations that are equipped with Cisco Meraki MX Security Appliances. Unfortunately, the MXs don't yet support route based VPNs, and Azure only supports multiple site to site networks when using route based VPN. I think similar challenges may exist with AWS and other cloud service providers. I think I may be able to work around this limitation using a virtual firewall, such as Cisco ASAv, but I haven't been able to find any documentation or marketing material that makes it clear this is suitable. I know I have done hub/spoke VPN with physical ASAs in the past, but I have no experience with ASAv. Has anyone got any experience doing cloud provider hub with ASAv (or any other virtual firewall) and branch office spoke using firewalls that don't support IKEv2 or route based VPNs, such as Meraki MX, Cisco ASA etc?