Sketch of proof of the weak bound: Suppose $W$ had dimension $d=o(\log k)$. By pigeonhole, there is narrow cone in $W$ such that the projections $w_i$ to $W$ of $\geq k/6^d > \sqrt{k}$ vectors $v_i$ lie in that cap. Any two vectors in that cap have inner product $\geq 1/2$ times the product of their norms. Hence $\langle w_i,w_j\rangle \geq |w_1|_2 |w_2|_2/2 \geq |\delta|^2/8$. Then the projections $u_i$ of those same vectors $v_i$ to the orthogonal complement $U$ of $W$ satisfy $\langle u_i,u_j\rangle \leq -|\delta|^2/8$ for all $i$, $j$ distinct. By a standard argument, this condition can be satisfied by at most $O(|\delta|^{-2})$ vectors. 

Actually, isn't question 2 brutally trivial? The following argument seems to show that the space $W$ spanned by the eigenspaces with eigenvalue $\geq \delta$ has dimension $\geq k$. Suppose this weren't the case. Then there would be a non-trivial linear combination $\sum_i a_i v_i$ orthogonal to $W$. Thus, on the one hand, $$\left\langle S\left(\sum_i a_i v_i\right), \sum_i a_i v_i\right\rangle < \delta \left|\sum_i a_i v_i\right|^2 = \delta \sum_i |a_i|^2,$$ but, on the other hand, $$\begin{aligned}\left\langle S\left(\sum_i a_i v_i\right), \sum_i a_i v_i\right\rangle &= \sum_{i,j} \overline{a_i} a_{j} \langle S v_i, v_{j}\rangle\\ &= \sum_i |a_i|^2 \langle S v_i, v_i\rangle \geq \delta \sum |a_i|^2.\end{aligned}$$ Contradiction. 

Some slightly-more-specific questions that refine my main question are: Do the hypotheses of this theorem often come up in natural settings? What's the upshot of the conclusion? Is it that proper forcing which preserves $\mathrm{MM}$, leaves the theory of a small but not-that-small chunk of the universe unchanged? 

My question is whether this weaker version of square is necessary to get a lower bound in terms of large cardinals, or whether there is some large cardinal lower bound on the consistency strength of "square fails everywhere" itself? 

I'm re-reading a paper of Stevo Todorcevic's entitled "Localized Reflection and Fragments of PFA" and there's a claim in the proof of one of the lemmas that I thought I understood but now I'm not so sure. The claim is this: 

Just like most mathematical theorems, you can formalize Godel's Theorems in some first order language (with some "standard" interpretation under which the formalization means what it's supposed to mean), turn the proof into a purely syntactic string of formulas, and figure out which formulas in that first order language are needed as axioms. I'm embarrassed to say I don't know exactly how strong the assumptions we need are to carry out the proof of Godel's Theorems, but there will be some weak fragment of ZFC probably not much stronger than PA which will do. So we would be using a theory slightly stronger than PA to establish the incompleteness of PA, but why should that be a problem? The axioms needed for the proofs of Godel's Theorems are probably pretty natural, probably pretty close to PA, and probably have a natural interpretation. If you believe these axioms have this interpretation, then you would have no problem with Godel's proofs or the interpretation of the theorems. If not, then you're probably pretty close to believing PA is inconsistent, in which case you would probably: 

A $t$-design on $v$ points with block size and index $\lambda$ is a collection $\mathcal{B}$ of subsets of a set $V$ with $v$ elements satisfying the following properties: (a) every $B\in\mathcal{B}$ has $k$ elements, (b) for every subset $T$ of $V$ with $t$ elements, there are exactly $\lambda$ sets $B\in \mathcal{B}$ such that $T\subset B$. The Ray-Chaudhuri-Wilson inequality states that, for any $s\leq \min(t/2,v-k)$, $$b\geq \binom{v}{s},$$ where $b=|\mathcal{B}|$, the number of elements of $\mathcal{B}$. Question: what happens if you drop the assumption that all sets in $\mathcal{B}$ have the same number of elements? Can you still give a lower bound on $b$ similar to the above? Feel free to assume that every $B\in\mathcal{B}$ satisfies $|B|\leq 2 |V|/3$, say. (Notes: 1) the case $t=2$ is known ("nonuniform Fisher's inequality"); 2) there are papers by Frankl-Wilson and Babai on "the nonuniform Ray-Chaudhuri-Wilson inequality", but they generalize something else from the same paper.) 

Let $v_1,\dotsc,v_k \in \mathbb{R}^d$ be unit-length vectors such that $$\sum_{1\leq i,j\leq k} |\langle v_i,v_j\rangle|^2 \leq \epsilon k^2.$$ What sort of lower bound can we give on $d$ in terms of $k$ and $\epsilon$? Must it be the case that $d\gg \min(\log k,\epsilon^{-1})$, say, or anything of the sort? Is that tight? 

In order to get the relative consistency of some statement, it suffices to find a notion of forcing, and a condition $p$ in that forcing, such that $p$ forces the desired statement. It seems to be the case, most often, that the interesting statements we try to force end up being forced by the whole poset. A sufficient property for a poset to possess to make the above phenomenon occur (in the case where all parameters in the forced statement are canonical names for objects in the ground model) is almost homogeneity: For every $p, q \in P$ there is an automorphism $i$ of $P$ such that $i(p)$ and $q$ are compatible. It makes sense that if you're building a poset to force something, the whole poset forces it (there's also the ad hoc reason that you could throw out the part that doesn't force it). However, it might happen that in trying to force a particular statement, you build a poset where some, but not all, of the conditions happens to force a different interesting statement. Also, I haven't given this much deep thought, but it seems natural for most posets to be almost homogeneous. My questions: Are there any interesting, instances of independence results forced by part, but not all, of some poset? Are there examples of commonly encountered posets which aren't almost homogeneous. (If there ends up being a big list of answers, I'll add the "big-list" tag and make it community wiki) 

It depends on who the people here are! (a) In the Arabic-speaking world, where mathematics was alive and well, prime numbers did not lose their interest; in fact, as John Stillwell said above, the statement "Wilson's theorem" dates from that period. (b) In most of Europe, there was essentially no pure mathematics of interest throughout the Middle Ages. (About the one exception is Fibonacci, who of course got at least part of his mathematical education outside Europe.) Still, it would not surprise me if prime numbers turned out to be one of the few things in what we call number theory that was ever discussed in Western Europe during the Middle Ages. Reason: the popularity of Nicomachus's Arithmetic, translated (freely) by Boethius. 

(Note: this started as a different question that soon changed form, thanks to the answers.) Let $G = \mathbb{Z}/4\mathbb{Z} \ltimes H_4$, where $H_4$ is the Higman group and $\mathbb{Z}/4\mathbb{Z}$ acts on $H_4$ in the obvious way (permuting the four standard generators cyclicly). The group $G$ is generated by two elements, $a$ and $t$: here $t$ is a generator of $\mathbb{Z}/4\mathbb{Z}$, and $a$ is such that $t a t^{-1} \cdot a \cdot t a^{-1} t^{-1} = a^2$. As is well-known, $H_4$ has plenty of normal subgroups (though none of finite index). My question is about normal subgroups of $G$ other than $\{e\}$, $H_4$, $G$ and (thanks to a commenter for reminding me of this last one) $2\mathbb{Z}/4\mathbb{Z} \ltimes H_4$. (a) Can you prove that the normal closure in $G$ of any word of the form $a^{k_1} t a^{k_2} t a^{k_3} t a^{k_4} t$ ($k_1,\dotsc,k_4$ integers, not all $0$) necessarily contains $H_4$? (b) Can you prove that the normal closure in $G$ of any set consisting of two distinct words of the form $a^{k_1} t a^{k_2} t a^{k_3} t a^{k_4} t a^{k_5} t$ must contain $H_4$? Note: I am saying "can you prove this" on purpose; a few lines of GAP code (sent to me by Kate Juschenko) suggest that what I am asking you to prove is in fact true. Note 2: Playing around with the code a bit more suggests that, in fact, the normal closure of $(a^3 t)^4$ does not contain $H_4$. Anti-note 2: the normal closure of $(a^3 t)^4$ does contain $H_4$ (unless I've bungled). The proof I can give for this involves words with powers about 2^256 - no wonder GAP couldn't find the proof. The same argument should work for $(a^k t)^4$. (c) Can you prove that the normal closure in $G$ of $(a t)^5$ does not contain $H_4$? (GAP fails to prove that this is false, on KJ's computer and mine, at least. Any further information on the normal closure is welcome.) 

For $\kappa = \omega$ the above holds, it is a theorem due to M. Pouzet. The proof hinges on the following fact: 

Here's an answer due to Andy Voellmer: If $\mathbb{P}$ has a dense subset $\{ p_i : i < \kappa \}$ of size at most $\kappa$ then by separativity, the map $f : \mathbb{P} \to 2 ^{\kappa}$ defined by $f(p) = \{ i < \kappa : p_i \leq p \}$ is an injection. This is probably what Andreas Blass meant by "arguing directly from separativity." 

They also show that $\mathrm{PFA} \rightarrow \mathrm{ISP}(\omega_2)$ (and $\mathrm{SP}(\omega_2)$), so one can read this as saying PFA implies $\omega_2$ is as "compact" as a supercompact, minus the inaccessibility. On the other hand, there are consequences of PFA (including the statement of PFA itself) which seem to say that $\omega_2$ is very much incompact. For instance, consider Rado's Conjecture (RC). RC is the statement: If $T$ is a tree such that every subtree of size $< \omega_2$ can be decomposed into countably many antichains, then so can $T$. It's not hard to see how RC is, in some sense, saying that $\omega_2$ is compact: If we replace $\omega_2$ with a compact cardinal $\kappa$ in the statement of RC, then the statement is true by the "compactness of the language $\mathcal{L}_{\kappa,\kappa}$" characterization of $\kappa$. But PFA contradicts RC. Nonetheless, both PFA and RC are usually obtained by proper forcings which collapse a supercompact to $\omega_2$. PFA itself seems to say $\omega_2$ is incompact: Let $\mathbb{P}$ be a proper forcing, and consider the language which has a constant symbol for every element of $\mathbb{P}$, a binary relation symbol (for the relation on $\mathbb{P}$), a unary predicate for each dense subset of $\mathbb{P}$, and a unary predicate which will stand for a generic filter. Consider the theory consisting of the positive diagram of $(\mathbb{P},\leq,p\ (p\in \mathbb{P}), D\ (D \subseteq \mathbb{P}\mbox{ dense}))$ together with formulas saying that $G$ is a filter and $G$ meets every $D$ (a new formula for each $D$). PFA says that any subtheory of size $< \omega_2$ has a model, but there's no filter meeting every dense set in the ground model, so loosely speaking, this theory doesn't have a model (although I suppose there could be a model which adds unnamed elements to each dense subset and has a generic meeting each dense subset at an unnamed condition). My question is: Is there some way to reconcile the fact that PFA seems to simultaneously say that $\omega_2$ has properties strongly indicative of some sort of compactness, and also has properties strongly indicative of some sort of incompactness? 

When exactly were $\ell_p$ norms first defined and used? (Here is what I know, or think I know: Lebesgue and/or Riesz had something to do with them, but in some sense they go back to Minkowski, since Minkowski's inequality is (in essence) the statement that an $\ell_p$ norm is a norm.) Here is what is really my main question: how were $\ell_p$ norms ($p\geq 1$ arbitrary) first used? What was their motivation? It is clear that $\ell_1$, $\ell_2$ and $\ell_\infty$ norms are very natural, and their use long predates the formal definition of "form". The $\ell_4$ norm also pops up on its own sometimes. In contrast, $\ell_p$ norms for other $p$ seem to arise most often in the course of a proof, as a tool, when one needs some notion of "size" that falls between an $\ell_1$ and an $\ell_2$ norm (for example). Did the first uses of $\ell_p$ norms fit this framework? Can you think of some interesting (and preferably early) instances that do not obey this pattern? 

Let $P\in \mathbb{R}\lbrack x\rbrack$ be given. (In practice, the coefficients could be given as, say, decimals to sufficient precision.) Let $M\geq 1$, and let $I$ be an interval in $\mathbb{R}/\mathbb{Z}$ of length $\epsilon \ll 1/M$. Can we find (more or less) quickly the values of $m$, $1\leq m\leq M$, such that that $P(m)\in I$? Notes: (a) For $P$ linear, this isn't hard. Let $P(x) = a_1 x + a_0$. By Dirichlet approximation (which we can implement quickly using continued fractions), there are $Q\sim M$, $q\leq Q$, $0\leq a<q$ such that $a_1 = a/q +\beta/q Q$, where $|\beta|\leq 1$. For $P(m) \in I$ to hold, we must have $m \equiv a^{-1} b \mod q$, where $b$ is of the form $(\lfloor (\alpha - a_0) q\rfloor + c) \mod q$, where $\alpha$ is the midpoint of $I$ (say) and $c=O(1)$. Let $0\leq r<q$ be such that $r\equiv q^{-1} b\mod q$. Then we are tasked with finding $k\leq L/q$ such that $P(k q + r) \in I$. Now, $P(k q + r) \equiv \beta k/Q + a_1 r + a_0$, and so we must find $k\leq L/q\sim Q/q$ such that $\beta k/Q$ lies in an interval contained in $\lbrack 0,1/q\rbrack$. This we can do just by division (over $\mathbb{R}$). (b) For $P$ of degree $\geq 2$, this cannot be very easy: for $q$ an integer, $L=q$, solving the special case $P(x) = x^2/q$ is equivalent to finding square roots mod $q$, and that is equivalent to factorizing $q$. At the same time, I would see any algorithm that works in time $O_\epsilon(M^\epsilon)$ as being acceptable, so factorization isn't a hard barrier. 

A non-principal ultrafilter $\mathcal{U}$ on $\omega$ is a p-point (or weakly selective) iff for every partition $\omega = \bigsqcup _{n < \omega} Z_n$ into null sets, i.e each $Z_n \not \in \mathcal{U}$, there exists a measure one set $S \in \mathcal{U}$ such that $S \cap Z_n$ is finite for each $n$. A non-principal ultrafilter $\mathcal{U}$ on $\omega$ is Ramsey (or selective) iff for every partition as above, there exists a measure one set $S$ such that $|S \cap Z_n| = 1$ for each $n$. Clearly, every Ramsey ultrafilter is a p-point. What is known about the converse? I couldn't find anything, not even a consistency result, in any searches I've done or sources I've checked. Is very little known/published about the converse? 

Consider the tree of finite partial attempts to build a well-ordering, and notice that it has size continuum. More rigorously, let: $$T = \{ f : n \to \omega\ |\ n \in \omega, f \mbox{ injective } \}$$ ordered by extension. This is clearly an $\omega$ branching tree of height $\omega$, and its branches are precisely the injections $\omega \to \omega$. But we're interested in the set of well-orderings of $\omega$. Now, those injections which are bijections give us distinct well-orderings, but perhaps there are too few of them. What about the branches that aren't surjections? We can create distinct well-orderings out of them too: if a branch $b$ is not surjective and $X$ is the set of naturals missed by its range, consider the well-ordering obtained by taking $b$, then concatenating on to its end the numbers in $X$, ordered naturally. So the branches of our tree are in bijection with a set of well-orderings of $\omega$, and there are continuum many branches, so there are continuum many well-orderings. Note that the set of well-orderings we get is not even the set of all well-orderings. In particular every well-ordering we get has order type $\leq \omega + \omega$. 

What are the main open problems on lattice-basis reduction algorithms (such as LLL)? I am looking for problems satisfying the following two conditions: (a) their solution would likely be of some practical utility, (b) their statement is neat and simple. (For instance, I understand that, while the fact that LLL performs better in practice than it does in theory is interesting, important and, by definition, not fully explained, it is also difficult to phrase clearly, due to the fact that "real-world" inputs are not typical, i.e., don't tend to mimic what would seem to be a natural distribution from a mathematical perspective). Please understand this question to cover also algorithms that find a short vector in a lattice (without finding a full basis). For example - the ratio between the shortest vector that LLL finds and the minimal vector can be as large as exponential on $n$. Finding the minimal vector is, if I understand correctly, computationally hard - but what about finding a short vector whose ratio to the minimal vector is much less than exponential? (I understand there is an algorithm that does give a ratio that is slightly less than exponential - what is it?) How interesting and how hard is this felt to be? 

Let's restrict ourselves to first-order predicate logic. The Deduction Theorem tells us that (1) implies (2). That (2) implies (1) is an easy consequence of modus ponens. (2) implies (3) easily because of modus ponens as well. But you and Joel have already pointed out (3) doesn't imply (2). 

Checking this axiomatization works It's clear that if $\mathcal{G} = (V,E)$ is a finite directed serial graph and $s \in V$, then $(V,N(\mathcal{G},s),E,s,\in)$ is a model of this theory. Conversely, if we have a finite model $(V,N_0,E,s,\epsilon)$ of this theory, then $(V,E)$ forms a directed serial graph with $s \in V$. Now let $N_1$ consist of those $Y \in N_0$ such that $\forall x (x \epsilon Y \rightarrow V(x))$. I claim that: $N((V,E),s) = \{ \{x : x \epsilon Y\} : Y \in N_1\}$ But I won't prove this. A remark about some "unnaturalness" It should seem like I could have done things differently so that things looked more natural and the above claim could be proved more easily. The way I've written 2 and 3 are not the most natural, but I've done it for a reason. 2 says that if $\vec{x}$ is a tuple which is sure to contain an infinite path starting at $s$, then there's a member of $N$ consisting precisely of the members of $\vec{x}$. 3 says that if $\vec{x}$ is sure to not contain an infinite path starting at $x$, then there's nothing in $N$ consisting precisely of the members of $\vec{x}$. The formulas in 2 and 3 are in prenex normal form, where the matrix is a conditional where the left side only involves the symbols $\bar{E}$ and $\bar{s}$, and the right side only $\bar{N}$ and $\bar{\epsilon}$. Moreover, the antecedents have variables $\vec{x}$ and the consequents have variables $\vec{x}, Y, x$. The point You want a theory equivalent to axiom 1 and schemas 2 and 3 above, but you want to replace 2 and 3 with (probably finitely many) axioms which don't mention the symbol $\bar{E}$. I feel like there ought to be some interpolation-type theorem (along the lines of Craig Interpolation or Lyndon Interpolation) which says this can't happen, i.e. something which says that a theory in which each axiom mention either only $\bar{V}, \bar{E}, \bar{s}$ or only $\bar{V}, \bar{N}, \bar{s}, \bar{\epsilon}$ can't prove a theory which has axioms like those in schemas 2 or 3.