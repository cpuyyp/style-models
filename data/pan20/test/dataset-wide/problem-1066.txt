In the strictest sense a can do more than just query data. At least in Oracle there is the for_update_clause that “lets you lock the selected rows so that other users cannot lock or update the rows until you end your transaction.” (From the SQL Lanugage Reference). 

With a rights table for each element, as soon as you add an element you will need to add a table. This would add to application maintenance. The downside of putting everything in one table is that you might run into scaling issues, but those could be mitigated using partitioning, materialized views, and/or virtual columns. Likely such measures would not be necessary. As far as the table design, if this were on Oracle I might suggest something like this: 

My problem turned out to be specifically with the initial stages of the export before it starts writing to the export files. I upgraded to 11.2.0.2 from 11.2.0.1, switched to statistical estimating and throttled the method to the lowest resource manager group and that seemed to solve the problem. The other answers to this question may be useful for others. 

They don't want to write or forget in the future to write this, so they come up with the solution of making all NULLS -5000. Magically their original query handles NULLs without any changes. What they don't realize is that now someone who wants to exclude these values has to write this: 

Database control is a web based tool for managing a single Oracle database that is installed on the same box as the database itself. Grid Control is a web based tool for managing multiple Oracle databases that can be installed on a separate server and has its own database. We are currently using the 10g version of Grid Control and are considering the pros and cons of upgrading to the 11g version of Grid Control vs. abandoning it for DB Control. As such we would like to quantify what features/benefits we would loose and what features/benefits we would gain with each route. We are interested in the obvious as well as the obscure/smaller/intrinsic/potential. 

Create a new database and setup views of the original database's tables for one schema using a database link. Copy the package code for the application using that schema to the new database. Switch that application to use the new database. It should work exactly the same, except that it will be slower due to the link. For each table or group of related tables, add package code that for each database call that maintains data in both the local and remote tables. There are many ways you could do this. One way would be to have a switch table with a row for each application table. You could make a replication routine for the table and when the tables are in sync it could update the switch table to let the code know that it doesn't need to maintain both tables. 

The difference is that and can be used in a PL/SQL block, while cannot. The following will work in SQL*Plus: 

I know it would be easier to find something pre-built, but you could write a small application in your favorite language to handle the simple task of asking the database for the data and writing it to a file. For this you should take advantage of the suggestion from Jack Douglas to modify the reporting procedures to create CLOBs. Your app could then retrieve the CLOB and write the file. 

No, it is not possible to have this single backup command do the level 0 to a different location than the level 1. It is possible to change the script to determine which files don't have level zero backups and do a separate backup just for those datafiles before running the existing command to the incremental location. 

I've checked the sqlplus settings and they are all the same. I didn't see any database parameters that looked out of the ordinary and they both have identical NLS parameters. Both databases use the same character set. I realize I could define a format for every column being queried, but this should not be necessary as it is not on any other DB. The database having this problem is 11.2.0.1, while all our others are 11.2.0.4, so perhaps there is a bug that I haven't been able to find. The sqlplus client I am using is 12.1.0.1 in both cases. Update: The symptoms don't match exactly, but Doc ID 330717.1 talks about column widths in sqlplus and basically says you can't guarantee anything without setting the format. I can accept this, but since the behavior is consistent, it seems like a cause can be determined. 

Doing a and then a should cause a new to not show any entries in most situations. Here are a few situations that could cause this to not be the case. 

A method we found to be viable was to convert production to use the HSM and then clone the partition containing the key for production to development. This needs to be repeated with each clone of the database and then a post clone step can modify the key for the lower environment using normal key change processes. 

In this case a function isn't necessary because the nested query will always return a number even if the number is zero. If you want to see the output for all accounts simply remove the clause. 

The view accomplishes all three goals. You can query it for a building to find everything it contains and you can query it for a sub-location to find what building it is in. 

The format mask needs to be changed to 999,999,999,990. The 9 format suppresses the value if it is a leading zero, whereas 0 prints it. 

It sounds like the transaction is being committed (perhaps automatically) even when the application times out. Changing the behavior would be the best option. If you can't do that, you could put the database action in a package and then have the package check after it runs the action to see how much time has elapsed. If the step took more than 45 seconds then it should , otherwise . Although this answers your question, it is a fragile solution and you really should look into changing the behavior or causing a database disconnect when a timeout occurs. 

My guess is that the vendor wants their data accessed through web services and any joins with the data from your own database to be done in an application layer. The performance of such a configuration would likely be vastly inferior to a join over a database link even if it were not cached. 

In addition to the impdp/expdb option already mentioned, you could restore/recover the database from your backups to a new location and then enable flashback database to revert the restored database anytime you want. The advantages of this method are that it will make sure your backups are good, verify and improve your recovery procedures, and allow for faster reverting. The downside is that it will take longer when you need a fresh copy. Here is an overview of Flashback Database from the documentation. 

In the interface, if the user wants more information about the activity than the log entry can provide, the entry could be joined with the appropriate table. Some activities could forgo a details table if the log entry is sufficient. When new activities are added, the detail table, log entry, and log display could each be created and added in any order. The definition of the log table would not have to change, nor would the definition of other detail tables. 

All Oracle databases support some type of application that the Oracle DBA would need to have some knowledge of. What makes an Oracle Applications DBA different than this? Does the term mean that they support the Oracle Applications and not the database, or does it include responsibilities for both the Oracle Applications and the database. If the latter then this seems to be done differently than every other type of application that can run with an Oracle back end. For example, you don't see Oracle .NET DBAs. Can someone clear up my limited understanding on this topic? Update: It seems very clear from the two answers so far that I did not word the question well enough. My context is not Application DBA in the Developer DBA sense vs. Production DBA. I am asking about the particular job title of "Oracle Applications DBA" or "Oracle Apps DBA". Do a search for the phrase and you'll get results like the following: $URL$ $URL$ $URL$ etc. The best explination I have found so far is from $URL$ which says: 

A user has a table they would like to update. Depending on the data in other columns they want a particular column to be updated with an ascending value starting from 1 that is gap-less. The rows that will not contain this ascending value also need to be updated. Is there a way to do this with a single UPDATE statement? Create sample data: 

You are not doing anything wrong and your understanding is correct. Materialized views that are created or altered to have a refresh schedule use rather than . This would be unexpected given the following wording from the 11.2 Administrators Guide (emphasis mine): 

Values don't need to be exact in order to use an index. In your particular example, a Range scan will limit the amount of data examined. An index on both bounds allows the data to be range limited on both axis. A range scan operates conceptually similar to how you would look at a map. If you wanted to find the Washington Monument at Latitude: 38.889449 Longitude: -77.035232, you might begin your search by focusing on 30 to 40 Latitude and -70 to -80 Longitude. If you just looked at the Latitude you would have a lot more map to look at than when you look at both. Here is a demonstration in Oracle. 

Here is a thought. Track all replies by all users in one table that has a unique entry for each user key and reply address. Store a count of replies and perhaps a date of the last entry. A query could be done for any user retrieving the top ten most responded to addresses. Infrequently used entries could be periodically purged based on the number of replies and when the last reply was. 

bilinkc's solution works fine, but I thought I'd toss mine out as well. It has the same cost, but might be faster (or slower, I haven't tested it). The difference is that it uses the First_Value instead of Row_Number. Since we are only interested in the first value, in my mind it is more straightforward. 

My test case ran fine on multiple other databases and multiple sources (including oracle support) asked if the ANONYMOUS user had been dropped. Although it had not, there were some XML DB Repository changes that were made without a full understanding. To try short cut the problem I re-installed XDB using note 1292089.1. This allowed my test case to work correctly and after dropping the created types and tables and re-registering our XML schema, everything worked correctly. 

You should be able to just do a restore/recover over top of the existing Host2. If you are trying to avoid a complete recovery, then I suspect the answer is you can't, but there are two notable exceptions. 

CRUD is meant to define the characteristics necessary for a database as it relates to persistent storage. It is not meant to describe everything that could be done by a database engine. To make a comparison, fundamentally a vehicle is a device used for transport. While true, this definition certainly doesn't include all the detail entailed in a modern automobile. A database engine might handle multiple users, transactions, MVCC (Multiversion Concurrency Control), buffers and caches, ACID (atomicity, consistency, isolation, durability), as well as different isolation levels. A read may pull data from memory, remote databases, and multiple tables on disk processing it using SQL through multiple explicit and/or implicit code paths in order to present it to the requesting application. A create may allocate storage, provision structures, assign values, and do it's own processing before storing data. Etc.