If those random bytes are random, passing them through a hash function adds nothing. If they are only somewhat random, hash + truncation is better than just truncation. However, are from a strong RNG, so you can use them as is. The problem is that 8 bytes is not always unique. You solve it by looping until you get one that is unique. However an attacker could do the inverse: guess until it hits a real ID. The probablity of guessing a particular ID is \$2^{-b}\$, where b is the number of bits in the random number. If you have n users in your database the probability is n times as high. With \$n = 2^m\$, the attacker needs only about \$2^{b-m}\$ guesses to hit some ID. If your ID's are 8 bytes: 

Recursion adds its own cost, though, so whether it's faster in practice would require testing. An alternative would be to add a second iterative compression function: 

On Python 3 you can encode the letters into bytes and avoid inside the loop, for similar performance. You might still make it about 1.5x as fast if you replaced the -> algorithm with something faster ( and depth first search?), but that's about it. 

If you set some bounds and the multiplier to 1, it should draw a proper style maze, it's just a bit boring that way. Since the tree data isn't really stored after the generation, here's an example of what the tree looks like at 3000 nodes in 3D. There's probably a better way of doing it but it worked for me. One thing I've realised is I may be able to merge with , but I've given up on coding for now so I dunno yet. Edit: Added a few extra bits, mainly for Maya. You can now remap coordinates, so for example, you could use a 3 dimensional generation and swap with , so basically you have the 3D generation, but only 2D slices of it that you view by changing the time.I also added the shaders too, so now you can see 4D generations properly. To be totally honest, I thought they'd look cooler (the 4D generations, not shaders), but they're a bit disappointing haha, but I'll try render a video later to show what it looks like. If anyone has an idea for the 5th dimension or any others, I'm all ears. 

You are saving some data that you never use. , never used after this. The whole parameter is unused if you remove the assignment. already is. If you remove from here, you can also remove from . 

You should define the lower level method instead. will use that to define and that way you are sure to get efficient testing. Speaking of which: 

In python 2 you can remove the invocation. That alone saves a few seconds. A set is faster for testing, so that's also an easy fix. Take advantage of 's and by noticing the length stays constant and you are at 2x the speed: 

By choosing block size close to , you only need to keep about \$\sqrt x\$ items in memory at a time. 

That's a brute force search of hashes for a particular prefix, meaning it's complexity is \$O(2^n)\$, where \$n\$ is the number of bits in the prefix. In your case that's \$2^{28}\$. You can't make it faster in terms of complexity or the hash would be broken, but you can increase the constant factor. 

In response to the comment by holroy, I decided to keep with float (as opposed to store the decimal value as a separate int) because I've still got to think about conversion to and from the game world. With the current way, unless the float value goes above the block size, it's literally just a single addition, whereas the other way would be a lot slower, and the precision to that level isn't really needed. I did the block method in a previous project which was about octrees, where the coordinates were stored relative to each 3D block, which was split into 8 smaller blocks (so a coordinate would be for 4 nested blocks, which results in . The problem with this approach is if a coordinate was at 16, that's too high to store, so you'd need to recalculate everything for 5 blocks instead of 4 (which upon writing this, I've realised it may be as simple as multiplying all of block 4 by -1, though I'm not sure). The boundaries can also be a bit confusing, as the size of the block is to , like -255 to 256. I wanted this to be able to scale as much as needed, without getting overly complicated, and the current way seems to accomplish this fine. 

The actual hashing is done in and OpenSSL. Those pretty much cannot be reduced, so at best it could be made ~3 times as fast. 

Nothing else really. The s at the start of all your strings are a bit ugly, and some people prefer using empty print statements to indicate extra empty lines. 

By default pickle uses an ASCII format, so you shouldn't really open the file in binary mode, although nothing should break if no one touches the file. You could leave out the s from both calls or use binary pickling by passing to . 

In the other place you correctly used . The difference is that executes the given string as an expression, which is seldom what you want (and usually unsafe). 

Again, I do not think relying on this is a good idea, but it does not seem insecure either. Personally, I would rather make the number of iterations a smoother function of time, i.e. round after the multiply. You still get different iteration counts for different passwords, but you also avoid the abrupt stepping up every two years. Also, you lack any code to upgrade the iteration count of password hashes as time goes by. That should probably happen somewhere in the class, e.g. if the iteration count is less than some fraction of the current. 

: What type the input is : How many bytes to look at for . Because this number will always be quite low, it's stored as a bunch of 0s, ending with a 1. : How long the data is : The input stuff As to why there is both and , for example, if the input has 255 bytes, the current way would result in 9 bits to say the length is 255, whereas having only 1 value would result in 255 bits to say the same thing. When reading the data, instead of splitting the string up, it just uses offsets on which part to read. I'm not so happy with writing it but didn't know a better way, as I just store it as a string and basically use or . The en/decode functions work with the string of binary numbers, and the and functions just get it to and from a human readable form. For the record, I'm planning on having something in , just haven't thought of what yet. Example: 

What's the worst case running time of this? At most \$O(n)\$, since has \$n\$ values and there are no cycles. However, since you are comparing ranks in : 

Python 3 introduced a new cleaner format for the common case when you want to step up from the current class and pass (the first argument): 

First, the obligatory pointer to PEP 8. In particular, your class names and some docstrings do not follow it. Variable names and line lengths arguably as well. Next, a couple of specific cases where you could make the code clearer or more efficient: 

At this point you can probably guess that I'll recommend doing away with the list. A generator should work. If on Python 2, is probably better than as well. (Note, I didn't mention . That could be changed into invocations if you are on Python 2, but you seem to be on Python 3.) 

Read the input in blocks, which you sort and save into files. Merge the files while iterating by always choosing the extremal item. 

Now I've grasped the very basics of Pygame, I thought it'd be useful to make a few classes that I could use later on if I try make a simple RPG style game. I've done this to handle the coordinates for the player movement (and possibly for other things too), and tried to do it in a way where you wouldn't get the floating point precision errors that Minecraft and similar games get when you travel out very far. I tested it against the module, and mine appeared to up to 10x faster for small movements, though the speeds evened out when using super large movements like +- 10000000000000. It's only half a days worth of work so it's not perfect, I can't find any more bugs though. It's recommended you input the coordinates as strings though if you're using large ones to start with, especially if you're using floats. 

For any Maya users, this doesn't include the animation or colours yet, but here's a class to build it in 3D. You only need to iterate through to use and , so if you have a different 3D software package it'd still be easily possible to display. 

There's also a question mark I have: â€“ that works in Python 3, but not Python 2, because . Since your code seemed to work for you, I assume you are on Python 3. I'm not sure if Python 3 people think making it portable with a dot/cast is a good idea or not (i.e. ). There's always the explicit if you can't decide. 

Any GPU limitation on salt lengths is small, unlikely to last, and will not necessarily apply to ASICs. I do not think it is a good idea to rely on it. The salt is only used on the first iteration of PBKDF2 so it might even be possible to precompute the first step with a CPU and leave the rest for a GPU. It would be fine to halve the salt length, but since it only costs memory and a constant amount of work, it is not a problem to leave it as is. Nit: You misspelled "length". 

Personally I find your use of a global variable fine. Using a singleton class for encapsulation where a module would do is IMO needless complexity. If you can have multiple high score objects it's a different matter, of course. 

Normally the game speed with pygame is locked with the fps, so I attempted making a simple two classes that'd be super easy to use, to allow for the same game speed no matter what the fps is. For each frame, it calculates the difference between the amount of ticks that have passed, and how many should have passed (I get that this way could be better, but people don't change this mid game right?). For example, the difference at 60fps at 60 ticks per second is 1, at 30fps, the difference becomes 2, at 120fps, one frame will have a difference of 0, and the next 1. I did my own version of ticks since I locked the actual ticks to the fps. With the frames per second, I set it to calculate it every x seconds, so it's a bit more accurate and avoids times so small it causes zero division errors (0.1 seconds for 1753 frames is more accurate that 0.00005704506 seconds for 1 frame). If you don't limit the fps, the inbuilt fps function just returns 0. There does seem to be a bit of a problem though, and I'm not sure what's causing it. I'm sure I've done the framerate calculation correctly (with a minimum time so it doesn't end up working with tiny floats), but setting the fps to 500 reads as 333, and 1000 reads as 500, which is really strange. Setting it to something really high or quite low returns something that looks a lot more correct. I've not really used a with a class containing another class before, so I'm not sure if I've done it right (I originally only had the one class, but realised and needed the class called each time), so any feedback would be good as to what I didn't do well.