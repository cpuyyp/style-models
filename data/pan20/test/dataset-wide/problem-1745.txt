This is a well-documented set of processes and some perusal of Ubuntu's own website will define what you need to do. In short, you want to centralize the administration of user ID's, passwords, etc in an LDAP directory and set up autofs to allow a given user's directory to be mounted from a central file server whenever they log into a given client machine. The client machine setup is laid out here while the server setup is here. The overall Ubuntu server administration guide is also excellent, as found here. This last resource covers not only network logins and such but also a huge number of other common tasks. It's a good reference and the Ubuntu people put a lot of work into it. 

Hardware (MAC) address prefixes are allocated on a per-vendor basis and that vendor may assign addresses within said prefixes however they see fit. There is also no guarantee that a given address is unique. The result? There's no way to hierarchically summarize addresses. Worst case this yields a global routing table with some significant subset of 2^48 addresses. To put this in context, as of today the number of prefixes in the (IPv4) global routing table is just shy of 246,000 routes. That quarter million routes represents the summarization of hundreds of millions of individual host addresses. IPv6, in contrast, is designed and allocated with the idea of hierarchical addressing. Lots of addresses means that subnets can be large, sparse and scalably allocated while still stemming the propagation of routes. Keep in mind that the /48 that's readily available as a basic unit of allocation is equivalent to 65K times the size of the entire IPv4 Internet. A well-summarized IPv6 Internet can accommodate literally trillions of end host addresses in a table the same size as- or smaller than- the current global table. 

Take a look at some of the copy-on-write file systems (btrfs and ZFS, for example) that actually take measures to validate the state of on-disk data. This only makes sense in the context of multi-drive setups, though, as you need to give the file system at least a fighting chance of finding a clean copy of your data. 1TB disks are crazy cheap at this point and certainly wildly cheaper than the potential fallout of the unscheduled crash you're almost certain to hit. Seriously - what you're asking about is analogous to asking to find a way to keep driving on a tire that's bald and has a gigantic bulge on the side. We can't say precisely when it's going to end badly just that it will. 

The DHCP server is offering an address, but the firmware is going to error out (cryptically) if it isn't able to pull a boot image. Take a close look at the tftp server settings on 192.168.0.9. I'm not sure which tftp server you're using, but generally the path is relative to the directory passed to the daemon on startup, rather than an absolute path. Fire up a tftp client on another machine and try downloading a file from the same directory to confirm proper function. Alternately, try running a packet capture to watch precisely what the DHCP server is offering to the client and what actions the client is taking as a result. 

Generally a DHCP relay is supposed to pick up a broadcast from a client and forward it to a specific server (read: unicast) address. Given that the packet sent by the relay to the server can be routed anywhere, the idea of cascading relays doesn't make a lot of sense. In practice it would be more likely to have some kind of intermediary DHCP server that derived pools from an upstream server. 

You want to take a look at the system-wide limits set in /proc/sys/fs/file-max and adjust it there (until next reboot) or set fs.file-max in sysctl.conf to make it permanent. This might be helpful - $URL$ 

The Cisco side isn't configured for MST. Take a look here for specifics, but you need to set the 3750 to use the appropriate mode and assign the various ports in the switch to an instance corresponding to the HP's (likely instance 0, but I don't know their implementation). That should - in broad strokes - get the switches at least speaking the same protocol. Beyond this, I would highly recommend that you explicitly configure one of the three as the root bridge. This is configured on a per-instance basis - lower switch priority wins. A quick Google search turned up some suggested example configs for interoperability. The document in this link has some appropriate warnings about older IOS revisions, but if you're running something reasonably current it's safe to disregard. 

Also worth noting - the labeled hazard is generally for optics actually using lasers. This is, in most cases, for single mode - which, in addition to being quite a bit more powerful, also is at a wavelength not visible to the human eye. The problem here is, in part, that there isn't really even an immediate pain impulse to tell you there's a problem. Multimode, in contrast, is much lower power and is transmitted via an LED on a wavelength visible to the eye. It's still not a great idea to look into such an optic, of course, but it's not dangerous enough to warrant the warnings of various SM-based media. 

I know this is late (putting it mildly), but this might be handy as a pointer for someone in the future. On almost any reasonably modern Cisco switch there is some version of private VLAN (PVLAN). The idea of PVLAN is to keep hosts within a given VLAN from being able to talk to one another unless explicitly allowed to. There are three types of ports in PVLAN: 1.) Promiscuous - A port configured as promiscuous can send and receive to any port in the VLAN. Your router's port would likely be promiscuous. 2.) Isolated - Can only send traffic to promiscuous ports. 3.) Community - Can send traffic to other ports in the same community and to promiscuous ports. In your scenario you'd have all of the hosts mentioned in the same VLAN. The externally managed boxes would be set up as isolated while the remainder would be set up in a common community. Your router/gateway would be a promiscuous port. The actual implementation of this is going to vary based on which switch platform you have in use, but the principles remain the same... 

When you configure a VM it gives you the option of assigning a number of CPU's. These -are- virtual CPU's. Generally the configuration presents these CPU's as copies of what the physical host contains but you do have the option of selecting a different CPU type, assuming that type is compatible with the physical hardware in the box. 

I think you answered your own question. Removing the HP switch allows everything to work. Putting the HP switch back breaks it. Start by testing the connection between the Cisco and HP switches and work your way back. We don't have enough information to debug the HP switch (L2? L3? model number? configuration?) but it seems like your issue is most likely there. 

The answer to this depends on what kind of role the device plays, its location in the network and the quantity of devices that need to be managed. A very small number of devices could do something like the default address approach (i.e. SOHO devices). If typical deployment calls for less than 50 or so boxes and there's a centralized location then some sort of basic serial console setup is fine. This approach can (and does) scale to large numbers of devices in the case of network hardware, but this is in some part a function of history. If the intention is for many hundreds (or thousands) of devices deployed on a wide basis then working out some kind of mechanism for dynamically pushing configurations, firmware, etc can be a big win. Using DHCP to pull not only an address but also some measure of custom configuration (link to central config server, pull down image based on serial/MAC, etc) has been an approach that has been used to good effect by some vendors. 

You can control the number of instances of nfsd but each instance of nfsd might have multiple operations queued with the kernel. In Linux and Solaris (as far as I remember) the default has been 8 processes for a long time but there are plenty of circumstances where it makes sense to increase this number. I haven't heard of any absolute limit to concurrency in NFS as a protocol, however. 

Ideally your ISP generates a filter based on the RIR information such that only your specific /25 is permitted via your BGP peering to them. The various registries (ARIN, RIPE, APNIC, etc) have mechanisms by which routes can be certified as belonging to particular entities. That said, BGP (as widely deployed) has no means to confirming that a given prefix legitimately belongs to a particular ASN or, indeed, whether the prefix was actually originated by the right network. There are (...and have been over the years) efforts to secure BGP by allowing for the cryptographic signature of prefixes as they're originated and propagated (see BGPsec as an example). Keep in mind that whatever approach is adopted has to make it through the standards bodies, be adopted by various vendors, some kind of set of central authorities has to be able to manage it, the carriers themselves have to adapt it to their operational processes, etc. Overlay all of this against a wildly decentralized network that encompasses most the planet and it gets even more difficult. In the mean time proper filtering at the edge is very much in the realm of widely accepted best-practice for carriers and when bogus advertisements do occur the complaints and filtering follow pretty quickly. 

The way that dedicated management ports are usually configured in Cisco equipment (routers and switches, at least) is generally placing said port into its own vrf and then applying ACL's and such as appropriate to limit access. The vrf serves as a completely separate routing table - which speaks to both requirement for potentially overlapping IP's as well as assuring that traffic cannot be forwarded through the isolated port. You can also associate various services (snmp, aaa, etc) with the vrf to follow its particular routing requirement.