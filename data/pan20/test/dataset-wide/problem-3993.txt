It is possible if and only if 4 divides n. Douglas Zare showed that if 4 does not divide n, then it is impossible (btw, his argument might be simpler to state mod 2 - if 4 does not divide n, then it is already impossible to get all numbers divisible by 4). Now, if n=4k, do the following: 1, 12, 2, 10, 4, 8, 6, 7, 5, 9, 3, 11. This will give 2k-1 n's, 2k-1 n+2's and two n+1's. Next, do 12, 14, 12, 14, 12, 14, 12, 14, 12, 14, 13, 13. This gives 4k-2 2n+2's, one 2n+3 and one 2n+1. Now, for simplicity, subtract 2n+2 from each number. We have all zeros but one +1 and one -1. Make the permutation so that we double the number of +1's and -1's in each step, until they become >n/4, then "mix them a bit"* so that in the next step we can exactly n/2 of both. Then an alternating sequence will give all equal numbers. $^*Edit$: As Douglas pointed out this mixing is not that clear how to do. So instead, I claim that we for any i from 1 to n/2 it is possible to get exactly i +1's and i -1's. The proof is by induction - we either double or double -1, by putting a +1 and a -1 next to each other. Eventually we can get n/2 of each and we are done. However, this my method only works for the numbers 1, 2, .. , n. What if we start from another sequence? Mod 2 the problem is always solvable, maybe that helps, but over Z already 1, 0, .. , 0 is not clear how to solve. Edit: As Doublas pointed out this is possible if and only if n is a power of 2. So to summarize, I think if 4 does not divide n>1, then you can not get all equal numbers starting from 1, 2, .. , n, if 4 divides n you can, while if is n>2 is a power of 2, then it seems you can start from any sequence. (Though we have not seen a full proof of this last part yet.) 

I think it is enough to use induction and Bertrand's postulate, that there is always a prime between n and 2n for n>1. Let me try to sketch the proof that we always reach 0, 1 or 2. The induction hypothesis is that taking the primes up to p and starting from any |z|<2p, we reach 0, 1 or 2. Suppose we want to prove this for the next prime after p, denoted by q. We know that q<2p. Initially, |z|<2q. Once we subtract (supposing z>0) q from it, we get z< q< 2p. 

I realized that once we suppose $\kappa$, $|\mathcal{X}|$ and $|\mathcal{Y}|$ are all $O(1)$, there is a much simpler argument. For each entry of the matrix that is not in the last column, pick a number from $[-\sqrt n,\sqrt n]$ and select the last number of each row such that the marginal becomes $t$. This gives the required $\sqrt n^{(|\mathcal{Y}|-1)\cdot|\mathcal{X}|}$. For completeness, here is my $Old$ $answer$: I think they use the following fact: The number of ways to put A (identical) balls into B (ordered) bins is ${A+B-1 \choose B-1}$. If A is big compared to B, this is about $A^{B-1}$. More precisely, I think they suppose $|\mathcal{X}|$ and $|\mathcal{Y}|$ are both $O(1)$. Here is a sketch of the computation (not rigorous at all!!!): In the problem, first we have to decide in which rows the at most $\kappa \sqrt n$ difference will appear, so we put at most $\kappa \sqrt n$ balls to $|\mathcal{X}|$ bins, so far, omitting $\kappa$ and summing for the number of balls from 0 to $\sqrt n$, about $\sqrt n\cdot \sqrt n ^{|\mathcal{X}|-1}= 2^{|\mathcal{X}|\log n /2}$ possibilities. Obviously in most cases this distribution will be quite even, so in each row we further have to divide $\kappa \sqrt n/ |\mathcal{X}|$ balls into $|\mathcal{Y}|-1$ bins and then use the last bin to make the marginal equal to $t$, so we get (ignoring $|\mathcal{X}|$ as it is $O(1)$) about $2^{(|\mathcal{Y}|-2)\log n /2}$ possibilities in each row. In total $2^{|\mathcal{X}|\log n /2} \cdot (2^{(|\mathcal{Y}|-2)\log n /2})^{|\mathcal{X}|}$, just what we wanted. 

I think the asymptotics is $\log$ N, but this might have a constant multiplier depending on what you count exactly. The solution is basically known as Radix sort. Imagine that you get any sequence of N unsorted numbers. Represent each with $\log$ N digits. We sort first with respect to the least important digit, then the second least and so on, finally with respect to the leading digit. This is done by dropping smaller numbers to L and larger numbers to R. 

It is known that a constant approximation is also NP-hard (under randomized reductions), see Daniele Micciancio: The Shortest Vector in a Lattice is Hard to Approximate to within Some Constant (and in general more papers from him). If you perform the original LLL algorithm, then their are two constants that they choose to be $\frac 12$ and $\frac 34$ that they pick (see (1.4) and (1.5) in the original paper). If you instead use $\epsilon$ and $1-\epsilon$, then you get an algorithm that gives roughly a $(1+\epsilon)^n$ approximation (where $n$ is the dimension) and I think runs in time $2^\frac 1\epsilon$ (though I am not 100% sure about this, but should be something like that). I guess an open problem is to show that there is or isn't a polynomial time polynomial approximation. 

Maybe I misunderstood something, but consider the following simple example. Let $V=(0,\infty)$ and let the maximal edges be the (open) unit intervals, except $(0,1)$. Any cover contains a sequence converging to $0$, so in fact there isn't any minimal cover at all. Update: Noah asked whether there is an example where all edges are finite. Here I give such an example. Take $V=\{\frac 1i\mid i\in \mathbb N\} \cup \{-\frac 1i\mid i\in \mathbb N\}$. For any $n\in \mathbb N$ we define two maximal edges. The first is $\{\frac 1i\mid i\le n\} \cup \{-\frac 1n\}$ and the second is $\{-\frac 1i\mid i\le n\} \cup \{\frac 1n\}$ (note that these are the same for $n=1$, but this won't matter). Again there isn't any minimal cover. 

A pencil is a collection of some lines through a point, called the center of the pencil. If the points of the plane are colored, then call a pencil bichromatic if there is a color that is present on all the lines of the pencil such that this color is different from the color of the center of the pencil. Given any non-monochromatic coloring of the plane with finitely many colors, and $m$ directions, $\alpha_1,\ldots, \alpha_m$, is it true that there is a point $p$ and an angle $\varphi$ such that the pencil determined by the lines of direction $\alpha_1+ \varphi,\ldots, \alpha_m+ \varphi$ through $p$ is bichromatic? This is related to polymath16, see why here. I can only prove the statement for $m=2$. 

Your rules are not completely clear to me but the language that you use as an example (with ababbabbba) is not a context free language as it does not satisfy the pumping lemma, so you can go beyond the context free languages. 

I learned analysis a while ago, so let me define what I want. Suppose we have a set whose boundary is a closed Jordan curve that has a unique tangent at each point. Is it true that this set is (Lebesgue) measurable? What if we also suppose that the tangents change continuously? I am interested in any modification of the question which is known. 

This question is about 3-colorings of the plane in which every line is bichromatic (or monochromatic), i.e., there are no three collinear points of different colors. Such colorings trivially exist, see e.g. $URL$ However, there are more interesting such colorings, for example the one in Monsky's proof using valuations, see e.g. $URL$ These colorings are useful when we want to apply Sperner's lemma (about graph-theoretic triangulations) to solve some problem about geometric triangulations (where a vertex of one triangle might fall on the side of another), that is why I wonder what different constructions there are that are not based on a simple modification of the above two examples. 

This is not an answer, just a long comment. As pointed out by John Mangual, this game is similar to Mastermind. In fact, it is even more similar to the game defined by Erdos and Renyi here: $URL$ In your language their game is the following: We are given the first row of the matrix $M$, denoted by $M'$, (so $m=1$) but what we multiply it with, $X$, is not a vector, but an $n\times a$ matrix. Our goal is to reconstruct $M$ from $N=M'X$. They show that this can be done whp if $X$ is a random matrix and $a\ge 10n/\log n$. Of course if $M$ can be reconstructed whp, that also implies that $H(N)\ge (1-\epsilon)n$. So one possible way to answer your question would be to show that their theorem holds even in the case when $X$ is a circulant matrix, as this is equivalent to $X$ being a vector and $M$ being circulant. new part So suppose we want to compute the probability that for two different random vectors, denoted by $v$ and $u$, multiplying them with the rotations of a random vector $r$ we get the same values, i.e., if the rotations of $r$ are denote by $r_1,\ldots,r_k$, then what is the chance that for all $i$ we have $vr_i=ur_i$. For any $i$, this is like a random walk, as $v$ and $u$ are also random, so $Pr[vr_i=ur_i]\approx 1/\sqrt n$. Now I claim that this statement is true even in the following conditional form if $k$ is small enough: $Pr[vr_i=ur_i\mid \forall j\ne i: vr_j=ur_j]\approx 1/\sqrt n.$ I don't think this is that hard to prove, but I cannot see a solution now. 

Well, I might be totally off again, but I think that for every spanning tree $T$ we get $H(T)=G$. As you have already written, obviously $E(G)-E(T)\subset E(H(T))$. For a tree edge, $e\in E(T)$, denote the vertices of the two components of $T\setminus \{e\}$ by $A$ and $B$. Now we have $e\in E(H(T))$ if and only if the number of edges between $A$ and $B$ is odd in $G$ (not counting $e$). But the number of edges between $X$ and $V\setminus X$ is always even in an even graph, so we are done. 

You can suppose that every non-deterministic choice is given on the witness tape, I think it is easy to see that these definitions are the same, if you have further doubts, then please specify exactly where. The proof fails if the witness tape is not one-way because an NL machine cannot remember what choices it made earlier, while with a two-way witness tape you could scroll back and check. 

This a a theoretical question about poker type games. I'm sure I don't have to explain the rules - you can consider No Limit Texas Hold'em or some simple theoretical model, where each player holds a number from the $(0,1)$ interval. We only consider heads-up, i.e., when two players play. Suppose that at the beginning of the game the size of the pot is $1$, and both players have $n$ chips (their stack). The stack-to-pot-ratio of the game, SPR, is $n$. 

Suppose that we want to find one of finitely many elements (called pivot) by asking binary questions (one after the other) of which for at most $e$ we might get an incorrect answer and our goal is to minimize the number of questions needed in the worst case. This is known as the Rényi-Ulam game, for more basic info, see Wikipedia. For more info see the Pelc survey and Cicalese's book. After some questions have been asked, we can classify the elements depending on how many answers must be incorrect if the given element is the pivot. If this number is greater than $e$ then the given element cannot be the pivot, while in every other case it can be, so our goal is to have at most one element for which at most $e$ lies are possible. The state is the vector that gives the number of elements in each class, e.g., $(x_0,\ldots,x_e)$, so our goal is to have $\sum_i x_i=1$. A question can be also represented by a vector $(q_0,\ldots,q_e)$ which describes for how many elements from each class the answer would be YES. Suppose after some questions we are in a state $(2x_0,\ldots,2x_e)$. Is it possible that the even splitting question $(x_0,\ldots,x_e)$ is not optimal, i.e., there is another question which leads to a faster solution? I have already asked some experts, like Katona and Cicalese, and they did not know the answer. 

Suppose we have a graph where every edge is colored red or blue. We say that a path is alternating if the red and blue edges alternate in it. Our goal is to find many edge/vertex-disjoint alternating paths from a given vertex $s$ to another given vertex $t$. Has this problem been studied before? Update: It DOES NOT seem to me ANYMORE that the following, Menger-type theorem is true, as pointed out by Ilya in the comments: Lemma: We say that a partition of the vertices into $S, T, R, B$ is a colored cut if $s\in S, t\in T$, there are no edges between $S$ and $T$ and, except for the edges between $R$ and $B$, the vertices of $R$ are only adjacent to red edges and the vertices of $B$ are only adjacent to blue edges. There are $k$ edge/vertex-disjoint paths from $s$ to $t$ if and only if after deleting any $k-1$ edges/vertices, there is no colored cut. Update: Gyula Pap told me that if we consider the directed version and edge-disjoint paths, then doubling every vertex (to redin-blueout and bluein-redout) reduces the problem to the monochromatic Menger's theorem from which (if I see well) the above lemma follows. So now I am mainly interested in the vertex-disjoint version. 

I am almost sure this problem is NP-complete. The reduction is from Planar 1-in-3-SAT, where we are given a 3CNF and a planar bipartite graph whose vertices are the variables and the clauses, with an edge between them if the corresponding variable is in the given clause. A very sketchy reduction is to start for each variable with 4k points, where k is the number of its occurrences, e.g. with (0,1),(0,2),..,(0,k),(1,0),..,(k,0),(k+1,1),..,(k+1,k),(1,k+1),..,(k,k+1), so we either take k horizontal or k vertical segments. Then our choice is led through a polygonal path to the clause component, which is another simple gadget that requires one incoming path. I know this is not a full proof, in fact I might be wrong, but working out the details is usually a tedious job that goes beyond a MO answer...