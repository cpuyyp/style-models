One way to view functionalism is as a response to the problems discovered with the mind-brain identity theory. The identity theory says (very roughly) that each mental state is identical to some brain state. There are well-known problems with this, notably Kripke-style counterexamples which employ a posteriori necessities. We can try to avoid the problems with identity theory by saying that mental states aren't correlated with particular brain states, rather they're correlated with particular configurations of physical systems. This is enough to avoid at least the most obvious of the Kripke-style counterexamples. You should also note that functionalism is a species of physicalism/materialism. This is because it doesn't posit new substances/properties over and above the natural properties we already know exist. (Granted, it does posit functional properties, though functionalists will say that we already recognize these in other domains). So functionalism is just a version of the physicalism you're already familiar with, albeit a more sophisticated one. 

One standard way to deal with this sort of situation is to distinguish between explicit and implicit beliefs (See Gilbert Harman's Change in View, Ch.2). Say that a belief is explicit if one possesses a mental representation whose content is that belief, and say that a belief is implicit if it is not explicit, but is (easily) inferable from one's explicit beliefs. Thus, we can say that you implicitly believe each member of the given set as long as you explicitly believe, say, the Peano axioms. 

Utilitarianism says that what we ought to do is maximize overall pleasure/happiness, or at least what we ought to do is what we reasonably expect will maximize pleasure/happiness. More generally, consequentalist theories of normative ethics say that what matters is well-being (here you fill in your favourite theory of well-being), and because well-being matters we should try to bring about as much of it as possible, i.e. maximize it. If by saving the data cubes you maximize overall happiness, then utilitarianism says that saving the data cubes is the thing to do. But this isn't necessarily the utilitarian's response: we can imagine scenarios where utilitarianism says that it would be morally wrong to save the cubes. Suppose the woman is a utility monster, or that the cubes won't actually help anyone, or whatever. The important point is that whatever you do, you're maximizing happiness. Utilitarianism doesn't care how you go about doing that, just that it happens. As far as other normative ethical theories go, I think they'll also say that the (im)morality of saving the cubes depends on a number of factors. Take a Kantian, for instance. They'll say that so long as you're acting on a maxim that you could reasonably will to be universal, or that you're not using anyone as a mere means to an end, it is OK to save the cubes. And a virtue ethicist will say that so long as by saving the cubes you act virtuously, it will be permissible, or maybe even obligatory, to do so. The difficult part is accounting for all of the non-moral features that bear on whether your are actually acting virtuously, or treating people as a mere means, or whatever. As far as utilitarianism/consequentialism goes, you might find this page useful: $URL$ 

Nothing, as far as I can tell. Stalnaker, for instance, is a metaphysical realist but an anti-Lewisian. Rather, to get from semantic externalism and possible worlds semantics to Lewisian possible worlds you need the premise that the only or at least the best way to correctly capture the semantics of modals is with Lewisian possible worlds. I hope I've managed to track your question and what's bothering you. If not, please let me know and I'll take another stab at it. 

To me it is difficult to judge if the technical antonym to determinism, which is either probabilistic or non-deterministic (the latter two are not identical mathematically), corresponds well to what we informally refer to as free-will. That would be the philosophical question left unanswered for me. But to summarize for your titled question, one necessary condition (but possibly not sufficient), is that the causes of the action not be 'functional' (which is to say almost tautologically, that the cause can't have a single possible outcome). 

That is a theorem (do the truth table) and it is built up out of falsehoods, in a manner of speaking. So yes you can construct a theorem out of falsehoods or contradictions if you like. 

A straight answer is difficult as this is very open ended, I can give examples for one side (that philosophy matters in the 'real' world) and limited argument for the other (it doesn't matter). For the relevance/impact of philosophy: 

An algorithm is a specification (particularly of operations to take on a machine). As a specification, it is an encoding of many possible things but none of them particularly algorithm specific. It can be an encoding of what you imagine, an encoding of some behavior viewed empirically, an encoding of some desired end. The qualifier 'foreign to human understanding' is something orthogonal to the construction of an algorithm. One can create a random algorithm (or any kind of mathematical encoding) and it might be inscrutable (there are theories that attempt to quantify this inscrutability). This line of thought leads towards algorithmic information theory. As to scientific phenomena evolution or consciousness, I think that's a matter of scientific exploration. There is an attempt to determine the knowledge exactly (through experimentation) where if it is a process one could presumably specify a Turing machine. But some phenomena have been found to be inherently non-deterministic (quantum mechanical processes). Of course one can always attempt to model such phenomena mathematcally (and here in particular much work has been done in quantum Turing Machines and quantum complexity. But simply, if you don't know something about your process, you really can't specify it. That is a specification really is a form of encoding of knowledge. So if there are unknowable things, then they can't be specified (by definition). One might be able to encode something -about- that lack of knowledge (like in say a probability distribution or non-deterministic rules). 

Euclid and Cantor, whatever they are saying, are using a refined and stipulative vocabulary: 'set', 'whole' 'greater' 'part' mean something very exact to them ('greater' has a different meaning between them). Euclid uses 'greater' like the more modern (actually Cantor's) definition of 'subset'. Cantor interprets 'greater' not as the subset relation, but as the 'cardinalilty' relation. (actually, Euclid's notion is somewhat underspecified, but like most of his mathematics, is not wrong at all, just in need of the slightest clarification, which is presumptuous to say since it took more than two thousand years to get that clarification via Cantor (for sets) and Hilbert (for pure axiomaticity). Carvalho, from your explanation, seems to be interpreting these words non-mathematically, or with an interpretation that doesn't match what either Euclid or Cantor meant. The set of natural numbers can be labeled one way, N, the set of evens another, E. Yes, E is a subset of N (there are things in N that are not in E), but also |E| = |N| because of the mapping n in N -> f(n) = 2n, and so f(n) is in E (and you can go back directly, that is there is a one-to-one onto correspondence between N and E, which defines 'same cardinality'. Carvalho says Cantor is 'confusing numbers with their mere signs'. I think Carvalho is misunderstanding how labeling of mathematical objects works; he is confounding the proof of cardinality with the construction of the objects at hand. The ordinal nature of the naturals (and the evens) is irrelevant to the proof. There is a question as to why this problem is even being discussed under philosophy when it is a matter of elementary logic/mathematics. Mathematics is a philosophical exercise, it is a pure mental manipulation of concepts, except it comes out of the scientific tradition rather than the humanistic one. Carvalho's difficulty with the problem is just a mature and well-spoken misunderstanding which in the mathematical tradition is only a minor stumbling block to set theory for newcomers. 

You don't hold anger against them, rather, anger holds you. Anger gives you the illusion of power over someone that caused you pain, but it's actually the exact opposite. Anger is hate and is also of the same spirit as resentment. We often become like what or who we hate. We say, "I would never do to my kids what my parents did to me" and then we do the same thing, because we become what we hate, against the entire might of our will. This is because anger controls you, you do not control it. Anger keeps you subject to the object of your hate. If we consider power the ability to do as you please, and weakness to be the absence of power, then we should conclude that anger makes us weak, because it causes us to do things, think things, say things we would never normally do. In other words, it robs us of our power; our Will. An angry person can never be reasoned with; as such, anger is like drunkenness. There is no wisdom in anger, no love in anger and no strength in anger. Forgiveness is where the power is. When you forgive, that spirit of anger is released and you once again have control over your life and your Will can once again be put to use. Under anger, the will is subject to the spirit of anger. You do what the anger wants, against your own best judgment, helplessly. Under forgiveness, anger is banished and you have your life back, your will back, your control back, your judgement back, your love back. Anger is hate and there is no love in anger. Love is the absence of hate. When you forgive, you lose the anger, you lose the hate and you gain love. Anger keeps your utterly powerless. It's impossible to act according to your best judgement when you have an angry spirit. You forgive for your own "selfish" reasons. You don't do anyone any favors by forgiving them. No one cares about your forgiveness. No one can earn your forgiveness. No one values your forgiveness the way you would want it to be valued. No. Instead, we forgive so that we can live again, be right again, be free from hate and once again be returned to our strength. We forgive to be strong, powerful, in control and abandon weakness and bondage. Unforgiveness is a prison for your Will. Without your will, you are all but dead. Life is about the Will, and with forgiveness you have your Will back, so you have life. Hate is death and love is life. Forgiveness is the strongest move anyone can ever make in life. The difficulty comes by not recognizing the voice of your own ego, telling you that you should not forgive because the other person doesn't "deserve" it. This is a lie that the ego tells us so that it can stay in control. The ego wants to stay in control. The ego makes us act against our own best judgement all the time, yet it robs us of all our power, our Will, our might, our true strength. The ego must be recognized and allowed to die in order to posses the Will and get control of your life, and choose forgiveness.