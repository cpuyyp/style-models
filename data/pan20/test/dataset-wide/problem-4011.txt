The integral converges as it is easily seen to be upper bounded by $\sqrt{\pi/2}$. However, Laplace's method does not seem to work out as the maxima of the function $S(x) = -a\sqrt{1-e^{-x}}-x^2/2$ is located at the end point $0$. This question enquires about a similar problem, however, with the major difference that the $S(x)$ function there is given by $-a(1-e^{-x})-x^2/2$. The second answer to that problem suggests using a modified form of Laplace's method as given by V. Zorich, Mathematical Analysis II Chap. XIX, Par. 2.4, Theorem 1, to tackle the issue of maxima at an endpoint. However, for the problem at hand, this method breaks down as the function $S(x)$ is not differentiable at $0$. So, Laplace's method cannot be applied here. I tried using the transformation $1-e^{-x}\to x^2$ to obtain the integral $$\int_0^1 \frac{\exp(-a x-(\ln(1-x^2))^2/2)}{1-x^2}2xdx$$ From this, intuitively, it seems to me that, at least for large $a$, the integrand is concentrated highly around $0$, and there it seems to be approximated ``well'' by $2xe^{-ax}$, which produces a $\sim\frac{1}{a^2}$ trend. However, all this is very intuitive and I don't know how to transform this intuition into rigorous statements. Also, this intuition seems to serve well for getting asymptotics, but my true intention is to obtain tight upper bounds. As Laplace's method seems not to be a suitable choice, I do not have much idea about how to proceed to say anything about an upper bound. Please help. 

Not really sure if this should count, but: From Chebyshev's proof using the central binomial coefficient that there exists some constant $C>0$ such that $$ \pi(x) < C\frac{x}{\log x} $$ for sufficiently large $x$, and from the infinitude of primes, we get that $$ \log x \ll x. $$ 

Hi! Not sure if this is exactly what you are asking for, but for non-linear equations in three variables you can fix a $b<1$ arbitrarily close to $1$ and then construct an equation so that $|A| > bN$ and there are no solutions to the equation in $A$, by using congruence conditions as was done for $x^2+y^2=z^2$. Take $x^2+y^2=p^2z^2$ for $p\equiv 3 \bmod 4$, $p$ sufficiently large, and form $A$ by deleting $p\mathbb{Z}$ from $\{1,\dots,N\}$. There are no solutions since $-1$ is not a square $\bmod p$. But if $p$ is fixed, then one wonders how much larger $b$ can be beyond size $\frac{p-1}{p}$. 

Nice question! For a point of view from the perspective of Goldbach's conjecture, perhaps one can consider also Theorem 3.7 of "The Hardy-Littlewood Method", 2nd edition, by R.C. Vaughan. 

I have a sequence $\{x_n\}_{n\ge 0}$ with $x_0>0$, controlled by the difference inequality: $$x_{n+1}\le ax_n^2+b$$ where, $a,b>0$. Had $b$ been $0$ and $a<1$, I would find $x_n\to 0$ as $n\to \infty$. However, the presence of $b$ makes finding closed form next to impossible, except maybe for some specialized values of $b$. But I am not interested in closed forms, I am interested only in the necessary conditions on $a, b$ for the convergence or divergence of the sequence, or at least finding an upper bound for $\lim_{n\to \infty}x_n$, if the limit exists. It seems that if $a,b<1$, the sequence becomes bounded, and an upper bound is possible (although not sure if a closed form of the upper bound exists), and that if $a>1$, the sequence might diverge to infinity, at least the right hand side of the inequality seems to do so; but what about the following cases: 1) $a<1,b>1$, 2) $a=1,b>0$ Please direct me to references. I think probably the literature of nonlinear dynamics would be helpful in answering questions like this, but it would be really helpful to get pointers for specific topics in that field that might help answering this question. Thanks in advance. 

Just a two cents worth here. :) Chess itself might perhaps not be too mathematical, but the chess evaluation functions of any chess-playing computer program seems like a mathematical object. After all, these are maps from the set of chess positions to $\mathbb{R}$ and they are bound to satisfy various properties. Given any two chess programs that are both strong and might be expected to be decent (in terms of current technology) approximations to objective truth, one might probably expect them to be "close" in some meaningful way that one could perhaps attempt to define. 

Here's an attempt to say something about your nice question. It surely follows from Igor Rivin's nice sketch and the Math Overflow question he linked to. Fix $r$. The quantity $E_r(x)$ in the edited question satisfies $$ E_r(x)\gg \sum_{\substack{m \leq x \\ \omega(m)=r\\ \mu(m)^2=1\\p|m \Rightarrow p \equiv 2 \bmod 3}}\sum_{\substack{n \leq x/m\\ \mu(n)^2=1\\p|n \Rightarrow p\equiv 1 \bmod 3}}1. $$ The inner sum in the above, by what you wrote about $E_0(x)$, satisfies $$ \sum_{\substack{n \leq x/m\\ \mu(n)^2=1\\p|n \Rightarrow p\equiv 1 \bmod 3}}1 \gg \frac{x}{m(\log x)^{1/2}}. $$ By induction on $r$, say, and using $\sum_{\substack{p \leq x\\p \equiv 2 \bmod 3}}\frac{1}{p}\gg \log\log x$, one has $$ \sum_{\substack{m \leq x \\ \omega(m)=r\\ \mu(m)^2=1\\p|m \Rightarrow p \equiv 2 \bmod 3}}\frac{1}{m}\gg (\log\log x)^r. $$ So one has $$ E_r(x) \gg \frac{x(\log\log x)^r}{(\log x)^{1/2}} $$ where the implied constant depends on $r$. 

I think this limit could be found, had the target set been a commutative ring, by an application of Newton's identity, but because of the noncommutative nature here, I cannot apply that principle here. Is there any way to tackle this problem? Please make reference to any material available, as I do not have any proper background on non-commutative ring theory (nor on ergodic theory applied to rings, for that matter), apart from the basics of rings. Thanks in advance. 

Let $\{x_n\}_{n\ge 0}$ be a sequence of reals such that $x_{n+1}=g(x_n)$, where $g:\mathbb{R}\to \mathbb{R}$ is a continuous function such that $0$ is a fixed point of $g$. My question is the following: 

Let $\{X_n\}$ be an ergodic sequence of random variables, $X_n:(\Omega,\mathcal{F})\to (S,\mathcal{S})$ where the target set $S$ is a matrix ring. My question is, 

Is there a method to find a tight upper bound on the given integral? Note that the integral is upper bounded by $\sqrt{\pi/2}$, and thus converges. I first thought about applying Laplace's method. However, the function $-x^2/2-a(1-e^{-x})$ is decreasing and achieves maximum at $x=0$ which is an endpoint of the domain of integration. As a result, I don't think using Laplace method is a good idea to find an upper bound. Numerical evaluation indicates an asymptotic of $\sim \frac{1}{a}$, but I am not sure how to proceed to say anything about an upper bound in terms of $a$. Any ideas? Thanks in advance. 

How can I determine whether $A_1,A_2\in GL(n,\mathbb Z)$ conjugate in $GL(n,\mathbb Z)$ and if they are, how can I find a $P\in GL(n,\mathbb Z)$ for which $A_2 = P^{-1}.A_1.P$ ? In $GL(n,\mathbb Q)$ one could achieve this by checking if the Frobenius normal forms (FNF) are equal and if they are $\quad\quad FNF_2 = FNF_1$ $\Leftrightarrow P_2^{-1}.A_2.P_2=P_1^{-1}.A_1.P_1$ $\Leftrightarrow A_2=M^{-1}.A_1.M\quad\quad\quad M=P_1.P_2^{-1}$ I found an algorithm which gives the FNF of a matrix with P a matrix of integers. Is there an way of performing subsequent elementary similarity transformations on $P_i$ (and hence also on $P_i^{-1}$) until $P_i\in GL(n,\mathbb Z)$ while also checking whether it is even possible to arrive at such a $P_i$? 

FYI: in crystallography, G are called space groups in three dimensions. Space groups which are semidirect products, are called symmorphic. Some thoughts that might lead to the solution: 1. Since T is normal in G we can write for every isometry $(t_q,q)\in G\quad$ ($t_q$: translational component, q linear component) $\quad\quad T=(t_q,q).T.(t_q,q)^{-1}$ $\Leftrightarrow T= (t_q,q).\lbrace (t,id)\rbrace.(-q^{-1}.t_q,q^{-1})$ $\Leftrightarrow T=\lbrace (q.t,id)\rbrace=q.T$ So q is a permutation of T. Since T is isomorphic (as a free $\mathbb Z$-module) to $\mathcal{L}^{n}$ and since q is orthogonal ($q\in O(\mathbb{E}^n)$), we find that $q\in Aut(\mathcal{L}^{n})$. This means that the set of all linear parts of G, which we'll call $Q(\mathcal{L}^{n})$ is a subgroup of $Aut(\mathcal{L}^{n})$. 2. Consider a coset $(t_q,q).T\ $ of T, then we can write $\quad\quad (t_q,q).T=\lbrace (t_q,q).(t,id): t\in \mathcal{L}^{n}\rbrace$ $\Leftrightarrow (t_q,q).T=\lbrace (t_q+q.t,q): t\in \mathcal{L}^{n}\rbrace$ $\Leftrightarrow (t_q,q).T=\lbrace (t_q+t',q): t'\in \mathcal{L}^{n}\rbrace$ which means that each q belongs to exactly one coset of T so that $Q(\mathcal{L}^{n})$ is isomorphic to $Q$. 3. From 1. and 2. we find that in any case (i.e. also when G is not a semidirect product) $Q$ is isomorphic to a finite subgroup of $Aut(\mathcal{L}^{n})$. 4. If we have $G=T\rtimes Q$, there exists a homomorphism from $Q$ to $Aut(T)$ and since T is isomorphic to $\mathcal{L}^{n}$ (as a free $\mathbb Z$-module) $Hom:Q\rightarrow Aut(\mathcal{L}^{n})$ 

For example, let $g(x) = x^2$. If $x_0<1$, then we have $x_n = x_0^{2^n}\stackrel{n\to \infty}{\to} 0$, and the rate of convergence is quadratic. Note that if $g$ is Lipschitz, then I can always find an initial condition suitably so that the sequence converges to $0$ linearly. However, this estimated rate would only be an upper bound on the actual rate, as it was seen for the $x^2$ example, the actual rate is quadratic and is thus very fast. Please provide some references to relevant literature. Thanks in advance. 

Lets say, $A\in \mathbb{R}^{m\times n}$, and $D\in \mathbb{R}^{m\times m}$, where $D$ is a diagonal matrix with positive diagonal elements, and all the elements are $\le 1$. For simplicity, assume that $A^TA$ is positive definite. It is easy to see that $$\lambda_{\max}(A^TDA)\le \lambda_{\max}(A^TA)\cdot \max_{i}D_{ii},\\\lambda_{\min}(A^TDA)\ge \lambda_{\min}(A^TA)\cdot \min_{i}D_{ii}$$ However, are these bounds generally tight? For example, if $D$ is such that one of its elements is $1$, and all others are equal to some small number $\epsilon$, then does the lower bound on the least eigenvalue produce a sever underestimation of the lowest eigenvalue of $A^TDA$. Specifically, 

The density Hales-Jewett theorem implies that there cannot exist perfect magic hypercubes of fixed side length $k$ and arbitrarily high dimension $n$ whose cells are filled with the consecutive numbers $1,2,\dots,k^n$ and for which the numbers in cells along any geometric line sum to the magic constant $\frac{k(k^n+1)}{2}$. For, take the cells with numbers $ 1,2,\dots,\left\lfloor\frac{k^n}{2}\right\rfloor $. This always has density about $1/2$, and so by the density Hales-Jewett theorem, will contain a hyperline for sufficiently large $n$. But no $k$ numbers from this set of density about $1/2$ can ever sum to the magic constant. 

The following is for a finite board (the question actually assumes an infinite board). For an $N\times N \times N$ board, wouldn't $2N$ rooks suffice? The idea comes from adapting the checkmate with two rooks for the two dimensional case in which the two rooks alternate rows and force the king to the last rank. For the three dimensional case, for each $y$ with $1\leq y \leq N$, place one rook at $(1,y,k)$ and another at $(2,y,k+1)$. Then, for $y$ going from $1$ to $N$, move the rook at $(1,y,k)$ to the square $(1,y,k+2)$. Again, for $y$ going from $1$ to $N$, move the rook at $(2,y,k+1)$ to $(2,y,k+3)$. Each for loop over $y$ involves moving, alternately, the rooks with $x$ coordinate $1$ by increasing their $z$ coordinate by $2$ units, or the rooks with $x$ coordinate $2$ by increasing their $z$ coordinate by $2$ units. We alternate, so that a for loop in which the rooks with $x$ coordinate $1$ are moved is followed by a for loop in which the rooks with $x$ coordinate $2$ are moved, and vice versa. Eventually, either the rooks with $x$ coordinate $1$ or the rooks with $x$ coordinate $2$ will have $z$ coordinate $N$. The effect of this is that a subset of the squares guarded by the rooks form a "floor" of two layers that keeps moving upward. So if the black king is between this "floor" and the top of the $N\times N\times N$ cube, it gets pushed to the top face. The "floor" must be moved upward in such a way that it never becomes disconnected, so that the black king can never escape to beneath the "floor" through some gap. For an infinite board, @Noam Elkies has already mentioned $5N$, so the following is not an improvement: the "ceiling" (and the other walls of the $N\times N \times N$ cube) can be formed by placing $N$ more rooks at $(N,y,N)$, for each $y$ with $1\leq y\leq N$, and $N-1$ more rooks at $(x,1,N)$, for each $x$ with $1 \leq x \leq N-1$, and $N-1$ more rooks at $(x,N,N)$ for each $x$ with $1 \leq x \leq N-1$. 

Let $\{X_k\}$ be an ergodic process. I know that if $f$ is a smooth real valued function then by Birkoff's ergodic theorem, $$\lim_{n\to \infty}\frac{1}{n}\sum_{k=1}^n f(X_k)=\mathbb{E}(f(X_1))\ a.s.$$ Is there any similar result for the $\limsup_n$ or $\liminf_n$ of the sequence $\{f(X_k)\}$, i.e. results which involve expectation? More specifically is there a way to find $$\limsup_n f(X_n),\ \liminf_n f(X_n)$$ almost surely? Though I have asked the question for the general ergodic processes, even results for stationary processes like Gaussian processes will be helpful to me. Also, if they are not available, it will be very kind if someone can give me some references that I can use to find methods to find these results. Thanks in advance. 

One observation: $$A = I+L,$$ where $L$ is a lower triangular matrix with $0$ in the diagonals. This matrix $L$ can be seen to satisfy $L^n=0$, and $L^j\ne 0,\ 1\le j\le n-1$. Thus, one can write $$A^{-1}=(I+L)^{-1}=\sum_{j=0}^{n-1}(-1)^jL^j$$ 

Any reference to literature and existing techniques will be highly appreciated. Thanks in advance. Edit: Another observation that I have made is that, if we have some $x^\star$ such that $\nabla f(x^\star)=0$, we can write the following $${x}^{n+1}-{x}^\star=({I-AG}({x}^\star,\ {x}^n))({x}^n-{x}^\star)$$ where $$G({x}^\star,\ {x}^n)=\int_0^1 \nabla^2f(x^\star+\tau(x^n-x^\star))d\tau$$ Then, analyzing convergence of the sequence $\{x^n\}$ is equivalent to finding suitable conditions on the minimum and maximum eigenvalues of $AG({x}^\star,\ {x}^n)$. Does the function $\|x-x^\star\|_2$ then qualify as a Lyapunov function? Even if it is true, I can not find an analog of $f(\cdot)$ which acts a Lyapunov function for the general case. I have read a few sections of the paper that @dohmatob referred in the comments, but I think I cannot find a Lyapunov function for this problem using the techniques introduced in that paper. The matrix $A$ is creating the problem. 

Consider the Euclidean group $E(n)$ as the semidirect product for Euclidean vector space $\mathbb{E}^n$ with its orthogonal group $O(\mathbb{E}^n)$: $E(n)=\mathbb{E}^n\rtimes O(\mathbb{E}^n)$ Then the following short exact sequence splits $1\rightarrow \mathbb{E}^n\rightarrow E(n)\rightarrow O(\mathbb{E}^n)\rightarrow 1$ Now consider a subgroup G of the Euclidean group which translational subgroup T (all isometries in G with trivial linear part) can be identified with a lattice $\mathcal{L}^{n}$ in Euclidean vector space, i.e. all $\mathbb Z$-linear combinations of a chosen basis. The translation subgroup T is normal in G and we can write the short exact sequence $1\rightarrow T\rightarrow G\rightarrow Q\rightarrow 1$ where quotient group $Q=G/T$. This short exact sequence splits iff $G=T\rtimes Q$. This is the case iff Q is isomorphic to the automorphism of the lattice so that we can write for example the following split short exact sequence $1\rightarrow \mathcal{L}^{n}\rightarrow G\rightarrow Aut(\mathcal{L}^{n}) \rightarrow 1$ 

As far as I understood, the Fourier decomposition of a function $\boldsymbol{F}\colon\mathbb{R}^{n}\to\mathbb{R}^{m}$ where $\mathbb{R}^{n}$ is endowed with the Euclidean inner product $\left<\cdot,\cdot\right>$ is given by $\boldsymbol{F}(\bar{x})=\int_{\mathbb{R}^{n}}{\tilde{\boldsymbol{F}}(\bar{\nu})e^{2\pi i \left<\bar{\nu},\bar{x}\right>}}{d\bar{\nu}}$ where $\tilde{\boldsymbol{F}}(\bar{\nu})=\int_{\mathbb{R}^{n}}{\boldsymbol{F}(\bar{x})e^{-2\pi i \left<\bar{\nu},\bar{x}\right>}}{d\bar{x}}$ How does this come about and for which functions does it apply? I'm not even able to find the right framework to work in (Hilbert spaces?). Secondly, could I just replace the Euclidean inner product by the Minkowskian inner product when in Minkowski space?