The method to making these setting persistent is dependent upon your particular distribution of Linux. 

The PackageCode is different. The Installation Sources should be different too. From the user downloaded executable installer: 

It's not clear from your question what the actual problem is. You have six domains, one of which requires SSL. You have one dedicated IP address. This should work just fine (see BillThor's answer). Why do you need another SSL-enabled domain? Does Cpanel require SSL? If Cpanel is the only way to configure your host, perhaps your hosting provider should pay for the extra IP and not you? If your hosting provider is requiring you to have one IP address for all your HTTP domains and one IP address for your HTTPS domain, I suggest you contact them and find out why. It is unnecessary, although I can't think of anything "wrong" it, other than you have to pay for another dedicated IP address. 

Do you have DNS aging and/or DNS scavenging properly configured? As you said yourself, it sounds like you have too many old DNS records hanging around on your domain controller. My suggestion is to look into setting up DNS scavenging or at the very least, delete the old A record (x.x.x.84) and then renew your workstation's DHCP lease for testing purposes. DNS scavenging will periodically remove the old DNS records that were dynamically generated when a client received a DHCP lease. This is a Good Thing (TM). DNS records are only good (and useful) if they are actually fresh. Having a bunch of records that point to clients that are no longer there isn't useful. You might also want to look at your DHCP lease TTL to make sure that it appropriately matches your DNS TTL and "aging" policy. A contrived example: if your TTL for DHCP leases is 12 hours and your DNS aging policy is to keep records for three weeks, you're just setting yourself up for trouble. The earlier mentioned technet blog post is a good place to start. 

To further complicate things I'm seeing multiple explanations of the error. WMI Troubleshooting Tips says that it is a failure to load a WMI provider: 

Is it possible to bridge aliased interfaces? And use their standard "parent" interfaces independently with full functionality? Here's the scenario: I have a Linux based firewall and router with two interfaces (, ). I would like to bridge for IPv4 traffic and route for IPv6 traffic using just these interfaces. Would it be possible to setup and for IPv6 routing and forwarding, while at the same time bridging and as a "passthrough" IPv4 bridge (all of the IPv4 routing is done on other side of this machine) so I can setup packet filtering rules both on the bridge and on the standard , and interfaces? 

I am working on a migration from a VMware vSphere environment to a Hyper-V Cluster utilizing Windows Server 2012 R2. The setup is pretty small, an EqualLogic PS6100e and two Dell PowerConnect 5424 switches and handful of R710s and R620s. The SAN was configured as a non-RFC1918 network that is not assigned to our organization and since I am working on building a new virtualization environment I figured that this would be an appropriate time to do a subnet migration. I configured a separate VLAN and subnet on the switches and the two previously unused NICs on the PS6100's controllers. At this time I only have a single Hyper-V host cabled in but I can successfully ping the PS6100 from the host. From the PS6100 I can ping each of the four NICs that currently on the storage network. I cannot connect the Microsoft iSCSI Initiator to the Target. I have successfully added the Target Portals (the IP addresses of PS6100 NICs) and the Targets are discovered but listed as inactive. If I try to Connect to them I get the following error, "Log onto Target - Connection Failed" and ISCSIPrt 1 and 70 events are recorded in the Event Log. I have verified that access control to the volume is not the problem by temporarily disabling it. I suspect the problem is with the Portal Group IP address which is still listed as Group Address of old subnet (I know, I know I might be committing the sin of the X/Y problem but everything else looks good): 

If you have loop problems I feel sorry for you son, I got 99 problems but a switch ain't one. You setup a Layer-2 loop on LAN1. Hyper-V Virtual Switches are just as susceptible to Layer-2 loops as regular switches. When you added the 3rd interface on your Intel Quad Port card to LAN1, you added a second path between your D-Link Switch and your Hyper-V Virtual Switch. Depending on what your end goal is, you'll want to configure NIC teaming, a separate Hyper-V switch, VLANs or just passthrough of the interface to a guest. 

In short keep your network simple and you will keep it secure. The cornerstone of your security plan should be controlling physical network access, the principle of least privilege and resisting implementing systems whose security requires more infrastructure that you have available (publicly accessible services for example). 

Yes, you should set the root password on your MySQL database and then keep it in a secure and recoverable escrow facility. There's no "checklist" for security, security is a process and a mindset but there are a few core principles one of which is defense in depth: Defense in Depth - Never put your eggs in a single basket. Authentication - Passwords are a "what you know" authentication token. Problem: a default password (in this case a blank one) is known by everyone. Therefore you no longer have an authentication mechanism for your database. Summary: Setting a password "costs" you very little and makes the attacker's job significantly harder. It's a good buy. 

I would really question your need to have this many VLANs on a network this small. Unless you have very specific reasons for requiring separate VLANS for each department it sounds like you adding a great deal of complexity without much (perceived) benefit. Sometimes we have to resist to urge to be overly clever. 

Now the shared object files are a little different. I like to use a combination of and . Let's say I'm interested in the object files linked against : 

The Attempted Solutions: How we have tried to fix it This seems consistent with the information in VMware KB 2038918 and VMware KB 2037408. I tried following the resolution path in VMware KB 2038918 by connecting to vSphere Web Client using the SSO Administrator account () and adjusting the Base DN for groups to be narrower instead of the base of the domain in case we running into timeout issues when doing group enumeration. This did not resolve the issue, however I was able to successfully Test Connection. The web client seems to just crawl though, for example it took over three minutes to open the 'Edit identity source' dialog window. VMware KB 2037408 does not seem to apply in our case as authentication fails whether or not we use Windows session credentials or if I manually supply my Active Directory credentials. I have restarted both the VMware vCenter service and failing resolution of the issue, the entire vCenter server. This did not resolve the issue. 

The consensus (which I agree with) seems to be don't defrag on servers because the benefits aren't worth the performance hit during the actual defragmentation. However, TechNet's article on doing Physical to Virtual conversions recommends defragmentation as a method to reduce the amount of time required to do a P2V. This is especially important if you have a limited maintenance window in which to complete your P2V. 

As I want to package one for ElasticSearch I need to know what is expected. If I understand you correctly, you are in the process of packaging ElasticSearch as .deb for distribution. If that is the case, and you are building a .deb package for public distribution I recommend you 1) fully read the relevant sections on packaging in the Debian Developer's Reference and ask on the appropriate Debian mailing-list (probably Debian-Developer). Generally speaking, will just remove the binaries and libraries associated with a package while will remove the binaries, libraries, documentation, and configuration files. It is considered bad form for your package to nuke the user's data without at least informing them first. I really suggest you check with an experienced Debian Maintainer before deciding how to proceed - especially if you want to submit this package to Debian repositories. Another word of device: As a long-time Debian user, almost nothing annoys me more than a 3rd party distributing their software as a .deb that does follow standard Debian conventions. If you want to keep your users, please ensure that your package is well maintained and meets the guidelines as laid out by the Debian team. 

You'll need your Audit Policy set appropriately so Windows will log the events in the first place (why this isn't a default setting is beyond me). Additionally you will want to use different EventIDs ( and ) for Windows Server 2003. 

That is too bad as it sounds like the cause of this issue is the embedded card authentication program. Keep on the vendor, maybe they will actually fix their software. 

This is a tricky problem. The best solution would be to replace the LAN2 Router with something that you actually have a degree of management control over. If you can't disable NAT there are probably other places this router falls short. However, my hunch is that you cannot replace this router with something more appropriate for political reasons (otherwise you already would've done it...). My first suggestion would be to put a Squid proxy in somewhere and use that log to per user internet access. The best place to put it would be on LAN1, but then all of web traffic from clients on LAN2 will appear to originating from the LAN2 Router courtesy of NAT. You could place it downstream of the LAN2 router, but then you'll have to port fowrard through its NAT so the clients from LAN1 can reach it. Doing this is kind of ugly. Another idea would be to rely on something like Netflow, SFlow or RMON if your switching infrastrucutre on LAN2 (and LAN1) supports it. Just forward the appropriate ports through your LAN2 router and place your flow collector on LAN1. Unfortunately, flow analysis is largely Layer-7 unaware so while you will be able to measure traffic, usage and counter statistics you won't get the HTTP-centric details that a web proxy would provide. Still it might be better than nothing. 

Is this possible? Probably. Is it a good idea? Nope. It looks like kind of like you're trying to reinvent the wheel. Apache supports a pretty wide variety of authentication backends and since it looks like your organization already has an LDAP implementation in the form of Active Directory I would recommend you take a look at mod_authnz_ldap. In the long run, I'm willing to bet the time it takes to implement, maintain and secure your text file based system will be significantly more than the time it takes to work with your Directory Services team. 

Remember, it's not your network. It's their network. You are here because they are here. I think if you take the long view, you can educate the segment of your users that fall into the "don't know" category and not the "don't care" category. Their knowledge will gradually increase (and your headaches will decrease). They can even become pretty valuable assets. 

No, you would not have to replace your firewall with the proxy. Your proxy should complement your firewall's services, not replace it. In order to ensure that all of your systems pass through the web proxy to browse the internet you would 1) configure the browser or operating system of each client to use the proxy. This is commonly done with either GPOs or the use of WPAD for Windows clients and 2) place a redirect rule on your firewall for traffic bound for either port 80 or port 443 that does not originate from the proxy to an internal web page that notifies users they must use the proxy for web access. This will ensure that non-proxied web traffic will be blocked and the user is notified in some manner. Other than the potential use of DHCP's Option 252, for configuring clients I'm not sure what DHCP has to do with this. 

You can query the appropriate registry keys to see what the network profile is set to. You need to look in to find the subkey for the appropriate interface. This will require a little detective work but the easiest way is look for the MAC address of your current default gateway. Once you've located the interface's SubKey take note of the ProfileGUID. You can then use the ProfileGUID to locate that interface's Profile settings . From there setting the REG_DWORD:Category back to 2 should set the interface's profile to Domain. You need to turn off the NLA service before you make the change to the Category attribute. A simple will stop NLA and netprofm. Once you make the registry change restart it: . 

Bottom line: Before you start throwing money at the problem (even if you have lots of money to throw) figure out what's actually wrong first. 

This typically caused by the Certificate Authority for your domain's Active Directory Certificate Services being unavailable. Try looking into why your Domain Controller cannot participate in auto-enrollment. 

Layer-9 considerations are prompting a migration from Citrix XenServer to Hyper-V as our shop's virtualization platform of choice. This will require me to migrate our existing virtual machines from XenServer to Hyper-V. A hand full of these VMs are running Debian. Unfortunately, Debian does not seem to be on the list of approved/supported guest operating systems. In fact it seems that running Debian as a guest operating system is rather difficult, although apparently not impossible. I have two interrelated questions: 

Consider using Tripwire. Tripwire will allow you to monitor files for changes by recording their checksums and then encrypting them. It's not integrated in with the system as well as mtree is on BSD, so it requires more configuration and upkeep but it will get the job done.