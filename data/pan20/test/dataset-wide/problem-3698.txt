In a context of blind source separation (e.g. you want to extract the voice of a singer from a song), many approaches consist in maximizing the independence between the components of a certain decomposition of an input signal. However, the signals are often considered only as random variables, although their temporal structure is often strong. I am interested in reading / learning / developing about an appropriate generalization of this approach where the signal is now modeled as a stochastic process (and even a diffusion process is it makes things simpler). So first I need a manageable definition and measure of the independence between the components of a stochastic process. For a random variable $X$ on $\mathbb{R}^n$, the Kullback-Leibler divergence between the joint and the product of the marginal distributions of $X$ is often used to measure the degree of independence between the components of $X$. It is written $$ I = \int p(X) log \frac{p(X)}{\prod_{a=1}^n p_a(X_a)}dX $$ where $p_a(X_a)$ is a marginal probability function. If $I=0$, the components are completely independent. How can I generalize it to stochastic processes? On this link $URL$ is given the definition of the independence between two stochastic processes. I guess this could lead to a formal generalization but I do not manage to write it. Can anyone do it? Besides, I am afraid it would lead to unpractical computations. So I am thinking that maybe with sufficient strong conditions on the stochastic process (which will not be worse than the usual ergodic random variable approach), one could simplify this expression up to a practical one. For instance, assuming that the process is solution to a stochastic differential equation, I am dreaming of the power of Girsanov theorem to compute the fraction in the above equation... Do you have the answers to my questions? Do you know any litterature on this topic? Any advice about the direction I should take? Thanks for your help. 

Let $LR(\mu/\lambda;\nu)$ be the set of Littlewood-Richardson tableaux of shape $\mu/\lambda$ and weight $\nu$. Then there is a canonical bijection between $LR(\mu/\lambda;\nu)$ and $LR(\mu/\nu;\lambda)$, presented in a paper by Pak and Vallejo ("Fundamental Symmetry map"), in a paper by Danilov and Koshevoi ("Commutor"), and in a paper by Henriques and Kamnitz. Is this what you want ? In the paper by Pak and Vallejo actually two "Fundamental Symmetry maps" are presented. Danilov and Koshevoi show that they coincide, and that they coincide with their "commutor", and with the map defined by Henriques and Kamnitzer. The references: Igor Pak and Ernesto Vallejo. Reductions of Young tableau bijections SIAM J. Discrete Math. 24 (2010), no. 1, 113--145. doi: 10.1137/070689784 (Also $URL$ V.I. Danilov and G.A. Koshevoi The Robinson-Schensted-Knuth correspondence and the bijections of commutativity and associativity. 2008 Izv. Math. 72 689 doi: 10.1070/IM2008v072n04ABEH002415 A. Henriques and J. Kamnitzer The octahedron recurrence and $gl_n$-crystals Adv. Math. 206:1 (2006), 211-249 

About your first question: remark that when $m=n$ these matrices are sometimes called "semi-magic squares" (like "magic squares" but without the "sums along the diagonals" condition). About the constructions of families of such matrices, there is another paper by Brualdi: R.A. Brualdi, Algorithms for constructing (0, 1)-matrices with prescribed row and column sum vectors, Discrete Math. 306 (2006), no. 23, 3054-3062. You can see also this paper by Fonseca and Mamede on the same subject: $URL$ Here the construction is related to other combinatorial objects (pairs of semi-standard Young tableaux of conjugate shapes), as you wished. 

Hello, working on some machine learning problem I end up facing a problem which looks like generalizing the notion of Cauchy product. I briefly go back to Cauchy products before exposing my question. Consider, two sequences $(a_n)_{n \in \mathbb N}$ and $(b_n)_{n \in \mathbb N}$, which are assumed to be absolutely convergent (for simplicity). Then one can define another sequence $c_n = \sum_{k = 0}^{n}a_k b_{n-k}$ such that $$\sum_{n=0}^{+\infty} c_n = \Big(\sum_{n=0}^{+\infty} a_n\Big)\Big(\sum_{n=0}^{+\infty} b_n\Big)$$ In the simpler framework, this is known as Mertens theorem and the (pedestrian) proof can be found in this wikipedia page. My question consists in the possible generalization / extension of such result to the case where the sequence $b$ would have two indices. More precisely, if one introduces another sequence $(\theta_n)_{n \in \mathbb N}$, I would like to consider the case of $$b_k^n = \prod_{i = k}^{n} \theta_i$$ and I am interested in computing the double sum $$\sum_{n=0}^{+\infty}\sum_{k = 0}^{n}a_k b_k^n$$ Note that, if all the $\theta_i$ are equal (and smaller than 1), then we fall under Mertens theorem range of application. But what if the $\theta_i$ are different? Is it still possible to have such a result where the sums eventually separate? I have tried but failed to extend Mertens theorem's proof to this case. Any link to references which may help me figure this out would be most welcome. Besides, if one could show me a path to learn more about sequence with two indices, I would be very happy! Cheers 

The evaluation of the Schur function $s_{\lambda}$ at the $n$th-roots of unity is the coefficient of $s_{\lambda}$ in the expansion in the Schur basis of the plethysm $h_k[p_n]=p_n[h_k]$ of the complete sum $h_k$ with the power sum $p_n$, when $k\cdot n=|\lambda|$ (and $0$ if $|\lambda|$ is not a multiple of $n$). Indeed, consider the Cauchy identity, $$ \prod_{i,j} \frac{1}{1-x_i y_j}=\sum_{\lambda} s_{\lambda}[X] s_{\lambda}[Y]. $$ Take for the $x_i$ the $n$th-roots of unity $\zeta_i$. Therefore the evaluation of $s_{\lambda}$ that you are looking for will be the coefficient of $s_{\lambda}[Y]$ in the expansion in the Schur basis of $$ \prod_{i,j} \frac{1}{1-\zeta_i y_j}. $$ On the other hand, $$ \prod_{i,j} \frac{1}{1-\zeta_i y_j}=\prod_{j}\frac{1}{1-y_j^n}. $$ This is the generating series for the complete sums $h_k$ evaluated at $y_1^n$, $y_2^n\ldots$ , that are exactly the plethysms $h_k[p_n]$: $$ \prod_{j}\frac{1}{1-y_j^n}=\sum_k h_k[p_n[Y]]. $$ These plethysms expand in the Schur basis: $$ h_k[p_n[Y]]=\sum_{\lambda} d(\lambda,(k),n) s_{\lambda}[Y].$$ The coefficient $d(\lambda,(k),n)$ is the evaluation you are looking for, for $k \cdot n = |\lambda|$. For any particular computation of the $d(\lambda,(k),n)$ you may use SAGE or John Stembridge's SF package for Maple. For a general study, you should find at least some examples of such plethysms in Macdonald's classical book. You will find more recent results by googling "plethysms power sums complete sums in Schur", for instance by William Doran, or Carbonara+Remmel+Yang. EDIT: Actually it is easy to evaluate the Schur polynomials at the $n$-the roots of unity, from the definition of the Schur polynomials as "bialternants". One gets that the evaluation of the Schur polynomial is nonzero if and only if the classes modulo $n$ of $\lambda_n$, $\lambda_{n-1}+1, \ldots, \lambda_1+{n-1}$ are a permutation of the classes of $0,1,\ldots,n-1$. Then this evaluation is the sign of the permutation. About the evaluation of the monomial functions, since this is what you are really interested in. A method for evaluating the monomial functions at the roots of unity is presented in Alain Lascoux and Marcel-Paul Schutzenberger's "Formulaire raisonné de fonctions symétriques", ex. 5.14, with a reference to a paper of 1881 by E. West. I think it generalizes indeed your computations by inclusion-exclusion. The method consists in expanding the monomial functions in the power sum basis. Note that the power sum $p_r$ at the $n$-th roots of unity is $n$ if $n$ divides $k$, and $0$ else. The expansion of monomial functions in the power sum basis is explained in Example 2.7 of the "Formulaire raisonné de fonctions symétriques". It is also explained in "On the Foundations of Combinatorial Theory. VII: Symmetric Functions through the theory of distribution and occupancy". Peter Doubilet. Studies in Applied Mathematics 51 (4), 1972. Say you want to expand $m_{(\lambda_1,\ldots,\lambda_k)}$ in the power sum basis. Consider rather the "augmented monomial function" (which is, by the way, the function you are really interested in): $$ M_{(\lambda_1,\ldots,\lambda_k)}=\sum x_{i_1}^{\lambda_1} x_{i_2}^{\lambda_2} \cdots x_{i_k}^{\lambda_k} $$ where the sum is carried over all arrangements $x_{i_1},x_{i_2},\ldots,x_{i_k}$ of $k$ variables. The expansion of $M_{\lambda}$ in the power sum basis involves the set partitions $\Pi$ of $\{1,2,\ldots,k\}$. They form a lattice under refinement, whose smallest element is the partition $\hat{0}$ in $k$ singletons. This lattice admits a Möbius function. Let $B_1$, $B_2,\ldots,B_{\ell}$ be the blocks of $\Pi$. The Möbius function on the interval $[\hat{0},\Pi]$ is: $$ \mu(\hat{0},\Pi)=(-1)^{k-\ell} \prod_i \left( \text{card} B_i -1\right)! $$ Set $\lambda(\Pi)$ for the partition whose parts are the $\sum_{i \in B} \lambda_i$ for $B$ block of $\Pi$. Then the formula is: $$ M_{\lambda}=\sum_{\Pi} \mu([\hat{0},\Pi]) p_{\lambda(\Pi)} $$ where the sum is over all set partitions $\Pi$ of $\{1,\ldots,k\}$. When evaluating at the $n$-th roots of unity you obtain: $$ \sum_{\Pi} \mu([\hat{0},\Pi]) n^{\ell(\Pi)} $$ where the sum is over all partitions $\Pi$ such that all parts of $\lambda(\Pi)$ are multiple of $n$, and $\ell(\Pi)$ is the number of blocks.