It's best to build the source RPM with , or better yet with as this tool will keep the build environment clean and separate from the system it's running on, by performing everything in a chroot. This does not need to be done on the actual system which the final RPMs are intended for; you can always spin up a virtual machine running the same target operating system and perform the build on that. And if you can't, there is always the new COPR service from the Fedora Project. This build service lets you submit source RPMs for EL 5, 6, 7, and current versions of Fedora, builds them on Fedora servers, and creates yum repositories which you can then use directly. It's very similar in functionality to the PPA service from Ubuntu. Of course, since this is a package which came with the OS distribution, you could simply install the existing binary packages which you can find on any CentOS mirror. 

Bash might not be installed. Unlike other distributions, Debian and Ubuntu use dash, a stripped down Bourne shell, as the default /bin/sh shell. 

The init script for iptables will never return exactly that string; it will always have something else in it, and there are also failure conditions which don't match that string at all. Instead, you should check the exit code from the script, as it (on EL and Fedora) returns non-zero if the firewall is not active and zero if it is active. 

The problem is not Fedora 20, nor is it Mock. It's RHEL 5. The RPM macro was set to in both RHEL 4 and RHEL 5. The problem is that the macro was never used to build those distributions, so nobody paid any attention to its value. It only became an issue when people began backporting packages from later Fedora which did use the macro. And, of course, because RHEL is a "stable" enterprise distribution which aims to not break compatibility during its lifecycle, this will never be changed. The macro works as you expect in RHEL 6 and 7. If you still have to support RHEL 5 boxes, you (and everyone else) are stuck with workarounds like the ones you already proposed. The simple and clean one is the first one you suggested: 

Keep in mind that this will allow outgoing connections to anywhere. The secure fix is to write a local policy confining and allowing it to connect to port 5037, access USB devices, etc., but this is a lot of work... 

TLS certificates are issued for hostnames, not for IP addresses. Use the appropriate hostname in your URL. 

Aside from preventing any overcommit at all, and preventing the system from using all free memory and swap, this also causes additional memory to be reserved for admin and user processes as specified in and . I can't find a single system I manage, embedded, desktop or server, where this setting is anything other than 0. Finally, about DD-WRT... I'm not happy with them. They went overly commercial some time back and stopped making regular releases and updates. These days I recommend OpenWrt as a platform for building embedded systems. 

First, make sure you have set up bridging properly so that your virtual machines can communicate with the network. Second, create an IP Pool containing your /29 network and the gateway address within that /29. Setting the gateway address correctly is probably the part you missed. Hetzner will let you know which address in the /29 is the gateway. Third, assign IPs to virtual machines and enjoy. 

means that another process is already listening on port 80. Only one process can listen on a given port at a time. To find the process, run as root: 

First, we need a definition. Long-lived protocols are those for which the connection is intended to remain open indefinitely. (An example of such a protocol is ssh. While an ssh connection can be short, it is meant to be able to idle forever, thus the protocol is long-lived.) Short-lived protocols are more transactional in nature; a particular action occurs, or series of actions, and then the connection is closed. By these definitions HTTP is a short-lived protocol, even with keep-alive. The fact that an HTTP connection may remain open for minutes or hours while data is being transferred is irrelevant. And Keep-Alive is a performance optimization meant to allow a client to make multiple requests of the server over a short period of time. Servers must drop an idle Keep-Alive connection after some time, because they have only a limited amount of resources for holding open ports, and the client doesn't need it to remain open anyway. Because HTTP cannot remain open and idle forever, and is not designed to do so, it is a short-lived protocol. 

You can also use fail2ban to do this, as it already has preconfigured jails which process the postfix logs; they merely need to be enabled. For instance, put in your : 

Look at the firewall entries on the remote server. Most likely something is blocking ICMP requests used by ping and traceroute. 

Your application only bound to 10.141.36.41. You cannot reach it on any other address. To resolve the problem, change the application's settings. 

On March 4, 2013, Red Hat provided updated OpenSSL packages which address this issue. You can receive them through your normal update channels. The original answer was: 

Generally, password expiration is used to force users to change their passwords. What it sounds like you want to do is to lock the account, which prevents all login. What I would suggest you do instead is, when you create the account, also set up an at job which will lock the account after four hours. For example: 

NetworkManager has only a very basic CLI which, unfortunately, is not capable of creating connections at this time (but can bring them up and down). If you need to configure a machine without a GUI it's strongly recommended you use the normal (non-NM) method as described in the documentation and do not use NetworkManager at all. I will note that you haven't actually given a reason to use NetworkManager on this system, so I have to recommend against it. If you really have to do this, the NetworkManager way on Red Hat-derived systems is to add all of the IP addresses to the same file. This was described in the NetworkManager documentation under Device Aliases. Example: 

The simplest solution is to run two mail servers on premise. One handles only incoming mail, while the other handles only outgoing mail and knows nothing of the first server. 

On the host: Look at your process list. A KVM machine started with VT-x acceleration will contain the command line option (possibly along with other related machine options). 

Check the permissions on the directory. I would bet that it's set to deny access to anyone but yourself, for instance: 

You can try submitting the form with no error code selected, and hope for the best. If you're lucky, a human being might read it. You can also try contacting AOL Postmaster by phone, on +1 703 265-4670 (reportedly AOL postmaster operations are now being handled in India; you've been warned). 

You said that is owned by and has permissions . This means that all users can write to the directory, but only root can read. The result is that PHP can create session files, but cannot go back and read them later. This appears to be why your sessions are failing. Fix the ownership and permissions so that can both read and write (). For instance: 

You can if you really want, but I wouldn't bother regenerating 2048-bit DH parameters for OpenSSH. There are much more important things you need to do to secure SSH, like disabling weak crypto. What I would do is delete the existing ones which are less than 2048 bits. 

This looks perfectly normal to me. Most video (and even audio!) players request small chunks of the file at a time, and then request more later, as the user actually plays the video. 206 is only sent when the user-agent specifically requests a specific range of the file, rather than the entire file. 

The version of firewalld in RHEL 7.0 has no "save" script and no way to copy the running firewall configuration to the permanent configuration. You save a firewall change with firewalld by adding to the command line making the change. Without it, any change you make is temporary and will be lost when the system restarts. For example: 

Looks like just another random connection attempt from part of a botnet. Assuming your mail server is properly secured, you can ignore it. Of course, this is a good time to check and ensure that your mail server is properly secured. 

The reason everyone puts nginx (or another server such as Apache) in front of their app servers is that everyone has static content such as images, CSS and JavaScript, and strange requirements which are unique to their application. Your app server (CherryPy, gunicorn, whatever) is optimized to run your app and serve its output. While the app server can also serve static content, they are almost never well optimized for this task, since it's secondary to the main purpose of the app server. (Some app servers will also help by minifying and compressing your CSS and JS, so that the web server in front can serve these resources even faster.) In addition, the actual web server can do much more than high performance content serving. Things like caching, header manipulation, URL rewriting, geolocation, and many other features that would just bloat the app server to no good purpose. Typically you would run the app server alone only when developing the application, when you are the only user, and performance is not an issue. Even if your site is low traffic, you would like it to be faster, right? Low traffic sites which are slow don't generally grow into high traffic sites... 

You need to remove the anonymous users, as MySQL's pattern matching will match them first. Run the script or remove them manually. 

Don't disable IPv6. It is not optional anymore and you will not be able to communicate with some people without it. Instead, fix your SPF record so that it passes mail originating from your IPv6 address. 

Server Support Most current versions of popular server software support SNI. Setup instructions are available for most of these: 

You activate a zone by binding a network interface or source IP address range(s) to it. Any firewall rules in the zone then apply to that network interface or IP address range(s). 

This will be the general process. See the man page and your own local configuration for the exact commands to use, if you don't already know them. 

PHP logs this particular event, (along with many other abnormal things) so you should also watch its logs. For example: 

You have only installed the PHP language bindings, which allow PHP to communicate with memcached. You haven't actually installed memcached. If you want to run memcached, you will need to install it. (And there is no such daemon as memcache.) 

You don't need to do this. Just enter in the failover IP, netmask 32, and gateway address in the installer, and everything will work. The routes that used to go in are auto-generated by the kernel now. To use it in a kickstart is the same way: 

Shopify doesn't support IPv6 (which may be a big problem for you later) so just remove the old AAAA record. Your DNS records appear to be hosted by "Web-2u Limited". 

Note well that this displays summary information and doesn't contain quite all the information that might have displayed. 

You can set the secure flag on a cookie regardless of whether the connection made to the origin server was secured or not. The client interprets this flag, and won't actually set the cookie if the connection wasn't secured. According to RFC 6265: 

Also redirect the output somewhere. will simply display the entire file without pausing and then exit if standard output is not a terminal. For example: 

PowerDNS logs to the local syslog, so it is the syslog daemon you need to send a HUP signal to when you rotate the log files. You do not need to signal PowerDNS at all. For example (taken from the logrotate configuration for rsyslog): 

I'm not sure you read Apache's docs on mod_autoindex closely enough, as it does reveal two ways to set descriptions. Probably not your fault; they are kind of buried... First, you can use to set individual descriptions for files or groups of files by partial match. Second, you can set and Apache will use the of each HTML document as its . This is CPU and disk intensive though. Descriptions given by take precedence.