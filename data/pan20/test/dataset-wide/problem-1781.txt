Try using a Powershell script for New-ADUser with try/catch or in order to find a duplicate AD user before you get to the point where Exchange renames the alias. Then you can use whatever logic you wish to get it named the way you want. 

Then I create a Scheduled Task in Windows Server 2008. If I set up the task to use my Domain Admin account, great. But I'm trying to get it to run as a separate domain account for Scheduled Tasks. If I use that account, folders get created, but files aren't copied. I get the following error: 

It really depends on your situation. We do let most users have more than 1 login available, in case they move from one desk to another and only need to do a quick login somewhere else. The applications that they might use may enforce a single login, but our AD is not so strict. If, however, you are using 1 login for multiple users, that's a definite security no-no. Each user should be associated to his or her own account. 

I doubt that this affects your Win 7 testing storage server, but if you're going to replace the storage server with a different dedicated SAN or NAS, check the capabilities of your vendor and how that will affect your storage presentation. For one vendor (EMC in our case), they recommended the VMWare servers use NFS to access the storage, rather than iSCSI. Exposing the VMs via NFS lets the SAN/NAS hardware perform deduplication and thin provisioning. iSCSI to VMFS datastores on the same hardware would prevent the SAN/NAS features from running. 

I don't think there's any way to do this after looking through Microsoft's password policy documentation, but on the off-chance that someone was particularly clever: Is it possible to create a policy so that only business days count towards password expiration? The idea being that a password that expired on Saturday would not necessitate a helpdesk call until Monday, and VPN users would be able to continue to get in. We're Server 2008 R2 here. The best workaround I can come up with is to enable this in Outlook Web Access: $URL$ But not sure how this will play with our Duo two-factor. I'm open to third-party stuff if that will work. I don't see this as a PowerShell opportunity, but tell me if I'm wrong. 

I'm reasonably certain that the only way to mitigate this will be to use WSUS, Systems Center, or some other sort of patch management automation. You'll need to create at least one separate group for Servers, then use whatever system you choose to deploy on the patches that you want. WSUS has no additional licensing, so at the very least you'll be able to test this without any purchase, just time. 

Unless you have a very compelling reason, I would split off some of your services on VM2, so that a problem in SQL doesn't knock out your file server, filling the file server knocks out your IIS, etc. With the thin-provisioned disk (as ewwhite recommends), you should still have plenty of room for everything. 

If you are setting up Networker with a single Networker Server, the Server is also a Storage Node by default. In small environments (like mine, and likely yours), the Storage Node role, Server role, and Admin Console role are all on the same server, so that's where your VADP should be. A Storage Node is a Networker server (little 's') that has backup Devices (in your case, the DataDomain, but also tape drives, autoloaders, more disk, etc.) attached to them. Even though the DataDomain is not DAS, it is still controlled by the Storage Node. When you get to larger installations, it can be helpful to split backups across multiple Storage Nodes for better performance. So the Chicago office backs up to a DataDomain on a Storage Node in Chicago, while the NYC office backs up to a tape autoloader on a Storage Node in NYC. The Networker Server (big S) then keeps track of what data is on which Storage Node. If you haven't logged into EMC's Powerlink site, make sure you get access to get the manuals (which aren't easily available otherwise...grrrr...). I'd also recommend the EMC Networker Administration video training, since that helped clear up the whole Networker architecture in my head so it made some sense. I had very similar issues trying to get up to speed with our setup. 

The most basic and easiest? Get an upstream vendor to do it. I'm going to make an assumption that your site is small (under 100 users), given that you aren't talking about other staff you have. In 2016, I'm hard-pressed to find a good reason for email to be in-house. Even enterprise installs are going cloud on email. Google, Office 365, or hosted Exchange will all do it better and cheaper once you factor in hardware, software, services, and skillsets. If you absolutely must keep it in-house, at least put an integrated email security system in front of it. We use Mimecast, Barracuda if you're getting hardware, but doing it all in Exchange alone, when you have other things to do? I don't see added business value there. 

I'm at my wits' end on this one. Scenario End-user is trying to print at home to her wireless printer, a LaserJet Pro M1217nfw. Every time she tries to connect, it asks for admin privileges to install the driver. After some research, I find this article: $URL$ I make the changes to the two printer classes in Group Policy. I've ensured that the GPO has been applied to the laptop. Using a laptop with the same GPO, I was able to get my home USB printer to connect (using my normal user privs, no elevation). Great! When my user tries it at home, though, she isn't able to get any farther than a UAC prompt. This happens when she tries to do this wirelessly or via a USB port to tes. My theory is that I need to add another device type. If there is a way for me to determine what Device Class that printer is asking for, I suspect I could just add the GUIDs to the GPO, but I don't know how to determine that. Nothing is leaping out at me in Event Viewer. So: 1.) What am I doing wrong for laptops accessing home printers? OR 1A.) Is this not a best practice at all to let users install printers on work laptops? If that's the case, how do you manage users' home printing? 2.) If my solution is just to add a Device Class, how do I find out what Device Class a peripheral is identifying itself? 

If you have little to no budget, I'd recommend that you use some free (as in beer) wiki software of your choosing (even Google Sites would probably be fine). I'm afraid I don't know offhand a particular template that will help for your documentation, but the big advantage the wiki has (over, say, a Word/Excel template) is that you can easily see the changes to a particular page over time using the history function. It's more cumbersome to do something similar with an Office document. This would be best for account info, privileges, procedures, and other similar documentation. For software & hardware audits, inventory, configuration, I'll second the recommendation for Spiceworks. Download and install on a spare PC if you don't have the budget for a true server now. While we didn't opt for it when we were checking out helpdesk/network monitoring software, it is free, and it seems to have a nice community built around it. 

This might be better for Superuser...but can also be covered here. It seems clear that you've lost DNS on the client somehow. If you can connect to sites/servers by IP, but not via domain name, that would confirm it. Check your network settings and make sure that there is a valid DNS entry in there for your DNS server. You can try using the Google DNS 8.8.4.4, but bear in mind that if you tried this on many corporate networks, it may not work. You may only be able to use the internal DNS, since a firewall may stop outbound DNS from all but the internal DNS servers. If you truly think it's malware, you might also want to check the hosts file and make sure it's not redirecting all of your traffic to who-knows-where. 

Viable, possibly. There's a lot to look at on that dedicated PC. In general, you're going to want a dedicated piece of hardware to be your router rather than a PC, if for no other reason to reduce the visible attack surface on an internet facing device. A support contract to handle the hardware on the single point of failure wouldn't be a bad idea, either. :) The usual suspects in router or firewall hardware should be able to provide what you need. Be sure to mention load-balancing when you ask, or you may end up with a simple failover solution on the router/firewall. Not that that's necessarily a bad thing. 

I've verified my domain\Scheduled Tasks account has Full Control NTFS permissions on both the source and destination, and the Full Control Sharing on my hidden \server1\backup$ share. Just for giggles, I've tried adding the domain account to the local Administrators group on both servers. This works fine, but that seems like a lot of privileges just to copy files. Any ideas on what I'm missing? EDIT TO ADD: I've tried using the robocopy \copy:DATSO flag rather than \copyall (I can skip the auditing info), but I still get the same error. I've also tried using runas \noprofile \user:my Scheduled Tasks user for the robocopy command. I get the same error again. I'm not averse to simply adding the user to a Built-In group, though Administrators seems like it would be overkill. I'd be interested to know how others handle their Scheduled Tasks. 

I have verified that I am logged in as root, and that the /mnt/esxshare directory has been created. My biggest concern is that my web research so far indicates that ESXi can't actually mount SMB shares, only ESX can. I also would need to enable the firewall on VMWare to allow SMB, but ESXi doesn't seem to have an interface to that either. Am I correct? I'm open to other suggestions on how to get a share mounted, but I'm a Linux newb. My only other theory would be to do an NFS share somewhere, mount that in the Service Console, and then get on with the esxtop logging I need to do. I've also got a message in to our vendor asking for help, but I'm hoping to understand what exactly is failing to get a better understanding of the VMWare guts. Any help would be greatly appreciated. Thanks! CC UPDATE So it doesn't appear like my prospective vendor has any options for this, either. We're still new to virtualization, so we'll consider using ESX Server when we upgrade from our current 3.5 installation in the next year or so. In the meantime, the best we can do is measure peak IOPS of our current system, and get stats from other non-VM systems that connect to our SAN. Hopefully that will be enough. 

Short answer to "do you need DNS pointing to Domain Controller for GPO to work" is yes. spacenomyous has the answer up there. I'm guessing that if you're new to AD and DNS, you may also be new to DHCP, which will dynamically grant IP addresses and associated settings to clients. You can add that role to the DC (or other server), and then point your clients to use DHCP to update the network settings, including DNS entries to have them all point to internal DNS. If you absolutely must set them on each computer, then you should be learning some Powershell scripting to automate. If you can do a .vbs script, then you can look at the following link to figure out how to update the clients: $URL$ 

We have a VMWare ESXi 3.5 server that we are trying to get performance information on via esxtop logging, but I can't get an SMB share to mount so I can store the logs there. What am I missing? The command I'm trying to use (per the vendor's instructions) is: 

There are a number of questions that arise from what you're describing. First, if you're talking about vSphere, you should check that the hardware (which you don't describe) is on the VMware's Hardware Compatibility List (HCL). This will tell you if vSphere is going to be an option. If it's not on the list and you run into trouble, VMware will tell you it's unsupported, and you're out of luck. You also need to reconsider your hardware. Fault-tolerance doesn't seem to be addressed if you're just using a workstation. You definitely need to have some sort of fault-tolerant RAID 1, 5, or 6 setup, so that one HD failure doesn't ruin your day. Hot-swap HDs will make your life simpler when one fails. Plus server hardware should have redundant NICs, redundant power supplies, error-correcting RAM...just buy a server. Server hardware is cheap compared to the value of your office being down while you figure out what's wrong and restore from backups. Unless you have particular vSphere experience or needs (there's nothing in particular I see in your post), I don't understand why you wouldn't use Hyper-V virtualization that is built into Windows Server. For modest needs as you've described, VMware appears to be overkill. Since you already need to upgrade Windows (and you definitely do -- Windows 2003 end-of-life is July 2015), Hyper-V would offer less complexity in this scenario, and it comes as part of your license. 

If you've got Mac OS X Server, you should be able to create a SMB share. I don't have a Mac server in front of me, but I believe it's in Server Preferences-->File Sharing. Once shared, your PCs should be able to get to the drive directly by mapping the drive on the client. If you're just using a regular Mac as a server without the Server software, you can still enable Samba at the Unix level, or use SharePoints as a GUI to set up a Windows share. 

I'm planning some expansion on an HP MSA1000 SAN. My boss says that we need to have two separate arrays on the new enclosure, one for Bays 1-7, the other for Bays 8-14. Is there any reason that we need to do this? My plan was to have the entire expansion shelf be 1 array, then create RAID 6 logical drives from that. I don't understand what splitting drives into separate arrays gain us. We don't have dual controllers, so there's no benefit there. Thanks, CC 

I thought that EMC kept all of the documentation behind a login wall unless you are a customer, but it turns out that's not true. So I was able to download the manual and check it out myself. Turns out you can take the Data Domain backup to tape. In Networker lingo, this is a backup clone. This will lose the Data Domain's deduplication, but the clone should be readable by Networker in a disaster recovery situation without the Data Domain hardware. That's what I see from the manuals, anyway. Still wouldn't mind getting a sanity check from someone who has actually used Networker, but I may have what I need. 

If your backup needs will stay under 50 GB, then hosting at $URL$ would work for you. They explicitly allow a backup user as long as you stay under that. They also have SFTP, which is a more secure option than straight FTP. 

At this point, you're ready to bring in your 2016 DCs. The big problem with your second bullet point is that making a new domain force all new AD accounts for your users and computers. Note that creating an account with the exact same name doesn't give the same permissions, because it's all based around SIDs. So in that scenario, you will need to rejoin all the PCs, all of your users will need to reset their passwords, and it sounds like a big bag of hurt for anything more than a trivial (<5) number of users & computers. If one of your users happened to encrypt a file client-side, that's also reliant on AD SIDs, and wiping out your AD will wipe out access to the files. As a bonus, the 2008 DC can be your secondary DC (always have 2 DCs), so you'll only need to install 1 new 2016 DC for now. That would be stable enough to let you go on to the next fire until 2008 support ends in 2020. If 2000 was good enough for the network thus far, it doesn't seem that moving to 2016 for AD is going to have huge benefits.