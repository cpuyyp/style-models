I've seen [+constricted glottis] described as encapsulating ejectives and implosives, but the feature matrix according to Hayes (2009) (that I pulled from his personal website over here: $URL$ only lists the glottal stop as being [+c.g.]. Is there disagreement here? Or an error? 

I've been using the two terms interchangeably. One of my assignments is asking me to identify cases of both suppletion and irregular inflection. I've been going over course notes/google to no avail--they seem like the same thing to me. The only bit of difference is that one seems to have a more synchronic focus, and the other a more diachronic one...what's up with that? 

Last year I had a prof who denied the existence of adverbs, and instead posited a class of words that were labelled "intensifiers". Many words that would have been otherwise been labeled as an adverb were then labeled as an intensifier. What's the point of the label "intensifier" in the first place, compared to "adverb"? To me, they seem to be two different names for the same thing. 

Say you're analyzing a completely "new" unstudied language, and you come across a set of sounds [g],[k] that are in complementary distribution and that you suspect are allophones of the same phoneme. What do you then call this phoneme? Do you just ask the native speakers what sound they think it is? Or look at elsewhere conditions? Why call it /g/ over /k/, or not something entirely different? 

For future people who may need this, I ended up writing a webscraper and compiling everything from www.minpairs.talktalk.net. You can view/download the corpus here: $URL$ 

It all depends on what sort of questions you want to ask about language. One way to divide up language is by breaking it into its constituent compositional parts. 

I'd like to see a spectral representation of my left and right channels individually. I'm not sure which channel Praat's spectrogram corresponds to. How do I show multiple spectrograms, with each corresponding to a different channel? 

I suppose, like many things in linguistics, this may vary depending on your framework--but which one is more acceptable? 

Update here: I ended up using phonological corpus tools to calculate the phonological edit distance between sets of transcriptions. If interested my code is over here. 

In english, taboo language may be realized as swear words--though I could see some languages not having "swear words" in the english sense, while maintaining "vulgar expressions". All cultures have taboos. However, do all cultures have linguistic taboos? 

Phonetics - studies the physical speech signal. Sound is interpreted in the brain, which leads us to: Phonology - studies the how speech signals are perceived, as well as mental categorization of sounds. These conceptual sound categories may combine to form morphemes, which leads us to: Morphology - the study of the smallest units of meaning (e.g. "book"+"-s"="books"). Morphemes may combine to form words, and those words combine leading us to... Syntax - the study of "sentence level" structure--how words combine to form phrases, and those phrases combine to form sentences. Of course, words and phrases just so happen to have meaning, this leads us to... Semantics - the study of meaning, both at the lexical and phrasal level. But of course one word may have slightly different meanings in different contexts, which brings us to: Pragmatics - the study of meaning in context. 

Another technique that would be relevant for your comparative task is keyness analysis, which basically looks at words* which occur significantly more often in one group of texts than in another. The technique comes from the field of corpus linguistics, a field which has developed a number of techniques and tools for analysing large amounts of texts in both qualitative and quantitative ways. Wikipedia has an introduction to corpus linguistics ($URL$ and you can find a brief introduction to keyness analysis on the site for Wordsmith Tool, a corpus linguistics software ($URL$ *note that keyness analysis can be done at the level of words, but also semantic groupings of words or POS categories. In the latter cases, it would involve identifying categories which occur significantly more often in one corpus than in another. 

That I am aware of, most corpora of British English are not freely available. There are, however, corpora of British English, including POS-tags and formal language, which can be downloaded by individuals, although I am not aware of any which are open source. These include: 

If I'm remembering correctly, according to Atkins and Rundell (2008) [1], many projects build their own software, but there are also commercial packages such as TshwaneLex ($URL$ Atkins and Rundell (2008) go into some detail about the requirements of such software, so you may find their book helpful. They mention that there are two types of software which are needed for any lexicography project: what they call a Corpus Query System (CQS) and what they call a Dictionary Writing System (DWS). The point of a CQS is to access evidence on the basis of which dictionary entries can be written; in that sense, their needs are very similar to those of standard corpus linguistic software* (which include the ability to draw up concordances, as well as other features). The point of the DWS is to offer an interface for generating and storing what will make up the content of the dictionary. [1] Atkins, B.T. Sue and Michael Rundell (2008) The Oxford Guide to Practical Lexicography. *an example of corpus linguistic software is AntConc, which is free, though probably not powerful enough for a lexicography project. You can see a list of commonly used corpus linguistics software here: $URL$ 

One word for this phenomenon is collocation - which is defined in many ways, but generally refers to two or more words which have a tendency to co-occur. The wikipedia page ($URL$ currently defines it both as 'a sequence of words or terms that co-occur more often than would be expected by chance' and as 'partly or fully fixed expressions that become established through repeated context-dependent use' (two different definitions with different theoretical implications). Examples on the Wikipedia page include 'nuclear family' and 'make a decision'. Research is ongoing to explore the idea that collocations are (mentally) processed differently from other groupings of words. A good starting-point to read about this could be Michael Hoey's theory of lexical priming, which holds that what we know about a word comes from our experience of it, so that our mental representation of it includes knowledge about the words it tends to co-occur with. Hence when we encounter word X, we will more easily retrieve words which often co-occur with word X than words which co-occur less often with word X. An example of a study referring to lexical priming in relation to language processing is Gagné (2001) [1]. [1] Gagné, C. L., (2001), 'Relation and lexical priming during the interpretation of noun–noun combinations.', Journal of Experimental Psychology: Learning, Memory, and Cognition, Vol 27(1), Jan 2001, 236-254. See: $URL$ 

A great number of loanwords from Ancient Greek have been integrated into Czech with great attention to the original forms. For instance, many Ancient Greek nouns from the third (athematic) declension preserve their stem consonants when declined in Czech. Consider the proper name Paris (the Greek mythological prince). In the table given on the linked page, the forms on the right (Paris, Parise, ...) demonstrate what the regular Czech declension would be, but the ones on the left (Paris, Parida, ...) are the ones that are actually used, to correspond with the original Greek declension Πάρις, Πάριδος, ... Another common example are loanwords that were originally dental stem neuters, such as δρᾶμα (drama). Such Czech nouns are commonly declined with the irregular interfix -at- (drama, dramatu, ...), so as to approximate the Greek declension δρᾶμα, δράματος, ... Of course, the prime example is the Greek name Ζέυς, in Czech Zeus. In Ancient Greek, it was declined irregularly as Ζέυς, Δίος, Δίι, Δία, Ζέυ. The Czech loanword faithfully replicates this irregularity and declines as Zeus, Dia, Diovi, Dia, Die, Diovi, Diem. 

On the other hand, pronouncing лён, he would articulate the palatalised [lʲ] as before, but then directly detach the tongue from the ridge and move it back to articulate [ɵ], i.e. he would omit step two. I'd say that the difference is audible in the recordings in the Wiktionary entries. Actually, the sequence (palatalised consonant) + (iotated vowel) might be heard even more clearly in the recording of свинья. I may later try to record myself carefully pronouncing the discussed sequences, but I don't really have a lot of experience with audio recording, so it may come out terribly. 

Browsing through Wiktionary, I ran across a note in a-stem declension tables (like žena) which claims that -asъ is the expected Balto-Slavic form of locative plural, which is however found only in some Old Czech documents and is replaced elsewhere by -axъ in analogy with the other declension types. I've never seen this claim in literature, Czech or any other, and it does not seem to be substantiated on Wiktionary, so I was wondering if anybody here might have some pointers on this. 

An old question, but perhaps the answer might still be useful. First, I believe that regarding Slavic languages, iotation is considered a feature of vowels (iotated vowels are preceded by [j]), while palatalisation is a feature of consonants (during their articulation, the tongue is raised towards the speaker's hard palate). Of course, the terminology may vary. Regarding their interaction in Russian orthography, 

pronounce the л as a palatalised lateral approximant [lʲ], i.e. with the tip of his tongue on the alveolar ridge and with the tongue itself slighty curved upwards, so the blade of the tongue is closer to his hard palate. He would then detach the tip from the alveolar ridge and move the body of his tongue even closer to the hard palate to articulate the approximant [j], before moving on to the vowel [ɵ].