(Strictly speaking, there is no 'time' quantum operator, but the above may still be derived.) What this tells us is that what seems like complete and total conservation is actually only conservation over sufficiently long time periods. In essence, things 'average out' to something well-described by calculus in the 'classical limit'. Feynman diagrams are another example of 'averaging out' craziness in a way that results in what we see. They involve summing all the different paths a subatomic particle can take, to get the 'average path'. That's not quite true, but a good enough approximation. If you want to ask about what happens on extremely short timescales (like the Planck time), take a look at vacuum fluctuations, which are the result of exploring what that uncertainty principle between ∆E and ∆t actually means. 

This is a telos-dependent matter. Consider an alternative scenario, from Hilary Putnam's The Collapse of the Fact/Value Dichotomy: 

Critical realism's focus on ontological realism is an acknowledgment both of the above problem and the necessity of actively theorizing in that domain. Smith's To Flourish or Destruct is an example of such theorizing. One of the thing Smith mentions is that sociologists in America have had a tendency to ignore or simplify the motivational structure of humans, as if that can be [largely] ignored when studying social phenomena. A reason to downplay motivational structure is that it is not directly observable; to do it justice, one has to posit models which are not purely inferred from sense-data. Critical realism is happy to do this; some of its competitors find this unacceptable. For causality, the blog post Causal realism and historical explanation will hopefully get you started. It is written by philosopher of social science David Little. P.S. As regards Kant, Roy Bhaskar said the following: 

Destruction of any and all blood diamonds. Shame for those who are found in possession of them and have not destroyed them. 

I know almost nothing about Hegel, but your description is awfully similar to one of Owen Barfield's ideas, which he espouses in Unancestral Voice and Saving the Appearances: A Study in Idolatry. His idea is that in order to have 'evolution', one needs two things to happen: 

I claim that this, however, is not quite the right question. It asks us to explain what already is. What if we wish, instead, to predict the next observation? This is a subtle shift, from:      A. What best explains a given sequence of observations?      ↓      B. Where does a given sequence of observations most likely point? If I am allowed to tweak your question from A → B, then we can talk about two different options for B:      I. The next observation will be like previous, and require no increase in Kolmogorov complexity.     II. The next observation will be different, and require an increase in Kolmogorov complexity. If we run into enough II-type observations, I claim we are justified in inferring that our universe is infinite in description, via induction, despite the problem of induction. Furthermore, via Fitch's Paradox, the potential for infinite knowledge requires an extant omniscient being. So either everything that is knowable is already known, which would lock us into an epistemically finite universe, or there is an extant omniscient being, which means that being is infinite. 

It turns out that when Nozick asked people if they'd like being hooked up to an 'experience machine', most people said no. I found a random poll which has 38% of people wanting to plug in and 62% wanting real life. Note that this is just a forums poll, so take it with a grain of salt. Assuming 'no' to the experience machine: We are not guaranteed that human thriving has finite 'definition'. Consider an analogous question: will science ever 'finish'? Will we ever discover every physical law, with the only possible research left to be discovering the initial conditions of the universe to finer and finer precision? It's not clear. Using induction, we could say that we ought to expect science to continue finding deeper and deeper laws of the universe. Perhaps human thriving is the same: so far we seem to be finding more and more complex forms of human thriving; who says it will ever cease? Indeed, we know from addiction studies that just about any routine stimulation of the brain loses its effectiveness in creating fulfillment, over time. Our brains seem to get bored of things and want new experiences. Given this, I would say that no, we will be very bad at predicting future happiness, just like we're bad at predicting future science, unless you're talking only one or two years into the future. We can make very broad predictions—like more greenery makes for more happiness—but there is no evidence that we'll be able to be precise in the way that Sam Harris seems to require. 

Bacon was frustrated with speculations which did not lead to improvements in the human condition. And so, he argued that scientia which is not pragmatically useful (or meta-pragmatically useful) must be discarded. The trick here is that "pragmatically useful" depends on the person's desires. A Saturn V rocket is useful if you wish to go to the moon, but grossly inefficient if you want to feed the poor. Josef Pieper's 1957 Knowledge and Freedom is a sustained critique of this epitomizing of pragmatism. According to Pieper, when the pragmatic is made the judge, philosophy is murdered and the sciences are hamstrung. True freedom requires freedom from the current desires of mankind. This may seem paradoxical until one realizes that the university cannot exist if the mob is allowed to rule. Neither can it exist if there is no unity whatsoever. The word itself is a combination of 'unity' and 'diversity'. The actual shift to technological (vs. social) control may be captured by the following from Charles Taylor's A Secular Age: 

Unfortunately, Lewis does not admit the possibility of > 1 god. I've been playing a bit fast and loose with the term 'god'; I could say instead that there could be > 1 standard of morality, such that all standards are incomparable to each other. But wait a second. Lewis is assuming that #1 is a valid operation. That prohibits any two standards from being incomparable. This allows us to construct a total order:      i.  S1 ≤ S2 ≤ S3 ≤ ... ≤ SN Here, SN is the standard by which all other Si are measured. SN is the אֵל above all אֱלֹהִים. 

This would mean that you can never [perfectly] know all the inputs for your model; it implies that Laplace's demon and Maxwell's demon are impossible in principle†. If you don't have all the relevant inputs, you cannot make perfect predictions. † Unless perhaps you start in a state of perfect self-knowledge? I've been thinking through Fitch's Paradox of Knowability lately. This makes the white stone in Revelation 2:17 intriguing! 

[19] See Paul Ricoeur, "Structure, Word, Event" in Conflict of Interpretations: Essays in Hermeneutics (Evanston: Northwestern University Press, 1974), 79. [20] Ibid. [21] An enterprise such as that of Jacques Derrida might be termed a "poststructuralism" which conceives an absolute text that refers only to itself and consists in the endless play of signifiers in a closed and again ultimately dead and meaningless system. See Jacques Derrida, "Structure, Sign and Play in the Discourse of the Human Sciences," in The Structuralist Controversy: The Languages of Criticism and the Sciences of Man, ed. Richard Macksey and Eugenio Donato (Baltimore: Johns Hopkins Press, 1970), 247–64. From the cited Conflict of Interpretations: Essays in Hermeneutics: 

As an initial attempt, I would say that an experience machine would be:     good for addicts     bad for those interested in 'the truth' How to define 'addict' is a bit difficult, so I'm going to be sloppy. I mean to include those addicted to any physical substance as well as those addicted to any repeated experience—like gaming of any sort. Importantly, 'addict' doesn't have to define a person throughout his/her lifetime. This might be important. Getting lost in an addiction for short periods of time might be healthy; Proverbs 31:6 says: 

(source: Purdue) Now, consider what the above means. If you take the stereotypical view of a lawyer as scum of the earth, you probably are dead in the water. If, however, you see justice as extremely important, then what kind of person would you want to play a role? Hopefully people who can think clearly, see the ramifications of things, and think about how to improve society. Asking "What would be good for society?" is one of the most important questions for at least a subset of a nation's population to be asking. When that question is asked, philosophy is done. This doesn't mean e.g. scientific results cannot be used, but when that question of goodness is asked, philosophy is necessarily a part. N.B. Even if Sam Harris' The Moral Landscape is implemented, philosophy will be required to determine how to interpret results, e.g. of MRI scans of the brain. Harris and others might believe that once this is done, philosophy will be obsolete. That, however, is code for "Never question the system, except on its own terms." In part, philosophy exists to question those terms. 

Belief in authority is completely warranted; try avoiding it on the part of astronauts in space shuttles and space stations. The machines they use are simply too complicated for them to understand such that they know why they ought to do/​not do everything in their training. This has always been true; how many of the beliefs a hunter-gatherer requires to survive were obtained experimentally vs. trusting elders? What we need is an intelligent way to test authorities/​experts. An arguably bad example would be anti-vaxxers. A better example might be the question of whether excessive sugar or fat is worse for health; see for example The sugar conspiracy. Two facets emerge: (i) one needs a certain competence to question authorities; (ii) the authorities can go badly wrong. Does this mean that nobody ought to flee in the face of the impending hurricane Irma? (example) Now, plenty of religion has resources for self-critique. I had the privilege of visiting some famous Protestant Reformation sites this week, including The Wartburg [castle], where Martin Luther was holed up while Catholic authorities sought his life. The Old Testament is rife with self-critique (e.g. Ezekiel 34); Jesus and the apostles went much further in the NT. What you would have to do is establish that their critique cannot possibly go as far as is needed. Here you may have a problem, as the NT advances a form of critique which can regularly get its proponents killed; a moral ethic of 'enlightened self-interest' may preclude such behavior. So, I would argue that in order for our confidence in science to not fall prey to the errors of religious dogmatism, anything must be open to question. There is a problem here—in questioning everything, one changes what is assumed in any particular question—but hopefully this can be ignored, or quickly dismissed by pointing out that everyone presupposes a few basics, like the principle of non-contradiction. All religion I'm aware of seems to presuppose much more than this. A proof that it is possible to not presuppose nearly so much is left to the reader, or another Philosophy.SE question. 

For fun, I suggest asking whether the philosophy of Atomism was helpful to scientific endeavor. If it were, I suggest that calling something 'true' only after science has verified it (or attempted to falsify it) is tantamount to saying that something is only 'food' after it is served—not when it is in ingredient form. We can define our terms this way, but doing so might hide the fact that we need things in addition to science to discover what is true. Just like the newscaster needs a huge support staff to do what he does. Valuing only the last stage of a process is a great way to do the process poorly. 

It used to be that understanding of reality included 'contemplation' of it. Aristotle was famous for this, and the 2010 Scientific American article Aristotle's Error gets at what Bacon was reacting to: 

Causal powers must be different in kind from the physical objects upon which they act. Consider, for example, F = ma. Rewind history to before we knew it had any problems. For all we knew back then, there was a real causal force which caused all objects to obey it, precisely. That is, there was something awfully like an abstract object, existing timelessly and without location in space, which causes all objects to act as if F = ma. Today, we know that F = ma is only an approximation. However, that's not really a problem, because we can just posit some more sophisticated version—perhaps some form of M-theory—which produces F = ma in some circumstances, a more complex General Relativity in other circumstances, and something even more complex near the event horizons of black holes. One could try and deny the very idea of causation; Regularity Theory is a view which does this. However, Regularity Theory has some serious problems, as pointed out by Rom Harré in Causal Powers: Theory of Natural Necessity. One could also argue for a kind of causation which is located within spacetime instead of in the "timelessly and without location in space" manner which I discussed, above. However, this would require major changes in how we even think about science; it typically requires that how objects behave is not dependent on spacetime. Furthermore, it is hard not to think that some sort of rationality is required in how objects behave, such that if, say, the physical constants were different in one part of the universe than the other, that there would be an underlying law as to why and how they shift from being one value to another. It seems to keep coming back to laws which hold timelessly and without location in space, which means they are manifestly different from physical objects. 

     — F. Scott Fitzgerald, The Crack-Up David Politzer, winner of the 2004 Nobel Prize in Physics, told me in 2004 that a crucial stage in intellectual maturity is the ability to hold two contradictory ideas in one's mind without immediately rejecting one of them. Note that he discovered asymptotic freedom, which is predicated upon the then-counterintuitive effect of a binding force which grows stronger with distance. One may have been tempted to call this contradictory to all then-known knowledge. I end with the fact that general relativity and quantum field theory, two of our best models of reality, contradict each other, seemingly inherently. One is continuous, the other is discrete. Nobody is close to empirically unifying them, although there are many pie-in-the-sky theories. However, to reject one or the other or both on the basis of the contradiction (which becomes measurably relevant near black holes) would be insane. We must remember that the picture of the thing is not the thing. Ceci n'est pas une pipe. Contradictions in model does not mean contradiction in thing/​person modeled. 

My point is that life contains an incredible amount of pattern-matching that uses no explicit numbers nor symbols recognizable as math equations. Good businessmen understand the patterns of human behavior and are able to make use of that knowledge to make cool things and get lots of money. Good musicians have an innate grasp of the math behind sounds that please our ears, even if they have no idea what group theory is. Biologists made fantastic discoveries without strict equations by being able to reason at a 'fuzzy' level. We err greatly if we think of mathematics as being restricted to e.g. geometry, calculus, statistics, and probability. Mathematics is merely "the study of patterns". I would argue that anyone of high intelligence is good at some kind of pattern-matching and use. 

Note the "thousands of trees but has never seen a forest". This would be a preference to focus on particulars—an empiricist attitude—over and above a focus on universals—a rationalist attitude. I propose that Albert Einstein, Lee Smolin, and Massimo Pigliucci are correct: we need to find new, productive, holistic ways to think about science, ways which don't just discretize and reduce to basic elements. 

God can violate the laws of logic. (e.g. create a square circle) God can choose a different definition of 'good'. 

I propose the reason is a contemporary distrust of holistic thinking, combined with a contemporary obsession with analytic thinking. Consider the persistent myth of right vs. left brain. According to the myth:      right brain: emotion, intuition, creativity      left brain: logic, critical thinking, numbers, language Regardless of it being a myth, I have found that those in philosophy and the sciences have a strong preference for 'left brain activity'. There is a different way to break this down, provided by William James in his Pragmatism: A New Name for Some Old Ways of Thinking. He breaks philosophers down into two categories: 

Take, for example, wave–particle duality. How can a photon be both a wave and a particle? Well, we can say that photons propagate as waves but interact as particles. A contradiction is thereby eliminated by clever distinction. Is there any end to such cleverness? For example, what of an object that looks like a square from one perspective but a circle from another? Suppose we make use of stereo vision so that one eye sees 'square' and the other, 'circle'? Therefore, I think there is sound wisdom in the following: