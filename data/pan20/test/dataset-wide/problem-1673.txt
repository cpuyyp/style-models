You would use to determine that a packet originated locally on the system, where outgoing packets are associated with a socket, instead of a forwarded packet that originated from another system, which has no associated socket. 

You should put your actual web site in an Apache block, and have the default host serve only the Apache test page. If you are using name-based virtual hosts, like most people, then just ensure that the default virtual host appears first in your configuration. You can check your configuration with a command such as . See also Apache's examples for more information. 

This message is harmless and can be ignored. It is a note to kernel developers. Red Hat also published a statement to this effect in its KB (subscribers only, boo). 

Don't get into this situation in the first place. Shared hosting providers are notorious for having difficulty handling large traffic spikes to a single customer, and since you don't run the machine, there's not much you can do to optimize things. Probably the best you can do on shared hosting is application-level caching. For instance, if you use WordPress, install W3 Total Cache in disk caching mode. If you realistically expect large amounts of traffic on an ongoing basis, you would do best to move to servers you control as soon as possible. The point at which I would start planning to get off shared hosting is about 5,000 unique visitors/day. By the time you get to 10,000 you should be long gone. (This is just a rule of thumb; your provider may be better or worse.) 

You didn't specify a valid address for nginx to connect to; is not a valid destination IP address. To resolve the issue, specify the actual IP address, such as . 

Linux already does some writeback caching. Look into pdflush and how it works. Unfortunately it takes some time to understand all the details, since it's quite complicated, but if you're wanting to tune it (e.g. for laptops) then that's the place to start. 

I was able to ping these machines, so I suspect they are simply dropping the queries. This suggests that these servers haven't been set up correctly to serve your domain. This makes your next step to contact them and find out why. 

Don't send mail a nonexistent address if you're actually expecting a reply. Use an address which actually exists, and then your app doesn't need to do anything more than check the mail. 

Like many of us, I spent yesterday updating a whole lot of systems to mitigate the Meltdown and Spectre attacks. As I understand it, it is necessary to install two packages and reboot: 

If you just have one (or maybe a few) of these to match exactly, then you can check the argument explicitly. 

You set everything up correctly (except for politihacks.com having no A record at the moment). The 301 redirect from digest.politihacks.com to politihacks.com is coming from the wordpress.com service. You will need to contact them to have this corrected. 

You're doing it wrong. Your point-to-point tunnel uses only two addresses of the /64, which is SixXS's end, and , which is your end. No other addresses in that /64 should be used. You should configure your local network (and rtadvd) with the separate /64 or /48 subnet that you were assigned, e.g. . (Also make sure you have in .) 

You need to set on the export. Otherwise, accesses by the root user are mapped to an anonymous user (usually nobody). 

Whenever someone tells you to add sources from unstable or testing onto your stable system, you should ignore them and keep looking for another option. This is the #1 most common way Debian systems get broken. To fix your system, change all your sources back to , then run: 

Anyway, you are not passing on the header, which is the most likely reason I can think of why your URLs are being mangled. Try setting that: 

There's nothing exactly like Linux containers in the Windows world. App-V is probably the closest you'll get. 

You're using Ubuntu, which like its Debian parent has the nasty bad habit of enabling and starting every service which gets installed onto the system, whether they are wanted or not. This increases your attack surface; you should check carefully for unwanted services. In this scenario the firewall helps you by ensuring that only the services you want to be open to the public are actually reachable. 

But keep in mind that you will lose the output from the script; more importantly, if there is a problem and the script outputs an error on standard output instead of standard error (as many shell scripts do), you will lose that as well. When something goes wrong, this will cause you a whole lot of unnecessary frustration. So, you really should do nothing to the systemd unit. Rather, if you don't want the script to output anything on success, fix the script. 

You can use the remi repository, which provides PHP 5.4 as well as MySQL 5.5 and some other LAMP related stuff not available with CentOS base or EPEL. If you use this repository, I strongly recommend the yum-versionlock plugin to ensure that your version of PHP remains on the 5.4 branch. 

Your site is hosted behind CloudFlare. Using SSL on CloudFlare requires a paid CloudFlare account. Contact CloudFlare to make the necessary arrangements. 

I also have to agree with @aairey's advice to do a minimal install. In CentOS 5, this requires the use of a kickstart file; CentOS 6 has a special minimal installation CD. 

If you're using MySQL 5.1's built-in InnoDB, then index creation and removal are very slow. This was addressed in 5.5 with fast indexes. Update MySQL if possible. Alternately you can replace the built in InnoDB from 5.1 with the InnoDB Plugin (though this should have already been done; given that you're having this issue it probably somehow wasn't). 

Docker can't be run in a container without a specialized setup. Get a proper virtual machine if you want to use Docker. 

What you did wrong was to create your own instead of editing . Put the file back in its standard location. Debian 8 has (finally) moved to systemd, and the old init script and are no longer used. Of course, this was a bad idea even when they were in use, but it's especially a bad idea now. 

You have at least two obvious problems here. First, you didn't define a in your block. You instead misplaced it in one of the blocks. This is one of the most common nginx misconfigurations. Second, you have a typo in one of your statements. should be . 

During OS installation, if you simply configure the IPv6 address, prefix 64 and gateway address as given by OVH, the installer will create the necessary static routes for you. 

No, that won't work. In order to sign certificates you need your own certificate authority certificate. The certificates you purchase are signed by a certificate authority, but specifically marked as not being a certificate authority certificate. Check the "Certificate Basic Constraints" in your certificate, and you will see that it "Is not a Certification Authority". 

You didn't install the EPEL 7 repository. That's the EPEL 6 repository. Remove it and try again. Better yet, install nginx from their own repositories to ensure that you stay up to date with critical and less critical upstream fixes. 

Use RHEL/CentOS 5.9 instead, which has device driver support for this card. If for some reason you can't use 5.9... You can get the driver update disk directly from LSI. Look for LinuxMPT_SAS_RHEL5-6_SLES10-11_PH21-4.28.00. This package is very large and includes source code and many binaries, among them will be a 1.44MB driver update disk image for RHEL 5 which you can provide during installation. Note that these drivers are only guaranteed to work on RHEL/CentOS, and may not work with Oracle Linux due to its using a different kernel. 

For the processor to be usable in a multi-socket configuration, it must expose the QuickPath Interconnect externally. Intel desktop processors do not do so. You'll need to use a Xeon, and not just any Xeon; some of the lower end ones can only be used in single socket configurations. Check its specifications at Intel's ARK site to make sure that it can be used in a multi-socket board. For modern processors, this will be listed as Scalability with a value of e.g. 1S, 2S or 4S (sockets). 

It "works fine" but the performance is going to be much poorer than if you installed Integration Services. This is because it provides paravirtualized drivers for performance-critical virtual disks, network adapter, etc. 

Recent Red Hat-based distributions (RHEL, CentOS, Fedora) also distribute updates as binary deltas, changes from the installed package to the new package. This can result in a bandwidth savings of as much as 90% when installing updates (just make sure is installed to take advantage of it). Consider this example from CentOS 7.0: . The original Firefox 24.5 package is 49 MB, the Firefox 24.7 package is 50 MB, but the delta RPM that updates Firefox 24.5 to 24.7 is 6 MB. Original RPM: 

You must check the permission, not only of the socket (file) but of all the parent directories. If any of them deny access, your request will fail. For instance: 

For a host firewall where the default input policy is to deny trafic and the default output policy is to permit traffic, most all of your rules will be in the INPUT table. It's sufficient to have the stateful rule and then rules to open ports for any incoming traffic you need. For example, to allow ssh and http connections: 

The big problem I see here is that you only send an RSET command to a mail server if it has already rejected a message you proposed to send. I suspect the mail server, after rejecting the email, simply firewalled you or otherwise ignored you. Your next step is to contact the mail server administrator. 

Let us see... The IP address 165.254.162.243 is on AS14627, which is a company named Vitalwerks. WHOIS tells me that they have the entire /24. A brief look at Google tells me Vitalwerks is the business name of NoIP.com, a dynamic DNS provider. Have you installed a dynamic DNS update tool, or any other software, from this company? If so, you'll likely find it is the source. If you have not, then you may find the source is malware. A few years ago, you may recall, Microsoft got a US federal court to authorize an extremely overbroad seizure of noip.com's domains in order to stop a botnet that was using some subdomains. 

Unfortunately, Google hasn't been too helpful here; most people seem to have the opposite problem. How do I cause requests for anything in the directory or the file to be sent to Drupal's 404 page?