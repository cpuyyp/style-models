Anyway. The RPM build of PHP actually rebuilds PHP four separate times. It is built once without any extensions enabled, for loading into Apache as , then built again with all extensions as shared memory objects. And a build for the PHP command line, and a fourth build whose purpose I forget right now. So what happens is, the builds with no extensions built in are bundled with the extensions built from the other build. Thus PHP may say that it was configured without any extensions, yet still be able to use them. 

You should no longer need to run any command to detect new devices; they should be detected and configured automatically when you connect them. If you have a device that isn't, then you should investigate that specifically. 

Yes, you can download the drivers from the upstream KVM project. If you want an installable RPM package, similar to that provided by RHEL, then you can use the virtio-win yum repository provided by the Fedora Project. 

In your current configuration, nginx is never started automatically. Note that the symlinks that start with indicate that the service will be stopped (illed) in that runlevel. Symlinks that start with indicate that the service will be tarted. 

Yum refreshes its cached data automatically if it has been more than 90 minutes since the necessary data was last fetched. And it only downloads the needed data, instead of everything possible. So in general you don't need to do this manually. If you really want to cache the data manually, use followed by . 

If you really mean to access the server remotely, then open up the proper firewall port (default 3306). 

The command may reboot the system without shutting down system services or unmounting filesystems cleanly. It's supposed to shutdown the system normally, but apparently this doesn't always happen. To avoid this problem, use the command with the appropriate options to have it reboot the system. An example: 

For the configuration you want, you need to have the virtual machine's NIC use your existing bridge br0 on the host. Unfortunately vagrant-libvirt doesn't seem to support this configuration (it only uses macvtap, which is meant to take over a physical interface completely and doesn't help you here because the host cannot use the interface). I would contact the author of vagrant-libvirt and ask for this functionality to be added. 

You're trying to install the wrong package. First, attempt to locate the correct package containing the file you need. 

Ensure that remote administration of the RV-042 is actually disabled. Dispute the finding with Trustwave and cite that you have a compensating control, namely, that all connections to those ports are immediately dropped. 

Keep in mind you'll have to wrap this in an to test for IE 10, and If is evil, so this configuration will probably come back to bite you. If you only have one in the block, you'll probably be OK... 

This generally indicates that you edited your configuration file with an editor that replaces plain single quotes and double quotes with "smart quotes". Indeed, in your configuration file the smart quotes are visible and distinct from the other quotes: 

Don't use a separate location. In your configuration there are no fastcgi directives to handle the case where the user is not a bad_user, thus nginx treats it as a static file and serves it directly. Instead, put the check in your existing block, and then check for there. For example: 

Reloading php-fpm interrupts active connections, such as yours in this circumstance. When possible you should avoid doing it, or if you can't, do it asynchronously, after you've completed sending the data to the browser. 

Here you will fail and get the error . In this case, you'll need to either read the gem source code or contact its developer to find out what package he/she meant for you to have. It should be listed in the gem's documentation as a system requirement (if the developer bothered to write documentation). 

You're trying to use a pre-release Linux distribution. You should expect that it will have bugs, crash, destroy all your data, etc. You absolutely should not attempt to install it on your primary computer unless you're actively developing or testing it and you are willing to live with complete data loss on that machine. If you were actively developing or testing it, you would report bugs on Launchpad. 

is a Ruby gem, so it only makes sense that the Ruby interpreter would be running it. A typical invocation of would be: 

ReiserFS does not appear to be supported at all in RHEL 6 / CentOS 6. No such package exists in the CentOS repositories, nor is filesystem support available in the kernel. 

You tried to send email to Google from a residential or mobile (3G/4G) ISP. Almost all of these are blacklisted and you should expect mail to be always delivered to spam or bounced entirely. To solve the problem, relocate your mail server somewhere else. 

You seem to have misunderstood how DNS works. DNS in this case resolves names such as to IP addresses such as . You can't have a different IP address for a different port or service. Thus, you need to use the same IP address for HTTP, HTTPS and every other service that might be served with that domain name. 

You already installed Puppet Enterprise 3.7 on this computer. You cannot downgrade to 3.3 using the installer. 

If you choose a specific delimiter, and that character appears in the regular expression, you must escape it, or choose a different delimiter. Because nginx does not need the ability to perform replace operations on regular expression matches, (e.g. ) it also does not need to use a delimiter, thus when you specify regular expressions in nginx, no delimiter is used, and (almost) nothing needs to be escaped. 

Second, I'll check the whois record for the address. APNIC also says it's registered to UTM. Not looking good for your supposed American... 

From your stack trace, we can see that the kernel hit a page fault and then tried to read some data from your squashfs, at which point it got hung for 120 seconds (or more). This suggests that something is wrong with the flash drive, DVD or whatever media from which you're booting the system. You were not at all specific about this, so you'll have to look at whichever device has a squashfs filesystem on it. 

This is a really bad idea, since it is going to take you off the security/bug fix update path. If you decide to do this, you'll have to purchase Extended Update Support in order to get supported security and bug fix updates. If at all possible, you should update to the latest minor version. (They are roughly comparable to Windows service packs.) With that out of the way... You may be able to use the create-release script to create a channel for a specific Red Hat release. However, this script doesn't seem to have been updated in a couple of years, so it may not work for RHEL 6. Another option is to download the DVD for the specific release you want, and use it as a local yum repository. Finally, you can call Red Hat and take advantage of that support you're paying insane amounts of money for. 

Since you run the server, you may also want to use ModSecurity with the Core Rule Set. Many of Bad Behavior's rules are reimplemented here (look for my name and/or Bad Behavior's name in them) and the ruleset also contains many other rules which may be helpful to you. 

So, haproxy is binding every local port from 32768 to 65535 inclusive. This is a problem because, by default, outgoing connections bind a local port within this range: 

You're doing the wrong thing. But you do have another choice. First, storing the password in a file is completely silly and a serious security problem. Rather, configure to permit the necessary actions without a password. Second, don't try to run the non-interactive command and an interactive shell at the same time. This won't work. You'll have to run them separately, but you will be able to run them this way: To have sudo start an interactive shell, you simply run . 

Fedora 21 and RHEL/CentOS 7 use the new Python-based postgrey reimplementation. In this implementation the only change you need in your Postfix configuration is to call the service from . For instance, taken from my own mail server: 

If you have three or more geographic locations you're going to deploy to, I'd go ahead and spend the effort to go multi-master. If you only have two locations, you can get by with a read replica and proxy for now. 

Don't send the URLs to the browser in the first place. Instead, resolve them yourself on the server side while you're creating the HTML pages and insert the CDN URLs in their place. 

From the grub screen, edit your boot commands and add to the end of the boot command line options. Then boot it up. This isn't guaranteed to work (if is your root filesystem it will fail). If this fails to get you a shell, you will have to go find a CD-ROM drive. Once you have a shell, you can run to attempt to recover your RAID array. Find out what devices are supposed to be part of it: 

Here we see that this IP is in AS209 (which you can store instead of the IP, or in addition to it, if you wish) and is registered to Qwest Communications, which you can then display. 

The directory you intend to deploy to should already exist and have the correct ownership and permissions before you try to run Capistrano to deploy to it. So you need to handle that beforehand, probably in the same chef recipe where you created the user. 

Create a new PVHVM instance and move all your data to it from the original instance. Update the old instance to boot with pvgrub. You will need to have Rackspace support complete this step for you after you verify that the instance is bootable. 

This option is available in Server Manager. On Windows Server 2008 R2, scroll down to the Resources and Support section, and click Turn on Windows Error Reporting. Then choose Yes, automatically send detailed reports or Yes, automatically send summary reports. 

You should not have IP addresses meant for guests assigned to the host. (And you should not be using interface aliases. Those were deprecated many years ago.) Instead, create a bridge, and add enp2s0 to it. Then assign your KVM guests to that bridge and assign their IP addresses in each guest. 

When Red Hat's networking scripts set multiple IPv6 addresses configured in , for whatever reason, they are applied in reverse order, so that the last address listed in becomes the address used by default for outgoing connections. Reversing the order in which IPv6 addresses are listed is generally sufficient to fix the problem. To answer the only vaguely related bounty question: IPv6 static routes can be set by adding them to a corresponding . The format of this file is the same as the command with that bit omitted, e.g.: 

Amazon CloudFront sends an HTTP/1.0 request to your origin server, which causes nginx to refuse to send a gzipped response (by default). Setting works around this broken behavior in CloudFront. (It's been 15 years since HTTP/1.1, anything still speaking HTTP/1.0 is fundamentally broken...) However, once you set it and reload nginx, you also need to invalidate your objects in CloudFront so that new (gzipped) copies will be fetched. 

You've installed some third-party repositories, all of which ship incompatible versions of the same package. The repos shipping bad packages are: 

Run on the device. It should automatically detect the new size of the iSCSI target and resize the PV. After that point you should be able to use the additional space to expand your logical volumes or create new LVs. 

You don't need to - and shouldn't - use to change users in an init script. Use or better, instead. The command should be available from RHEL 5 and will do the right thing with respect to SELinux contexts, etc. 

You're better off to not compress the data. rdiff-backup does analyze files for differences, but if they're compressed archives, it may not be able to find any differences and thus be forced to store the entire new file again. Also, you can use to compress the ssh connection and save some bandwidth. Finally, if possible, you should get some more bandwidth; that's barely better than dialup (or maybe it is dialup?). Backing up 12GB of data would take weeks over dialup, and even the 2GB difference could take days.