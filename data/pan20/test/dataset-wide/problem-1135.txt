There isn't any way to reset autoincrement such that it goes back to the beginning and just overwrites existing data. Autoincrement isn't built that way. What you could do is rather than . You'd have to either pre-populate every record with blank data so that every entry is always an update, or you could write a procedure which tries to read the next ID first and then either inserts or updates accordingly. Either way, you will need to track the next ID yourself instead of letting the database handle it for you (with autoincrement). When you get to the maximum value, reset the next ID to 1 and keep going. Thinking Practically: The largest value for UNSIGNED BIGINT is 18,446,744,073,709,551,615. Depending on what is in your record you are looking at thousands (even millions) of petabytes of data. Are you sure you aren't going to have space constraints with that much data? You may find that what you need to do is purge out data that is old enough to be discarded as you go just to make room in your database. If you do that, then you can avoid the prepopulation and just insert every time. If you purge periodically, say every night, then you just need to wait until the gap between where your remaining data is and ID=1 is big enough that you don't have to worry about ID collisions. When that happens, reseed your ID and start inserting from ID=1 again. If you do this, then you can go back to using autoincrement. Edit: Additional Information about reseeding... OP mentioned in a comment that the command for reseeding an autoincrement column in mysql is of interest. This command will reset the starting autoincrement value: 

Now, based on how many records you have as a rule, and how many records you have, you might decide to do some denormalization. You have to decide what is easier to build, maintain and use and makes more sense in your application. 

SQL employs a concept known as domain name integrity which means that the names of objects have a scope given by their container. Column names have to be unique, but only within the context of the table that contains the columns. Table names have to be unique, but only within the context of the schema that contains the tables, etc. When you query columns you need to reference the schema, table and column that you are interested in, unless one or more of these can be inferred. When you write a query, you need to reference the tables in your query by name directly or by using an alias, e.g. Customer.ID or C.ID from Customer C, etc., unless your query is so simple that it only references one table. There was a time when there was a technical requirement for uniqueness of all column names, which applied to old ISAM databases and to languages like COBOL in the 1960s and 70s. This got dragged along for no good reason into dBase in the 1980s and has stuck as a convention well into the relational and object DBMS eras. Resist this outdated convention. When the shift from flat file and network databases to relational databases happened in the 1970s and 80s, the idea of joining tables was new. So some people chose the convention that a unique name could be repeated if one column was a reference to another (i.e. foreign keys). This concept is called a "natural join" and a lot of people still advocate for doing this. I am not a fan of natural joins because it requires you, ultimately, to throw out the concept of domain name integrity and force the whole column reference into the column name. The issue with natural joins is that you either have to be hypocritical or you have to make your column names long and unreadable. Let me illustrate: It may sound like a good idea that the primary key of the Customer table is CustomerID. Then in your Invoice table, your foreign key to Customer is also called CustomerID. This would be a natural join and it all sounds good so far. Here is the problem. What if your convention is to have a column on every table called LastUpdatedDate? So are you meant to join every table to every other table by LastUpdatedDate? Of course not. This is the absurdity of natural joins. In order to avoid this absurdity you would need to jam the table name into the column name as a prefix. However, if you have multiple schemas in your database, you can't stop there. You also need to add the schema to the column name, and so it goes. Another place where natural joins break down is when you have multiple relationships between the same two tables. You if you need two references to Employee on your Invoice table (Sold By and Approved By, for example) you can't call them both EmployeeID. 

The primary importance of first normal form is not that it eliminates redundancy, but rather, it's that it eliminates repeating groups. Instead of having multiple columns of the same kind of data in a record, (0NF) you remove the repeated information into a separate relation and represent them as rows. This is what constitutes 1NF. Tables that have columns like: , , or that contain list-oriented data like: violate 1NF. 1NF is important because it is much more flexible than 0NF while being much easier to use when inserting, updating and reading data. This is because every type of data element (e.g. customer phone number) has exactly one column in which to find it and that column has only one piece of data for each record. This means that you can use simple SQL statements to read or write individual data elements without having to parse delimited strings or use constructions like: and so forth. Regarding 1NF vs 3NF, the normal forms are cumulative. A table in 3NF is also in 1NF, so it is just as true to say that "Every table in a relational database should be in 1NF" as it is to say that "Every table in a relational database should be in 3NF." I would say both of these are true, but I would add "unless you have a really good, well considered reason to denormalize". 

Using correlated subqueries is not a recipe for blinding speed, but the advantage of this is that you don't have to rank everything, you just have to count entries in an index relative to a user's particular scores. Of course, only your query optimizer will know for sure. 

If your hierarchy is rigid (i.e. the levels are consistent and mandatory) then there is nothing wrong with representing each level as it's own table. This is your first option, except that instead of having foreign keys on the person table to each of the organization levels, you should have a single foreign key on the person table to the leaf level of your organization, and then each level in turn refers to it's parent/container. i.e.: => => => => => With this modification, your tables will be in third normal form (3NF) which is always a good starting point from a design perspective. If, on the other hand, your hierarchy might be at all fluid, then keeping a hierarchy in a single table with a self-referencing (involuted) foreign key is a better option from a code stability perspective. This is your second option. One issue with this second option is that relational databases are not brilliant at handling unleveled trees in this form. There are, however, a couple of pretty useful techniques for managing this type of data in this format a little more easily. You can Google around for adjacency lists and visitation numbers to learn more.