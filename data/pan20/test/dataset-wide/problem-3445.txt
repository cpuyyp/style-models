The money goes to banks/brokers. In fact most of the revenue in the financial sector comes from fees like that. This is to compensate the bank/broker from taking the risk of carrying the opposite position on their books for a while, and the labor put into actually trading for you. A part of it is probably also profit. Since there are large entry costs, one would expect the financial sector to earn profits. 

If this is your definition of "post-scarcity economics" then you need not look very far though. Over the last 150 years, technology has greatly reduced the need for human labor required for production of an 1850s consumption basket. Indeed people had that same debate in the 19th century (see Luddites), then again in the 1930s (see Keynes' famous essay on Economic Possibilities for our Grandchildren) and again today. Of course stuff is still as scarce as ever, and society is qualitatively organized much as it was 100 years ago, except that of course everybody is much better off. 

You have to understand how international debt works. These are not loans, but bonds. China buys a US bond for e.g. 98 USD. This bond is a promise by the US treasury to pay 100 USD one year from now. China owns a lot of this type of bonds. Once the bond hits maturity, China is paid 100 USD and the thing it typically does with these 100 USD is it buys the same type of bond again. If it decides it no longer wants to hold US debt, it can do one of two things: First, it could decide to sell all it's bonds at market prices to someone who's willing to buy them. This would be a terrible idea for the Chinese, since they'll lose a lot of money in this kind of fire sale. Second, it could just stop rolling over the debt and invest its foreign reserves in other kinds of bonds. In any case what will not happen is that the US suddenly has to pay back all it's debt at once. It will become more expensive for the US to refinance it's debt, since the demand for treasuries will go down, but this is more of a long run problem. Also, it is not trivial to find an alternative asset market that can absorb an investment of 1200 billion dollars without prices going through the roof. 

The advantages of 2-4 are that more people end up contributing to both the design and the code of the project, and it goes into a kind of ecosystem where strong ideas survive (by procreation if you will) and weak ones don't. Bugfixing and feature addition become community efforts. In scenarios #2 and 3, the developers adopting the project benefit from sound engineering principles and mature code. 3 and 4 are correlative. In scenario #4, the developers benefit when other people adopt and improve the code and give back (#3). It's advantageous to contribute back to the project so that your improvements get cemented in as other fixes and improvements go in on top of them, which you continue to benefit from. In my experience, all of these scenarios are commonplace. On my current software project, I'm one of about 12 developers and have worked on a system for about two years. We have incorporated about 5,000 open-source projects! We have spawned only a few new FOSS projects, and contributed back to maybe half a dozen. We aren't particularly good citizens in this case (other companies are much better), but this shows you the sheer scale of how this all works. Even on small projects, contributions from open-source can easily number in the dozens or hundreds. If we did not use any open-source software, development costs would balloon by a factor of 100-10,000. Scalability happens because of modularity of design and also through this kind of survival-of-the-fittest process where code can get refactored, forked, and so on. Survivability is usually better than proprietary alternatives because even if the code is no longer maintained, it's out there and other people who find value in it can maintain their own fork of it. Companies come and go and employees are hired and quit even faster. If you add a software dependency that you don't have the source code for or have only a small in-house team to maintain, you have incurred substantial risk. Big projects like the Linux kernel, gcc, Android and others often have a large number of companies actively contributing. It's not true that it's easier to write good and correct code than it is to read it (in most cases). Nor do you have to read all of the software you're using even if you are making modifications. You have to dive deeply into sections of it and read a lot, but not the whole. I could say more here about unit tests, but will omit that for brevity. The majority of open-source software is not developed by people in their free time. The practice is so phenomenally beneficial that it works without an optimizing marketplace. I personally suspect some kind of market-driven approach would greatly help, but I don't know what that approach might look like. People argue that there is a marketplace where reputation is the currency, but I don't think that's an accurate model. One currency at work is the time it takes to adopt a new piece of software. You want to find and use something that is active, simple, has good documentation, etc. So like a shopper you're looking for the best quality product for the least amount of time invested. 

This is/was a huge topic in macro and labor. Traditionally, macroeconomists calibrate models that require huge labor supply elasticities to match the data. Then labor economists estimate labor supply elasticities from micro data and find very very low elasticities. Imo the labor estimates are more trustworthy than the macro calibrations. Check out $URL$ for a summary of the issue and citations to the further literature. 

You need to remember two properties of derivatives and expectations. Everything else stays the same. 

There is a lot of newish research on the adverse consequences of Globalisation and more generally De-industrialization on low skilled workers in developed economies. A good place to start is Autor, Dorn, Hanson in the AER 2013. David Autor has other interesting work on this topic as well as on automation. Your questions have quite a normative ring to themselves, and it seems to me you already know what kind of answers you want. It is true that discussing the adverse effects of Globalisation or technological progress on some people in rich countries has become a more active research topic. But I think most people are very still far from questioning free trade or technological progress as Pareto efficient. And I think the overwhelming majority of economists still thinks that industrial policy in a developed country is a silly idea. So I don't think you are going to find this big trend you are looking for. Also, as a sidenote, even development economics has moved quite far from the kind of research that debated the industrial policy you have in mind. It's mostly about RCTs and institutions now. 

They develop that piece themselves and it becomes property of the company. Or they buy a closed-source solution from another company. They find an open-source project that solves this problem and it's a perfect fit and the license is suitable. They just incorporate it into their project, which may or may not need to be open-sourced depending on the license and how it's used. They don't contribute back to the project. They find an open-source project that almost solves this problem but has either defects or deficiencies. They improve on it and they may contribute those improvements back to the base project. They don't find anything they like enough, so they start their own project and decide to open-source it. 

I'm not an ecomonist, but have been tossing around some ideas in my head for a long time and thought I might ask here what resources or existing work might be out there. There are a lot of market sectors where the cost of manufacturing one additional unit of a good is essentially zero. Almost all (or nearly all) of the cost is in development. It seems to me that the efficient market hypothesis must break down in this regime, since efficiency could always be increased by not redistributing goods but rather cloning them at no cost. I believe Pareto efficiency may not even apply in these markets. This is potentially a problem/opportunity for sectors such as software, music, news, website content in general, customer data, and more. We see a variety of methods that have been adopted to help create more efficient markets. Subscription-based services, open-source software (the main currency there is not money), crowd-funding, snowdrift coop, and more. But I'm curious if there might exist a theoretical market economy that maintains some version of efficiency into this regime? Is there some modification to our current systems or some new form of currency that could be introduced that would self-regulate and optimize here? I'm not much concerned with practicality, just theory. An alternative way of looking at this issue is that producing some types of goods necessarily benefits people who are not buyers or would not ordinarily be. From this perspective there might be other industries to consider such as public infrastructure, basic research, or military. Normally these are government-regulated, not market-regulated. Anyway, that's the general scope of problems I've been thinking about. Is this even a real or recognized problem? Can it be measured? (I feel like the advertising industry may hold a key to measuring this, but I can't figure out how or even quite why.) How else is this effect characterized? What measures of efficiency have been proposed? Are there any solutions? I know I'm going to need additional education in this field, but I don't yet know which direction to head in. I feel like I might make some progress given some new definitions of efficiency and coding up simulations. (My background is in particle physics.) Existing terminology might help me search through literature. 

Industrial Organization is the field concerned with estimating supply and demand relationships in individual product markets. You can see for example Einav and Levin for a description of what empirical IO people are up to. The specific models are usually much more complicated than what you learn in Mankiw, tailored to specific markets, and very strong assumptions are required to estimate them. For recent IO papers, you can see for example the NBER working paper series. 

I am by no means an expert on this, but maybe this helps. Here is a simple example for a bellman equation $V(y) = \max_x u(x,y) + \beta V(y')$ $s.t. \, y' = f(x,y)$ This is a functional equation in an unknown function V. A solution to this problem is a function V that satisfies the equation above. If you look at the equation, it's pretty clear that the solution has to be a fixed point of the operator on the RHS of the bellman equation: if you take the correct V and an arbitrary y and calculate $\max_x u(x,y) + \beta V(y')$ $s.t. \, y' = f(x,y)$ you will get $V(y)$. The operator that is the RHS of the Bellman equation operates on functions, and the solution is a fixed point in some space of functions. It's a different question whether this fixed point exists and how to find it. Here, you appeal to the contraction mapping theorem: under typical assumptions on u and provided $\beta<1$, the maximization step above is a contraction mapping for any guess of V. This means that there exists a unique fixed point V, and you can find it by successive iteration.