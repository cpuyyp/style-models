The zeta function of a variety $X$ over a finite field is a priori defined to be a point counting function, i.e. it is the following product over the closed points of $X$ (thought of as a scheme): $$\zeta_X(s) = \prod_{x}(1 - | \kappa(x)|^{-s})^{-1},$$ where $\kappa(x)$ is the residue field of $x$ and $|\kappa(x)|$ denotes its order. (This is motivated by analogy with the Riemann zeta function, which is what we get if we apply the same definition with $X$ replaced by Spec $\mathbb Z$.) Now this will be a Dirichlet series involving only powers of $p^{-s}$ (if $p$ is the char. of the finite field), and so replacing $p^{-s}$ by $T$, we obtain a power series in $T$, whose log can be reinterpreted in the usual way as a generating function counting the number of points of $X$ with values in the various extensions of $\mathbb F_p$. Now one can count these points by the Lefschetz fixed point formula (applied to the $\ell$-adic cohomology), and this gives the alternating product of char. polys. of Frobenius that you write down in your question. Of course, one could write down their product, rather than their alternating product, but the resulting power series would not have any particular interpretation; in particular, it wouldn't be related to counting points of $X$ in the same way that the zeta function is. Milne's definition of the $\zeta$-function directly in terms of $\ell$-adic cohomology is to some extent putting the cart before the horse; as Stopple notes, it is a reasonable definition only because of the back story about counting points and so on. Nevertheless, if you want to take the definition in terms of cohomology as the basic one, then you can ask yourself: how should you define such a quantity if you want it to behave well under chopping up varieties (which is what motives essentially are --- pieces of varieties cut out by correspondences). The basic quantity that is defined in terms of cohomology and which is additive with respect to cutting up spaces is the Euler characteristic. And for this additivity to hold, it is crucial that involve an alternating sum, with the sign being dictated by the cohomogical degree. The reason is that the behaviour of cohomology under chopping up and/or gluing is given by the excision and Mayer--Vietoris long exact sequences, and it is the alternating sum of the dimensions which is additive in exact sequences. Viewed cohomologically, the zeta function is like an enhanced, multiplicative version of the Euler characteristic, and like the Euler characteristic, for it to be multiplicative with respect to cutting up varieties, we must form it via an alternating product. In conclusion: I think that the "deep reason" that you are looking for is the yoga of Euler characteristics. 

There is nothing wrong. A typical case will be $\mathbb F_q = \mathbb F_{p^2}$ and $\varphi = -p$. Since $q^{1/2} = (p^2)^{1/2} = p$, this is consistent with RH. 

Dear Fellow, You can't move $E$ (!), hence there is no contradiction with it having self-intersection -1. Indeed, if you take a normal vector field along $E$, it will necessarily have degree -1 (i.e. the total number of poles is one more than the total number of zeroes), or (equivalently), the normal bundle to $E$ in the blown-up surface is $\mathcal O(-1)$. [Added:] Here is a version of the argument given in David Speyer's answer, which is rigorous modulo basic facts about intersection theory: Choose two smooth very ample curves $C_1$ and $C_2$ passing through the point $P$ being blown-up in different tangent directions. (We can construct these using hyperplane sections in some projective embedding, using Bertini; smoothness is just because I want $P$ to be a simple point on each of them.) If the $C_i$ meet in $n$ points away from $P$, then $C_1\cdot C_2 = n+1$. Now pull-back the $C_i$ to curves $D_i$ in the blow-up. We have $D_1 \cdot D_2 = n + 1$. Now because $C_i$ passes through $P$, each $D_i$ has the form $D_i = D_i' + E,$ where $D_i'$ is the proper transform of $C_i$, and passes through $E$ in a single point (corresponding to the tangent direction along which $C_i$ passed through $P$). Thus $D_1'\cdot D_2' = n$ (away from $P$, nothing has changed, but at $P$, we have separated the curves $C_1$ and $C_2$ via our blow-up). Now compute $n+1 = D_1\cdot D_2 = D_1'\cdot D_2' + D_1'\cdot E + E\cdot D_2' + E\cdot E = n + 1 + 1 + E\cdot E$, showing that $E\cdot E = -1$. (As is often done, we compute the intersection of curves that we can't move into a proper intersection by adding enough extra stuff that we can compute the resulting intersection by moving the curves into proper position.) 

$\mathcal C$, the category of almost zero modules, i.e. modules for which $m M = 0$. This is a Serre subcategory because $m^2 = m$ in the context of Faltings's theory. $\mathcal C'$, the category of torsion modules, i.e. modules such that $x M = 0$ for some non-zero $x \in m$. This is a Serre category just because $V$ is a domain. 

Another way to phrase the same structure on $\mathcal V$ is to say that for each $g\in G$, there is a given isomorphism $\alpha_g: \mathcal V \cong g^\*\mathcal V$ such that for $g,h \in G$, one has $h^*(\alpha_g) \circ \alpha_h = \alpha_{g h}$. This latter condition can then be translated to a corresponding condition on the sheaf of sections of $\mathcal V$, which finally can be translated to a condition on any sheaf. What this amounts to is that one has an action of $G$ on the sections of the sheaf (let's call it $\mathcal F$) compatible with the $G$-action on $X$. The only thing one has to be careful about is that since the sheaf may not be determined by its global sections, one has to think about sections over arbitrary open subsets $U$, and then one has to take into account the fact that $U$ may not be $G$-invariant. So putting it all together, one gets for any $U$ open in $S$ an isomorphism $\alpha_{g,U}: \Gamma(U,\mathcal F) \cong \Gamma(gU,\mathcal F)$ (which is the action of the element $g \in G$), compatible with restriction to open subsets, and such that $\alpha_{g,h U} \circ \alpha_{h,U} = \alpha_{g h, U}.$ Caveat: I hope I have my composition formulas correct, but if I've gotten things tangled up, I'm sure they'll be corrected. 

A slightly more general answer: if the objects in question have no non-trivial automorphisms (i.e. non-identity isomorphisms from itself to itself) then no danger will come from treating isomorphisms as the identity. (E.g. the real numbers has no automorphisms as a field, and so any two copies of the real numbers can be unambiguously identified as fields.) But if $X$ and $Y$ are isomorphic but Aut($Y$) (or, equivalently, Aut($X$)) is non-trivial, then the identification of $X$ and $Y$ is not uniquely determined (because you could always postcompose with a non-trivial automorphism of $Y$, or precompose with a non-trivial automorphism of $X$, to obtain a different identification), and hence in this case there is not an unambiguous identification. (A typical example of this is the isomorphism between a finite-dim'l vector space and its dual; there is not a uniquely determined such isomorphism, and so one should not identify the two, although they are isomorphic.) In some contexts, although there is not a uniquely determined isomorphism, there is a canonical choice, e.g. the identification of a finite dimensional space with its double dual. Such isomorphisms are normally described in the language of natural isomorphisms between functors (e.g. the identify functor and the double duality functor are naturally isomorphic as functors from the category of finite-dimensional vector spaces --- over some given field --- to itself.) Often it is safe to identify objects that are identified by a natural isomorphism in some category theoretic framework that is suitable for the problem at hand. But even in these cases, sometimes one has to actually know an explicit description of the natural isomorphism (e.g. because you might need to make a computation involving both objects, which will of course require you to know how they have been identified). In particular, when identifying two objects via some natural isomorphism, it is good form to explicitly describe the natural isomorphism at some point, unless the natural isomorphism in question is utterly conventional (e.g. the double duality isomorphism for a finite-dimensional vector space; and even then, one might write something like "we identify $V$ and $V^{\vee\vee}$ via the usual double duality isomorphism"). Added: This answer is very similar to that of Charles Staats, which was posted while I was writing.