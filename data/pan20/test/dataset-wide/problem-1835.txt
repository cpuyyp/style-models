There's a big difference between swap being used and the machine actively swapping. The kernel will preemptively move more and more onto disk as it sees calls for large amounts of memory. If the stuff moved out to disk isn't that frequently used then it's not necessarily a huge problem. If data is constantly being swapped in and out then there's usually a big problem. The real measure here is to look at something like iostat to observe how much data is actually being passed back and forth in a given interval. That said, a 15G VM on a 16G box is probably not going to play out well. The OS itself requires a certain amount and there's always a percentage of overhead for the VM. If you are, in fact, actively swapping then you may see substantial improvements just backing off to, say, 12 or 13G. 

The amount- or type- of traffic matters a lot less than the code associated with actually allocating memory and the associated tracking of state information. If you want to get a very rough sense of what this implies take a look at the amount of code in the Linux kernel associated with TCP vs that associated with UDP or ICMP. An incredibly rough comparison shows TCP requiring something like 10x the number of lines of code found in UDP. In IP networking the amount of state maintenance required is one of the most important determinants of scalability. For TCP endpoints this is expressed not just in SYN/ACK but also in ongoing maintenance of sliding windows, sequence numbers, buffer management and QoS actions, etc. Check out the complexity of the FSM for tcp and consider the inherent lack of same in UDP... 

Try putting it in brackets [2001:470:...] or ipv6:[]. A great many parsers can't differentiate between a text entry and a v6 address. 

Keep in mind that a socket is a tuple of sec/dst address, src/dst ports and protocol and, as such, the number of permutations is a lot more than 64k. There are some situations where outbound connections on proxy servers might have issues based on particular implementations but port numbering hasn't been a big issue traditionally. 

The client specs call for PoE+ / at for a reason - it needs to pull more than the 15.4W that an af switch is supposed to provide. If things go wrong you could be looking at damaged equipment. Even if it comes up you're pushing your switch past specified tolerances, which pretty much means a postponed failure. If you want to run PoE+ on a PoE switch then get a PoE+ injector. 

If the two subnets (the /28 and /26) are both bridged to the same interface then you need addresses in both networks on the upstream network (i.e. a secondary address on the router for the entire network). Think of the virtual hosts on the bridge as if they were connected to the same switch as the host's NIC. The fact that the host (i.e. bridge0) is in a different IP subnet implies that there needs to be some kind of gateway between the two. Two options - either renumber all of the hosts into the same network or provide some kind of routed interface between the two. 

This can vary -massively- and has almost no correlation with the amount of bandwidth you're seeing on an interface. A single 50M flow (which would account for one of your devices) could be in constant use and would, as a result, generate flows only when you hit the natural timeouts (so every 5 mins or so - 288 flows a day). At the same time a DoS attack could be generating 50Mbps of 64 byte packets, each with a different src/dst L3 and L4 tuple and you'd be staring down 1M flows per second. Obviously these are extreme examples but the point is that the nature of the network and the type of traffic you're carrying will make a big difference. The other variables are the Netflow version - old style V1/V5/V7 vs V9, the latter of which has capabilities for aggregation, summarization and customization. The other potential point is the use of Netflow sampling (on the higher end / SP side of Cisco). What I can advise is that scaling Netflow is usually pretty linear. Your best bet by far would be just gathering some empirical data about what's being pushed right now and sizing your infrastructure to accommodate a healthy margin over that. I can tell you that I've been in enterprise environments on the smaller side of medium that were pulling from a similar number of devices and were seeing ~120-150 million flows per week. I can tell you that in many environments where Netflow is being pulled from a similar number of devices in fairly diverse enterprise networks (on the smaller side of medium) that I've been in shops where I was 

Multiple IP addresses is not the same thing as multiple interfaces. Typically a single interface represents a single L2 network but can have multiple IP addresses (sometimes known as aliases or secondaries). Multiple interfaces, in turn, generally correspond to distinct L2 networks. 

In short you're blocking the wrong port. SIP registration happens on port 5060 (TCP or UDP). The 10000+ ports are going to be for actual RTP bearer traffic, not call setup. Adjust your firewall to block 5060 and 5061 inbound and you should stop seeing the messages. While you're at it you might also consider whether you even want or need your system to be listening for SIP registrations on all interfaces. Remember - you likely connect to your provider, not vice-versa. 

Run 'netstat -an | grep :161' - if you don't see the address of your Ethernet adapter (i.e. only 127.0.0.1:161) then you need to configure agentaddress in your snmpd.conf. 

The best you can realistically accomplish is essentially balancing connections across the three connections. You'd have three network address translation (NAT) gateways (..could be in one physical box). The network would send a given individual network connection out one of the three circuits and the translated address would serve as the mechanism to assure return traffic came back to the right place. The effectiveness / uniformity of distribution of traffic across these links is a statistical exercise. Your network device will choose the outbound path based on some collection of attributes (source / destination IP address, source/destination L4 port, source destination hardware address, etc, etc). The number of attributes used and the actual even distribution of these attributes determine how many connections go to a given link. It's entirely possible that an inefficient setup could send all of your workstation's traffic out a single link - which basically nets you no more performance than having purchased a single 2G connection. It's also possible (though less likely) that the amount of actual bandwidth you need is distributed amongst flows that are perfectly balanced across the three circuits. In more sophisticated multihomed setups there would be additional routing information available to send traffic via a (nominally) better path, but the focus in those circumstances tend to be more on increasing availability than performance (although both can be positively affected). This also implies a lot of additional network design questions and a not inconsiderable degree of cost and paperwork. Here are some issues worth considering- 1.) Not all connections are created equal. Your performance may vary substantially as particular bits of your traffic are directed out the various circuits. The latency (i.e. time to reach) a particular site could be 4-5X higher with one provider than another. Similarly, policies and terms of use might differ between providers. One ISP might have no problem with VOIP traffic but absolutely will not allow SMTP, while the second allows anything and the third has an issue with just one of the two. The result? Yikes. 2.) Unless you've got a decent degree of sophistication in your setup (i.e. the routing information I alluded to above) then there are a lot of failure modes that could be very troubling. Imagine that your address translation device didn't realize that one of the three connections was out of service. An unknown portion of traffic would be lost, but the impression to the end user would be randomly freezing sessions or odd performance while standard diagnostic tools (i.e. pings) might look just fine. Bear in mind that there are a lot of "gray" failures - which is to say the link might appear fine to the router but in reality no traffic can pass. 3.) The statistical connection sharing tends to work better with larger numbers of users and connections. If it's just you and a few others, there won't be as much of a win. 4.) None of the above addresses any sort of inbound connections (i.e. web server, mail server, etc). That's a whole other set of issues... There are ways around these problems - special gateways, custom scripts, etc but they're typically not simple to maintain and troubleshoot. The underlying point is that nothing comes for free. You can get somewhat better performance under certain circumstances with multiple connections, but only at the cost of some amount of operational complexity (...which has a dollar value all its own) or you can bite the bullet and spend the additional money for a smaller number of larger connections. Good luck.