For a star to become a nova, it needs to have a mass at least 8 times greater than our sun. For a supernova, it needs to be larger. The first stage is the hydrogen fusion into heavier elements. The energy created pushes the hydrogen outwards. If there was no fusion, the star would be a low smaller. When the hydrogen fusion in the core slows down (due to a lack of hydrogen), the star shrinks and helium fusion takes over as the main process. At this time, it is believed that the core of the star is about 25% hydrogen and 75% helium. The outer layer of hydrogen doesn't change. Eventually, the star makes iron as a fusion product. The fusion to make an element heavier than iron consumes more energy than what it produces, so when the "iron fusion" (creation of iron) process slows down significantly, the star collapses. This collapse causes a massive pressure and temperature increase in the core, which triggers the fusion of heavier elements; although it is a net loss of energy. This burst of energy blows the star apart. The difference between a nova and a supernova is the amount of fusion that happens before the core is blasted apart. Since fusion only takes place in the core, and the core is less 1/100 the volume of the star, when the star goes nova (or supernova), the outer layer of the star is blown outwards. 

For a more objective test, we could try to look for early maps or sketches of the moon made by astronomers before the invention of the telescope, which should presumably represent the limit of what the naked human eye could resolve. (You needed to have good eyesight to be an astronomer in those days.) Alas, it turns out that, while the invention of the telescope in the early 1600s brought on a veritable flood of lunar drawings, with every astronomer starting from Galileo himself rushing to look at the moon through a telescope and sketch what they saw, very few astronomical (as opposed to purely artistic) drawings of the moon are known from before that period. Apparently, while those early astronomers were busy compiling remarkably accurate star charts and tracking planetary motions with the naked eye, nobody really though it important to draw an accurate picture of the moon — after all, if you wanted to know what the moon looked like, all you had to do was look at it yourself. Perhaps this behavior may be partly explained by the prevailing philosophical opinions at the time, which, influenced by Aristotle, held the heavens to be the realm of order and perfection, as opposed to earthly corruption and imperfection. The clearly visible "spots" on the face of the moon, therefore, were mainly regarded as something of a philosophical embarrassment — not something to be studied or catalogued, but merely something to be explained away. In fact, the first and last known "map of the moon" drawn purely based on naked-eye observations was drawn by William Gilbert (1540–1603) and included in his posthumously published work De Mundo Nostro Sublunari. It is quite remarkable how little detail his map actually includes, even compared to a tiny 40 by 40 pixel image as shown above: 

Our sun will eventually become a white dwarf. A star 10 times it mass will become a neutron star. A star 100 times the mass of the sun will become a black hole. So if 100 stars came together into one mass, it would collapse into a black hole. It is currently believed that a super massive black hole (at least 1000 times the mass of our sun) is at the center of our galaxy and also in the Andromeda galaxy. This is where all the iron might be found from this region of space. 

How fast does the blast front of a supernova expand at? Is it close to the speed of light or is it less than a quarter of the speed of light? 

It doesn't seem so far-fetched to me. Sure, you might be off by a few pixels, due to differences between the human eye and a computer monitor, but the order of magnitude seems about right — the detail in your images, viewed closely, more or less matches what I see when I look at the full moon. Of course, you could fairly easily test it yourself: go outside on a dark night, when the moon is full, and see if you can spot with your naked eye any details that are not visible (even under magnification) in the image scaled to match your eyesight. I suspect you might be able to see some extra detail (especially near the terminator, if the moon is not perfectly full), but not very much. 

The moon orbits the Earth in roughly 29 days. So in 14 days, it would be on the other side of the Earth. 

I've read that a gas giant, like Jupiter, doesn't have a rocky surface. But planets must start as a rocky conglomerate of flotsam. 

The further north you go, the time between sunset and darkness becomes longer, no matter the season. The reason is due to the velocity at that latitude. If there is 10 min of twilight on the equator, then there is $10\sqrt{2}$ min at 45° latitude, 20 min at 60° latitude, ... Added: I used the website that @barrycarter listed above and discovered that there are 2 maxima and minima during the year. The solstices have the longest twilight times and the equinoxes have the shortest twilight times. 

Galileo's sketches of the moon, based on early telescopic observations, from Sidereus Nuncius (1610), via Wikimedia Commons. Few, if any, of the depicted details can be confidently matched to actual lunar features. Much more accurate drawings of the moon, also based on early telescopic observations, were produced around the same time by Thomas Harriott (1560–1621), but his work remained unpublished until long after his death. Harriott's map actually starts to approach, and in some respects exceeds, the detail level of even the 60 pixel photograph above, showing e.g. the shapes of the maria relatively accurately. It is, however, to be noted that it is presumably based on extensive observations using a telescope, over several lunar cycles (allowing e.g. craters the be more clearly seen when they're close to the terminator): 

The only light you would see, would be from the stars outside the black hole. Any light that is generated inside the event horizon would be refracted towards the singularity. You wouldn't see the object in front of you since the light would not reach your eye. 

I agree that the crater needs to be lined, but you also have the problem of maintaining a satellite in stationary orbit above the crater. Nearly impossible unless the crater is on the equatorial plane. Also, a stationary satellite around the moon would be influenced by the Earth, so you would need to burn fuel to keep the satellite in position. 

Left: Thomas Harriott's lunar map, undated but probably drawn c. 1610-1613, based on early telescopic observations, quoted from Chapman, A. "A new perceived reality: Thomas Harriot's Moon maps", Astronomy & Geophysics 50(1), 2009; Right: same photograph of the full moon as above, scaled down to 60 pixels across and back up to 320 px. Based on this historical digression, we may thus conclude that the 40 pixel image of the moon, as shown in the question above, indeed does fairly accurately represent the level of detail visible to an unaided observer, while the 60 pixel image even matches the detail level visible to an observer using a primitive telescope from the early 1600s. Sources and further reading: