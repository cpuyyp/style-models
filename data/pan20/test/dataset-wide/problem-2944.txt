The human brain does not go through every logical option when making a decision. Doing so takes too long and results in sub-optimal decisions. Neuroeconomics suggests that (1) our decision making process follows a diffusion approach, where data accumulates until one option passes a threshold, and that option is taken. It also suggests that we rely on emotions as a heuristic. Because if that, we might make what appear to be paradoxical decisions, but because we don't parse through every option until we find the right one, our brain doesn't fall into the infinite loop issue. That being said, it is possible that the universe itself is not logically consistent. While inconsistent mathematics may seem like a purely academic line of thinking, it is possible that the universe itself has actual paradoxical conditions. Take relativity and quantum mechanics. They are incompatible, and we are trying to find a grand unification theory. But maybe there isn't one. Maybe the universe obeys both, and we just live in a logically inconsistent universe where both of these theories, or something very close to them, are indeed true. 

Indeed, but we can apply parsimony at least. If we have two sets of theories which both explain the data equally well, the most parsimonious one is the most likely to be correct. Once we have shown that two sets of theories explain a data set and have run out of reasonable ways to test them, we just take the simplest collection we have and assume that the system is true, until we are shown otherwise in future experiments (or events in life). System of Theories To better explain what I mean by system of theories, consider testing some concept in thermodynamics like the rate of heat transfer. We measure the temperature, using fluid thermometers, in two containers, connected by a conductor over a course of time and plot it to see if our theory holds. But are we really measuring temperature? No. We are measuring the volume of the fluid in the thermometer, and using theories of material science to infer the temperature. Therefore you are not testing the theory of rate of heat exchange. You are testing the system which includes not only that theory, but the theories used to produce the measurements as well, and if you get a result that's reasonably inconsistent, you are not falsifying a single theory but the collection of theories used to make the prediction. Robustness of Theory I would like to add that I generally look at theories as being "robust" or non-robust. A theory is more robust if all reasonable methods to show it false have been made and there are a number of other theories which are dependent on it. The theory body of theory of evolution is important in a number of other fields, such as medical science. If evolution is false, then a lot of our medical theory, including epidemiology, falls apart. It has also gone through a lot of rigorous testing. Therefore it is quite robust. I personally like the word "robust" much better than "true" or "proven" when talking about scientific theories. 

With any category argument, you need to start with a definition. While a dictionary definition might work, it is usually more useful to find expert definitions. I would see if you can find some papers and academic quality books on the topic of literacy. See if your library has something like The Anthropology of Literacy. If you can find a recognized definition which includes more than just reading and writing, and especially if it already would imply that understanding of programming is a form of literacy. One argument is that programming languages are just that: languages. If that is the case, then you can start directly from the definition "knowing how to read and write a language." I think most people would accept that definition and it is the argument that I would use. One way you can bolster the argument is through the citation of legal cases which are consistent with your position. This article cites a pertinent case and this specific quote from the case may be the linchpin in your argument: 

One way to justify an appeal to authority is to define expertise as follows: a person is an expert on a topic T, if and only if, he has authoritative and comprehensive knowledge on the topic. While such a person likely does not exist, as there's often something that's unknown even to those who are amazingly well versed on a topic, yet known by someone else, we can reasonably assume that those who have gone through extensive education, who have defended their positions repeatedly, etc are experts. So why does appealing to expert opinion work? If we assume that the person is an expert, then he knows all that is known about the topic (comprehensive knowledge), understands the topic fully (authoritative knowledge), and is honest enough to not make a claim that is not known, by him to be true. Therefore, assuming expertise, we can safely utilize the claim made by the individual. 

First, let me kill that idea. Anthropologists do not accept the idea that early humans were cave dwellers. While there have been a few groups of people who did, for the most part, caves are not very hospitable environments. They are dark, cold, and wet. A lot of material was found in caves because neanderthals and early anatomically modern humans used these caves as part of their rituals. As for how misogynistic early humans were, there is a lot of discourse on this matter. Almost certainly there was a lot of division of labor, but it is complicated to determine how these people lived. We usually look to existing hunter-gatherer societies to give us some insight. I need to look into this study more, but it seems to have some useful information related to this topic. Ignorance & Headlines Now as to why the article in question makes the claims that it does. For one, it is a matter of ignorance. We are still clinging to a lot of false myths about early humans. For another, it fits an agenda. For these articles, the truth is less important than getting a lot of readers. The topic resonates with a lot of people and so, even if it does not match scientific theory and evidence, it is still a "good" article in the sense that it gets readers. 

I agree. We can at most, right now, shift the probability of a theory being true by an infinitesimal amount. However, there are two ways of thinking about science. One way is to look at it as a system of confirmation: every time we make a prediction from a theory and it turns out to be correct, we get closer and closer to knowing that the theory is true or, if we keep falsifying theories, we keep getting closer to the correct one. It is true that this does not seem to be justified with current mathematical frameworks for science. However, not everyone accepts the idea of scientific confirmation, even to any degree. I do not. However, falsification is nice. Consider a collection of theories {T1, T2, T2, â€¦, TN} and we use that collection, as a whole, to determine the probability distribution of outcomes for a given experiment. Using little more than probability theory and the assumption tht reality is logically consistent, we can say that if an observation is unlikely, given the probability distribution derived from our collection of theories, then the collection of theories, as a whole, are unlikely to be true. Of course, how to modify that collection used to make the prediction is tricky. But we continue to make modifications and make predictions until the point where we have run out of reasonable ways to falsify the system. 

As far as the US courts are concerned, Java is no different than French. If you can understand and write Java code, you're literate in Java. If you cannot understand or write code in any programming language, then you are illiterate as far as that is concerned. Foundations There is always a question of whether or not an argument is valid. As long as a position is logically derived from a foundation, then it is valid, up to that foundation. If someone is not willing to accept SCOTUS rulings on the meaning of a word, then we have to see if we can use a different argument, but at the very least, it is a good starting point, and the argument itself made by the justices might work as material towards a modified argument. 

It is the other way around. Falsification is just a statistical form of proof by contradiction. In proof by contradiction, you start off by assuming that a premise p is true. Then you show that such an assumption leads to a conclusion q, which has already been shown to be false. So long as we assume that our axiomatic system is logically consistent, this result implies that p is false: p -> q and ~q together imply ~p. In falsification/hypothesis testing, we start with a theory T, and then we make an observation O. From T we can determine how likely O is. If the probability of O given T is low, then we can say that the probability of T given O is low. Of course, if the probability of O given T is 0, then we end up with an absolute falsification which would be exactly the same as proof by contradiction. Of course, in falsification, we rarely have absolutes, and even worse, we are not really testing a single theory but we are using a whole body of theory to come to our conclusion. This result makes since a bit more messy, and I discuss this issue in more detail here.