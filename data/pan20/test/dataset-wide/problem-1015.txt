I agree with some of the other comments though that perhaps your servers are set to auto update and this is how it could have occurred. Based on how your server is configured and combined with the changes to how CUs are installed, it could have auto updated. 

The RSAT tool was updated with the general availability of Windows Server 2016. By going to the same link as the preview RSAT, $URL$ you can update your workstation with the new version. 

While it doesn't specifically state anything, something changed in the Windows 2012 R2 OS that allowed using MSA or gMSA for SSRS and I'm assuming it's related to the quote above. I just ran into a similar situation a few months ago during an upgrade/migration to SQL Server 2016. The original OS was running Windows 2012 and I tried everything I could to make it work but it never worked with SSRS until OS changed to Windows 2012 R2. 

I would suggest using SQL Server Data Tools (SSDT), which is essentially the latest iteration of the Visual Studio Database Projects. I use this at places that do not already have a way to source control their databases since it easily integrates with TFS, which most Visual Studio shops use for source control. A couple pros I have for using it are: 

Jon gives you some links to SQL Server audit information in the comments. That is a definite way to see who is doing what and when on a server. Depending on what you are looking for that may be a good enough answer. Auditing isn't free, though. Capturing some of the data required can be expensive to trak and take some time to track. One approach here - depending on what you are looking to do with this information is to look at the DMV - this DMV shows you various statistics about access (insert, update, delete, scan, seek and lookups) for your indexes. You can join this DMV to tables that contain information about your tables or views like sys.tables or sys.indexes to see the details. There are some caveats about this approach (data gets reset when SQL is restarted, there is a bug in SQL 2012 where the stats are apparently reset after an index rebuild, and other caveats described by Joe Scan in a couple posts) You can see an example of querying this data in this post from 2007 written for SQL 2005 but still most applies today. 

Yes. Now my disclaimer is I'm not your licensing rep or Microsoft so you should check with them on questions. But the verbiage in the various license guides is typically "A Server running SQL Server - or any of its core components (SSRS, SSAS, SSIS)". So if you are using SSIS on a server standalone, by the licensing guidelines you are running one of the core components on another server and that should be licensed separately from any other machine running a core component. Depending on the load of your SSIS server, I have typically found that in many installations, just running the SSIS server on an already licensed machine - be it your warehouse server or a staging server or even your main production server works. When you get into complex SSIS workloads with lots of moving parts and pieces and high overhead, you may start considering a separate processing server that perhaps also contains the DB instance for your SSIS logging and reporting type of environment. I'd say that I have to consider that sort of separation for performance rarely lately, though I have in the past. Microsoft publishes several detailed and overview license guides. This one here is an example for SQL Server 2012. 

Having said all that, I still use it and recommend it. I generally try to let developers use just that tool instead of SQL Server Management Studio (SSMS) because I look at SSMS as a DBA tool and SSDT as a developer tool. 

LinkedServerName would be the real linked server name and SourceTableName would be the name of the table in the linked server. 

SQL Server Reporting Services (SSRS) is a server-based platform for hosting reports. Report builder is client tool that may be used to create reports to deploy to SSRS. As such, you would use SSRS to manage security on for the reports that you may have deployed with Report Builder. 

Based on the comments, it seems the answer is to create a clustered index on the column you want to use to partition the data and then make sure your non-clustered Primary Key index is not partition aligned so you will not need to add the partitioned column to the primary key. By doing this, you can keep the primary key "simple" and use it like you normally would in a non-partitioned table. 

There is a lot of info out there about this behavior going back years. Here is a thread: SQL Server Management Studio slow opening new windows Common thread there seems to be SSMS is trying to reach a location in the internet. Another thing there states to change the user feedback Opt In setting. Maybe one of these options will speed it up 

shows Jones to be a designer on the Nile project but we know that is not the case. Let us assume instead the business model did say there were MVDs of and . In this case, what those MVDs mean is that if an employee plays a role, and if that role is on a project, by definition that employee plays that role on that project. In this example, that same EmpRoleProj table is now not in 5NF and now does suffer from redundancy. Now, the facts that Smith is a designer and there is a need for a designer on the Amazon project are stored redundantly as those facts could be inferred from joining Table 1 and Table 2! Likewise, taking the join of Table 1 and Table 2 now does not result in a spurious tuple as the inference that Jones is a designer on the Nile project is a fact now based upon the business rules defined by the MVDs. This is why you cannot assess the normal form of any R-table without knowing the dependencies and the defined key. Making any assumption, even one that seems to you to make sense, can be dangerous. If you are ever asked what normal form an R-Table is in, you must ask for the dependencies to assess. In addition to Fabian's series of papers, Chris Date's works provide the best information available on normalization theory. 

There are no hard and fast rules about the order here. The purge and history cleanup jobs (on a system that doesn't have years of history that was never purged) are generally very quick. I typically schedule those weekly at midnight on a Friday or Saturday - and it just works, they may take seconds to single-digit minutes for most systems. You could even do them at 8AM on Saturday or Sunday after all is done. Those jobs won't really cause issues or break our database. So they can run independently of worrying about those. Hopefully, you are in full recovery and doing log backups. The only real hard and fast rule I use is: A.) I don't delete my backup until I know my next one is good B.) I always verify and use checksum (and test restore when I am able), C.) I do my full backup AFTER my checkdbs each week - so I know when I have a good checkdb, I have a good backup right after it. D.) I keep my full backups, log backups and any diff backups since my last good checkdb so I can always get back when needed (I explained this in a rather long-winded - sorry - blog post about Corruption resistant backup strategies.) 

Your server authentication mode may be set to Windows only instead of Mixed Mode, which will allow Windows logins and SQL logins. If true then the SQL login will not work. In SQL Server Management Studio, you can right-click on the server and then go to the properties. Then go to security and see how the server security is configured. You can change it there also. If it is set to Windows only then you will have to use a Windows login. If you want to change to mixed mode to use SQL login, you can make the change but that may require the instance to be reset to take affect. 

I would say the stored procedure itself probably does not include the comment with the current script date. SQL Server Management Studio adds that when you generate the view of the procedure. In my experience, the stored procedure itself starts with CREATE or ALTER and anything above that is added by SSMS when you look at the code. 

I had similar issue before. I had all SQL Services that I needed running on MSA or gMSA except for Reporting Services (SSRS); this stayed this way on Windows 2008 R2 and 2012. This issue went away when moved to Windows 2012 R2. In my experience, SSRS was the only service that would not run on MSA or gMSA on OS prior to Windows 2012 R2 but the database, analysis, agent, and integration services all worked ok with them even when not officially supported (MSA running with SQL Server 2008 R2). At this link, $URL$ it states: 

Before considering performance you need to think about normalization. If you can interchangeably concatenate or not concatenate Group A and Group B then it sounds like B functionally depends on A and that means your table is not fully normalized. One example of a problem this could cause is if you don't currently have any products that fit into a given group and sub-group then you have lost the information that those groups and sub-groups even exist. If for example you delete the rows for A2-B2-1 and A2-B2-99 you have lost the information that A2-B2 is a group subgroup. You need to go back to understand the business rules here and if this is a possible use case you need to implement tables for product groups. This analysis must be done regardless of how you decide to cluster. Once you have completed normalization and if you still have this table structure (say you now have a product group, product sub group, and a product group sub group table which parents your Group-Sub Group-Product table), you regardless NEVER want to concatenate columns into a single column. This concatenation breaks 1NF as now you have 2 different date element concepts in the same column. You would be unable to query for all products in a given sub group across groups. From a SQL Server clustering perspective, if this table will always be queried by product group/sub group, and possibly product id, and that is it, you will want to create a clustered index on all 3 columns. That will best support your query as data in the table will always be ordered by the 3 columns and you can seek right to the group/sub group/product you want. If you make random value inserts into the table over time however you will need to tune the freespace you allow in the index as well as periodically reorganize/rebuild the index over time to maintain clustering order. 

Yes from that link it supports it. A Database Snapshot is a read only "frozen in time" (when the snapshot was taken) view of data. This is a tool useful in some recovery, reporting and rollback preparation scenarios. The isolation levels you are asking about are all covered by the line talking about Snapshot Isolation Level (Row-level Versioning). I would question what sort of workload you are putting against SQL Server Express that needs a snapshot isolation level as there are other restrictions on SQL Server Express that tend to make it not a great fit for busier, high concurrency apps (Most notably database size and memory restrictions) but this is certainly supported from that edition features matrix you linked. 

Are you using transactional replication for this database? You may be able to use some of the system tables there to help narrow it down. Do you take transaction log backups frequently? Each log backup has a header and that header explains which LSNs it contains so you can at least narrow it down to a range by restoring headeronly and figuring out which backup the LSN is in and then at least know within the frequency of your log backups when that was done. - you can also look at the header for diffs and fulls to help narrow down if you have a needle in haystack situation. 

Normalization, more formally called Projection-Join Normalization, is a scientific process in which one can remove redundancies in R-tables due specifically to join dependencies which are not implied by the candidate keys. The join dependencies are exploited by taking projections based on them to create two or more tables from the original table which removes the redundancy. It is important to note that normalization cannot remove all redundancy. Instead, it can remove only redundancies caused by join dependencies not being implied by the primary key. The first 3 normal forms and Boyce-Codd Normal Form (BCNF) deal with redundancies due to functional dependencies not implied by the candidate keys. While most designers talk about normalization to the third normal form, what they really mean is normalization to BCNF as that is the normal form with respect to the functional dependencies. Functional Dependencies In order to determine if either table is in any normal form, 1NF or 3NF, (and thus an R-Table), we must clearly state the functional dependencies. A mistake most designers make is to assume the functional dependencies based upon what makes sense to them. In simple examples this isn't usually a problem, but in complex real world scenarios it is deadly. For your example let us assume the following functional dependencies for the first table: