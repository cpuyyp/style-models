EDIT:Comments part 1. I don't have a theoretical justification right now, but the history of complexity theory shows that the structure of much smaller complexity classes are at least very difficult to understand. Many experts "believe" that there are pseudo-random number generators (PRNG), so RR's Natural Proof theorem applies and there is no "natural" property of sets/functions that can be used to prove a lowerbound for the complexity classes satisfying the condition of the RR theorem. I think a person accepting the existing of PRNGs can at least claim that there are no simple combinatorial structures for these complexity classes. part 2. You are looking for a combinatorial property of sets of strings in a complexity class. The computational complexity of checking a property is a good measure. Any property stated in the first order logic (on a finite structure) is $AC^0$. The RR theorem applies to properties which are in $P$, i.e. can be checked in polynomial time given the truth table of the functions (characteristic functions of sets restricted to inputs of size n). Encoding Turing Machines (TM) is not difficult, and I think it can be done if one goes a little above $AC^0$, e.g. $TC^0$ is probably capable of checking if a string encodes a TM. You are looking for a property that holds for all functions in a class, but not for those outside it. The negation of it would be a property of the kind considered in RR's theorem. By these considerations, I think there are no properties of the kind you are looking for unless there are no PRNGs. definitions: $AC^0$ is class of sets of strings accepted by (uniform) circuits of polynomial size and bounded depth, i.e. there is a constant $d$ and a polynomial $p(n)$ and a sequence of circuits $\{C_n\}_{n \in \omega}$ using unbounded fan-in $\land$,$\lor$,$\lnot$ gates and of depth $d$ and size $p(n)$ that accepts them. $AC^0[n]$ is the same as $AC^0$ but allows $mod_n$ gates. $p$ is a prime number. $TC^0$ is the same as $AC^0$ but allows majority/threshold gates. A property $Q$ is natural if it is: 

Carl's answer is correct. There is also a to more direct way to achieve the same thing. The Tennenbaum's theorem holds for much weaker theories, e.g. $I\Delta_0$ (even for far weaker theories like $IOpen$ plus some number theoretic principles, but not for $IOpen$, a result due to Shepherdson). $I\Delta_0+exp$ is finitely axiomatizable, see Haim Gaifman and Constantine Dimitracopoulos, "Fragments of Peano's Arithmetic and the MRDP Theorem". It is also a sub-theory of $PA$. For more on Tennenbaum's theorem and weak arithmetics, have a look at this paper: Shahram Mohsenipour, "Hierarchies of Subsystems of Weak Arithmetic", to appear in "Set theory, Arithmetic, Philosophy: Essays in Memory of Stanley Tennenbaum" (edited by J. Kennedy and R. Kossak), Cambridge University Press. 

useful: i.e. does not hold for simple functions (functions of low complexity) but holds for some function in the larger class, constructive: i.e. can be checked in polytime from the truth table of the functions, large: i.e. for some k and all large enough n, the property holds for at least $\frac{1}{n^k}$ of the functions. 

This post is about Natural Proofs barrier in computational complexity. There are two recent papers related to this. They are: 

Alexander Razborov mentioned them at the end of his talk in the first Barriers Workshop at IAS in 2009. The video of his talk is available here. He mentioned that a possible way to respond to these would be to make the largeness condition relative. So here is my question: 

"I saw at once that Julia Robinson had a fresh and wonderful idea. It was connected with the special form of Pell's equation (6) $$x^2-(a^2-1)y^2 = 1. $$ Solutions $<\chi_0, \psi_0>, <\chi_1, \psi_1>,\cdots, <\chi_n, \psi_n>,\cdots$ of this equation listed in the order of growth satisfy the recurrence relations (7) $$\chi_{n+1}=2a\chi_n-\chi_{n-1}$$ $$\psi_{n+1}=2a\psi_n-\psi_{n-1}$$ It is easy to see that for any $m$ the sequences $\chi_0,\chi_1,\cdots, \psi_0,\psi_1,\cdots$ are purely periodic modulo $m$ and hence so are their linear combinations. Further, it is easy to check by induction that the period of the sequence (8) $$\psi_0,\psi_1,\cdots,\psi_n,\cdots (\mod a-1)$$ is (9) $$0, 1, 2,\cdots, a - 2,$$ whereas the period of the sequence (10) $$\chi_0-(a-2)\psi_0,\chi_1-(a-2)\psi_1,\cdots, \chi_n-(a-2)\psi_n,\cdots (\mod 4a-5)$$ begins with (11) $$2^0, 2^1, 2^2,\cdots$$ The main new idea of Julia Robinson was to synchronize the two sequences by imposing a condition $G(a)$ which would guarantee that (12) $$\text{the length of the period of (8) is a multiple of the length of the period of (10).}$$ If such a condition is Diophantine and is valid for infinitely many values of $a$, then one can easily show that the relation $a = 2^c$ is Diophantine. Julia Robinson, however, was unable to find such a $G$ and, even today, we have no direct method for finding one. I liked the idea of synchronization very much and tried to implement it in a slightly different situation. When, in 1966, I had started my investigations on Hilbert's tenth problem, I had begun to use Fibonacci numbers and had discovered (for myself) the equation (13) $$x^2 - xy - y^2=\pm 1$$ which plays a role similar to that of the above Pell's equation; namely, Fibonacci numbers $\phi_n$ and only they are solutions of (13). The arithmetical properties of the sequences $\psi_n$ and $\phi_n$ are very similar. In particular, the sequence (14) $$0, 1, 3, 8, 21, \cdots $$ of Fibonacci numbers with even indices satisfies the recurrence relation (15)$$ \phi_{n+1}=3\phi_n-\phi_{n-1}$$ similar to (7). This sequence grows like $[(3+\sqrt 5)/2]^n$ and can be used instead of (11) for constructing a relation of exponential growth. The role of (10) can be played by the sequence (16) $$\psi_0,\psi_1,\cdots,\psi_n,\cdots (\mod a-3)$$ because it begins like (14). Moreover, for special values of a the period can be determined explicitly; namely, if (17) $$a = \phi_{2k}+\phi_{2k+2},$$ then the period of (16) is exactly (18) $$0,1,3,\cdots,\phi_{2k},-\phi_{2k},\cdots,-3,1.$$ The simple structure of the period looked very promising. I was thinking intensively in this direction, even on the night of New Year's Eve of 1970, and contributed to the stories about absentminded mathematicians by leaving my uncle's home on New Year's Day wearing his coat. On the morning of January 3, I believed I had found a polynomial B as in (5) but by the end of that day I had discovered a flaw in my work. But the next morning I managed to mend the construction. What was to be done next? As a student I had had a bad experience when once I had claimed to have proved unsolvability of Hilbert's tenth problem, but during my talk found a mistake. I did not want to repeat such an embarrassment, and something in my new proof seemed rather suspicious to me. I thought at first that I had just managed to implement Julia Robinson's idea in a slightly different situation. However, in her construction an essential role was played by a special equation that implied one variable was exponentially greater than another. My supposed proof did not need to use such an equation at all, and that was strange. Later I realized that my construction was a dual of Julia Robinson's. In fact, I had found a Diophantine condition $H(a)$ which implied that (19) $$\text{the length of the period of (16) is a multiple of the length of the period of (8).}$$ This $H$, however, could not play the role of Julia Robinson's $G$, which resulted in an essentially different construction." 

You can Skolemize a theory to get a universal theory which is a conservative extension of the original theory. By Gentzen's cut-elimination theorem, any formula provable in this theory has a proof where all formulas are subformulas of the theorem and axioms of the theory. If you are proving a $\Pi_2$ formula, all formulas in the proof will be $\Pi_2$. $\Pi_2$ sentences are extensively studied in proof theory, they are closely related to the provably total functions of the theory. 

I am not sure if this answers your question, but it was at least too long for a comment. First, note than one can interpret Sam Buss's bounded arithmetic theories like $S^1_2$ in $Q$, so it is not as weak as it seems at first sight in expressing and proving theorems. One can use a reasonable formula to exclude those non-standard numbers which are too pathological and prove consistency of $L$ (if $S^1_2$ proves consistency of $L$). I am not sure but you might find Pudlak's criticism in the last part of Hajek and Pudlak, and his alternative condition that you are looking for might be "sequential theory". Also take a look at this article which cites the Bezboruah et al. 1976 paper. (By the way, Bezboruah et al. (1976) seems to be a decade before Nelson's Predicative Arithmetic (1986) which shows that one can interpret $I\Delta_0$ in Q.) 

I will not answer the question since I think it is not completely defined without completely specifying the machine model. In the following I explain why. Note that the exact running time of a machine is not natural mathematically, it heavily depends on the particular model of the machine we use (that is why in complexity theory we get rid of such constants using asymptotic notations like $O$). Therefore, the question of computing the running time modulo some value is not natural either. We can easily consider a machine model where all halting machines halt in even number of steps and another model where all halting machines halt in odd number of steps, and in both cases your question is trivially computable. Even more artificially, we can define a machine model where a halting machine with size $k$ halts in even number of steps iff a particular machine halts in $k$ steps (which would make the problem uncomputable). These are all valid models of computation though artificial ones. The function is trivially computable in one model of computation, and uncomputable in another model of computation. That tells us that the question is not a natural one. Note that this is not the case regarding $BB$, it is uncomputable in all acceptable models of computation (having same computational power as Turing machines). The answer doesn't depend on the particular model of computation we use, the numbers will be different, but the question about computability has the same answer in all of them. Your question about $BB(k) \mod 2$ for a particular fixed completely specified model of computation is well defined, but IMHO it is not a very interesting one: it is too much dependent on the particularities of the machine model. Unless you have some reasonable restrictions on the models such that the answer will be the same on all such models the question would not be very interesting IMHO. In a sense, this is similar to asking if a particular Diophantine equation has any integer answers without explaining why that particular equation is of any interest. Here is the same, from mathematical perspective, the answer to the question is not a natural one and too much dependent on the particular encoding of the machines and I don't see any way of getting around this dependence. (Also from practical perspective, I also don't see any use for computability of this function.)