I would call this a conditional promise rather than a conditional statement. As such, it doesn't have a truth value. In the event I am healthy, I fulfil my promise by coming to the class; in the event I am not, the conditions for the promise are not present - I didn't break the promise, but it seems a little odd to say I kept it. This doesn't work as an example of material implication, because it fails to distinguish cases that are plausible from those that are not. "If 3 is a perfect square, then 3 is not prime" is plausible not because 3 is not a perfect square, but because all perfect squares are not prime. After all, "If 3 is a perfect square, then 3 is a transfinite number" is hardly plausible, but it has the same false antecedent. Dutchman conditionals may well be treated as special cases of conditionals. They have a rhetorical purpose in which typically someone might assert some proposition P and someone else responds with, "if P then I'm a Dutchman" - meaning they consider P to be absurd and so they counter with an absurdity of their own. 

False cause, or questionable cause, occurs when one reasons from an effect to a cause, but the identified cause is incorrect or doubtful. Reasoning from effects to probable causes is a kind of abductive reasoning and is extremely common. There is nothing intrinsically wrong about reasoning in this way, but it becomes questionable if there are many possible causes and no reason has been offered as to why the other possibilities are ruled out. It may also be questionable if there are many contributory causes rather than just one, or if the cause has been confused with the effect. 

Given that your conclusion is contradictory, it cannot be true in classical logic, but that doesn't necessarily mean that any argument that has it as its conlusion is invalid. It is possible for an argument to have inconsistent premises. So, for example, the following argument is valid: 

This answer should be read as a kind of extended comment on alanf's answer, which I broadly agree with, but would like to qualify. Deutsch argues that probabilities can be eliminated from physical theories, in other words, that we have no need of stochastic processes in a physical theory. In particular, he is concerned to maintain that quantum theory, which has often been interpreted to involve fundamental indeterminacies, can be understood instead as a deterministic account of how particles and fields behave across a multitude of worlds, according to the many-worlds interpretation. Deutsch then proceeds to dismiss the epistemic notion of credences, but this need not follow from the rejection of physical probabilities. We, as cognitive agents with limited and imperfect capabilities, never possess perfect information about anything. Whenever we make decisions, which is all the time, we are forced to make those decisions under uncertainty, and unless we have some way of quantifying that uncertainty, we will be prone to making bad decisions. This is why probabilities show up in decision theory: it does not mean we are making decisions about stochastic events, merely that we are making decisions with incomplete or imperfect information. The probabilities are simply there to quantify the uncertainty. Bruno de Finetti showed how, using Dutch book arguments, we can start from a very innocuous and plausible notion of what consititutes a bad or irrational decision, and proceed to derive probability theory from it. Others, including Richard Cox and Edwin Jaynes, have shown how a primitive notion of inference can be used to derive probability. The upshot of this is that inductive reasoning using epistemic probabilities is very much alive and well and flourishing in statistical practice, and in particular in the machine learning/articifial intelligence domains. As to your specific question of what kinds of tests statisticians perform, there is no general agreement about methodology. The three main camps are classical (frequentist), Bayesian, and likelihoodist. The classical approach broadly involves forming null hypotheses, designing experiments to test them and rejecting the hypothesis if the results are significant (Fisher), or testing hypotheses according to their false positive and false negative error rates (Neyman and Pearson). Bayesians specify prior probability distributions and use data to update those distributions. Likelihoodists take two rival hypotheses and calculate a likelihood ratio that allows one to say which hypothesis is confirmed relative to the other. 

The conditional you describe in your question is the material conditional. It is a truth functional connective with the truth table T/F/T/T. It is just a truth function, which is to say that its truth depends only on the truth values of its arguments and not on their propositional content. This kind of conditional is not well suited to expressing causal relations, since "A causes B" is not a truth function of A and B. Causal judgements usually support a corresponding counterfactual conditional. If A causes B then we can usually say "if A were to happen B would happen", or "if A had happened B would have happened," and these are not trivially true merely because A is false. Counterfactual conditionals, like causal claims, are not truth functions and so cannot be represented by a simple material conditional. Several attempts have been made to explicate causal relations using a logical formalism. John Mackie analysed causal relations as an INUS condition, i.e. that the antecedent A is an Insufficient but Non-redundant part of an Unnecessary but Sufficient condition for B. David Lewis has an account of causation in terms of relations between possible worlds. Judea Pearl has an account of causation that can be expressed using a probabilistic do-calculus. None has achieved any general consensus. 

You are asking several questions here. Firstly, what kind of questions is philosophy of science concerned with? Here are some of the most important: How does scientific knowledge advance? Is there a distinctive scientific method, and if so how does it work? Is there a clear difference between what counts as science and what does not? Is there a clear way to demarcate good science from bad science? How objective is science? To what extent is scientific knowledge shaped by sociological or ideological considerations? What is the nature of scientific explanation? Or, what does 'explanation' mean in a scientific context? What is the relationship between observation, theory and model? What is the nature of a scientific law? What is the nature of causation? Do we need this concept, and if so what account can we give of it? Is some kind of determinism true, and if so, what are the implications? What is the relationship between different sciences? Is it entirely reductive in nature? Does science have anything specific to say about what kinds of things exist? Do theoretical entities such as electrons or quarks exist or are they just useful fictions? Can evolutionary theory entirely displace the concept of teleology? What do scientific theories such as thermodynamics, relativity and quantum mechanics have to tell us about the nature of time, space and matter? What does the general theory of evolution tell us about human nature and mankind's place in the universe? Are there ethical implications of scientific research? Are there fundamental limits to what scientific investigation is capable of teaching us? Are there truths that science is not capable of reaching? Secondly, what impact does philosophy of science have on science? This is harder to answer. Some scientists, including Newton, Einstein and Poincaré were very philosophical in their approach to scientific thinking. Some philosophers of science have been widely read by scientists, such as Karl Popper and Thomas Kuhn. Other scientists, such as Feynman, are dismissive of philosophical considerations. Thirdly, how has philosophy shaped our society and enriched our knowledge? This is a huge question, and you would need to study the whole history of philosophy to answer it. As far as science is concerned, we might say that philosophical thinking historically gave birth to the sciences. In the time of the ancient Greeks, all knowledge was considered philosophy. Once philosophers learned how certain problems could be solved empirically, philosophy gave birth to natural science. As late as the 18th century, the terms natural science and natural philosophy were interchangeable. Philosophical thinking also gave birth to psychology, linguistics, formal logic, economics, etc., so in a sense, everything we know ultimately comes from philosophy. 

The two different symbols on the page you link to are indeed different. The first is the turnstile symbol Ⱶ which may be read as 'proves', while the arrow → is material implication. These are very different. Material implication is a symbol in the object language defined by the truth table that you give, i.e. T/F/T/T. Turnstile is a symbol in the metalanguage that can be read as P proves Q, or Q is a theorem on P. The rule of conditional introduction can be understood as meaning that if Q is a theorem on P, then P → Q is a theorem. More generally, it might be written like this: if Γ is a set of propositions, then from Γ,P Ⱶ Q, one can deduce Γ Ⱶ P → Q. If Γ together with P proves Q, then Γ proves that P materially implies Q. This is called the deduction theorem. In natural deduction, we can use the rule of conditional proof to the same effect. You may assume any P you like, proceed to prove Q from it, then discharge the assumption to introduce the material implication P → Q. As to logical constants having corresponding introduction and elimination rules, this is no accident. In the Fitch system, the logical constants are specified by these rules. The idea of harmonious introduction and elimination rules was introduced by Gerhard Gentzen and taken up by various others. The idea is that the corresponding I and E rules should be 'inverses' of one another, in order to ensure that they don't have unruly consequences. In a famous paper back in 1960, Arthur Prior ("The Runabout Inference Ticket" Analysis 21: 38-9) showed that defining logical constants without restrictions could allow you to prove anything. This inverse relationship between the I and E rules is called logical harmony. Michael Dummett argued that classical logic has no harmonious way of defining the rules for negation, while intuitionistic logic does, though this has been disputed. If you would like to follow up with some more information about logical harmony, these papers might be useful: Steinberger, F. (2011) “What harmony could and could not be”. Australasian Journal of Philosophy 89: 617-639. Rumfitt, Ian (2016) “Against Harmony”. Forthcoming in Robert Hale, Crispin Wright, and Alexander Miller, eds., The Blackwell Companion to the Philosophy of Language, 2nd edition. Oxford: Blackwell. I believe both papers can be found on philpapers.org. 

Alice: People should not be allowed to keep dangerous animals in their homes because of the risk that one escapes and injures somebody. Bob: But zoos have lots of dangerous animals and they never injure anybody. Bob is clearly missing the point, which is about whether dangerous animals should be allowed in homes. Zoos are run by competent professionals. I guess this is what you mean by arguer doesn't know how to argue. 

The kind of conditional you are referring to is often called a counterfactual, because the antecedent is typically false. Lewis regarded these as quite different kinds of conditional expressions from so-called indicative conditionals. Lewis broadly follows a similar path to Stalnaker and uses possible worlds to explain their meaning. Stalnaker has it that a counterfactual "if A then B" is true if B is true in the most similar possible world in which A is true. Lewis modifies this by allowing that there might be a whole set of relevantly similar possible worlds, without requiring that there is a uniquely most similar one. The term 'similar' here is difficult to cash out in practice, because to get plausible results, it is necessary to give priority to possible worlds with the same laws of nature as our own world, even if this implies that tiny miracles have to be posited to account for the divergence between the possible worlds and the actual world. This in turn leads to problems accounting for how to quantify the size and ordering of such miracles. In his book "Counterfactuals" Lewis develops this idea into a formal logic called VC. To apply it to your example, which we might naturally express subjunctively as "Mostly, if on a Saturday morning I were to go to the gym, I would wear a suit and tie," would on Lewis' account be: in possible worlds which are similar to the actual world, but in which, because of a small miracle, the counterpart of me has decided to go to the gym, in most such circumstances my counterpart is wearing a suit and tie.