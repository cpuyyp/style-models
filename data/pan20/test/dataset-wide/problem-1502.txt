Basically, the code just looks consistently written. That being said, it's not really organized. The Bad 

Really, all of my objections are related to this tenet of software engineering, and especially object oriented programming: Do one thing, and do it well. Putting validations into your domain objects means they are serving a dual purpose: Hold data from a storage medium AND ensuring it is valid. Do one thing and do it well. The domain object should hold data. The validation layer should ensure things are valid. Putting validations into your storage manager means it is serving a dual purpose in the same manor. You should be able to swap out one layer for another with minimal refactoring. If you have to copy and paste of rewrite lots of code, then your application needs additional layers with looser coupling. 

shouldn't work because - well, imagine this: runs and now temp is set to the last node. Then, the check is ran . Because the last node is not null, it will run , and because you're already on the last node this means that temp becomes null. The check then runs again, and as temp is null it moves out of the loop and attempts , which doesn't work (and probably triggers an error) as temp is null. You're gonna want it to check the next node before it sets temp to that value, as it does currently. As for code review, the logic seems sound, and presentation is up to you, however if this were my code there would be a few things I'd do personally, however I'll put an example instead of points: 

Trying to use JavaScript like a class based language is what you make it. It sounds like someone was expressing an opinion, rather than imperial evidence. As for your implementation, it's very confusing how you'll expect to use the object. Be very careful with mixins or, "multiple inheritance." If you need multiple inheritance, I would argue that you need Composition over inheritance. 

This seems pretty clean to me. It's very testable, which is a definite must-have. It also decouples the reformatting of user input from the view-model. Looser coupling between layers is a positive thing. The downside is that you'd need to create a service for each view model. I'm going back and forth in my head whether this approach is best, or if defining some custom class and property attributes might be more worth while, and then use the service to process any object in a generic manor by looking at the attributes associated with a view-model property. Some pseudo code: RegisterViewModel.cs 

The Sieve of Eratosthenes works by going through and marking all numbers that can be divided into, essentially. Take your input "n", for which you want to find all the prime numbers up to it. The sieve starts at 2, and multiplies 2 by increasing amounts until the multiplication is about to exceed the value "n" - in your program, this is accomplished through the integer division and then iteration up to the calculated result. So, as it multiplies the values together, it marks the result as non-prime. Meaning that 2, 4, 6, 8, 10... etc are all set in the bitarray as 0 (meaning non-prime in this context). It moves on to the next value, so it starts at 3. The process repeats as it marks all multiples as non-prime. Time to move on to the next number - 4. As 4 has been marked as non-prime, it skips over 4 and moves on to 5. This continues until it finally reaches the number which is the value of its square root, so when you are using the sieve to get primes below 100, that means the algorithm checks the multiples of values from 2 to sqrt(100), so 2 to 10. It doesn't need to go past this value as all prime values above that share multiples which values that have already been checked. So, for example, if we moved past 10 to check multiples of 11, we'll get 22 (which is divisible by 2, so has already been marked non-prime) and 33 (divisible by 3). The values which remain with a value of 1 are prime. tl;dr The algorithm goes through all prime values below or equal to sqrt(n) and marks their multiples up to n as non-prime. The remaining numbers must be prime. EDIT: The code above adds 1 to the div operation, which I didn't mention in my explanation. EDIT 2: This specific modification of the sieve is essentially the same as the original sieve, however rather than removing square values during the normal removal process it removes them separately at the end. 

Loop structure's OK, logic's reasonably good. There is obviously a Java library alternative of , but I assume you knew that. Some efficiency issues with excessive toString() and string-ification of what could be character operations. Here are some tips: 

Use where nulls are not possible, not . is only used locally -- keep it local. Referencing it outside the method can only be erroneous, so it shouldn't be visibly exposed to make that possible.. Carry calculation from is OK here, but could in related algorithms be brittle -- it can't handle a digit-sum > 19 as the maximum carry it can produce is 1. If addition completes with a carry of 0, it will output an unnecessary 0 digit. If Strings are your inputs, you should probably build a String as the result via a StringBuilder -- not an ArrayList. should be called or , if you're building the result in it. Build using StringBuilder in reverse order, and do it by character calculation rather than toString() if you want to maximize efficiency. Return the result from your function, and do the printing in main() instead. there. That way you have a general-purpose function and a fixed-purpose main() method for testing. 

I'm learning Java too! Looking at this the only thing I might suggest is that you only do the calculations that you need to. You could then remove all answer variables and print the result of the calculations directly, saving time and memory, albeit not much. In terms of presentation, I personally would use lowerCamelCase for variable naming, e.g. firstNum, and I would also indent all of the cases as they are within the switch block. Finally, for I'd make sure there was no space there. Despite what I say for the presentation, that part of it is totally up to you, so do what you prefer, as long as it looks clear! 

Permissions are better handled by a service, so that you can more easily unit test that layer, plus the permissions logic becomes portable between presenters to promote DRYness of your code (Don't Repeat Yourself). 

This way all of your rule classes are hidden. All of the validation rules are portable because they are created inside a model specific class, and it's easy to use an IDE's auto complete feature to discover which rules are available since the RuleBuilder class has strongly typed methods encapsulating each rule. On top of that, the IRule interface just accepts a value and not a model, making each rule unit testable to ensure your validation library is functioning properly. And for those who do some .NET/C# development, this pattern probably looks familiar if you've used the FluentValidation NuGet package for Visual Studio. Say what you want about .NET development, but there are some gems out there. I do like the pattern that FluentValidation uses. 

But do whatever suits you - as long as you follow the standards of any projects you're working on, the presentation of what you code in your own time is totally your decision (many will disagree with the way I've presented the code and many will agree - opinion varies from person to person, and there's no one way to present that pleases everyone). Furthermore, a comment about your comments. I didn't fix them in my example above, however I would be more specific to the code you're commenting by. So, for example: . That comment mentions things that aren't happening in the line directly below - I would make sure to comment each line as it happens in this case. I would also be a bit more explanatory about each line - so for example, in that same line that I was just commenting on I would say rather than , something along the lines of - although I would describe each process on separate occasions, as I mentioned, rather than together like I just did for the sake of example. 

This way all AJAX is centralized and abstracted away. None of the rest of the application even needs to know AJAX is at work. You could rewrite your repository layer to use asynchronous calls to the browser's IndexedDB for an offline application and you wouldn't need to refactor any of your other code. Controllers Over the years I keep coming back to this basic pattern when creating controllers in JavaScript. Controllers: 

There is absolutely no difference between and . The and properties created using are superfluous, and only serve to add weight to your JavaScript code. There is no logic behind the getting and setting of those values. On the contrary, consider a case where you do want some special logic around setting a value. In the code below, the property is a reference to a DOM node. When setting the DOM node we also want to set properties for the and to which the DOM node belongs: 

Use where nulls are not possible, not . is only used locally -- keep it local. Referencing it outside the method can only be erroneous, so it shouldn't be visibly exposed to make that possible.. Carry calculation from is OK here, but could in related algorithms be brittle -- it can't handle a digit-sum > 19 as the maximum carry it can produce is 1. If addition completes with a carry of 0, it will output an unnecessary 0 digit. If Strings are your inputs, you should probably build a String as the result via a StringBuilder -- not an ArrayList. should be called or , if you're building the result in it. Build using StringBuilder in reverse order, and do it by character calculation rather than toString() if you want to maximize efficiency. Return the result from your function, and do the printing in main() instead. there. That way you have a general-purpose function and a fixed-purpose main() method for testing.