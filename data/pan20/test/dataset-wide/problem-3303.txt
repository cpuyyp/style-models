I do not think ellipsis is the right way to approach the phenomenon, but it is probably what you want to produce an at least semi-plausible parse. My preferred analysis of such cases is developed in a dependency grammar (DG) theory of syntax; it does not involve ellipsis. If interested, I will happily provide the articles that I have written that examine the RNR phenomenon in some detail. 

The smallest answer fragment is fine, and the complete sentence answer is also OK, but the intermediate fragments are all bad. Why? Has anyone encountered an explanation of this aspect of answer fragments? Perhaps it is a trait of certain ellipsis mechanisms in general. Does anyone know? 

A couple decades ago when I was in middle school in Colorado, I was briefly taught to diagram sentences using the Reed-Kellogg system. I have heard that the practice of teaching sentence diagramming in schools in North America has fallen out of favor. But at Youtube, one finds numerous videos instructing one how to produce them. I am currently writing an introduction to a translation of Lucien Tesnière's The Elements of Structural Syntax. Tesnière's stemmas are similar to the Reed-Kellogg diagrams in a major respect. I am therefore interested in learning about the extent to which the Reed-Kellogg diagrams are still taught in schools in North America and elsewhere. Does anyone know the extent to which the art of diagramming sentences is still taught in schools today? Is the practice gaining or losing? Thanks. 

No, that analysis can hardly be defended in terms of X-bar theory. The analysis shows D'2 lower in the structure than D2, and DP2 as a sister of the head D2. A projection of a head can never appear lower in the structure than the head, nor can it appear as a sister of the head, but rather it must appear above the head. There are a couple of points that should be kept in mind when analyzing the structure of NPs. Perhaps the most controversial issue concerns whether noun phrases are NPs or DPs. The question assumes DPs, but that is a controversial assumption. A number of frameworks (Head-Driven Phrase Structure Grammar, Construction Grammar, Categorial Grammar, Meaning-Text Theory, etc.) assume NPs, not DPs. Hence one could reject the analysis shown based on this controversy alone. For arguments for and against DPs, see this article: $URL$ My personal view is that the traditional NP analysis of noun phrases is more defensible, and I think that the example illustrates a difficulty with the DP analysis in general. Most discussions of the DP-hypothesis remain with single determiners; they do not explore stacked possessives like in the example in the question. Consider the following examples in this regard: 

The question can be explored in terms of N-ellipsis (noun ellipsis, also known as NP-ellipsis). N-ellipsis is illustrated in the following b-sentences: 

I am not aware of literature that addresses the subject matter in the question directly. I have, however, thought about such cases quite a bit, and I have an unpublished paper that addresses some of the relevant data in part. The interrogative word how is often a predependent of an adjective. It is asking for the relevant degree associated with the property expressed by the adjective, e.g. how big, how loud, how helpful, etc. These are relatively straightforward adjective phrases (APs), as pointed out in the question. I do not see anything mysterious or unusual about them. Concerning examples with what, I think what often functions basically just like which, e.g. What apple do you have? = Which apple do you have?, What ideas is he promoting? = Which ideas is he promoting? In these examples, both what and which are functioning as interrogative determiners. On an NP analysis of noun phrases, they are predependents of the nouns that they introduce. But the analysis of examples like what a beautiful child are indeed more challenging. They are challenging because it appears as though the noun child takes two determiners, what and a. This seems to be a particular idiosyncracy of what. Other interrogative determiners are incapable of doing the same, e.g. *Which a beautiful child. However, English has a construction that seems related, e.g. 

An answer that produces a list of clear criteria that could be used to test the predictive accurracy of grammar frameworks would be difficult. The grammar frameworks listed in the question generally all have components that can be accessed to make predictions, and if a given grammar framework is lacking in a specific area (it makes no predictions in that area), it can always be augmented in one way or another. Neverthelesss, I think I can provide one major criterion. In the list of grammar frameworks mentioned in the question, worth noting is that two are constituncy-based (MP and LFG), one of them is dependency-based (MTT), and the other two are (to my knowledge) not so explicit about the dependency vs. constituency distinction (RRG, RCG). In a number of my papers (such as in the one linked to in the addendum to the question), I attempt to call out all constituency-based theories by pointing to the diagnostics that are commonly employed in syntax textbooks to identify syntactic structure, i.e. to the tests for identifying constituents (e.g. topicalization, clefting, pseudoclefting, proform substitution, answer fragments). I emphasize that all constituency-based frameworks make a terribly inaccurate prediction in this area. Here's an example: (1) Fred likes music. 

I think iterative fits best, although durative is another possibility. The verb keep can express iterative and/or durative aspect, meaning that it indicates the repetition of an event or action that persists. Iterative and durative are listed as an aspect in the Wikipedia article. Looking at that article, however, the number of aspects that one needs to accommmodate all the various morphological and lexical mechanisms across languages that can express what we broadly construe as "aspect" is very large. My assessment is that the science in the area is not exact, nor can one expect it to be exact based on all the nuances. The grammarian therefore has a measure of freedom in the nomenclature he/she employs to denote the aspect at hand. The particular inventory of aspects posited is likely to vary from one grammarian to the next. The situation is no different in other areas of grammar. The inventory of semantic roles (thematic roles) assumed varies from one grammarian to the next. The inventory of adjunct categories (causal, concessive, temporal, manner, etc.) also varies from one grammarian to the next. Why should it be any different for the inventory of aspects that the grammarian posits? There is, however, a more concrete way to approach the classification of a verb like keep. It is not an auxiliary verb, since it does not license subject-auxiliary inversion or VP-ellipsis, nor does it accept not as a postdependent: 

The challenge that such data present should be apparent. The theory of predicate-argument structures that one assumes should be in a position to recognize when the object is part of the predicate (as opposed to being an argument of the predicate). In this case, a shower is not an argument of took, but rather it forms the predicate with took. In sum, I think the endeavor is facing major challenges. There is no consensus about what does and does not count as a predicate in theories of semantics and syntax. The difficulties sketched here are going to require a decision after every turn. 

I am not aware that anyone has produced a typology of predicates in the sense of semantic predicate-argument structures. Of course loads and loads is written about semantic predicate-argument structures, but any attempt to produce a typology of these predicates is going to be fraught with much difficulty, since determining exactly what should and should not count as a predicate is difficult. I myself have written about how predicates are manifest in syntax, so perhaps I can help by illustrating the difficulty facing the intended endeavor. But first a couple of points of opinion: I suggest ejecting the "CFG" part of the question. Attempting to produce a typology of predicates based on a CFG backbone is going to be difficult and convoluted. Predicate-argument structures are much easier to deal with using a dependency-based model. I can back this claim up with my own research (if anyone is interested). Assuming a dependency-based model of syntax and semantics, Igor Melʹc̆uk's works are a good place to start. Two of his most known works are listed here: 

This sentence might mean that there are two babies, one in the crib and one on the floor, and we like the one in the crib, not the one on the floor, or it could mean that we like to keep the baby in the crib as opposed to, say, on the floor. The difference in meaning is captured in the syntax in terms of whether in the crib is a dependent of baby or of like. A second example: 

In both cases, the speaker is saying that Susan is definitely hungry, regardless of whether Tom does or does not know it. Verbs that allow the secondary predicate to bear presupposition like this are known as factive. Verbs like 'say' above that block their secondary predicate from bearing presupposition can be designated as non-factive. To sum up, the presence of presupposition is closely associated with the nature of predicates. Some predicates allow presupposition, whereas others do not. There is no easy path to understanding in such cases. One has explore which primary predicates allow presupposition, and which ones do not, and which types of secondary predicates always bear presupposition, and which ones are influenced by the primary predicate.