I also speak Standard North American English, and encounter problems understanding and being understood. For instance, a "root" is a [rʊt] for me, and if I ask a Kenyan what their word for [rʊt] is, they will have no idea, but if I ask for a [ruwt] then they can tell me. People from outside my US zone sometimes giggle when I say [rʊt]. My dialect can be particularly hard to follow if you don't know the patterns of syllable reduction and glottalization that typify Our Language ("tear" and "terror" are a minimal pair for vowel length in my dialect). I witnessed a Kenyan guy pointing out a [reobad] in a tree, which a bunch of Californian passengers thought was a "rail bird", and not a [lɛpɹ̩d]. My advantage was that I'm familiar with that dialect. I also found Newcastle-area English to be utterly incomprehensible for about a week, even though I knew all of the phonemes and had heard all of those sounds plus a lot more. It's just that I had never encountered that particular system before. The "heaviness" of an accent is really a measure of your subjective ability to map from what you hear to a particular meaning. It's actually not just pronunciation, quite often those other dialects have constructions that don't make immediate sense even if written down. There's a certain amount of quaint difference between US and posh UK English, but I have a hard time, sometimes, with non-posh UK especially working class lexicon. Intelligiblity is relative: relative to the complexity of mapping from one system to the other. The reason why RP is not so difficult for me to understand is that I've been exposed to bits of it most of my life, thanks to Monty Python and their ilk. So I would look to prior exposure as the factor that makes an accent easy vs. hard – it's not something intrinsic to the system. 

Look for very widely-spaced glottal pulses in the last 80 msc or so of [ɛ] in [lɛt], which is creaky voice on the vowel. You may also find that F1 and F2 are a bit higher in [lɛt]. (Pick a point defined from the beginning of the vowel, so that you aren't just measuring a consequence of the shortening of the vowel in [lɛt]). 

I am looking for candidates for the "most frequent" context-free spirantization of t. One almost-example is that Indo-European t became θ in Germanic via Grimm's Law. Another is that proto-Bantu t became r̥ in the Sotho languages. The problem is that Grimm's Law is not actually context-free, since it does not apply in clusters with fricative. (This also knocks out gorgia toscana which applies postvocalically). The Sotho example goes through because there are no contexts where t is preserved. I am not committed to the example being historical changes so if anyone can actually show that /t/ becomes a spirant of some sort in the synchronic phonology of a language, so much the better. I also know that context-free spirantization is rather rare. My goal is to empirically evaluate a claimed frequency difference between "t→θ" and "t→s". 

It depends on what you mean by "similar". Diphthongs like ai, au, ey, øi can be called "falling" diphthongs and ones like uo, ea, yæ can be called "rising" diphthongs. That refers to change in assumed sonority where a is said to be more sonorous that i. 

The primary problem that metrical trees are intended to solve is the representational problem of what the rule system actually produces. Prior to L&P 77 and as exemplified by the SPE analysis of stress, stress was a feature with scalar values theoretically ranging from 0 to infinity, though in practice values were capped at 5 because of this embarassment of riches. The SPE system also had a general convention that when a rule adds 1 stress to some vowel, all other stress numbers in that cyclic domain are reduced by 1. This system with stress numbers stuck out as a formal oddity, allowing way more possible types of representations than could be empirically motivated in language. There is no segmental analog to the stress-reduction convention, for instance you do not find that making one segment [+coronal] causes all other coronals to become one degree less coronal. Metrical trees limit the kinds of distinctions that can be made, which from a theoretical perspective is a good thing. The main insight of metrical systems is that language only needs a two-way distinction between "strong" and "weak" (or you may fill in the blank with "prominent", or "stress"). That distinction was combined with a theory of phonological constituency and a theory of locality (which effectively restricted how far you could look up to compute distinctions -- thus "4 stress" was not accessible information). Then you have a classic overgeneration argument: "SPE theory allows you to have all of those classes of rules and representations yet there is only evidence for class A; Metrical theory only allow you to have class A; therefore metrical theory is the superior theory". The line-drawing aspect of metrical trees is of course just a graphical means of representing certain formal properties, and the subsequence real question was, exactly what claimed properties are justified. The most robust distinction is the prominent / non-prominent distinction, which can be applied at all sorts of levels (i.e. within the syllable; between pairs of syllables; between pairs of pair of syllables...). The second is the concept of "constituency", where in fact there has been significant retreat in the amount of structure postulated (typically just syllable, foot and word). Earlier metrical theory tended to rigorously follow the principle of binary branching to the point that you had to break a string of 8 syllables up into a 4-deep tree grouping of syllables, whereas the facts on the ground never necessitated saying anything more than "syllables group into feet this way" and "this foot is the most prominent in the word" (I will remain officially neutral about the questionable construct "colon" between foot and word). SPE stress theory heavily exploited the assumption that "phrasal stress" and "word stress" are the same thing. With word stress vastly simplified under metrical theory, the next step, initiated by Liberman and subsequent work by Pierrehumbert, was to account for supposed stress differences at the sentence level, which was done by analyzing the facts in terms of tones in an intonational system. L&P77 does extend metrical representations to phrases by exploiting some of the power of metrical grouping, but when recursive constituency is eliminated as it was, the question arose as to how to deal with what such structures did -- and there is vast literature answering that question. So, prominence and some theory of constituency are implicit in metrical theory, and are well motivated, but recursive constituency which is also part of classical metrical theory is not well motivated. 

This answer by Richard Wright indicates that it does, assuming a "a fairly thorough and evenly distributed set of vowels", and similarly this summary says it performs well in reducing variation from physiological differences. By "account for", I assume you mean "effectively control for", since actual vocal tract length measurements cannot be part of the computation. 

As it happens, there is a model of speech production -- the Convertor-Distributor Model (Phonetica 57:128-38) -- advocated by Osamu Fujimura, which denies that there is ordering of elements in a syllable position such as "onset". To handle clusters like [pr], the model has bigger inventory of "segments", so [pr] would be a voiceless labial alveolar trill (assuming a trilled r). I don't agree with the model, but the point is that your proposal corresponds to something that exists in linguistic theory. 

The terms "hard" and "soft" aren't used in linguistics; instead, we describe the difference in terms of the difference in production (the vowel of "father" is a back vowel transcribed as [a] or [ɑ], and the vowel of "at" is a front vowel transcribed as [æ]). In the case of English "f" and "v" (or German "v" and "w"), [f] is voiceless and [v] is voiced. There are a certain number of ordinary terms that get pressed into service in describing sets of sounds, for example hard and soft, slender and broad, light and heavy, clear and muddy, which generally express some kind of positive / negative attitude towards one of the sounds. Usually, the negative term is used to described the "less ordinary" sound. For instance, voiced consonants like b,z may be called "heavy" as opposed to p,s which may be called "light". And it turns out that voiced consonants are somewhat less "ordinary" than voiceless consonants. But there aren't any standards for using these terms in ordinary language, thus when someone says that a certain sound is "hard", they could be referring to anything, though presumably something that they don't like. 

An aspirated glottal stop would be a fundamental contradiction (the vocal folds would have to be both spread apart and constricted). "Tenuis" does not preclude having secondary articulation, so [ʔʷ] wouldn't be an example -- tenuis is about phonation. This is a case where the wiki entry is in error, and the wiktionary has it right. There are languages with [ʔʷ], [ʔʲ] although they may be described as "glottalized w" etc -- there is no distinction. Examples are Yurok, Klamath, Lushootseed. 

For the most part, yes. The phoneme inventories of the languages are not identical so Serbian has <Ћ>=/tɕ/ and <Ч>=/tʃ/ and Russian does not have <Ћ>. There are "major" differences such as <Г> representing [ɦ] in Belarusian and [g] in Russian. Languages also differ in whether spelling reflects phonological rules, e.g. final <В>=/v/ in Russian is [f]. Belarusian changes /v/ to [w] finally and this does result in a changes of letters to <Ў>. 

The concept of "formant" was introduced by Gunnar Fant as "the spectral peaks of the sound spectrum |P(f)|", and it is general enough that it is applicable to any acoustic analysis. Of course linguists can embellish the concept in ways only applicable to speech or even phonological analysis, but strictly speaking, there is no difference. 

You seem to be talking about "neutralization". For example in German and Russian, word-final d and t are both pronounced [t]. We have a version of that in English, where the past tense d is pronounced [t] after certain sounds (as in "baked, based, laughed"). To make any sense of the English pattern, especially, you have to not think in terms of "letters", and instead think in terms of the sounds that the letter-sequences represent (somewhat obscurely in English). Given some two similar but distinct sounds of a language (like t,d) the language may have some rule which eliminates (neutralizes) the phonetic difference between those two sounds so that they are pronounced the same way. It could be that d becomes pronounced like t, or t becomes pronounced like d, or both are pronounced the same way like [ɾ], for example English write, ride having the contrast between t and d but writer, rider being pronounced the same way, in most American dialects, with [ɾ] in place of t,d.