You aren't conscious of the state of retinal molecules in your eye (cis vs. trans), but your vision is completely dependent upon it. You are really overstating what one can infer from having subconscious motivations etc.; almost everything that happens in our heads is subconscious. Also, you don't need to do a study to notice that some people (adults as well as children) act differently without being aware of it when they are hungry (as an example). So apparently at some level there are very obviously subconscious mental states. That said, there are numerous studies that involve various not-consciously-perceptible cues that significantly affect various behaviors of people. (Many of these are priming experiments; there's an overview of some relevant experiments from Scientific American.) So, yes, people have looked in carefully controlled studies, and yes, there's something there. But that hasn't much to do with dualism. 

Tegmark, unlike Lucretious (I think?), claims that consciousness is an emergent property, not fundamental. Contrast the "breath, heat, air, and a fourth nameless substance" which are apparently elemental with "the way information feels when being processed in certain complex ways". He certainly is not suggesting fundamental atoms of qualia like Democritus. Tegmark does, however, make stronger claims about the distinct existence of consciousness (composed as it is of simpler components) than do many. For example, liquid water vs. water ice are distinct substances made of the same molecules, and the two have drastically different bulk properties (and a sharp transition from one to the other). Tegmark's conception of consciousness seems to me of this form: made from components but clearly its own unique thing with unique properties (but these arise from the mathematics of information processing, not a certain type of substance). In any case, he's squarely in the camp of standard methodological naturalists, without even introducing anything extra physically. 

This question has a very clear intuitive answer: no, it would be horribly wrong. The task of the philosopher is then, typically, to explain why that intuition is correct. (Or, alternatively, to explain that it is okay, after which all the non-philosophers sigh, mutter about ivory towers, and make sure that philosophers aren't allowed to get anywhere near life-ending machines.) Perhaps surprisingly, many moral frameworks are not very well equipped to deal with these sorts of questions in a satisfying way. You can declare by fiat that life (or human life, or something) has intrinsic value regardless of whether there is anyone there to suffer from or enjoy it. The categorical imperative is also not that clear here: maybe the depressed scientist would think that it would be fine if anyone else took the same actions as he was about to. Utilitarian frameworks are not very good at balancing conflicting goals (the scientist's, to end his suffering, and most everyone else's, to keep living) since almost anything obvious you plug in as a way to combine individual value or desire yields highly counterintuitive results. But I think when the stakes are so high we can do an end-run around most of the typical concerns. First, it is typically considered immoral to do things to adults that they really don't want done even if they end up enjoying or not minding it. (We don't extend the same courtesy to children to nearly the same degree.) Thus, the point about the suffering is a red herring: you don't need to consider suffering to come to a conclusion. You merely note that most people want to keep existing, and the more of them you kill, the more horribly you're violating their wishes. You can work this into either consequentialist or deontological frameworks (choosing goal-fulfillment as a good, or via some typical formulation of the Golden Rule, for instance; not every choice will yield "the right" outcome, however). Second, in this example there's another level at which it's the wrong thing to do: evolution selects those creatures which manage to maintain life; as an evolved creature, this scientist is doing the most un-fit thing he could possibly do, and thus from an evolutionary perspective is utterly broken. Only those species that avoid such brokenness will survive and matter in the long run. Many individuals of some species--including humans!--sacrifice their own lives in order to maintain the species, and our moral instincts are powerfully aligned towards this kind of survival when necessary. Inasmuch as morality must serve evolutionary constraints, the scientist would be doing the most immoral thing possible. 

Corrosion isn't a great example because it is a bulk property of stochastic molecular interactions. There will always be some variability in what happens (perhaps undetectable, if the materials are identical at the atomic level); furthermore, when one says "will", one really means "the probability of failure is so low that one would never expect it to happen if all matter in the universe were placed in this condition over and over again for trillions of years". At a deeper level, favorability alone is not enough; some processes are intrinsically stochastic as far as we can tell (see questions on QM). For example, the probability of interacting with a neutrino is exceedingly small; you have to scale up the volume of your target immensely in order to have some chance of seeing something. (At a deeper level yet, see Michael Dorfman's answer about the nature of causality.) 

If you are asking is the meaning in your head all in your head, then of course the answer is yes. (I'm going to leave aside the details of your formulation, because it is specific to a degree that goes beyond what can be validated with present-day neuroscience.) But that misses the point of the twin-earth thought experiment. I don't think it's the best thought-experiment, but it's widely known, so let's go with it for now. In brief, suppose there is a twin earth where everything is identical and functions identically at a superficial level but where H2O is absent and there is a substance XYZ instead (which everyone there calls "water"). Now, in a sense, "water", being all in the head of both Earthlings and Twinlings (let's call them), are exactly the same thing, because they are the same thing-to-them. In particular, their mental states might be completely indistinguishable from each other, and thus we'd say that the meanings are indistinguishable. But in another sense, they are not the same because the substances are distinguishable (though not presently to Earthlings and Twinlings) and Earthlings mean H2O and Twinlings mean XYZ. And this is a very important sense of meaning since we have to interact with the outside world. We expect that meanings like those conveyed by "water" will attach naturally to whatever additional things we find out about water including whether it's actually H2O or XYZ. So after considering Putnam's argument one can accept your thesis and yet want more, which is to also have a theory of how many different brains can refer to the same (and/or different) external entities. The purely internal account makes that exquisitely difficult. (Yes, you eventually have to get there by considering how the models built by your brain end up with an expectation of various invariants including that XYZ isn't quite what we mean by "water", but adding that extra layer of interpretation makes the logical structure harder to see.) 

Chemistry is anti-entropic. Whether a reaction will occur or not depends on what is called Gibbs Free Energy. The fundamental equation is 

An uneducated but rational person can't distinguish between the two for precisely the reasons you stated. At that level, it is "just another religion". (I would not use the word "religion" quite that broadly, but "societally organized system of practices and beliefs" is quite a mouthful.) They might get a little bit closer by noticing, "Hm, I have an iPhone6, and it works. Everyone seems to agree that the Science-Priests made that possible. Maybe there's something to it." But that just shows them that the Science-Priests are closer to the truth of things when it comes to making iPhone6s than are, say, Jesuits. (The Jesuits will probably not claim that the goal of life is to have better smartphones, anyway.) The difference comes when the uneducated but rational (and skeptical) person starts to educate themselves, when they do have a crash course in relativity and cosmology. Because, uniquely, science (properly done) has exactly that rational and skeptical mode of thought suffused through it. When you trace it back (and you can say this, but one ought not believe it until one actually sees it happening), the justifications for belief are rooted in observations (of the world), not in opinions (of leaders and/or supposed deities). That is the key difference: when you dig, you have answers rooted in objectively reproducible effects. You can come to your own opinion; you don't need someone to give it to you. So my response is: yeah, from a distance it's hard to tell the difference. You've got to dig into some details to realize just how well-supported the main findings of science are (and dig more to know when sociology and politics have interfered to such an extent that you ought not be so confident of the reported findings any more (and maybe more yet to know when science-religion conflicts are really a case of knowledge vs superstition, and when it's custom-of-group-A vs custom-of-group-B)). There isn't, as far as I can tell, any shortcut. But at least there's a road to walk, and you don't have to go very far before you can tell that it's really well-lit. 

This is a much more appropriate question for cognitive scientists--if cognitive scientists do not know the answer, then we do not know the answer. It is an empirical matter as to how in control we are, as there seem no logical problems with everything from "complete control" to "no control at all (but perhaps with the illusion of control)". To convince yourself of this, note that there are aspects of behavior where each seems to be the case. For a control example: in the game Simon Says, people can reliably control themselves from following orders when the order is not prefaced with "Simon says". For lack of control: images with multiple contradictory interpretations (old woman/young woman, dog/rabbit, Necker cube) often generate an illusion of control if you ask someone to try to flip the percept when they feel like it. Typically, people report control, but the statistics of flipping percepts are identical to people who were not attempting control (and if you give them a cue on which to flip, they are unable to). Having decided that this is an empirical matter, the best thing to do is collect data or talk to those who have. 

The diminishing comes far earlier--once you accept a physical account of mind. This is what raises the question: why bother with religion when even our minds are just non-supernatural processes? However, if you decide that physical implementation is a cool thing for your deity or other extraordinary power to do, then of course religious experience is going to be physically implemented. Noticing that in fact it is doesn't really change anything. The next diminution of value doesn't come until you can show that the religious experience is caused by sequences of ordinary physical interactions with ordinary statistical properties, at which point you can pretty much rule out any sort of injection scheme where enlightenment is smuggled in where normally you'd only have randomness. We haven't demonstrated this directly--it's fantastically difficult--but there is no reason to suspect anything out of the ordinary. And even then it's still not logically inconsistent (even if it's not terribly parsimonious) to believe that all of the causal chains and random sampling was cleverly set up by a (near-)omniscient being for all time, and the physical implementation is just the mechanism by which said being chose to play out the entire scenario (to the degree of specificity desired).