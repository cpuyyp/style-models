Your query won't be giving you what you want because it will only consider a row a duplicate if BOTH ID01 and ID02 are duplicated. I'm sure there are better/prettier ways to do this but this query should work: 

First you'll need to nominate a computer that's going to act as the database server (obviously this will need to be one that all machines running the application can connect to over the LAN and that is always going to be running when the application is in use). We'll call this machine "server" On "server" download and install SQL Server Express from here: $URL$ - you'll want the version that is called "ExpressAndTools" and make sure you get the appropriate 32/64bit version depending on your hardware and OS (installing with default settings should work well enough for your purposes). Next you'll also need to download and install SQL Server Management Studio on the computer that currently has the application/database on (it's from the same link as above and is just called "MgmtStudio"). Once that's installed open it up and should pop a dialog asking for details of where to conenct. Enter "(localDB)\V11.0" as the Server name, select "Windows Authentication" and click on "Connect". You should then see an entry in the left hand column called something like "(localDB)\V11.0 (SQL Server V11.0 - domain\username)", expand that entry out and you should see a folder called "Databases", expand that and you should see an entry matching the name of your application's database. Right-click on that Select Tasks -> Backup. In the backup dialog make sure it's set to Backup type: FULL with the destination being "Disk" and click on "Add" to chose a folder/filename for the back up and then click Ok to start the backup. Once that's completed you'll need to copy the back up file to the "Server" computer, then open Management Studio on there and when it asks you for connection details use "localhost\sqlexpress" with Windows Authentication. Once your connected expand the node labelled "localhost\sqlexpress" in the left hand column, right-click on "Databases" and select "Restore Database", in the resulting dialog change the "source" radio button to "Device", click on "..." and then click on "Add" and browse to the backup file from earlier. Once that's selected it should populate the rest of the restore fields for you and you can just click "Ok". Once that's finished you'll need to update the "App.config" (or "Web.config" if it's an ASP.NET application) to reflect the new database connection string. You should be able to find a line similar to thi: 

So, my thought it that something else is locking up the database. It's possible that several updates to the same row are being made and maybe that is causing contention. Re MYSQL locking strategy, if you're updating a single row (in a transaction) you don't lock the entire table right? Query cache settings 

I have a couple of questions about tuning a MySQL (5.5) database. It seems the clients database server has never had any performance tuning done. Upon reading around, it seems the one thing is to set to "80% of the available RAM". Now, the physical size of the database is about 5Gig, and the available RAM on the server is 32Gigs. It seems to make no sense to me to make the . At the moment I have set 

Which, reading around (and running mysql-tuner script) seems about sane. My question is: Is it a bad idea to have a greater than the size of the database itself. Is it bad to effectively have all the data in the ? Warming the cache The other part is warming the cache. Reading other posts on the net, the suggestion is to run a bunch of to warm it. If I do that, I get the amount of RAM at point (1) in the picture below. If instead I run I get a heap more RAM used. Which, I assume means that I have more data loaded into the cache. Which seems good to me. 

This is reporting that it is taking 26 seconds for an update to occur. I see this in the logs, so, I'm not 100% sure that it is what it is taking on the MYSQL end, but, I assume it is. From reading around and other stack overflows it seems like setting will make the writes faster at the expense of being less ACID compliant. Now, the site I work on does not process $$$, and even if it did, losing 1 seconds worth of transactions would not be an issue at all. These 30 second timeouts are far more of an issue. My question really is, is it likely that this is really a issue? Also, just being paranoid here, can I still trust that will be respected in the case that I change this value. I do still want that when I run something in a transaction that I can be guaranteed that it will complete or not complete . Any help / pointers most appreciated! Update 

We had been running a SQL Server 2005 server for many years at our company when just recently, we ran into some trouble. The server was configured with RAID 5 and had one hot spare disk in the array. One of the disks failed, and then a second one failed shortly thereafter. Unfortunately we did not have backups of much of this data (please spare me the "should have had backups" comments -- I am aware of the importance of a solid backup plan). So we are two disks down, we have no official DBA, and the database is inaccessible. One of our IT personnel attempted to recover the RAID array and we believe the RAID began rebuilding but he was ordered to shut it down because there was concern for potential data loss during the RAID rebuild. We sent the entire server to a data recovery company. They spent two weeks working on the server, first by imaging all the drives and then by reconstructing the data from the RAID. I received a hard drive that contains all the "recovered" files. This is a collection of mostly database files (MDF) and trans logs (LDF). Each database that was on the server consisted of only a single MDF and a single LDF. I do not currently have access to the original server, so I have been attempting to attach these databases to another server running SQL Server 2005. However, when I try to reattach any of the databases I run into problems. Some of the various errors I have received are shown below. I have had no luck restoring any of these files. I followed the steps outlined in this article, and even then was unable to restore any of the files. We paid a large sum to the data recovery company for the recovery of the data from this server and I have been tasked with proving without a doubt that the data are or are not useful to us. I simply don't have the experience to know for certain, so I put the question to you, dba.stackexchange: Is there any way at all to restore these files? 

We had a SQL Server 2005 server that housed roughly 200 low/no traffic archive databases, and that server was not backed up to any other device. The database files (MDF and LDF) were stored on a RAID array, and when the RAID controller failed we were concerned we were going to lose our data. We sent the RAID controller and array to a data recovery company, and they were able to recover most of the files, but in some cases we have the transaction log but are missing the main data files. Is it possible to restore the database to the last transaction (which should be just after the database was created) using just the transaction log, or is this something that can't be done?