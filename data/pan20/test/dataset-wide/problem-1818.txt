Your local MTA thinks that mail for whatever domain you tried to send to should be sent to the local machine, but there is no user with that username on the local machine. Ensure that the server's hostname is not the same as the domain name you are trying to deliver to, and that sendmail is not configured to deliver mail for that domain locally. 

Handshake would seem to suggest that the controller is having trouble talking to the drives. I'd suspect electrical interference, bad cables, or possibly a bad controller. In the latter case the motherboard would need to be replaced. You'll only find the culprit by a process of elimination, by testing each piece of hardware separately. 

By default, libvirt only binds VNC listeners to localhost, regardless of what you specify on the command line. To change this, you need to edit the appropriate option in . 

GraphicsMagick was compiled with X support, and links to some X libraries, so that its functions that require X will work. From the README: 

Don't reinvent the wheel. Use logstash to get your logs off your systems. Have logstash send the logs to elasticsearch. Use the kibana front end for analytics. This combination is so common it's known as the ELK stack. And it's all open source. 

Your local X server does not support the "RANDR" extension. Most likely this is because it's a Windows-based X server. Try using a different X server, or better yet a Linux desktop (as all Linux desktops have this extension). 

You linked to the documentation, but you seem to have missed the part, right under the command it told you to run, which says: 

The writer will block waiting for the reader to become ready. What you really should worry about is what happens if s3cmd fails. Then you have to start all over. 

Here are some things you haven't thought of or were not aware of: Windows Server has a feature known as Desktop Experience which can be installed to make it work almost exactly like its corresponding client OS, even accepting the same GPU drivers. A typical rackmount server will not fit into your existing audio racks. While the width is the same and they use the same rack units for height, they are much longer in depth. Your typical 19" audio rack has 16 to 18 inches of depth, while a typical server may need 32 to 48 inches of depth. On the other hand, you can buy tower-style workstations which can be flipped on their side and mounted in a rack. The height on these is usually 4U, but they often are shallow enough to fit in an audio rack. 

You can use cgroups in an LXC container, as they are namespaced, but OpenVZ is very old technology and I highly doubt you will find a way to make it work. If you can, you should start converting over from OpenVZ to LXC as the former is likely to be abandoned sooner or later. It's LXC that all those OpenVZ devs have been building. 

For squid, set up SSL Bump and dynamic SSL certificates, and be sure to add your new CA to your users' web browsers. 

If you're using Shorewall, then you're about 90% done already. Otherwise you'll have to configure your own NDP proxy, such as ndppd. 

I'm creating and destroying virtual machines all the time, in order to test various services or applications, and so I'd like to use avahi to connect to them by their names so I don't have to use valuable space in my head for dynamic IP addresses that will likely be gone tomorrow anyway. This doesn't always seem to work. I currently have two CentOS 6.3 virtual machines, both running avahi-daemon, but one of them can't be reached by its name. The problem machine: 

I use group variables to define things which are common to a group (though there are precious few of these that won't fit in the role variables or defaults instead), group variables for global stuff, and host variables for anything that's unique to a host. For instance, I give a unique MySQL root password to every host, but I have SSL ciphers and protocols defined in so that, if they need to be changed, there is one source of truth for them. 

By default, messages to are posted in the room, where all administrators can read them. You can change this if necessary. For other addresses, simply add these to your vCard and you will begin receiving mail for them. 

When converting HTTP request headers to variable names, nginx will convert hyphens to underscores. Thus, a variable representing the header will be . This suggests that your should be declared as follows: 

All of your systems have a mask, while they should have a mask. Only use for localhost. In the Debian config, you should change: 

Don't set them up this way unless you have routed the block of IP addresses to a vRack. And, with such a small block, you should not attempt to route it to a vRack or you'll only have one usable IP address. If you route the block directly to your dedicated server, you may use each address individually with a /32 prefix and your existing default gateway. For instance: 

(Note that I've completely removed from this, as there's little good reason to be running this within a screen.) 

What this means in English is: If the client sends an HTTP/1.0 request, either an HTTP/1.0 response or HTTP/1.1 is acceptable, but HTTP/1.1 is preferred. The reason this is done is so that one end may advertise the highest version of HTTP that it can support, so that the other end may choose to upgrade its protocol support (if possible). Both ends will then decide what protocol version they can both live with. This design also helps to deal with buggy implementations, as RFC 2145 stated. It was also envisioned at the time that there may be further versions of the HTTP protocol, both minor and major versions, and the rules were meant to help ensure interoperability. Google's RFC-ignorant approach may break once HTTP/2.0 is finalized. (You know it in its draft form as SPDY.) 

It appears you've installed incompatible RPM packages for MySQL from a third party source. Probably these came from mysql.org. Unfortunately they aren't well integrated and cause problems like this. Currently the best integrated current MySQL RPM packages that I'm aware of are those provided in the remi repository. Using these packages will prevent problems like this in future. 

The real path of least resistance, of course, is to deploy to a Linux server. While the same is true of Linux, that you usually need a compiler, many distributions provide precompiled packages for the more popular software. 

You may be able to abuse to divert this mail. Unlike the other directives you mentioned, this one operates on outgoing mail. While it's not capable of dropping it, it can send it to a different mailbox, where you can then take appropriate action on it (such as suspending the customer who sent the mail). In you would have: 

Yes, but there are some caveats. This is accomplished through Server Name Indication, an extension to Transport Layer Security. What is Server Name Indication? Server Name Indication (RFC 6066; obsoleted RFC 4366, RFC 3546) is an extension to Transport Layer Security which allows the client to tell the server the name of the host it is trying to reach. SNI is compatible with TLS 1.0 and higher according to spec, but implementations may vary (see below). It cannot be used with SSL, so a connection must negotiate TLS (see RFC 4346 appendix E) for SNI to be used. This generally happens automatically with supported software. Why is SNI needed? In a normal HTTP connection, the browser informs the server of the hostname of the server it is trying to reach using the header. This allows for a web server on a single IP address to serve content for multiple hostnames, which is commonly known as name-based virtual hosting. The alternative is to assign unique IP addresses for each web hostname to be served. This was commonly done in the very early days of the web, before it was widely known that IP addresses would run out and conservation measures began, and is still done this way for SSL virtual hosts (not using SNI). Because this method of transmitting the host name requires the connection to be already established, it does not work with SSL/TLS connections. By the time the secure connection is set up, the web server must already know which hostname it is going to serve to the client, because the web server itself is setting up the secure connection. SNI solves this problem by having the client transmit the hostname as part of the TLS negotiation, so that the server is already aware of which virtual host should be used to service the connection. The server can then use the certificate and configuration for the correct virtual host. Why not use different IP addresses? The HTTP header was defined to allow more than one Web host to be served from a single IP address due to the shortage of IPv4 addresses, recognized as a problem as early as the mid-1990s. In shared web hosting environments, hundreds of unique, unrelated Web sites can be served using a single IP address this way, conserving address space. Shared hosting environments then found that the largest consumer of IP address space was the need for secure web sites to have unique IP addresses, creating the need for SNI as a stop-gap measure on the way to IPv6. Today it is sometimes difficult to obtain as few as 5 IP addresses (/29) without significant justification, often resulting in deployment delays. With the advent of IPv6, such address conservation techniques are no longer necessary, since a single host can have more IPv6 addresses assigned to it than the entire Internet contains today, but the techniques will probably still be used far into the future to service legacy IPv4 connections. Caveats Some operating system/browser combinations do not support SNI (see below), so using SNI is not appropriate for all situations. Sites targeting such system/browser combinations would have to forgo SNI and continue to use unique IP addresses for each virtual host. Of particular note, no version of Internet Explorer on Windows XP supports SNI. As this combination still represents a significant (but steadily decreasing; about 16% of Internet traffic in December 2012 according to NetMarketShare) portion of Internet traffic, SNI would be inappropriate for a site targeting these user populations. Support Many, but not all, commonly used software packages support SNI. (Omission from this list doesn't necessarily mean lack of support; it means there was a limit to how much I could type, or I couldn't quickly find the information in a search. If your software package isn't listed, searching for its name plus should reveal if support exists and how to set it up.) Library Support Most packages depend on an external library to provide SSL/TLS support. 

Have your favorite monitoring system monitor nginx's status or just spot-check it yourself for a snapshot of what's going on now. 

The server's IP address and port to connect to will be displayed on screen. To connect to a remote listener, enter: 

There are many ways to do it, but first you will want to search for binaries linking to . My one liner is (broken into separate lines for readability): 

Until recently (1.4.3) memcached had no support for authentication, so anyone who could connect to memcached could do whatever they wanted. You can set up authentication if you wish, and your version of memcached is recent enough. You also should firewall the port, allowing only specific IP addresses in your network to connect to memcached. This will help regardless of version. 

You don't. You use so that it handles this situation cleanly. It operates perfectly well offline using RPM packages directly, provided that all the necessary dependencies are available or already installed. 

All of the IP packets you send have an invalid checksum of 0. This may be an artifact of how the OS captures the packets, so we'll ignore that for now... This is probably causing you a lot of grief: It appears your ISP is repsonding to some (but not all) of your requests with ICMP Time Exceeded responses, which has the effect of severing your connection. For instance, see your SYN packet in line 324 and your ISP's response from 97.75.190.142 in line 327. Since your packets have a TTL of 64 set in them, this strongly suggests your ISP has a routing loop somewhere in their network. 

Close the client's account for Terms of Service/abuse violation. IF it was unintentional, you can accept them back after they've cleaned up their computers. But if it happens a second time, cancel the account forever. 

This means that nginx will not serve error responses generated by PHP, but have nginx handle them instead. Thus you get into your endless loop. To resolve the problem, remove this directive (it defaults to ) or set it explicity to . 

Most of the necessary missing libraries seem to be in the EPEL repository. I have no idea why PostgreSQL would want to provide them separately, and older versions at that. Beyond that, it seems something is probably wrong with your CentOS base repositories. For instance, is located in the base repo, but your copy of yum didn't find it for some reason. My guess would be that cPanel probably broke them, along with all the other stuff it breaks. So, I would start by installing the EPEL repository and check the other repositories to make sure you're actually getting CentOS base and updates. After that, I'd see what is still broken, and go from there. 

That level of latency is just fine for talking to a database. Many high traffic sites use a similar architecture and may even have higher latencies to their databases. I wouldn't worry about that. The only thing I would worry about is whether others can sniff the traffic. On OVH's network it's not likely, as their switches generally don't flood unwanted traffic all over the place, but it does potentially open you up to ARP poisoning attacks launched by other OVH customers. Rather than use the public network, I would use OVH's vRack. This creates an isolated network which cannot be seen by other customers at all. 

Now the logs will only contain denied traffic that was directed toward your host. From the man page: 

It's not in Belarus. And the website you used has outdated information. That IP address space really is shared-use private nonroutable address space. But some or all of it was previously assigned, and some routers might still know old routes for it. As for why you're seeing it in traceroutes, I could not say for sure. It is Comcast, after all, and only they can give you a concrete answer. But since the whole point of that address space is so that ISP networks can give their routing infrastructure private addresses, freeing up some IPv4 addresses, it stands to reason that Comcast is slowly but surely renumbering their infrastructure to use the RFC 6598 addresses. 

I suspect you got a bad disk image from wherever you got it. You can obtain a clean ISO image directly from Microsoft. (Login with the same credentials you signed up for DreamSpark with.) It could also be that something is wrong with your DVD drive. Try verifying the media after you burn your DVD. 

When using , by default it only matches against the command name (i.e. ). This won't match when the pattern you're searching for appears in the arguments. For this, you need to use the option as well: 

Type it "blind"? Hit Enter as soon as the (garbled) language selection appears, since it times out quickly. Then tap F6, Esc, type in and press Enter. You were probably missing the need to hit Esc right after F6. 

The means that the interface is bedded onto the motherboard. Other names apply for add-on cards: names refer to PCI (and its modern derivatives) expansion cards, where the first number is the slot on the motherboard which they're plugged into, the second number is the port on the card (a card may contain multiple ports) and the third number, if present, is a virtual function number. If it really bothers you, you can rename the interface to anything you want. 

RADIUS uses UDP ports, but you have not opened UDP ports in your endpoint configuration. Once you fix the endpoint configuration to open the correct ports, you should be able to communicate with the FreeRADIUS server. 

This occurs when the emergency shell is enabled. This debugging shell is spawned when dracut is unable to mount the root filesystem. Since the passwords are on the root filesystem, authentication isn't really possible at this early stage. Check the kernel command line for . This option should be set to or be absent, to disable the emergency shell. 

Of course, anything using NFS version 3 or 2 needs to be migrated to NFS version 4 (or higher) or decommissioned and replaced. But that's another post... 

You're using an OpenVZ based VPS. As with all container-based virtualization, you are limited to the kernel modules provided by the host. Your options are: 

The node did redirect you. As the documentation explains, the client is expected to connect to the specified node to retry the request. The server does not do this. If you're using , then you must use the option if you want it to follow these redirects.