So the notion of a world may in principle differ from a single row of a truth-table, or a set of rows of a truth-table. The first axiom would certainly apply for a single row of a truth table, but does not make very much sense for multiple rows of a truth-table; conversely, the fact that necessity is defined in terms of further worlds accessible from a single world mean that it does not make sense to treat a world in terms of a single row of a truth-table unless one is happy to see either the notion of 'necessity' or the notion of 'accessibility' trivialise. The Wikipedia page goes on to note various possible properties that the accessibility relation can have, including: 

The example of clouds is interesting because it is difficult to draw the boundaries between a system we would like to describe, and its environment. This problem exists in miniature for a great number of things, including apples, tables, and people. Is the air in your lungs a part of you? What if the air is dissolved in your bloodstream? What if that air is absorbed by a cell of your body, or a cell of some micro-organism living inside of you? Is that micro-organism, which is a part of an ecosystem which might be instrumental in your digesting food, a part of you despite being of an identifiable (non-human) species? The problem, it seems to me, is one of dividing the world into disjoint systems which we then (quite often) imagine interacting with each other. On the macroscopic level, with humans and apples and tables, this mode of reasoning is more-or-less unproblematic, assuming we ignore the (potentially) common provenance of the apple and the table from a single tree, and what happens to the apple once you manage to eat it. With clouds, we're struck with the fact that while there is definitely some difference between the interior of the could and a relatively water-droplet-free point on its exterior, there is no particularly meaningful way to define the boundary of the cloud even once we acknowledge that there can be gradients in water droplet density in the air, at least not on spatial scales of centimeters. (On scales of dozens of meters, we frequently recover the ability to make meaningful statements on such topics as light albedo and opacity.) So when you want to talk about a cloud as an object, or even merely as a substantially different aggregate system from clear sky around it, you often have to ask to what level of precision that you would like statements you make about the cloud to be evaluated. The very same is true of humans, and apples, and tables; only the precision which we may casually assume, without much reflection, in those cases is often quite extremely high. 

and suppose that q ⇒ (r v s). On the whole, we would tend to say OB¬r and OB¬s. However, given the choice, it is reasonable to suppose that it would be better to make them cry than to make them violent. That is: there is a sense in which OB¬r holds more force than OB¬s. This would suggest that OB(s/q). Suppose that you decide to tell someone a hard truth: then we have 

Perhaps the most important thing about a set S in itself is its cardinality, as the labels of the elements are not important to the set-in-itself (compare to the notion of a thing-in-itself, which is to metaphysics as a set-in-itself is to the philosophy of mathematics). As soon as you entertain the power-set, you are no longer considering the set in itself: although the elements of the set may as well be anonymous (albeit distinguishable) if you are only considering the set in itself, the distinguishability of the elements is significant to the distinguishability of the subsets, in which case the cardinality no longer characterizes the subsets. If every subset of order k is indistinguishable from every other subet of order k, perhaps because we have adopted a dogma that all sets of order k are "essentially the same", then indeed one cannot obtain a power-set ℘(S) which has a cardinality larger than S for infinite sets S. However, the question one should ask is why all sets of a given cardinality should be regarded as being for all intents and purposes as equivalent. I certainly do not regard a set of two ten dollar bills as being equivalent to a set of two twenty dollar bills, nor to a set consisting of one ten dollar bill and one twenty dollar bill. The reasons for this may be uninteresting to set theorists, but this is only to say that the subject matter of set theory cannot be neatly protected from application to non-set-theoretic problem domains. In this respect, I have a motivation to care, if I have a set of bills consisting of two twenty dollar bills and two ten dollar bills, which subset of two elements I consider. Thus the structure of the set, which may fade away if I consider the elements to be interchangeable tokens due to some detachment I have from the contents of the set, reasserts itself through the significance I attach to the elements as a consequence of the significance of the elements to a wider context. It is difficult to find a better example than the integers, if one wishes to consider an infinite set. Perhaps the difference in the significance of a googol compared to a googol-plus-one to me is pitiful, but I recognize that there is in principle a difference, and to the extent that I should care at all about the number googol, I should care about the difference between googol and googol-plus-one. Thus I should care about the difference between any two positive integers in principle; and so the proliferation of subsets of the integers of any given cardinality is of interest. If I grant this, it is difficult to avoid the fact of the uncountability of ℘(ℕ). The fact that we interpret ℘(ℕ) as a set with an extension larger than any possible notation system is an interesting one; one might suppose perhaps not that there are different degrees of infinity, but that there are systems of concepts which exceed our ability to reason non-constructively, by virtue of the fact that we can always construct a subset of the naturals about which any enumeration of proofs says nothing. However, distinguishability of labels is in essence the foundation on which mathematics is established, and to suppose that all sets of objects of a given cardinality are equivalent, despite that their elements may be given distinct labels, is to suppose that we can abolish all of the structure which mathematics is meant to describe. It is perhaps a self-consistent viewpoint, but I would maintain that it is an unproductive one, to say nothing about whether it is a necessary one. 

Classical logic obviously isn't such a logic, because implication is material implication; and common forms of intuitionistic logic don't work either, because the weakening inference which we want to avoid is usually valid (e.g. as a logical axiom at the link above). A possible starting point for such a search would be relevance logic, which at least is non-explosive and non-weaking: implications must actually allow one to derive the conclusion from the premise by reasoning with non-logical constants. It appears that paraconsistent logic (which is related to intuitionistic logic by a duality relation) may also provide an avenue for research, albeit one in which the notion of "falsehood" is quite profoundly problematised. But in any case, even while considering logical systems which are neither "weakening" or "explosive" in the sense above, you must somehow overcome two obstacles: 

Now, if you'd rather focus on the necessity of the symbology: technically you might not need it — but would you teach algebra without arithmetic symbols? The symbology of logic is nothing more or less than an efficient notation — albeit one without which you can accomplish very little in practise except muse deeply about the square of syllogisms a la scholastic philosophers. 

This is a bit of a circular question. What do we actually mean by 'truth', especially when referring to using notions of truth in reasoning about the world? An instructive exercise is to ask why we should think that boolean logic as we use it today is 'true'. When we get down to it, it seems to me that when we say that it is 'true', we actually mean that it is useful: we find it to be a reliable tool with which to do reasoning, and we find that whenever we make a mistake, the error can be traced to the ideas to which we applied logic, and not to the logic itself. That is to say: it seems a mode of reasoning which is as good as the information upon which it acts — it is subject to the maxim of Garbage In, Garbage Out, but it is not so brittle or sensitive to error that it is useless. This prompts us to trust it. If this is true of boolean logic, could another more subtle logic also prove similarly useful, or even more useful? Of course, boolean logic forces us to make precise distinctions when asking questions, which is potentially useful. But when considering the world around us, we run into famous problems such as the Sorites paradox. These paradoxes can be described as paradoxes of language rather than logic, but the distinction is perhaps illusuory: just as we are encouraged to ask whether a pile of sand is "a heap" or is not "a heap", we ask ourselves whether the Sorites itself indicates "a weakness of language" or "a weakness of logic". Because logic is only as useful as the language which is fed to it, and language only as useful for reasoning as the logic applied to it, the real question is how best to repair the flaw in the Language/Logic system, if we decide that it is worthwhile. But the real teaser is not the Sorites, and artificial distinctions in colloquial language, but advances in science. What ought we to say about Newtonian Mechanics — is it true? Well, it's useful enough for most purposes. It's not badly wrong. It's not correct enough to high enough precision for all purposes, but you can build bridges, skyscrapers, and lunar expeditions relying on just Newtonian mechanics and a bit of crude material science. And what about the Earth being round? If by 'round' you mean "a sphere", you should account for the bulging at the equator due to the centrifugal force; and if you mean "an oblate spheroid", you're still neglecting the variation in elevation. These descriptions are practical approximations to a very complicated 'truth', that is, a complicated state of affairs; and yet they're not what we would describe as "horribly wrong". They're just not 'perfectly' right; you can get closer to the truth by a more detailed description. So, if you're principally interested in ordinary language (which I'd be careful about — is cold a thing that can seep into your bones, does the Sun really rise and fall in the sky?), I would say that we already implicitly recognise that multivalued logic is more useful — 'truer' — than boolean logic. It's just that when we demand precision, we don't know how to move forward except to replace the complicated messy notion of truth with the idealised boolean one, and hope that degrees of error are numerically measurable, so that we can capture the truth (and our uncertainty about it) in quantity rather than verity. The only question is whether this is the best way of doing things. I rather hope that mathematics yields a multivalued logic which has greater practical power than boolean logic. And although it would be a formidable task to do so, I don't believe that it is a priori impossible. 

(The restricted quantification version would be written as , or "There are two [different] Elvises Presley".) We can carry out the inner quantifier to the front, which is putting the formula in prenex normal form: 

If you want to talk about logic versus computer science, how about computational complexity, which was basically founded by logicians? 

The following answers are informed by my background in the mathematical sciences. Hidden in the distinctions above are questions of certainty, epistemology, and expertise. 

This goes to show that when considering infinity — as well as many other sorts of mathematical concepts — what structure you consider important, that is what structure you require to be preserved by the transformations you wish to consider (such as matching from one set to another), will determine whether or not two objects are equivalent, or distinct. If you care about concepts such as dimension or measure, and demand that they be preserved by any functions you consider, then you can never bring a short line segment into one-to-one correspondance with a long one, or with a square. However, if you allow arbitrary functions, which may completely ignore the structural notions that you cherish, then you may obtain results which you find surprising, or even revolting to your intuition. This would ultimately be because there is a conflict between the ideas that you wish to consider, and the way in which you are considering it. 

which is the same as as before. Conversely, if there is some Scot who eats their porridge with something added, we have 

where it turns out that p is the Gödel encoding of P itself. Within the formal system S expressing P, the proposition is true only if S is consistent. From an external formal system T, we can prove P — which is why it's called an Incompleteness Theorem — because the external formal system can explicitly incorporate the fact that the logical structure of S can be encoded in number theory, so that propositions about integers are on the same logical level as propositions about P ∈ S. But the integer p is not itself a logical proposition, which is true or false; it is an encoding of a proposition. And in the meta-theory T, P ∈ S isn't a proposition either; it is an object within a mathematical structure, just as p is, and in T we have a specification of an isomorphism between S and a sturcture of the natural numbers. In this case, however much you may think to yourself in your native or adoptive languages, English and Arabic are not the languages of evaluating truth or falsehood, but rather more-or-less formalized systems for encoding truth or falsehood, in which it may be easier to arrive at logical conclusions; and you encode and decode propositions from those languages to some mental model in which you evaluate propositions as either true or false. The encodings and decodings to and from various languages are more or less like recursive predicates E and A on the expressions e, e' in English and a, a' in Arabic repectively, where if you are skilled there is a truth-preserving and reversible map t such that E(t(a)) ≡ A(a). But unless you have been taught how to evaluate A, you will be unable to evaluate any expression a of a proposition in Arabic as true; you will only be able to evaluate