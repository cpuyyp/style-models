Yes I believe your understanding is correct. The statement is indicative because it expresses a known state of affairs. The statement is conditional because it uses the classic "if/then" or "antecedent/consequent" structure. The statement is deontic because it refers to what "ought to be" or what is "permissible." A related statement, "if it were necessary that you live in Texas, you would be ought to watch football," would be classified as subjunctive deontic conditional because it expresses an unknown state of affairs. So, yes, you're correct as far as I can see... 

And now this is the moment that intuition and supervenience converge. Our intuition, along with everything else we feel, think, say, do, believe, and want - is the product of metabolism - a series of biochemical reactions. Since chemical reactions are governed by infallible laws of nature, therefore any process that inherits from them (via supervenience) is likewise infallible (including intuition). $URL$ $URL$ $URL$ 

I think that you're confusing validity and soundness. The validity of an argument is determined purely by its form, not by whether or not its premises are true. On the other hand, a sound deductive argument is a valid argument where all of the premises are true. 

I like @jobmark's excellent comments, just to summarize them as I understand them (since they're the answer to the question), it's more that these concepts are types of self-deception than that they are actually distinct from it. In fact, Anna Freud, for example, saw most of the defense mechanisms (not just denial but also things like projection, etc.) as forms of self-deception. To quote the second paragraph, 

The revisionist views basically view self-deception as a form of "motivated reasoning" or wishful thinking - e.g. "proposition x makes you feel anxious, so you resist believing it." 

Ethics deal with a set of rules governing conduct that a group of people have agreed upon, while morals deal with an individual's sense of right and wrong. They are intertwined in that each may inherit from the other. However, one may have a "moral dilemma" when their own sense of morals is at conflict with the ethics of their group. For example, let's say you are a cashier at a grocery store. You agreed at your hiring not to let customers steal. The act of doing that, therefore, is unethical. However, you notice a homeless family wander in and the children are hungry. They take a loaf of bread and some milk and leave without paying. You believe it would be immoral not to let them have the food they need. Your sense of morals and ethics are now at a direct conflict. 

First, I must admit I'm having trouble formulating this question because I'm somewhat confused about the relationship between these two items (cognition and qualia). Please let me know if I can improve it or if it should be multiple questions. I was recently reading a textbook (Cognitive Science: An Introduction to the Study of Mind by Jay Friedenberg and Gordon Silverman) on cognitive science. Unsurprisingly, it advocated functionalism. More surprisingly, it flat-out admitted that there isn't a good functionalist account of qualia. (I've heard this objection from John Searle and others but was surprised to hear an advocate of functionalism admit so bluntly that that was a problem). This strikes me as a rather fatal flaw: is cognition without qualia actually really consciousness? Can you actually separate the two? On the one hand, you have an experience and awareness of thinking. Who or what, exactly, is having the awareness? Cognition appears to be able to change and cause qualia; Albert Ellis et al (along with advocates of the Schachter-Singer theory of emotions) have argued (successfully, in my opinion) that your feelings about (and, therefore, your experience of) a particular situation is heavily cognitively mitigated. How can experience be both cognitively mediated and there be an awareness of cognition? You can also have "subconscious" cognition of sorts, which seems to be a problem for those who say that you can't separate the two. Is it possible to have consciousness that consists only of cognition (but not qualia)? Does it even make sense to talk about one but not the other? 

This must be a common example, as Wikipedia has the example same example in the article on Paradoxes of material implication. The article explains the paradox as: 

I've been interested in philosophical skepticism lately as I've just recently learned about the close relationship between certain schools of ancient skepticism and fallibilism, which I'm told is the most common epistemology of modern science. I've also learned about one particular philosopher among the ancient skeptics, Carneades, who originated the modern concept of probability. According to, for instance, The Internet Encyclopedia of Philosophy Carneades made use of the concept of probability, or in his tongue to pithanon, as the answer to the common response to skeptics that it is simply impractical to live while denying the existence of knowledge. While neither reason, ideas, nor perception can form the basis of knowledge, they all grant us probabilities that we can use to investigate our other impressions of reason or the senses, at least enough to get along with our practical affairs. Am I paraphrasing his philosophy wrong? So while I used to see philosophical skepticism as entirely different than scientific skepticism, or our modern scientific worldview in general, now I wonder if they are perhaps much more alike than I realized. Maybe it is simply that the concept of "knowledge" has changed over the centuries. For instance, whereas before maybe knowledge was identical with certainty and absolute truth, and now days our concept of knowledge is so infused with fallibilism and pragmatism, that in the ancient context we would find ourselves far more at home in the skeptic school than in any of the others. Basically, from the position of modern science, were the ancient skeptics right all along? Would it make sense to begin our epistemology of science with them? 

The Stanford Encyclopedia of Philosophy's article on self-deception describes a few common views of self-deception. Broadly, there are two major types of views: intentional approaches (which model self-deception on interpersonal deception) and revisionist approaches (which don't). The intentional approaches that the article describes are: 

No. In general, a fallacy is a fallacy. The fact that the conclusion happens to be true doesn't change the fact that it's a fallacy. You can come up with fallacious arguments for almost any conclusion. I can give you really bad reasons to believe that the sky is blue; it doesn't change the fact that the sky is blue or that the reasons I just gave you are bad reasons. Here's another problem: what if we tried to extend the same reasoning to premises of arguments, too? For example, suppose we used the following argument: