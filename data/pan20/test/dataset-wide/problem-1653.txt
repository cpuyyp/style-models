Your specific exercise What you are describing sounds like a variation on a convergence/divergence exercise. In particular, I used one of THESE lifesaver cards. They are clear or opaque; with the clear cards, one stands in front of a window and looks through the card toward something very far away and as a result, the red and green lifesavers will come together and form a 3D image. One gets them to "lock," (verified by reading the letters on the lifesaver), holds, and then converges (crossing eyes -- same as looking at something very close) to form a 3D image from the red and green images. This is the same phenomenon as magic eye images. When one changes the point of focus to a point behind or in front of the image, the images from the left and right eye will superimpose upon one another and form a new, composite image, which appears to be 3D if different features are present in each of the respective images. See THIS video instruction for using lifesaver cards as a validation of my explanation. The video is from a Behavioral Optometrist, shown by the FCOVD after the name (Fellow in the College of Optometrists in Vision Development). I'm using my past experience and participation in vision therapy, combined with illustrating that this particular exercise seems to perform the same mechanics (focusing up close, then looking far away) to find a "field" one can examine for efficacy. With just the description alone, it may have been tough to figure out of such a method has been tested, but, if we can pin the words "vision therapy" to it... we have a much better base in the available literature. 

Interesting claim! My delving suggests that this might be a fine line between truth and woo. First, the woo. I have strong suspicious about the following quotes from your provided SOURCE. 

As we were looking for laundry detergent yesterday, I noted that my wife was quite swayed by brand reputation/impressions than price. She stated that she didn't think one type of detergent really removed stains. I asked if she'd ever consciously been aware of this and noticed, and she said "No." It's not hard to find some other references like this, such as About's list of top detergents HERE: 

Question: Will placing a remote under one's chin increase its range? Bonus: If so, is the mechanism known? 

BTU Discussion The British Thermal Unit is a unit of energy. Analogs would be the calorie and the joule. Thus, the Department of Energy has taken each fuel type and translated it to an energy per volume output. Thus, if we know that a gallon of fuel X outputs Y BTUs, and we know the average number of BTUs required to move vehicle type Z a given distance, we have an efficiency value for each type of vehicle that has been normalized from fuel type to energy. Then we can analyze the energy required to transport a vehicle with it's typical passenger load (9.2 passengers per vehicle for buses, and 1.57 passengers per vehicle for cars) and determine energy per "passenger-mile." We want a lower value here, since lower BTUs/passenger-mile means that it takes less energy to transport a given number of passengers a given distance. 

Edit: Wow, I hate to do this after being accepted, but I need to change my answer! Vartec made the fantastic point that I was considering one had to get the entire amount of alcohol in a shot into one's blood stream. He is correct that I completely goofed on the amounnt and should have focused on Blood Alcohol Content (BAC), not how much one usually has to ingest to get drunk. If we keep the rest constant below, assuming all alcohol inhaled is absorbed, we just need the point at which there are ~5mL of alcohol in the blood (assuming an average total blood volume of 5L). With this adjustment, this method becomes incredibly more possible. Again, my apologies for the whiplash. 

So, it appears that they were specifically looking at a simulation known to work acceptably for low-cost/low-investment "opinions/perceptions." I was far more interested in the implications for major beliefs such as religion, global warming, vaccines, etc. I'm leaning toward saying that this type of simulation has nothing to do with these types of strongly emotional, personal, family-history-influenced, local-culture, and [even sometimes!] evidence-based beliefs. It seems more suited toward simulations situations where individuals want to make a quick decision that is mostly irrelevant to the grand scheme, and move on. The rest of the paper is primarily discussing the mathematical results of the simulations, illustrating what percentage of "unconvincable" nodes were required to win the overall group to a particular opinion. 

Why do I bring this up? Because I think the causation lines (if any) may run the opposite direction. I would not be surprised to learn that critical thinking/analytical tendencies are correlated with lack of religion such that the former implies the latter vs. the latter preventing the development of the former. 

Now I diverge into experience/background. I deconverted from devout, wholehearted, fervently lived Catholicism about 18mos ago (full story if you really want it HERE). What I wrote above does track with my experience and my nature. I have always been analytical and curious. I'm an engineer and took things apart as a kid. I want to know everything by the time I die. I analyzed and analyzed before I could buy something because I had to have the best purchase supported by the evidence (specs, user reviews, magazine reviews, etc.). I fact-checked claims I heard. I made spreadsheets to make sure I had the finances to buy a laptop when I was in college. But, I never turned my critical gaze toward religion. I literally just thought it was correct (and that was supported by a conversion experience I had) and started from that point -- in other words, my intellectual investment was in theology and spirituality, not apologetics our the foundations for why to believe. One day I wondered if non-gospel writers had written about Jesus and was sorely disappointed by my research results compared to what I expected. That was all it took for me to pursue my religion just like all my other endeavors. I suspected that the best way to analyze it's truth was to suspect its falsehood and try to prove it back to myself. I've failed in these past 18mos and am a non-believer, but one who's still got some books on my to-do list in order to put the case to rest. I'm surrounded by believers (7 years of my adult life was spent building friendships and relationships with other Catholics), and my experience has been that many are critical thinkers... but I would almost describe it as them not being free or able to question their own religion when we get into discussions. If I construct a complete analog for another religion or particular diddy from pseudoscience, they will agree wholeheartedly. But it's like there's a complete disconnect when those same critical principles start poking around theism. So... my answer is that 1) genes probably have a lot to do with it in the first place and 2) my suspicion (yet to be confirmed by studies) is that indoctrination might be more accurately said to create a "shell" around one particular area such that one can be highly critical but still a believer. And 3) we all compartmentalize, but the beliefs just aren't as divisive and so we aren't nearly as aware of it. I'll end by saying that I think most religions don't have a very good intersection with test-this-claim-now areas of the world; their claims are not predictable, verifiable, testable, reproducible, universally discoverable, etc. Thus, I think I'm gaining leniency with particular forms of theism that don't really matter except in the believer's. Sure, phrases like, "I'll pray for you" may be grating, but many/most will still recommend chemo, counseling, etc. to get "real" treatment. It's like a play belief that they don't really believe. I'd be much more interested in whether indoctrination with things like homeopathy, crystal healing, etc. prevent critical thinking, for in those ideologies, there seems to be a direct suggestion that evidence isn't really evidence, that all "supposed" scientists are involved in a gigantic conspiracy and don't really know what they're talking about or don't have the "spiritual eyes" to see, etc. In those types of belief, I really could see a hindrance of critical thinking, because they entail a direct opposition to empirical evidence and other foundations of critical thinking in the first place. For the rest, I think their sources of evidence are generally one sided and many may simply never get the "itch" to research their beliefs -- or a crack in the shell that lets them do so. But, I'm skeptical that such occurrences prevent critical thinking elsewhere. 

This appears to have a valid concern (increased risk of scratching the screen when laid flat), but has been mistakenly extended into a blanket recommendation with no basis (nebulous concerns about TVs/monitors "going bad"). How did I come to this conclusion? I figured one way to go about this would be to look into LCD TV/Monitor manufacturer's manuals to see if there were any warnings about this. While not guaranteed, I'd figure those who make these devices should know about this and at the very least have a vested interest in not being liable for returns if customers broke products and no warnings were given. Well, pictures say it much better than words: