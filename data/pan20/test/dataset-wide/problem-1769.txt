First, I would strongly suggest not doing this. As others have far more eloquently put, blocking a specific country doesn't fix the problem , it just defers it slightly. Also, when users from that country see you've blocked them specifically, it will only motivate them to cause you more problems. That said, if you really want to do this, IPinfoDB provide a free IP geolocation database, 

An alternative option - you can patch away the 10-inbound-connection limit, something commonly done by people using Bittorrent. $URL$ 

The command on OS X is pretty crappy.. The one included with most Linux distros allows you to change the sort-by column using and , there is a coloured mode (by pressing the key), and a bunch of other useful options. Is there a replacement command line tool? Ideally I would like for OS X, but because it relies on the filesystem (see this thread) it has not been ported (and probably will never be) The obvious answer is "Activity Monitor", but I'm looking for a command line tool! 

To visualize and administer LDAP, there are many options, here are some. I personally use ldapsh to perform some quick ldap edits. It visualizes your ldap tree as directory structure which is easy to navigate and make edits using vim or your fav editor. 

Thanks for the great responses. Since I will end up using the existing insfrastructure, I am going to answer my own question. :) I am not sure if this is a valid method but I gave points for all possible solutions. In short: I will be using SCCM for deploying Windows OS and packages. MDT for managing and testing images. When a client PXE boots, it will have two options: Install Windows/Install RHEL. After the authentication, the OS installation is automated. SCCM is used for post deployment operations and for linux I am going to test puppet/bcfg2. Thanks again. 

Over the past several days I have been trying to get the shadow to work with samba but haven’t been successful. Can someone check below config and let me know if I am missing something? We are using Equallogic SAN and iSCSI LUNS to mount volumes. I can cleanly access samba shares on Windows 7 clients but just not shadow copy. I have referred the official how-to but couldn’t get it to work. I see these messages in the logs. Any help is deeply appreciated. 

does have some additional features, like and things like holding packages (to stop them being upgraded) - nothing you couldn't achieve via other commands/methods, it's just more unified and nice to use. 

There is a Python 2.6 package for Ubuntu, $URL$ but only for the and releases. You could possibly grab the file and install it on previous versions, but things may break.. If fails you, compiling from source is trivial: 

Wouldn't a bootable Linux "live CD" (such as Knoppix, Ubuntu), or a BartPE disc be a better solution? If the system is "borked", surely it's going to struggle to run any VM software.. It also means you can access/edit/delete files that would otherwise be locked 

Err, if you left the monitor plugged in, would it have crashed? Pretty much any OS can run happily with no monitor attached. The only related problem I can think of is some motherboards refuse to boot if no video card is installed. There should be no performance difference between having a monitor connected, and not. There is a difference between running X11 and not (say to run Gnome, or KDE etc). The X server takes up memory and CPU cycles like any other process.. Disabling it is a good idea for a server, since most tasks can be done easily over SSH (or on the local terminal) 

We are using SCCM to deploy Office 2010 and it has worked very well. Most of the customization is done using the 'setup.exe /admin'. We divide desktops, laptops and servers to different collections(similar to OU in AD) and then further division based on tiers of deployment like IT, Accounts, sales, Executives. If anyone is looking for Windows 7 deployment, then SCCM 2007/2012 is way to go. It has a little learning curve as some of things just don't work out of box and need to be worked over-and-over again. But the end result is worth the effort. I used this link as reference for packaging Office 2010 for SCCM. 

I have found one way of doing this but looks like it will only partially solve it. Number of conflicting users: 250 Number of hosts with homeDirs: 50 seed for script. 

I went thru the same path recently where one of the top executives of my company wanted a home PC(not domain managed) to connect to office remotely and use his TWO computers(which has 3 monitors). Server side: We use Juniper's WebVPN and setup a user role to map the office PC to a local loopback address using secure applications manager. 

Of course you should try and install everything via your package manager (so you get automatic updates and such), but I tend to keep old versions of Python around, and putting them in shouldn't interfere with at all. 

Aside from providing a pretty console UI when you run with no arguments, it combines the various commands (and ) into one utility.. To search for a package and install it, using apt-get: 

Is there a script that will show memory usage as a graph, for example as a pie-chart, with each process being being a separate slice? I'm not looking for something like Munin to graph memory usage over time, but rather show the memory usage per-process at a single point in time. To make my request even more obscure, it is for a headless server (so no X applications). The simplest way would be to write a PNG file, or possibly an HTML file (which could use Javascript to allow the filtering of processes, changing between graph-types and so on) 

I'm experiencing a strange issue with a fabric script I'm using to bootstrap a server on EC2. I launch a stock Ubuntu 12.04 AMI (ami-3d4ff254), wait for it to start, then proceed with: 

The appears to run fine and gives no errors, however (2/3 of the time or so) installing throws a "no installation candidate" error. When I ssh into the server and run I get the same error. Running by hand, then the package installs fine. Any ideas on what might be happening, or ideas for debugging? 

We have a web service running on Amazon EC2. Currently we have some live user data stored on a single disk (EBS). We are considering moving to a RAID0 setup (we don't have to be concerned about the increased failure rate). If we do this migration, what is the quickest (to minimize site unavailability) way to reliably transfer the user data to the RAID array? One idea I had was to take a recent snapshot of the data, copy it over to the new RAID array, then when the site goes down for maintenance use rsync to copy only the changed data over. I'm not sure if this would actually save time or ensure data integrity though. 

(the port number is the office extension and was available). Similarly for other PCs and users. Remote user side: The user working from home will log on to WebVPN and start the Java Application. Once started, he/she can open mstsc.exe /span (/multimon for windows 7) and connect to 127.0.10.11:8891. Windows XP users might have issue with spanning across multiple monitors, when you maximize a window it will stretch across all monitors. In that case, use SplitView. Recommendation: WebVPN is much better than RRAS or client-based solution. You can setup many applications to stream thru VPN without needing to install it locally. Manage Home PC over Internet:(If you have a situation like me) In order to manage the remote home PC over internet, we used a NetSupport with Gateway enabled feature. Configure Netsupport gateway on the DMZ server(preferably windows) and edit firewall rules to allow traffic over internet. On home PC setup the http communication to the public IP or DNS address. Then you can connect NetSuport console to the remote gateway and just connect to the PC over internet. It communicates over HTTPS. We looked at MS Intune for this, but it doesn't allow unattended RDP which we needed as the executive might just walk-in and say, please fix my home PC. :/ 

Shouldn't be too many to change by hand, and hopefully your system doesn't differ too much from mine. 

I have a command that runs a disk snapshot (on EC2, freezing an XFS disk and running an EBS snapshot command), which is set to run on a regular schedule as a cron job. Ideally I would like to be able to have the command delayed for a period of time if the disk is being used heavily at the moment the task is scheduled to run. I'm afraid that using nice/ionice might not have the proper effect, as I would like the script to run with high priority while it is running (i.e. wait for a good time, then finish fast). Thanks. UPDATE: This is what I ended up going with. It checks /proc/diskstats and runs my job when the current IO activity hits 0, or we timeout. I'll probably have to tweak this when I look at what kind of IO activity our servers actually get in production: