In class we dealt with insurance economics and, specifically, adverse selection due to information asymmetry. As one possible solution we considered pooling contracts, i.e. the same contract for both high- and low-risk households for some average price. We showed and I understood why the high-risk households now would buy more insurance than the low-risk ones and thus everybody would act as if they were low-risk whether this is true or not. What I am not sure about is why there wouldn't be an equilibrium in a competitive market. It's clear that the low-risk individuals have reason to go for a lesser premium and, if some other insurer would offer this, then they would go there. Therefore, my questions are: 1) So why won't there be an equilibrium? I would think that if a new insurer appears with a better deal than the pooling contract, then there would again be the problem with adverse selection. Hence, the new insurer wouldn't appear and offer a better deal in the first place? 2) I also read that this is pareto-inefficient in that it disadvantages the low-risk households (obvious) but does not benefit the high-risk households. The latter point I do not understand since the high-risk households will have a higher demand since the pooling contract situation makes the insurance relatively cheap. Isn't that a benefit? 

I currently deal with interest rate theories, reading amongst others Paul Samuelson (1958) and Peter Diamond (1965). In Samuelson the possibility of a naturally occuring negative interest rate is introduced due to consumption smoothing and without some central bank mechanism. Often times I heard (or read) that the interest rate is impossible to decrease below zero as soon as some commodity is introduced that preserves its value over time, like land or some kind of neutral money. What I don't understand is, why? What is the idea behind that and what kind of concept is this neutral money as opposed to "traditional" money? 

You have $$ \begin{align} u(\lambda a + (1 - \lambda) b, \lambda b + (1 - \lambda)a) &= \sqrt{\lambda a + (1 - \lambda)b} + \sqrt{\lambda b + (1 - \lambda)a} \\ &\geq \lambda\sqrt{a} + (1 - \lambda)\sqrt{b} + \lambda\sqrt{b} + (1 - \lambda)\sqrt{a} \\ &= \sqrt{a} + \sqrt{b} \\ &= u(a, b) \end{align}$$ The inequality in the second line follows from Jensen's inequality for concave functions. I don't think you need to prove Jensen but you can even do that moderately easy with the AM-GM inequality if you want to. 

I am again running into problems with regard to expected utility and utility of expectation. This is very similar to this question I posted a few days ago. Since it did not clear the matter then I post this as a separate question as it is placed, I think, in a more general setting. This time I don't care about income but about prices. The question is as follows. Let $C(x) = cx^2$ be the cost function for some $c \in \mathbb{R}$. The output price is $p_s$ and variable according to the scenario $s$. The utility of the firm is given as $u(\Pi_s) = \log(\Pi_s)$ where $\Pi_s$ is the profit in scenario $s$. Now there are two scenarios. In the first, the price is $p_1 = \bar{p} + z$ with probability $w$ and $z \in \mathbb{R}$ constant and in the second, $p_2 = \bar{p} - z$ with probability $(1 - w)$. Derive the optimal output $x$ if the agent has to decide for the quantity before the price is known. In my opinion, there are two ways to solve this. Either I set up the first-order condition separately, i.e. $$\frac{d\mathbb{E}[u]}{dx} = w \frac{(\bar{p} + z) - 2cx}{(\bar{p} + z)x - cx^2} + (1 - w)\frac{(\bar{p} - z) - 2cx}{(\bar{p} - z)x - cx^2} = 0$$ which is quite cumbersome to solve for $x$ afterwards or I compute the expected price $p^* = \mathbb{E}[p] = z(2w - 1) + \bar{p}$ and then solve $$\frac{d\mathbb{E}[u]}{dx} = \frac{p^* - 2cx}{p^*x - cx^2} = 0$$ for which $x$ would then just be $$x = \frac{p^*}{2c}$$ What I don't understand is which approach should I use here and, in particular, why? I am familiar with vNM-rationality and the expected utility maximization context but I cannot see which one beats the other and what is the theoretical argument there: expected utility of possible prices or utility of expected prices? 

You are certainly right that Kahneman and Tversky neglect the importance of levels in their model (even though they do acknowledge the importance of levels informally, as in the quote you reference). However, this situation has now been rectified by Kosegi and Rabin, who include both 'levels' utility (i.e.'consumption utility') and 'gain/loss' utility (they also generalise Prospect Theory to handle many goods, and endogenise the reference point). As I understand it, the point of the Anna/Ben story is that marginal utility is a decreasing function of wealth. I would think that this is adequately captured by Kosegi and Rabin, assuming that we specify that levels utility is a strictly concave function of consumption, as is standard. Of course, a different route would be to allow the curvature of the Prospect Theory value function to depend on wealth (as you propose). However, I'm not sure what this would buy us above and beyond the Kosegi and Rabin approach. Moreover, the theory would still be missing the rather obvious fact that people do care about absolute levels of wealth, at least to some extent. 

I think that you are more or less than correct in thinking that cash that is never spent (nor expected to be) may as well not exist. Thought experiment: suppose that, unbeknownst to you and everyone else, £1 million suddenly appears under your mattress. If you never discover the money, it is hard to see how it could change anything in a meaningful way. There are some caveats, however. First, a game theoretic point: even if rich people never spend their money, threats to spend their money might influence outcomes. For example, they could pledge to donate lots of money to the political opposition unless the government does what they say. If this threat works, they will never need to pay out. Second, a ‘non-economic’ point: money gives you options, and people might enjoy having options in itself (even if they don’t spend the money). One might object to the kind of ‘options inequality’ brought about by an unequal wealth distribution even if rich people never spend their cash. Third, to bring us back to the real world, we should stress that, usually, rich people do consume more than poorer people. So while it might be interesting to discuss wealth inequality without consumption inequality, this is not a phenomenon which we are actually facing today. 

I have heard that people often handle uncertainty using point estimates not probability distributions. However, I have been unable to find any evidence for this in the heuristics and biases literature. I was wondering if anyone could point me to some relevant papers? To clarify, there is no question whether some people have some beliefs about the higher moments of distributions. However, it would not shock to me to learn that when (for example) considering by how much the stock market will rise tomorrow, people form a point estimate (perhaps using historic averages) but do really not think about the uncertainty surrounding their estimate. 

Currently I am trying to figure out some old problems for an upcoming micro exam. One of them is about production under uncertainty. The exercise seems standard to me, yet I am not sure whether I have the correct solution. The question is as follows. A firm produces goods with the cost function $C(x) = cx^2$ where $x$ is the good. The price $p_x$ is exogenously given. The utility function of the producer is given as $u(y) = \sqrt{y}$ where $y$ is the income due to profit. Determine the optimal amount of produced goods $x$ in case i.) $p_x$ is deterministic and (ii.) the price is random where it is $p^0_x$ with probability 0.5 and $p^1_x$ with probability 0.5. How will the output change if there is some future price $p^f_x > \mathbb{E}[p^s_x]$? My solution is as follows. First, we have that the firm's profit is $$G = p_xx - cx^2$$ and its utility $$ u(y) = \sqrt{p_xx - cx^2}$$ Now under deterministic prices the firm owner wants to maximize expected utility, hence $$\frac{d\mathbb{E}[U]}{dx} = (p_xx - cx^2)^{-\frac{1}{2}}(p_x - 2xc) = 0$$ and therefore $$x = \frac{p_x}{2c}$$ In case of random prices the optimality condition is now $$ \frac{d\mathbb{E}[u]}{dx} = \frac{1}{2}((p^0_xx - cx^2)^{-\frac{1}{2}}(p^0_x - 2xc) + (p^1_xx - cx^2)^{-\frac{1}{2}}(p^1_x - 2xc) = 0$$ right? After that I have to solve for $x$ and I got the result. Finally, if there is some future price which is higher than the expected price I am not quite sure how to proceed. Intuitively, I'd say that if the owner would produce more goods but how would I show that in an analytic manner? 

I am yet a bit confused about the actual application of the Efficient Component Pricing Rule (or Baumol-Willig pricing rule) for a network monopolist $M$. What I know is the following. The ECPR determines the optimal access price $a$ which $M$ charges some downstream competitor for accessing its network. More precisely, it says that the access price is the direct (marginal) cost plus the opportunity cost of the monopolist $M$ which is also equal to the retail price minus the saved (marginal) cost of the incumbent for not serving the costumer at the downstream market himself. On the other hand, in my notes, there is stated that the access price should optimally be equal to the marginal cost for the operation of the network. And this is where I am confused as I don't know which would really be the 'efficient' one? Let's consider a simple example. Let's say there's some network monopolist $M$ that can also serve consumers at the downstream market with a product that is priced $p = 10\$$. The marginal cost for serving the consumers is $c^* = 2\$$ per unit. The cost for maining the network, i.e. for operation and such, is $ C = 5\$$. What would now be the optimal price that the monopolist charges a downstream competitor which would like to access $M$'s network in order to serve the consumer, having a marginal cost for selling at the markt of $c > 0$? According to what I first understood it should be $a = p - c^* = 10\$ - 2\$ = 5\$ + [10\$ - 2\$ - 5\$] = C + [p - c^* - C]$. But according to my notes, it should just be $a = C = 5\$$. What is correct and why? 

In answer to your first question (can you get the Euler equation without a Lagrangean?), the answer is 'yes'. At least, there are less formal ways of deriving it. In general, assuming that a consumer chooses to consume strictly positive quantities of two perfectly divisible goods $x$ and $y$, then it must be that: $MUx/MUy = p_x/p_y$ (If this were not true, then the consumer could increase their utility by shifting spending a little more on one good and a little less on the other.) The so-called 'Euler equation' is nothing more than an application of this result, viewing the 'goods' and $C_t$ and $C_{t+1}$. If you delay your consumption by one period, you put your cash in the bank for one period, earning real interest at rate $r$. Hence, if we normalise $P_t = 1$, then effectively $P_{t+1}=1/(1+r_{t+1})$. In other words, consumption tomorrow is cheaper than consumption today (assuming $r_{t+1} > 0$) since delaying your consumption allows you to earn some interest. Finally, we assume that utility is constant, time-separable and exponentially discounted (as in your set-up). Thus we need to remember to put a $\beta$ before $MU_{t+1}$. To summarise, we 're-interpret' the variables in the tangency condition as follows: $MU_x = u'(c_t)$ $MU_y = \beta u'(c_{t+1})$ $P_t = 1$ $P_{t+1}=1/(1+r_{t+1})$ Finally, observe that if firms maximise profits taking the cost of capital $r_{t+1}$ as given with total depreciation (as you assume), they hire capital until $f'(k_{t+1})=1+r_{t+1}$. Plugging in yields the Euler equation. In answer to your second question (how can you derive it with a Lagrangean?), I would recommend that you try the following steps: 

$\lambda _t = \lambda _{t+1}f'(k_{t+1})$ Plug that in and you have it! The equation on which so much pointless macroeconomics built. 

In a recent paper, Edelman et al. examine (amongst other things) how discrimination on AirBnB varies with the characteristics of hosts. First, they conduct a field experiment which involves sending a large number of fictitious applications, some of which are associated with African-American names and some of which are not. Then, they regress whether an applicant is accepted on the guest race, a host characteristic and the interaction. For example, they regress acceptance on guest race, host race and the interaction of the two. The idea is that if African-American hosts (for instance) are less likely to discriminate, then the coefficient on the interaction term should be non-zero since the effect of receiving an application from an African-American should depend on whether the host is African-American. So far, so good. However, given that host characteristics are not randomly assigned, we should control for them. Otherwise, we might find that African-Americans are less likely to discriminate even though the real explanation is that they tend to offer expensive properties, and people who offer expensive properties are less likely to discriminate (made up example to illustrate the point). They seem aware of this, since they throw in various host and location characteristics as controls. But wouldn't it have been better to use the interactions of these covariates with applicant ethnicity as the controls? After all, we want to control for the fact that people with certain characteristics might respond to African-American applicants differently, and this means controlling for interaction effects.