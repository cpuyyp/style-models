Economics models usually assume that the structure of the economy is common knowledge among agents. Mathematically, an event is common knowledge if it lies in the meet of all agents' information sets. (The meet of a family of $\sigma$-algebras is the finest common coarsification of all $\sigma$-algebras in the family. See Aumann 1976.) However, in the literature when a paper makes the common knowledge assumption, one almost never sees the meet of any information sets anywhere. Let me give an example (Grossman and Stiglitz 1980). Grossman-Stiglitz model This is a model where two traders with (essentially) mean-variance utility are asymmetrically informed about the mean. By assumption, structure of the economy is common knowledge and traders are rational. Equilibrium price must therefore, first, clear the market and, second, be consistent with the uninformed trader's expectation. Details given as follows. Let $I$ and $U$ denote the informed and uninformed traders respectively. The traders have same CARA utility, $u_I(W) = u_U(W) = - e^{-\gamma W}$. The risk-free rate is $r$. The price of risky asset tomorrow is $P_2 \sim \mathcal{N}(\bar{P}, \sigma^2) | \bar{P}$. The informed trader $I$ knows $\bar{P}$; the uninformed trader $U$ only knows the prior distribution $\bar{P} \sim \mathcal{N}(P_0, \sigma_0^2)$. Let both trader have wealth endowments $E$. (CARA utility has no wealth effect, so $E$ plays no role in portfolio choice below.) Given today's price $P_1$ for the risky asset, trader's wealth tomorrow is $W(\phi) = rW + \phi (P_2 - rP_1)$ if he choose to hold $\phi$ units of risky asset. Maximizing expected utility, a traders' demand is $$ \frac{E[P_2|\mathcal{F}] - rP_1}{\gamma Var(P_2|\mathcal{F})} $$ conditional on his information set $\mathcal{F}$. For $I$, $\mathcal{F}_I = \{ \bar{P}, P_1\} $. For $U$, $\mathcal{F}_U = \{ P_1 \}$. The supply $x$ of risky asset is distributed $\mathcal{N}(\bar{x}, \sigma_x^2)$. Equilibrium is a price function $P_1(\bar{P}, x)$ such that $$ \frac{\bar{P} - r P_1(\bar{P}, x)}{\gamma \sigma^2}+ \frac{E[P_2|P_1(\bar{P}, x)] - r P_1(\bar{P}, x)}{\gamma Var(P_2|P_1(\bar{P}, x))} = x. $$ In other words, market clears and the uninformed trader computes his demand using the correct pricing function in equilibrium. Now in this CARA-normal setting, things are linear and one can solve for equilibrium by guessing a pricing function $$ P_1(\bar{P}, x) = A\bar{P} + Bx + C $$ and find $A$, $B$ and $C$ by matching coefficients. For example, compute $$ E[P_2|P_1] = P_0 + \frac{A \sigma_0^2}{A^2 \sigma_0^2 + B^2 \sigma_x^2} [A(\bar{P} - P_0) + Bx] $$ and $$ Var(P_2|P_1) = \frac{B^2 \sigma_x^2}{A^2 \sigma_0^2 + B^2 \sigma_x^2}\sigma_0^2 + \sigma^2 $$ Substituting into the market clearing equation and some tedious algebra gives endogenous constants $A$, $B$, and $C$. Instead, Grossman and Stiglitz do something more elegant. They point out that uninformed trader $U$ can condition on the residual demand for any realization of $(\bar{P},x)$ $$ D_{resid} = x - \frac{\bar{P} - r P_1 }{\gamma \sigma^2}. $$ What's even more clever, they note that, since $P_1$ is observed in in equilibrium, they first conjecture that $P_1$ and $$ \tilde{D}_{resid} = x - \frac{\bar{P} }{\gamma \sigma^2}. $$ are informationally equivalent. Then equilibrium condition becomes $$ \frac{ r P_1(\bar{P}, x)}{\gamma \sigma^2}+ \frac{E[P_2|\tilde{D}_{resid}] - r P_1(\bar{P}, x)}{\gamma Var(P_2|\tilde{D}_{resid})} = \tilde{D}_{resid}. $$ Now things are much less tedious and there are no endogenous constants $A$ and $B$ to solve for. $E[P_2|\tilde{D}_{resid}]$ is an affine function of $\tilde{D}_{resid}$ and $Var(P_2|\tilde{D}_{resid})$ is an exogenous constant. So that $P_1(\bar{P}, x)$ can be backed out immediately. Since $P_1$ is an affine function of $\tilde{D}_{resid}$, it is verified ex-post that they are informationally equivalent. Question To have the uninformed trader $U$ condition on the residual demand, the common knowledge assumption is used. Or, at least, $U$ knows that $I$ knows so that $U$ can put herself in $I$'s shoes and compute $I$'s demand. However, the meet of the information sets does not appear anywhere---as it should. Result of $U$'s calculations should be measurable with respect to the meet. If one is to formulate this mathematically, where would that appear? 

There's the well known step-by-step guide on "How to build an economic model in your spare time" by Hal Varian. Edit Based on further clarifications made in the comments that OP's interest is in behavioral, I'd recommend The Foundations of Behavioral Economic Analysis by Sanjit Dhami. The book covers, comprehensively, the various models in behavioral economics and how they are justified and applied. From the publisher: 

I'm inclined to say "yes" to $T_1>T_2$ and no to $P_1<P_2$. For simplicity, suppose the monopolist's marginal cost is constant. Then consumer surplus is the area under the (inverse) demand curve and above the marginal cost. In a two-part tariff scheme, the monopolist would charge entrance fee equal to consumer surplus and unit price equal to marginal cost. If, in your language, consumers with "high demand" are understood as those who are willing to pay more for each unit of the good than those consumers with "low demand", then high demand consumers generate higher consumer surplus than the low demand ones. Suppose monopolist can distinguish between the two types and offer different two-part tariff bundles to each (e.g. a theme park company operating in US and India charging different prices in the two countries). Then it will be the case that the monopolist charges a higher entrance fee to the high type (because they generate higher consumer surplus) but the same unit price for both types (because this is related to the marginal cost of production, which is the same regardless of the consumer types). 

Usually additive functionals are defined for (strong) Markov processes with continuous sample paths (diffusions) but I suppose you do have a Markov---AR(1)---time series and $\{ Y_t \}$ is indeed additive. So, in your case, $$ X_t = a_0 + a_1 X_{t-1} + W_t, $$ and you would like \begin{align*} Y_t - Y_{t-1} &= r_1 + (M_t - M_{t-1}) + r_2 (X_t - X_{t-1}) \\ &= a_0 + W_t + a_1 X_{t-1}. \end{align*} If such a decomposition exists, then conditioning on $\sigma(X_1,...X_{t-1})$ gives necessary conditions \begin{align*} r_1 + r_2 (a_0 + (a_1 -1) X_{t-1}) &= a_0 + a_1 X_{t-1} \\ \end{align*} with solutions \begin{align*} r_1 = (1-\frac{a_1}{a_1 -1})a_0, \;r_2 = \frac{a_1}{a_1 -1}. \end{align*} One can then substitute $(r_1, r_2)$ into $$ a_0 + W_t + a_1 X_{t-1} - r_1 - r_2 (X_t - X_{t-1}) $$ and check that it gives a martingale difference sequence $\frac{-1}{a_1 -1} W_t$. 

I'm not aware of any comprehensive list of theory conferences. But here are some usual suspects in North America: 

With more revenue and less cost, the monopolist will simply not be content at operating on the inelastic segment of the demand. 

In a separating equilibrium, different types choose different actions (Type I chooses $A$ and Type II chooses $B$). Then, upon seeing action $A$, P2 (the receiver) updates her belief using Bayes' rule: $$ \mu(\text{Type I}|A)=\frac{\Pr(A|\text{Type I})p}{\Pr(A|\text{Type I})p+\Pr(A|\text{Type II})(1-p)}=\frac{(1)p}{(1)p+(0)(1-p)}=1 $$ Therefore P2's conditional belief at node $x$ is $1$. Similarly for her belief at the information set $\{x',y'\}$ Pooling equilibrium 

It's from King and Rebelo (2000) "Resuscitating Real Business Cycles". Here is a link to the NBER working paper version. The graph is in Figure 8 on p.94. 

More of a comment: There should be an expectation operator in the statement of the problem, otherwise problem doesn't make sense. That "...the deterministic and stochastic value function must be the same..." is not quite right. The value of $\sigma^2$ is crucial in the restriction \begin{align} \rho = \left(-n + \sigma^2\left(1 - \frac{\alpha\gamma}{2}\right)\right)(1-\alpha\gamma). \end{align} If $\sigma^2 = 0$, then presumably $\rho < 0$ for economically reasonable $\alpha$ and $\gamma$, in which case the deterministic problem may be ill-posed. What is true is that the stochastic value function takes the given form only if the parameter restriction holds. Factoring out the Ito term $\frac{1}{2} \sigma^2$ from the right hand side $$ \sigma^2\left(1 - \frac{\alpha\gamma}{2}\right) (1-\alpha\gamma), $$ the restriction can be written as $$ \rho + n (1-\alpha\gamma) = \frac{1}{2} \sigma^2 [ (1-\alpha\gamma) - (-\left(1 - \alpha\gamma\right)^2)]. $$ On the right hand side, we have a elasticity of intertemporal substitution term $(1-\alpha\gamma)$ and a risk aversion term $-\left(1 - \alpha\gamma\right)^2$. What the restriction says is that, with a particular choice of $\sigma$, they offset each other, up to time preference $\rho$ and the drift $n(1 - \alpha\gamma)$. Therefore the value function is independent of $\sigma$. That the value function is independent of $\sigma$ is an artifact of the restriction, and choice of CRRA $u$. Not true in general. 

Hint You are probably working with (or given) a linear demand function of the form $Q=\frac{a}{b}-\frac1bP$, or its equivalent inverse form $P=a-bQ$, where $a$ and $b$ are positive numbers. Given that price elasticity of demand at the optimum is $-1$, which you were right to point out (assuming linear demand), you can use the elasticity formula \begin{equation} -1=\frac{\mathrm dQ}{\mathrm dP}\cdot\frac{P}{Q}=-\frac1b\cdot\frac{P}{Q} \end{equation} and the demand equation to solve for the two unknowns $P$ and $Q$. 

The key is about ownership of the right to broadcast through a certain frequency. If station A has the right to broadcast and B interferes in the way you described, then instead of paying B not to do so, A would simply bring B to court. However, if B is a more profitable station but cannot realize such profit unless it uses the channel that A owns, then B would have to pay A to relinquish its right to use the channel. The amount paid would have to be at least what A can make were it to use the channel itself. Since B is more profitable, it can afford to say such an amount while while retaining nonnegative profit for itself. 

$L^{\infty}$: the (Banach, usually) space of bounded measurable functions modulo the equality almost everywhere. Like all function spaces not involving holomorphic functions, it's really a space of equivalence classes. weak-$^*$ topology: the topology on the dual $X^*$ of any topological vector space $X$ induced by the $(X, X^*)$-pairing. "embedded in $L^{\infty}$": a (say) topological vector space $Y$ is said to be embedded in $L^{\infty}$ if there is an injective continuous linear map from $Y$ to $L^{\infty}$. (This is the usual meaning. In your paragraph, "embedded" just means viewing those indicator functions as representatives of their classes. The weak-$^*$ topology on $L^{\infty}$ is given by the identification $L^{\infty} = (C_0)^*$.) 

For economics, both micro and macro, written in mathematics as mathematicians would know it, try the Handbook of Mathematical Economics series, 4 volumes in total. See for example, this very nice article by Mas-Colell and Zame in volume 4 on general equilibrium. (Microeconomics, for example, by Mas-Colell-Whinston-Green falls far below this standard of rigor.) 

One proxy for cardinal utility would be people's willingness to pay (WTP) for a particular product. One can estimate WTP using consumption data (e.g. from Amazon/eBay purchases), or elicit WTP using economic experiments. Another (better?) way to estimate cardinal utility is through methods used in neuroeconomics. For example, one can monitor an individual's dopamine level/active brain regions while she makes decisions. To the extent that the neuro-transmitter/brain activities are associated with bodily (physiological) pleasure, which by the way is what Jeremy Bentham had in mind when he coined the term "util", we may assert that particular activities/decisions generate a measurable level of utility that is cardinal in the sense that it not only orders choice alternatives from least to most preferred, but also signifies the intensity of preference over each alternative. 

As you say (how did $\sin t$ in the initial problem become $\cos t$?), $\mathbb{Q}$ is a measure under which $W_t$ becomes $\tilde{W}_t - \sin t$, where $\tilde{W}_t$ is a $\mathbb{Q}$-Brownian motion. So Girsanov's theorem would say $$ L_t = E[\frac{ d \mathbb{Q} }{ d \mathbb{P} }|\mathcal{F}_t] = e^{ - \int_0^t \sin s dW_s - \frac{1}{2} \int_0^t \sin^2 s ds} $$ is one such measure. As for uniqueness, if we take $\Omega$ to be the canonical path space $C[0, T]$ with $\mathcal{F}$ generated by the cylinder sets. Then the Wiener measure would be unique, simply by the fact that the Brownian law says any two such measures must agree on the cylinder sets and therefore all of $\mathcal{F}$. In general, the Girsanov $\mathbb{Q}$ is unique up to the Brownian filtration $\mathcal{F}_{W} \subset \mathcal{F}$, since it is constructed $W$-pathwise.