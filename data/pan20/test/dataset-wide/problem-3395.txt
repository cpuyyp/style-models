macro123, You might want to have a look at MRW (1992) $URL$ and the literature on growth regressions in the handbook of economic growth and the handbook of macroeconomics. In addition, Acemoglu's textbook on economic growth will provide you with some useful references as well as a clear and concise introduction to the topic. Although, I believe that you'll also be a little bit disappointed as you'll find that something close to what you wish to do has already been done. 

Ben, Let me dispute the premise of the question. A high debt to GDP ratio cannot be bad by itself. The debt to GDP ratio becomes a bad thing when it is too high. Too much alcohol. Too much ice cream. Too much time spent online. These are all bad things because they are too much. But how do you know that these are too much? Let's take alcohol as an example. Too much alcohol can make you do stupid things which you'll later regret. But how much alcohol is too much? When you're with a group of friends and you all drink five or six glasses of beer, and do stupid things together then you're probably having a good time. Drink five or six glasses of beer in the afternoon at the office and you can get fired. This is generally considered a bad thing. The same quantity of alcohol is just right in one situation and too much in another situation because of the consequences. Now you've mentioned some consequences of public debt. The government usually borrows funds to spend it and re-allocate scarce resources. This can be a bad thing, but this can also be a good thing. The United States for example borrowed funds (and compelled its citizens to lend it funds) to fight the Nazi's. This is generally agreed to have been a good thing. The United States also borrowed funds to invade Iraq under George W. Bush. This is something that many individuals considered (ex ante or ex post) to be a bad thing. We can say that when the United States borrowed funds the debt to GDP ratio was high, but it was not too high because the costs were exceeded by the benefits (fewer Nazi's). The resources used could've been used elsewhere but the highest value of those resources was when they were used to decrease the number of Nazi's. Whereas some will argue that when the debt to GDP ratio was increased to invade Iraq, this debt to GDP ratio became too high. The costs were not exceeded by the benefits. The resources could've been used better elsewhere. In addition to the costs of re-allocating resources, there are some other costs of public debt. It has to be repaid through taxation and individuals don't like taxation and it distorts incentives. Some others have argued that a public debt can lead to higher inflation because the central bank might monetize it. Others have argued that it means less private investment as people save in terms of government bonds instead of corporate bonds. And this might eventually lead to lower output due to a decrease in the quantity of capital per inhabitant. There are many other potential costs. And these costs depend on the situation. There is not one economic theory of debt to gdp ratio. There are many economic models that are appropriate to make sense of different situations where the debt to gdp ratio might play a role. Returning to the question why a high debt to GDP ratio is bad, I hope you can see that it isn't. A high debt to GDP ratio is only bad if it is too high. And you can only know whether it is too high when you compare the costs and the benefits of the debt to GDP ratio and these depend on the circumstances. In addition whether it is good or bad is purely subjective. If you think that the consequences are worth it, then it's not bad. Next time that you might encounter a situation where someone declares that something is good or bad try making the distinction between what is and what ought to be. A statement that something is bad implies that the situation should be different and this is premised on a value judgement. You can't arrive at the conclusion that something is bad without a normative premise, a value judgement. The real world consequences of a high public debt to gdp ratio are is up for dispute. We can learn from what we see. But what value you attach to these consequences whether these are good or bad is not up for dispute. It's a preference. Just like chocolate ice cream is better than vanilla is a preference. 

$p(0)\geq c'(0)$ is assumed so that the inverse demand curve originates above the marginal cost curve. But what is the intuition behind this assumption? The highest willing-to-pay consumer is more than the marginal cost of producing the first unit? Is this going to be the variable cost of producing the first unit? 

Could you still argue the limited special edition CD is a substitute for the wireless controller? Maybe. But notice you still desire the wireless controller given it is wireless and limited edition. One of the reasons why you forgo the chance to buy this controller is you are effectively poorer than before. And this is an important distinction to make, because the decrease in the quantity of the controller may be from the direct impact of the increase in the price of the game CD but also the induced effect through your wealth (i.e. thinner wallet). If you want to investigate the true relationship between two goods, you have to take both wealth and price effects into account on top of the given information, say whether the good is Giffen or inferior or both or something else. Hope this helps. 

Consider the following 2x2 game: \begin{array}{|c|c|c|} \hline &C&R\\\hline M&0,0&3,5\\\hline D&4,4&0,3\\\hline \end{array} This game has two distinct pure-strategy Nash equilibria. I recall that in cases like this there is almost always a third mixed NE, and this had to do with the index theorem and having an odd number of equilibria. Can someone provide the idea behind the index theorem and why having two distinct pure strategy NE in 2x2, 2 person game, static, complete information results into a third mixed NE with probability 1? 

Often in macro pure exchange economy models (sequential trading), authors make the initial period good price $P_0=1$ asserting this set-up is to make the consumption at period $0$ the numeraire. But I don't see any detailed explanation or justification for doing this. Just to add some background story: The usual set-up is that agents are endowed with some units of goods, say oranges. So the unit of their consumptions is oranges. $P_t$ often the price, at $t=0$, of an orange consumption promised for delivery in period $t$. Why make $P_0=1$? 

In MWG, the authors introduce the consequentialist view of risk by assuming for any risky alternative, only the reduced lottery over final outcome matters to decision maker. From philosophical view, how reasonable and unreasonable is this assumption? Can you provide examples where this assumption is in fact reasonable while it isn't? 

The idea is that since agents are ex-ante identical, they should have the same (ex-ante) expected utility. Ex-ante identical means that even the agent does not know what's his type until resolution of type at date-1. Because they have the same preferences each agent's consumption profile must be identical. And the analysis can then focus on symmetric equilibrium. What symmetric means, as explained in the footnote, is that the consumption profile must be identical. The consumption profile $(C_1, C_2)$ represents the consumption for the agent at date 1 (if he is type-1) $C_1$ and the consumption for the agent at date 2 (if he is type-2) $C_2$. Otherwise stated $(C_1, C_2)$ does not depend on the type and each agent has the same $C_1$ and $C_2$. Since the types coincide with the date it's a little bit trivial but it really says nothing more than that. For the constraint, there is a mass-1 continuum of agents, each endowed with one unit of wealth, so the total wealth is 1. Then from that total wealth an amount $I$ will be invested in the productive technology whose return is $R$ per unit invested. Then it follows that : 

The first order condition of the maximization problem is \begin{equation} f'(x)-s=0\iff f'(x)=s \end{equation} We can then replace $x$ by $x(s)$ because this is the optimal value given $s$. Since this is true for every $s$, we can differentiate with respect to $s$ which yields \begin{equation} f''(x(s))x'(s)=1 \end{equation} Which can be rewrite as \begin{equation} f''(x(s))=\frac{1}{x'(s)} \end{equation} Then $x'(s)$ can be estimated by finite differences which would give $f''(x)$. 

This does not work like that. If you want to add-up all the debt in the world you will not end-up with 0. Think about a situation in which I owe you \$100, you owe someone else \$100, and this someone else owe me \$100. Total debt would be \$300, even if another guy is debt-free. Moreover, country debt (called sovereign debt) is not only owned by other countries but most of the world-debt, is owned by people, mostly through pension funds (and other investments). So even in a single-country economy, the country may issue some debt that consumers or firms can invest in. And the global amount of sovereign debt will be strictly positive. Again most of the world-debt is privately owned and it may even be the case that those five countries you're talking about don't hold a single debt contract. 

I think you are missing the credit risk attached to any loan. You, as an individual borrower, are far more likely not to reimburse your loan than a bank. Thus the loan is far less risky. Central bank money could only be qualified as "better" (even that does not mean much) because it is issued by the Central bank, deposits are issued by commercial bank, so you bear the risk that your bank fail, but it happens that in most country individual deposits are insured by some state agency. So I cannot really see why central bank money would be better than deposits. Nowadays, the amount of reserves that a bank must hold does not actually play a big role in the economy (as opposed to what most of economic textbooks and economic professors are teaching in undergrad schools). The most important part is the interest rate that is paid on those reserve, which is fixed by the central bank and which act as an opportunity cost for the bank when it decides to lend to an individual rather than holding reserves. However I see your point, but the fact is that this way of thinking is misleading. Banks create (in theory) as many loans as they want, because there are no physical constraints, if you want, that prevent them to do so. The only constraint is a regulatory constraint that states that in order to remain solvent (in order to be able to repay the depositors) banks should invest x% of the assets in reserves. Those reserves would be held on a central bank account in central bank money, and the return on those reserves will be the fed fund rate decided by the central bank (the same way a commercial bank decide how much interest it will pay on your savings account). So it is true that one more unit of reserves gives the right to issue more than one unit of loans but this does not mean that one money is better or worse than another. It's is just a matter of regulation. It may be hard to get, but the point is really that central bank money is safer so cheaper than deposits, no matter what regulatory constraints apply to banks. You may want to read this paper which may be a bit complicated but you should get the intuition. This two docs may be simpler (with nice pictures) : doc 1, doc 2. 

In Econ 101 textbooks, there are lots of examples and emphasis on marginal analysis leading to the greatest equation of all, $MB=MC$. My challenge is the following and wonder if anyone had a similar issue or a way to get over it: One of the textbooks examples use consuming pizza or water. First unit brings you the biggest joy. Then it diminishes. So student would understand each additional unit of pizza wouldn't bring the same amount (e.g. initial v. when you are full) utility. But then there comes a time where you are quite full and feel satisfied. At this point, additional unit of consumption would probably make you feel sick or vomit, so it is not "worth the money" to spend on. 

I am trying to clearly explain to the concept of "normalization" or relative prices. Because students are so used to just think of prices in absolute terms, it is initially tough to make the leap to the "relative" or "normalization" concept. What is your angle if you were to explain this to an econ 101 student? For example, the toughest part is to explain the "need" for looking at the ratio of prices. Who cares? Why is it useful? Thanks bunch. 

You get a similar type of for the other scenario. But how would I incorporate this into expected payoff of $i$ and how should I go about constructing a social welfare function? I feel like this is just a variation of all-payout auction with discrete action space for each $i$. 

Here I used $u(.)$ and $\alpha(.)$ interchangeably to represent the utility function. Can somebody elaborate the above claim just little more in detail please? I understand monotonicity implies local nonsatiation, hence, in any given small ball, you always have some bundle that you prefer that to x. Part of my confusion comes from the Figure they present, which is they put the bundle x on the indifference curve ($\{y\in X:y\sim x$}). But isn't $\alpha(x')$ on the diagnoal line Z? Please help. Thank you. 

I have read the statement below and don't quite understand what it means. This is probably because I don't have full understanding of duality with support function in math, but just to foster understanding... The statement is: 

Consider a static, complete information game with 2 players. Strategy sets are $S_1=\{U,D\},S_2=\{l,m,r\}$. Payoffs are irrelevant to this question as I am trying to get the concept of rationalizability correct. Suppose I want to verify whether $m$ is a rationalizable strategy for player 2. Then, I want to ask the following question: $\exists \sigma_1=(q^*,1-q^*)\in\Delta(S_1)$ such that for $\sigma^*_2=(0,1,0),$ $u_2(\sigma_1,\sigma^*_2)\geq u_2(\sigma_1,\sigma_2)$ for all $\sigma_2\in\Delta(S_2)?$ Now, suppose I have payoff matrix such that I could find $(q^*,1-q^*)$ such that it satisfies both: (1) $u_2(\sigma_1,\sigma^*_2)\geq u_2(\sigma_1,(1,0,0))$ (2) $u_2(\sigma_1,\sigma^*_2)\geq u_2(\sigma_1,(0,0,1))$. This means, I could find a valid range of $q^*$ such that for player 2, choosing $m$ provides a weakly better payoff for her compared to the degenerate (i.e. pure) strategies of $l$ or $r$. My question is: If I could find such $q^*$ that satisfies both (1),(2), then I do not have to check for any other strategy profiles in $\Delta(S_2)$, that is any convex combo of $(1,0,0)$ and $(0,0,1)$? My intuition is that for any $\alpha\in[0,1]$, I could simple have: (1)' $\alpha u_2(\sigma_1,\sigma^*_2)\geq \alpha u_2(\sigma_1,(1,0,0))$ (2)' $(1-\alpha)u_2(\sigma_1,\sigma^*_2)\geq (1-\alpha)u_2(\sigma_1,(0,0,1))$. and show that (1)'+(2)'implies the degenerate strategy $m$ for player 2 is a best response to some belief, $\sigma_1\in\Delta(S_1)$. Hence, the bottom line is (1),(2) is sufficient, and I do not have to check the convex combo of the two other pure strategies.