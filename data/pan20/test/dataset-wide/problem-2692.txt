I think what has confused you is the usual grammatical role of "nothing." It appears in sentences like: 

That says that there is no x such that if x is [the] number A wrote down, then everything is that number. Moving operators around a bit we get this equivalent statement: 

Proof. We assume that R is reflexive, with the goal of showing that (φ → ♢φ) is valid on reflexive frames. Let M = (F, V) be any model based on such a frame. For an arbitrary point w &in; W, we want to show that (M, w) |= φ → ♢φ. Suppose, for contradiction, that (M, w) |= φ → ♢φ is false. That will be the case iff (M, w) |= φ and (M, w) |= ¬♢φ are both true. By the box-diamond duality, this second conjunct is true just in case (M, w) |= ▢¬φ is true. But by the first conjunct, world w satisfies φ and since R is reflexive, it means that w sees a world (namely itself) that satisfies φ, so (M, w) |= ▢¬φ cannot be true. Since the assumption that (M, w) |= φ → ♢φ is false led to a contradiction, we know that (M, w) |= φ → ♢φ is true. Since (M, w) was arbitrary, we know that (φ → ♢φ) is valid on reflexive frames.                ■ Those two facts allow us to justify the desired claim, namely that: 

This is a hot topic at the intersection of contemporary metaphysics and logic, so see, for example the relevant parts of SEP articles on Fiction and Existence. My own, admittedly naive view, is that talk of fictional entities and fictional truths can be handled simply by introducing special quantifiers that range over fictions. Let's use 'Ê' to stand for the fictional existential quantifier, which is to be used as follows: 

There are two topics to be distinguished here for discussion: (1) the object language vs metalanguage distinction, and (2) the use of metavariables (which may be distinguished by using a different font, different color, Fraktur!, etc) in logic. I will limit myself to a few brief remarks about (1) and suggest that you look at the works cited at the bottom, and talk about some uses of metavariables in more detail.                                                 §1. Object-language vs Metalanguage Whenever you have two languages Lo and Lm such that the expressions of Lm are used to talk about the expressions of Lo, the two languages are respectively called 'the object language' and the 'metalanguage'. For example, so far I've been using English both as an object language and a metalanguage. You can notice the spots where I've gone beyond the object level to the meta level by finding the quoted expressions ' 'metalanguage' ' and ' 'the object language' '. Notice that I used double quotes there, because now I'm using English to talk about expressions (e.g. ' 'metalanguage' ') that are used to talk about expressions (e.g. 'metalanguage') of English.                                                       §2. Two uses of Metavariables Teller's boldface capitals are used as metavariables for arbitrary sentences of his object language. Suppose the object language is that of propositional logic: 

The setup here is more similar to dynamic epistemic logic than to ordinary epistemic modal logic (which has "static" semantics). The relevant connection is between MacFarlane-Kolodny's information state contractions and the model updates found in dynamic epistemic logic. Before we get to your specific questions, we must note that the M&K's main task in this paper is to solve a certain paradox (nicely summarized on p. 15) which involves epistemic modals, deontic modals, and the indicative conditional. As a result, when specifying their semantics they don't start from scratch, but assume that the truth-conditions of non-epistemic, non-deontic, non-indicative sentences are already given! To convince yourself of this, notice that the very first truth-conditions (on p. 19) are for the epistemic and deontic modals (the semantics for the indicative conditional can be found on p. 24). The observation just noted makes it impossible to settle your questions ( & ), but not because M&K haven't told us anything about what constitutes a world, but because they haven't told us anything about the truth-conditions of non-modal, non-indicative sentences at those worlds. They say that: 

The goal is to assume (1-2) and derive: ¬(C ∧ D) → (A ∧ B). I should start by saying that premise (1) is useless and in what follows we'll simply use premise (2). Here is one strategy you can take. It's pretty system-neutral, so try to implement it in your particular proof system and feel free to ask for further guidance if you're not completely sure how to proceed. Hope you find it helpful and good luck. 

'Obtains' is used instead of 'is true' because states of affairs are not linguistic or abstract entities like sentences and propositions. The sentence "the cat is on the mat" can be true. The proposition expressed by "the cat is on the mat" can be true. But the cat's being on the mat is not the sort of thing that can be true. Instead, it can 'obtain', exist, be happening, be realized, and so on. Of course, if neither of those alternative notions is clearer to you than 'obtains', this won't answer your question. 

Example. Let w be our world, and L(w) our laws of physics. An arbitrary possible world v is physically accessible from our world (wRpv) just in case the laws of physics L(v) at v don't violate any of our L(w). With this notion of physical accessibility we can define physical necessity as follows: 

Some formal notes to complement Mauro's excellent answer. As one would expect in a discussion of modality, we're going to talk about modal models when defining things. Most will be familiar with logics K, S4, and so on. K and its superlogics are too sophisticated for a discussion of metaphysical modalities, so we'll begin with pre-Kripke modal models, going back to Carnap. We start with the language: 

Here's how they define each of those properties. I apologize for the ugly notation; with no TeX option, I've tried to do all I can with alternative formulations of relations and HTML characters. Let each sentence s ε σ ('ε' stands for the set membership relation) have an associated finite language L(s) called the set of symbols occurring in s. According to C&K, system (σ, Sat_σ) is an abstract logic iff it meets the following conditions: 

Both the explication/concept and the theory of the informal conception of fatherhood are intimately tied to an underlying language, and consequently will look different depending on the choice of that language. That's only my way of looking at things. Someone else thinking about the logic of fatherhood would probably choose a different language and come up with a different set of axioms. For a treatment of explication as the process of moving from classificatory to comparative to quantitative concepts (we didn't talk about quantitative concepts above), look at the first chapter ("On Explication") of the following work: Carnap, R. (1950) Logical Foundations of Probability. 

This says that given any two agents α and β, if a proposition φ is among the truths recognized by α (Ωα) if and only if φ is among the truths recognized by β (Ωβ), then the truths recognized by α are β are the same. So for any two different 'versions' of the truth, there must be a φ that belongs to one but not to the other. If one of these guys is right, then both are and their Ωs coincide with Σ (the set of all truths). From that reasoning, (2) doesn't follow; what follows is this: 

I'll quote from his essay "On the Character of Philosophic Problems" (1984), which begins as follows: 

That last statement is a contradiction: it says that everything is k, but there is something that's not k. If my gloss of statement 3 is what was intended, then we can prove, on the basis of statements (1-3), by the explosion principle, that the number A has written down is 7. Oh, and that it is 3, and that it is 4, and so on. The point is that because (3) is a contradiction, anything follows from (1-3). 

The φ acts as a "guard" for ψ, meaning that the truth of ψ is tested only for those x in the domain that satisfy φ. In sum, guarded quantification, of which (3) is an instance, is a method of achieving restricted quantification in a language with only unrestricted quantifiers and an unstratified domain of discourse. 

Example 1. The usual sentential operator ¬ (of arity 1) is truth-functional according to (Definition) iff the truth-value of ¬φ is a function of the truth-value of φ. Is that the case? The usual semantics of ¬ is the following: ¬φ is true if φ is false, and ¬φ is false if φ is true. As you can see, to calculate the value of ¬φ, it is necessary and sufficient to know what the truth-value of φ is. Example 2. The usual sentential operator ∧ (of arity 2) is truth-functional according to (Definition) iff the truth-value of (φ1 ∧ φ2) is a function of the truth-values of φ1 and φ2. Recall the semantics of ∧: (φ1 ∧ φ2) is true just in case φ1 and φ2 are both true, and false otherwise. Again, since no other piece of information is needed to settle the truth-value of the conjunction, we know that ∧ is truth-functional. 

It's easy to check that (6) is true exactly when (7) is true. After all, S is a set of pairs (x, y) s.t. x is a son of y, and the second conjunct of (6) implies that x is j which according to (7) is s(m). Remark. The distinction between (6) and (7) roughly corresponds to the famous distinction between Russelian and Fregean views of definite descriptions. According to the Fregean view, 'the φ' denotes the unique individual satisfying condition φ, if such an individual exists. The Russellian view, on the other hand, regards 'the φ' as meaningful only in a context of a complete sentence (e.g. (6)). That, however, is another discussion.                                                                      References Halmos, P. (1960) Naive Set Theory; Chapters 6–8. Heim, I., Kratzer, A. (1998) Semantics in Generative Grammar; §4.4. 

If you were allowed to use a De Morgan's Law [ ¬(φ ∨ ψ &vdash; ¬φ ∧ ¬ψ) ], we could just push the negation in to obtain ¬A ∧ ¬¬(A ∧ B), cancel the double negation to get ¬A ∧ (A ∧ B), open the parens (justified by the associativity of conjunction) to get ¬A ∧ A ∧ B. From this we'd get &vdash;¬A and &vdash; A, which by &bot;-introduction would allow us to conclude &vdash;&bot;. 

Although the proof is easy, it still needs to be shown; otherwise we'd have to take it on faith that our axioms (if we have any) are true and that our rules of inference are truth-preserving. Similarly for the converse direction, which is called completeness: 

A historical footnote to Niel's already complete answer. In Aristotle's syllogistic the (all → some) inference is valid. The argument given for it in the body of the question is not. In modern axiomatizations of Aristotle's assertoric syllogistic (e.g., Corcoran's), the inference is captured as a rule called "a-i conversion." Modern logics don't validate the move because whenever the plurality (&approx; extension) corresponding to A is empty, the universal affirmation will vacuously be true, but since there won't be any As, the particular affirmation will be false.