These are not error messages but debug messages and are clearly marked as these. Unless you need verbose_ssl to debug a problem you should just switch it off. More background: it is showing every state it is going through when doing an SSL handshake. To display the description of the state it is using the function SSL_state_string_long from OpenSSL. This function does not have a string description for every possible state and returns 'unknown state' if it does not have a more specific description. Again, nothing to worry about. 

Thus, either get a single EV certificate which includes all the names you need or get multiple EV certificates. 

The screenshot for SSL checker shows an IP address of 162.209.88.109 (i.e. hosted at Rackspace) for this site and an issuer of "helotes" for the certificate - which suggests that some self-issued certificate was used here. But, the current DNS lookup shows an IP address of 50.56.149.253 (hosted at Liquidweb) and the SSLLabs analysis shows a properly setup publicly trusted certificate for this site. My guess is that not only a new certificate was created but that the site was also moved to a different provider. But, changes on the DNS setup are not reflected immediately (can take hours or even a day, depending on the setup of the DNS records) which means that SSL checker still showed the older setup. 

It depends on the server. Lat time I looked postfix was fine but sendmail could not properly check the hostname against the certificate. And yes, self-signed is one problem and the other main problem are missing intermediate certificates. But since mail delivery works anyway (since certificate errors are ignored by the sender) most admins don't realize the bad configuration or don't care. 

All what matters is that the certificate matches the hostname from the URL and that the certificate is valid and trusted. It does not matter if you have multiple IP address for the same hostname and use the same certificate on all of these. Such setup is actually very common for larger sites. 

This is the expected behavior of browsers. These warnings are there to discourage users from visiting this site because the browser can not determine if this is actually the expected certificate for this site or someone impersonating the site, like in a man in the middle attack. Essentially a self-signed certificate is saying "trust me, I'm the correct certificate" and there is no way to verify this claim. 

The client key is not used as the base for encryption, but only for identification of the client. With RSA key exchange the servers private key is used, which you have hopefully given in ssl.keys_list. With DH key exchange you will not be able to decrypt the pcap file because the key is based on random data only known to client and server. 

A certificate does not come with a cipher. It comes with a public key and the type of key restricts a bit which ciphers can be used (i.e. ECDSA vs. RSA authentication, RSA key exchange). The usable ciphers are instead depend on the TLS implementation and configuration in client and server. All *-SHA384 ciphers are defined only with TLS 1.2. This means to use this the protocol version supported by both client and server must be TLS 1.2. Any client not offering TLS 1.2 or later in the TLS handshake will not offer this cipher and a server which does not support TLS 1.2 will not have implemented this cipher anyway. 

The server can only request a client certificate or not and additionally provide a restriction which CA's are accepted as the issuer of the client certificate. What a client does with the information is fully up to the client, i.e. the server has no control over it. There is no way for the server to only optionally request a certificate. The server can ignore if it got no certificate but the client does not know if the certificate is essential or not, it only sees that a certificate was requested. This means that client will ask for the certificate because the server asked the client to provide one. 

The client does not provide a list of supported versions. The client provides the best version it can offer and the server is supposed to reply with the best version supported by the server which is equal or lower to the clients version. If the client then is not willing to accept a too low version the client will throw an error and close the connection. 

This is probably a combination of two errors: the server sending an invalid response and the AV handling this wrong response by corrupting it. The server sends a response with code 401 but no header. This is invalid according to the HTTP standard: 

While according to the protocols TLS 1.0 .. 1.2 are supported by the server the problem might be the set of ciphers which is unfortunately not shown in detail. There are a few ciphers which are defined new with TLS 1.2 and which can only used with TLS 1.2, notably all ciphers using SHA-256 or SHA-384 as HMAC. If only these ciphers are accepted by the server then this implicitly means that only TLS 1.2 protocol is accepted. For example the modern profile as currently shown by the Mozilla SSL config generator only includes ciphers available with TLS 1.2 or later and can thus not be used together with older TLS protocol versions. 

Again, this is only hop-by-hop encryption and the mail is available in clear for reading and modifying on each of the hops. Thus an attacker on any of the hops involved in the transfer (usually at least two, one at the sender and one at the recipients site) can intercept and also modify the mails and can of course restrict itself to deal only with selected mails. The only protection is end-to-end encryption using PGP or S/MIME. 

The server is closing the connection directly after receiving the ClientHello. There are various possibilities why this happens: 

In this case you must configure apache to not accept any clients which don't support SNI, i.e. . In this case virtual hosts without a configured certificate should cause an error at the client, i.e something like invalid server name or handshake error (depending on the browser). 

The redirect will be done in the HTTP protocol. HTTPS is HTTP wrapped inside a SSL connection, so if establishing the SSL connection fails because of a bad certificate there will never be the redirect to $URL$ So to make this working you have to use a certificate which the client accepts, e.g. matching the host name and issued by a trusted CA. If you take off the ssl it will just start a normal non-ssl http server on port 443 but the browser will try to talk SSL and thus you get this error about record_too_long. 

TLS 1.2 can be used with any ciphers defined for SSL 3.0 and later. This includes 3DES (DES-CBC3) ciphers. What you refer to is not a list which ciphers are usable with which SSL/TLS version but with which SSL/TLS version a cipher was introduced. Proof: 

So it actually established a plain connection and waited for EOF from the terminal and only after that it would start with the SSL handshake. 

You cannot redirect away from https if you have a bad (i.e. expired in your case) certificate. To get the redirect instruction the client has to first connect to the site and do a successful SSL/TLS handshake. Only after this is done the client will receive the response which redirects it away. Since a successful handshake will not happen due to the bad certificate the client will not get to the redirect. Your only choice is to get a valid certificate for the site and install it. Once you've done it you will be able to redirect the clients away from the https site. 

The certificate itself does not affect the scaling of the application. The performance might be affected by the size of the certificate and the chain, so a short certificate chain might perform better. But in practice this does not matter that much as long as session reuse is enabled at the server side (usually the default configuration). I think the main problem you have is that your side does not scale well, independent of the certificate. More users means higher load at the server and more use of bandwidth and if any of these resources is tight packets will be lost or will be processed too slow. In this case you get a variety of problems, including SSL downgrading or failure to establish the connection. 

I doubt this will work. FTP needs a control connection which you might tunnel through stunnel. But additionally to this it needs data connections for each data transfer (STOR, RETR, LIST...). Do you really use the same setup on the working command line? 

If the extension for the file is an indicator of the format this might be related to this setting here, because it looks like your are using the (binary) DER format instead of the required (textual) PEM format: 

Your site does not provide the necessary chain certificates. This is visible from the SSLLabs report: 

The computations during the TLS handshake need lots of CPU time and that's why it would have been important to provide information about the CPU load. It might be that you are simply hitting the maximum the CPU could do, either at the server or at the client. Please also note that apache bench is single threaded, so it would be enough to max out the performance of a single CPU core even if the others are idle. And even if you use multiple thread the computation still takes time. Using does not reflect what is really done inside the TLS handshake and it also tests only the maximum speed with a single thread, not with multiple computations in parallel and all the cache trashing etc involved. Thus while this might be an interesting benchmark to see what is possible it does not reflect reality in most cases. The fact is that TLS can reduce performance a lot, but with common HTTP traffic you will have larger requests, HTTP keep alive and TLS session reuse which all reduce the impact of the costly TLS handshake. But if the benchmark is actually limited on the server performance and not on the client performance the setup might reflect servers used for tracking, where you might have only a small response (i.e. 1x1 pixel) from lots of different sites without any kind of TLS session reuse or HTTP keep alive. 

In summary: I see multiple problems at the server side which might result in the problems you see. If you have access to the server try to fix them there. First it looks like the SSL stack of your target host (174.47.225.118) is kind of broken: 

Since you disable all SSL 3.0 ciphers and since TLS 1.0 and TLS 1.1 just use the SSL 3.0 ciphers and since IE 8 does not support TLS 1.2 there will be no shared ciphers. You will probably find some error messages about this in your log files. Note, that the POODLE attack is a design flaw in the SSL 3.0 protocol, not in the SSL 3.0 ciphers. Thus you should only disable the protocol, not the ciphers. Also, your current cipher suite includes very dangerous ciphers, because it includes ADH ciphers which don't require any form of identification of the server. With such ciphers man-in-the-middle attacks are possible. Edit: in your comment you mention that the client is using Windows 7. Windows 7 should support TLS 1.2 but since the client obviously did not do much updates on the system (otherwise there would be no IE 8 in use) it might be that there are problems with IE 8 and TLS 1.2. 

This refers to the pathLenConstraint extension of the certificate. With this extension a CA can restrict the depth of the possible trust path. For example a CA might issue a sub-CA but restrict it so that this one cannot issue more additional sub-CA but only leaf certificates. See also Certificates Basic Constraint's Path Length. 

Which means to make at least hop-by-hop encryption safe enough you have to add non-trivial fixes to multiple places and most of them are not in control of a sending MTA. To get in detail to questions from the comments: 

Just a guess because your question lacks the necessary details for a more detailed analysis: This might be caused by the Java application not supporting SNI. SNI is only supported in JDK 1.7+. And at least Cloudflare Free SSL works only if the client supports SNI. 

There is nothing special in the server log which shows a problem at the site of nginx. But, you description clearly indicates a problem in the clients network, i.e. 

The name which gets used to access the site should be contained in the certificate. Which means if you access the IMAP service with the hostname then it is not enough to have a certificate for only. If these are both the same IP address then you could of course simplify the configuration by accessing the IMAP service with and not . This is true for all protocols. 

Whoisguard is about hiding the real owner of a domain from the publicly accessible whois information and has nothing to do with SSL certificates or on how many servers you use the domain. 

Redirection is done at the HTTP level, i.e. after the SSL connection was established. Since establishing the SSL connection includes validating the certificate it is not possible to bypass the certificate check for redirects. 

Because you did not remove the vulnerable version of OpenSSL it is still on the system. Your new installation did not replace the files, but added new ones. Because the existing applications were linked against the old library the might continue to use it. So better upgrade your system the usual way, because fixed libraries are available for it. 

"\x16\x03\x01" are the first bytes of a SSL/TLS handshake. This means that the client is trying to speak HTTPS to the server, which is expected if you use a URL. And obviously the server is listening on the port where the clients sends the request too because otherwise the TCP connection would have already failed. With a normal request the port would be 443 which means that your server would have to be explicitly setup to handle plain HTTP on port 443 (this does not happen by its own or in the default setup). Or you've actually tried the URL and forced the browser to connect with HTTPS to the port reserved for plain HTTP. My guess that the problems are in the part of the server setup which you are not showing here. 

You get the error about from the server, so it refers to the validation of your client certificate on the server side and not to the (successful) validation of the servers certificate at the client side. That means the server does not like your client certificate. Please check your client certificate against the list of acceptable CAs, make sure it is not revoked and maybe do a tcpdump/wireshark to verify, that it gets actually sent to the server. If this does not help you might check log files at the server side for signs what went wrong. 

Then simply concatenate the translated ciphers with ':' for your ciphers string. Please note that the order is relevant. But, as you might see the rating from SSLLabs for google's server is 'B' because they still support SSL 3.0 and RC4. So instead of simply copying the ciphers (and forgetting to update them once google does) you might better follow the advice from Mozilla where several cipher combinations are shown and where they also explain in which cases which combination is useful. 

The host has both an IPv4 and IPv6 address. The web server listens on both IP port 443 so that the TCP connect is successful, but you somehow messed the SSL configuration for IPv6 up, so that the SSL upgrade on the IPv6 address fails. There are enough clients out there which use IPv6 if available and prefer it to IPv4 and these clients will fail. SSLLabs will not tell you about it, because it does not support IPv6 yet. But analyze.pl will tell you about it: 

For a list of ciphers supported by your version of OpenSSL (and thus by nginx) call on the machine where nginx is running. To translate between the syntax used by OpenSSL and the syntax you see in the SSLLabs results have a look at the man page for the ciphers command where you will find the translations like: