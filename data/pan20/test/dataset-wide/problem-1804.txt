Simple shell script wrapped around or . For larger installations, a Puppet recipe could reliably deliver the updated config file and bounce Apache afterwards. 

Note that the medium type is "802.3 LAN". That's the one you want. Other channels may look like this: 

I use a redundant pair of OpenLDAP servers for PAM auth and directory services via NSS. It's been 100% reliable so far, but nothing runs flawlessly forever. What steps should I take now so I have a fighting chance of recovering from failure of the LDAP server(s)? In my informal testing, it appears that even already authenticated shells are largely useless as all username/uid lookups hang until the directory server comes back. So far I've come up with only two things: 

Hmmm... Are you certain it's a 500 and not a 403? if the perms are wrong on the .htaccess file, Apache will reject all requests with a 403. 

Yes, assuming your sysadmin did not explicitly filter them out. They're sync'd as part of the "mysql" database. 

EDIT: Further research indicates you probably don't want the option an that you first need to run to load the kernel module. 

I haven't set up PAM-MySQL before, but assuming it's similar to other external database PAM modules, there will be a config file that you use to select the db credentials, which tables should be used, etc. Then you would insert just before the line in . Theoretically that should be all you need. 

That article describes recovering from completely deleting all of , so this extra step may not apply to your situation. 

According to my Dell guy, yes it should work. However, due to the PERC 5i's lack of NCQ support, you will not achieve the IOPS you would see on a PERC 6i. I have also just verified that the 2950 can be easily upgraded to PERC 6i, which is what I will be doing prior to switching to SSD. Also, I'm really happy with this 2.5" -> 3.5" adapter: $URL$ Its connectors are properly located to slide directly into a RAID chassis. Most adapters I've seen would not work. 

Meru runs some good bundle pricing on their smaller controllers. I think you need to call the reseller in your area to get pricing. I have 5 of their radios in a 10,000 square foot office and they work great. 

We use OTPW for this. Simple implementation. Easy to replicate the password list. The system requests passwords by number, so no problems trying to keep the lists in sync. 

If your users are logging in using key-based authentication (and they should) you can add ``command="/usr/local/sbin/validate_svn'' as the first field in their public key in . In order for this to be safe, though, you'll have to disable password auth. Otherwise they can log in with a password (bypassing the forced command) and edit to remove the restriction. Add a "Match" stanza to the end of for the user(s) that should only be able to use svn. It should look something like this: 

There are ways to add it to your script, but I would suggest an easier, more robust approach would be to add the path to the config for the dynamic linker directly: 

The effect is recursive as well; any new directories created after you set the setgid bit will also have the setgid bit set. An alternative to this approach, of course, would be a cron job that runs every minute and fixes the permissions on the files under . 

Installing a certificate / key on a linux machine is as simple as copying the file to the server. Most distributions have a standard location for storing the certificates and/or keys. The harder problem is configuring your application to look in the correct directory. What application will need to use this certificate? Are you installing a root certificate to validate the server cert? Or are you installing a certificate and key so you can serve information over SSL? 

What symptoms are you seeing when you try to reach the host? What do you mean by "doing a traceroute on the ip:443"? Ports are not relevant to traceroute. Can you show us the actual traceroute command you're executing? Is the traceroute to the DNS server or to the destination host? I'm also puzzled by "the trace fails after reaching the dns", as a traceroute to a host does not also traverse the DNS server used to resolve the host... Unless the DNS server is also your gateway. Can you clarify this statement a bit? That trace looks fine, assuming the destination host is 208.173.55.226. Traceroute is actually of somewhat limited utility as it frequently will be dropped when normal TCP / UDP packets for legitimate ports will be accepted. In some cases using tcptraceroute can be illuminating. 

The problem is having your hostname set to your domain name. By default postfix sets to include . If your hostname were , your config would work. As it stands, postfix thinks that mail for shoudl be handled locally yet local delivery is disabled, so it gives up. In general, hostnames should not be your domain name, but rather a subdomain of your domain name. 

It really depends on your network requirements and load. For example, for my most recent project I selected expensive, high-end switches because our SAN requires jumbo frames, flow-control, and large packet buffers. Most low-end switches can't provide all of those features or not all at once. Many low-end switches do not have adequate backplane speeds, so you cannot make full use of each port in both directions at once. Many low-end switches are not manufactured as robustly (cheap fans, cheap power supplies, etc.) so they are, in general, more likely to fail. So... Do you need to be able to read/write at Gb speeds on a majority of the ports at once? Do you have specialized network requirements? Is reliability extremely important? If so, then you want the FastIron. If not, the D-Link will probably be fine for a while. 

After much wrangling, I wasn't able to get the xfsdump solution to work. So I did what I should've done in the first place: tar. 

Nope. Unfortunately iptables only knows about the layer 2/3 stuff: ports, IP protocols, src/destination IP or ethernet addresses, etc. In order for iptables to know that the TCP stream contains SSL, it would need to analyze the content. It doesn't do that. What you would need is a layer 7 firewall, like the l7-filter project: $URL$ 

If the problem is failure to resolve, then it pretty much has to be a problem with the DNS servers or configuration. It's possible, albeit unlikely, that Pingdom and the unnamed other service have broken caching resolvers. It's also possible, ableit unlikely, that theplanet has broken DNS servers. It seems more likely that the DNS zone for your domain might be mis-configured, resulting in random failures. Lame delegation from the GTLD servers, for example, can result in intermittent failure. If you post the actual domain, we could tell you quite a bit more. Some things to check: 

Granting SELECT and INSERT on all tables should allow you to run . The link you posted to lists the commands it calls: 

This enables b-tree hashes of directory index data, dramatically improving lookup time. Of course, it's possible your install already has this enabled. You can check by running this command and looking for in the output: 

Seems to indicate I should be able to resume the backup. However, if I run xfsdump with the flag and specify a new device to backup to, this is what I get: 

Technically you could put anything at all in the place of "ACCEPT" as the result is ignored; just the presence of the match is sufficient: 

I'm trying to create a one-off snapshot of 5.5TB of data to 3 external 2TB drives. The data is on an XFS partition, so the logical option seemed to be xfsdump, as it can span multiple devices. As a test, I've created a number of smaller partitions on one of the drives so I can force it to reach the end of the drive in minutes instead of hours. The external drive contains two partitions, and , both 256MB in size. This is the command I'm using: 

Enable using whatever technique your distribution prefers ( on Debian-based distros). Add these directives to : 

If you have access to the source code, you need to create the socket with the option mentioned by Jacek. Also of interest are the and kernel flags (on Linux). The real problem is in the protocol design, which you may or may not be able to change. Interesting threads on the topic: 

It sounds to me like your firmware is probably behaving properly and you do have a legitimate IP conflict. Do you have a VMWare instance running anywhere on your home network? That's who owns the MAC prefix... 

It sounds to me like you're describing AFS, the most common implementation of which is OpenAFS. The key OpenAFS concepts are described here: $URL$ AFS is: 

You need to have the bash-completion modules installed. Some distributions bundle them with bash, others package them seperately. Once they're installed, you need to activate them. In Ubuntu/Debian, that's done by sourcing in your .bash{rc,_profile}. For CentOS 5, the process is documented here: $URL$ 

If that all looks good, it's time to check out your config. Start be moving your directory out of the way, like so: 

In a sane world, the output of the two would be identical. How they differ should tell you a lot about why this is failing. 

The script accepts the VERP address as its command line option, parses it and makes the necessary database updates to record the bounce. 

I'm a big fan of the relatively inexpensive KEMP LoadMaster series. They are full-featured load balancers with ASIC SSL offloading. They are non-OSS linux-based appliances. Support is outstanding and the feature set keeps improving, frequently in direct response to user requests. 

The output of apachectl is sent to stderr. The commands you are using attempt to filter stdout. To use grep in the way you are describing, redirect stderr to stdout, like so: 

All "ESTABLISHED" means is that the tcp session is open. It does not mean that they have successfully authenticated. Nmap, for example, will create a complete, legal TCP session when scanning port 22. (It's verifying that the daemon is , checking version strings, etc.) This person could be running a simple port scanner or even attempting to brute-force your passwords. To figure out what's actually happening, you'll need to spend some quality time with your logs. Spend most of your time looking for successful and failed logins. Also just running "" will let you know if someone is actually logged in via that connection. The output of can also be useful. 

This should return a list of the servers that handle the DNS for your actual domain. Hopefully it will be and . Next, move on to sending an request to each of the listed servers: 

I don't normally use on Ubuntu. It looks like it may have some issues with the newer upstart-based releases. As a quick fix, use the native script to fix the necessary symlinks: 

On their box, they would run . Then they would configure their web browser to point to "localhost:4444" as the proxy server. The local ssh client would accept the proxy request, forward it through the ssh tunnel to your server, where it would exit out to the internet. 

I'm guessing that the script works fine if you run it without . If that is the case, than your problem is that ssh is now looking for the public key in root's home directory instead of yours. Add a option to your ssh command specifying the path to the key you've configured, or use root's public key instead. If you're using to store a decrypted version of your key rather than using a passphrase-less key, you also need to edit and add to the so ssh can find your auth socket. 

You're listening on one of the ethernet interfaces but talking over the loopback. From the man page: 

So if there is mail being injected for 30 different domains, it may try to deliver a message to all 30 of them at once, but never more than one at a time to and never faster than 1 per second to . 

If you have access to the Apache config, add the authentication stanza to the that has SSL enabled. Then the redirect will always happen first. Also, using to perform a simple redirect is a bit of overkill. Use the Redirect directive instead. It's possible this may even fix your problem, as I believe rules are some of the last directives to be processed, just before the file is actually grabbed from the filesystem. 

Something is connecting to the port and then never sending data. HTTP 408 is a "timeout" error. There's a good writeup here: $URL$ 

The disk space problem is likely best solved with filesystem quotas. Unfortunately I have little experience with them. If you want to get fancier (restricting filetypes and such) you'll probably need to write your own script to validate the commands being passed from the client. The simplest script would be a shell script that performs a test similar to this one: 

You're trying to access a directory via Apache that does not contain an index file and you have not enabled "Indexes". This is also easy to test by looking to see if there is a file named (or .php, .htm, etc.) in . If there is not, either add one or add to the block. 

Mike's answer will probably work. But it's worth pointing out that you can accomplish this carefully selecting which startup files to put the verbose stuff in. From the bash man page: 

I had the same question a few weeks ago. The Dell support person I talked to claimed you could not just swap the drives, but had no explanation for the fact that there was not a separate part number for a SAS backplane. My own research on the PERC part, the backplane, and the SATA/SAS specs would seem to indicate that they are completely interchangable. 

No, on a standard install chmods are not logged (unless, of course, they're executed via ). Your best bet would be an audit of and files of the various accounts that have access to your system. 

If you're going to run a local DNS resolver on your server, you would point to your local BIND server (127.0.0.1) and let BIND resolve starting from the root nameservers, like any other nameserver. No "forwarders" entries needed in your . Strictly speaking, you would be ever-so-slightly decreasing the load on the root nameservers by leaving the "forwarders" entries in place. If you're just trying to get DNS resolution working on your box but don't need to run a DNS server yourself, then don't worry about and just point at your ISP's DNS servers. EDIT: It occurs to me I didn't answer the question in your title. 

The bit is the placeholder for the command. Whatever files are found by find are inserted in place of the brackets. The means to build up a long list of the found files and call the exec on all of them at once instead of one at a time, like the more traditional variant. 

(Assuming that the GTLD server listed those servers.) They should both return the same results, differing only in minor details like . 

It's possible, but The Right Tool is expect. There are also expect-like libraries available for most scripting languages. 

If, however, you just want to set up a proxy server on your box that they can connect to directly from their browser (by configuring your box as the proxy server) then you want something like squid. 

Yes, iPerf can easily max out even Gb connections. The example above by mkudlacek is, in fact, a maxed out connection, minus losses to TCP overhead. 

The first time you connect it will authenticate you against "a" and open a persistent, backgrounded ssh tunnel. Subsequent calls to "s" will open almost instantaneously through the pre-authed tunnel. Works great. 

If your LDAP directory has been correctly enabled, you will see a full list of all the users, formatted like a passwd file. If that doesn't work, I'm afraid I can't help as I'm not familiar with webmin. Ubuntu 10.04 does make it pretty simple to enable LDAP auth from the command line, though, using : $URL$ 

The lvextend command you executed would only extend the filesystem by 800MB (assuming default extent size), a rounding error when you're looking at TB filesystems. The flag means "extents" which, by default, are 4MB in size. If you wish to grow the filesystem by, say, 200GB, the command would be: . (Note the difference between and .)