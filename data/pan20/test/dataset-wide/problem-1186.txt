AFAIK the purpose of the property is so you don't ping-pong around servers indefinitely, potentially causing more issues. If you exhaust the number of retries that implicitly assumes that each node was attempted to host the role without success - so why keep flopping around causing more logs to be spewed for no reason? To simulate - have an actual failure... force shutdown (not cleanly) a machine (blue screen it on purpose - something like NotMyFault). Rip the disks out from under it, something to cause an ACTUAL failure. 

That's the node that is currently hosting the core cluster resources, it isn't the same and is just another role. Different roles can be owned by different nodes. In this case, they do not need to be the same - and generally most people don't care who owns the core cluster resources in a WSFC that only has SQL Server. It does make a difference in certain situations but for the vast majority, it makes no real difference. 

It seems to be that this isn't setup or running on the DR server, or a backup would at least be attempted. 

SQL Browser isn't running SQL Browser ports are blocked (1434 UDP) Incorrect DNS entries SQL TCP Port is blocked (custom port number for named instance) SQL TCP Port is blocked (Dynamic ports) TCP is not an enabled protocol 

I agree this should be moved to the dba stack exchange, though since I answer there as well I will post it here should it be migrated. The only way to access a mirrored database from the mirror server is through a database snapshot, which will require enterprise edition of SQL Server. It will also be READ ONLY, so this may not work for what you want. The other alternative is to take the backups of the primary (these, I would hope, should be available) and restore them for your use somewhere else up to the time you need. If using already taken backups is not possible, ask for a copy_only backup to be taken on the primary and given to you. 

Shared or replicated disks, yes. This is because the Disks "move" between servers. Each potential failover target has SQL Server installed locally and the service is started when the local node owns the resources and is given the online command. The local service starts and mounts the database files which are on the shared or replicated disks. This is why you don't need to change or replicate any SQL Server based items (logins, jobs, etc.). 

They could also get an error. I wouldn't assume it'll multiplex perfectly. This is why setting the maximum value too low can have a detrimental effect (also setting it too high!). 

AFAIK there is no way in TSQL to deal with this other than the way you currently are with XACT_ABORT. There are no structures that TSQL knows (or even cares about) as everything this deals with lives outside of TSQL. What is actually happening is called an "Attention" event which could range from a connection closing to an actual cancel (for example the sqlcommand.cancel() method). Since this lives outside of the actual query, it just tells SQL Server that something happened and that it needs to clean up some stuff. The actual query has no idea what is going on. Try/Catch is for query execution errors such as diving by 0, but not for any other type of errors. For example, compile/parse errors are not caught as the try/catch had never run. Since attention signals are not part of query execution (again, it's outside of that scope) it doesn't know anything about it and thus is not called as no execution exception has happened (according to the query itself). 

This is because there is no database on the secondary server, which completely falls inline with what you've posted. The "database" shows up under the Availability Groups folder on the secondary because that's the metadata of the Availability Group, not because the database is on the secondary. The reason it "works" with automatic seeding is because automatic seeding creates the database and seeds it on the secondary for you versus what you're doing now which is creating the AG but not preparing the database on the secondary. Thus, no database on secondary. 

No, there isn't a button to press to tell the REDO to run. It runs. Constantly. All the time. It doesn't run when it's blocked and it runs very slowly when it doesn't have the hardware to run properly (primary may be more powerful than secondary, etc.). If you look at the secondary, there should be an AlwaysOn Health extended events session running. Opening the XEL file in management studio (SSMS) will give you what has been captured. Look for any REDO BLOCKED messages. If there aren't any, run a perfmon on the system to check on IO latency and throughput, memory, and cpu utilization. 

Where to go from here: I'd start by taking a backup with continue_after_error to make sure that you have something of a record. Then restore that backup to an instance on the same patch level as the one it was taken from so that all testing can be completed on a copy of the database and not the database itself. Use the copy and the older backup of the database you have on a second instance to see what data is lost and what may be able to be manually salvageable. This is time consuming and lengthy, but may be needed. If you're really stuck, call in a consultant to help you with this as corruption is a great thing to cut your teeth on and gives you some semblance of liability. Check the objects associated with the corruption. If they are tables that don't have any super important data (say dictionary tables that can be rebuilt or don't change much) you might be able to get away with manually fixing the table by using the older backup to script out data. Check your storage subsystem, make sure you have the latest drivers, firmware, etc. Check for any failed drives in the array/san/nas/etc. Double check Ethernet cables, fibre cables, switches, etc. Find the root cause of the corruption or this may happen again. Run a health check on your storage subsystem/motherboard to make sure something isn't faulty with the hardware or controllers. Lastly, update your resume. 

There is nothing internal to AGs that would do this. This had to have been done by someone or something. The Logins and Users are mapped via their SID, thus if the mapping no longer was valid (different SIDs), the only way those can become different is either it was initially setup incorrectly or someone/something changed it. You could attempt to look at the default trace and see if it has any data, but if you weren't auditing for it chances are you won't find it retroactively as SQL Server doesn't save that type of data. 

That's a great step in the right direction (I work for Microsoft) of having a risk and health check of your instance(s). This specific check is something that we us to look for databases that may be having improper or no log management. In some cases (I've personally dealt with) the DBA has said, "Ooops that shouldn't be in bulk-logged..." and we've changed it back to Simple because it didn't need any point in time or extended recovery options. That's ok! The check does, however, give everyone a opportunity to look at the databases in question and make sure that something isn't wrong and that's the key distinction. Like I said above, this might just be normal and that's ok - however we wouldn't be doing our jobs properly if we just left it alone and didn't say anything, it's important. Anecdotally when I was a DBA for a large clothing company, we had a 3rd party application that used a cursor to loop through all employees every 15 minutes and run a stored procedure which deleted all of their history and then rebuilt it from scratch... in a single transaction. The database was 50 GB and the log file for it was.... 280 GB. That's how the app worked, I logged complaints and possible code changes with the 3rd party vendor and was summarily dismissed. It happens and some application just run that way.