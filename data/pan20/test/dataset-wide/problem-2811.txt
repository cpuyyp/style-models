This is a strong indication that at least in some contexts, we are talking about a paradox rather than about a fallacy. The fallacy of relative privation ("not as bad as") is listed under the red herring fallacies on wikipedia, i.e. it is a fallacy of relevance. So if the bigger problem is not really relevant in the context of the smaller problem under discussion, then it is indeed a fallacy. An unpleasant variant of this fallacy or paradox if the time and resources for the discussion the problem(s) are used to draw a relation between the unrelated problems. This form of the paradox can indeed happen in practice, take the principle of explosion in logic, which allows to deduce anything from a completely unrelated contradiction. A denial of service attack on a server highlights that even systems designed to guard themselves against this sort of unpleasantness are not completely immune to it. For instances of the paradox where the bigger problem is really relevant, the marginal return might help explain why sometimes the small problem promises a bigger payoff than the large problem for the same amount of invested resources. Again in the context of logic and computers, floating point numbers will forget small numbers, if they are added to big numbers. The remedy here is to try to separate different scales before putting them through black box algorithm. 

Look at this starting upside down. Q: Why do I wish to bake? A: I wish to bake so that I will have a cake. But... uh-oh, I cannot bake! I first need to add dry mixture to wet! Q: Why do I wish to add dry mixture to wet? A: I wish to add dry mixture to wet so that I may bake so that I may have a cake. But... uh-oh, I cannot add dry mixture to wet! I first need to mix dry ingredients! Q: Why do I wish to mix dry ingredients? A: I wish to mix dry ingredients so that I may add dry mixture to wet so that I may bake so that I may have a cake. But... uh-oh, I cannot mix dry ingredients! I first need to mix wet ingredients! Q: Why do I wish to mix wet ingredients? A: I wish to mix wet ingredients so that I may mix dry ingredients so that I may add dry mixture to wet so that I may bake so that I may have a cake. 

Even so I only read that paper in order to be entitled to answer this question, I think the paper is really worth reading even if you don't want to answer any question. It's easy to read, covers much ground, and even sketches the proofs for some non-obvious theorems. But is it relevant to philosophy? Well, it is an honest attempt to address an audience of philosophers and tries to reduce (or show how it might be possible to reduce) the gap between theory and reality in certain areas. 

We are part of several systems, some of which might form a separate whole in ways for which we don't have established concepts that we could use for comparison. These systems don't have consciousness in the usual sense, but they have other properties just as indescribable. I think "level of comprehension" or "level of understanding" misses the point, they are just different. It's also important to note that not every organization of humans, ants or other animals automatically forms a separate whole. For example, a separate whole should not draw too much of its identity from the identity of a few of its members. So mathematics is a separate whole, but a political party is normally not. 

So if the philosophy page would've had this property, three others would have it as well. However, 94% is still pretty good. To explain this phenomenon, let's have a look at a random page: 

Logically, your argument is correct. To counter it, someone will have to go against the premises. You're saying that you must conclude that a perfect god cannot exist if man exists. This statement is about truth, not about correctness of the argument. As I said before, the argument is logically correct. This surely doesn't mean it's true though. If I assume that all horses are brown, I can conclude that there exist no white horses. This is logically correct but not true because the premises are not true. Lastly, the points you make in your argument use more premises than they say they do. For example, your step 

At least for the German language, the notions Extension und Intension come from the context of Aristotelian logic and where established by the Port-Royal Logic: 

I was not able to access the 2015 Hirzebruch Lecture in Bonn. It would certainly be interesting whether Jaffe believes that the problematic practices still persist, or whether he was rather reporting on the success of his proposed solutions. Even if this may not be the answer the questioner has hopped for, the question prominently features that link to the 13 page opinion piece and a link to an unavailable lecture. Hence it should be allowed to point out that the opinion piece contains strong statements which overshadow (even so they may be true) any potential discussions about details of the suggested analogies used in the opinion piece. 

This begs the question - What does it mean to see a nouminal object? How is this different from phenomenal seeing? To get around this semantic difficulty, I shall use perceive to refer to nouminal observations. Claim : For an entity to perceive an object, that entity must be that object. Argument : If the entity were external to the object, it wouldn't have access to all features of the object. (A feature is one which could be perceived, thereby making the object a union of its perceivable features).. Example : Sam hears his own voice when he speaks and then frowns upon hearing his recorded voice. Which of the two is closer to his nouminal voice? The answer, of course, is his own voice as he speaks and not the recorded sample, as the recorded sample has passed through several filters thereby making it a phenomenal observation. 

1) Is Nothing some sort of concept, a concrete object, or a class of objects? Nothing is definitively not a concrete object. Also, if it were a class of objects, it would have to be the empty class. There might be certain contexts in which the empty class actually represents Nothing. (It is more the content of the empty class than the empty class itself, which represents Nothing.) The best guess seems to be that Nothing is some sort of concept, which can be represented by different things in different contexts (empty space, empty set, empty list, empty string). 2) Is Nothing an abstract concept, a class of concepts, or a scientific concept? It should be fine to assume that Nothing is an abstract concept, which doesn't necessarily exclude that it may also be a class of concepts and a scientific concept. 

Philosophy is one way to arrive at morals without religious support. This is indeed a good backing of religious morality, to give people who aren't going to philosophize all day, a book on religious code of conduct. A good example of the above, is to realize that most religions converge on most issues of morality, even though the histories of said religions might have been completely different. 

Blame should always go side by side with intent. Since the gambler didn't have any intent for the murder of his cousin, he cannot be blamed for the murder. Every event which occurs, has numerous prerequisites, the non-occurrence of even one of which would prevent the event from happening. For ex, while going to the anonymous group, there might have been a traffic jam due to a lousy driver, which led to them being late by a few minutes and running into the muggers. Had there been no jam, they would have got there a few minutes early thereby avoiding the muggers. In such a case, it is just faulty thinking to blame the lousy driver for a murder. 

There are programming languages that can, thanks to lazy evaluation, store the concept of something infinite without actually having to store it in memory. For example, in Haskell one can write for the list of natural numbers, which is infinite. You can use it as long as you don't ask for the whole list. For example, you can write for the first ten natural numbers. So, there's no problem with the concept of something infinite existing in finite hardware. Also, you don't argue why we can't be simulated in infinite hardware. 

Charles Taylor writes in the preface of Sources of the Self (p. x, Harvard University Press 1989), emphasis mine: 

The all important phrase here is if and only if, which would make the conditional bidirectional, where you could affirm/deny the antecedent/consequent and thereby confirm/falsify the consequent/antecedent. In unidirectional conditionals, such as the one in the example, there is uncertainty on its converse, hence denying the antecedent or affirming the consequent is invalid. So, given that : "If weather is good, we will go on a picnic", saying "if the weather isn't good..." or "We went on a picnic.." isn't useful as it will always be false, if followed by the consequent/antecedent or their converse. 

Not quite. Darwinian evolution, as it is, diverges significantly from our current moral systems. Our morality can be better derived from a combination of logical truisms along with the human conditions of well being and suffering. These are, as can be demonstrated largely orthogonal to Darwinian truisms and any sense of morality coming as a result thereof. Sure, there are examples, such as triage where our morality can be truly considered Darwinian, but a simple consideration such as the quality of life of the disabled, will show that this can by no means be a generalization.