Okay, so after answers posted and continued digging through the internet, I have found the solution...at least a temporary one. The answer is at: $URL$ The author details how to specifically find changes to logins using the default trace on the instance. This is great...sort of. The first problem is finding out how "busy" the instance is, which will affect the rate of rollover files created by the default trace. For example, I have one instance where the oldest rollover file is from 2/15. On another instance, the oldest rollover file is from 2 AM today. (!!!) So, to successfully gather any changes to logins, using this method, it has to be determined how often to execute the query...and dump the results into a table for later review. Thank you all for your suggestions and help in nailing down a workable solution. 

The best way is to use Ola Hallengren's maintenance plans, because the ability to determine AGs in the maintenance is already "baked in". However, if for some reason you don't want to or can't use his maintenance plans, then you'll need to insert the deterministic function, , to figure out if the database resides in the primary node or not. The example comes from: $URL$ 

Another, newer option, is using master.sys.fn_hadr_is_primary_replica('DbName'). I have found this super helpful when using SQL Agent to do database maintenance (coupled with a cursor I've used for years) and also when executing an ETL or other database specific task. The benefit is that it singles out the database instead of looking at the whole Availability Group...if that's what you need. It also makes it much more improbable that a command will be executed against a database that "was" on the primary, but let's say an automatic failover happened during the job execution, and it is now on a secondary replica. The above methods that look at the primary replica take one look and don't update. Keep in mind, this is just a different way to achieve very similar results and give more granular control, if you need it. Also, the reason this method wasn't discussed when this question was asked is because Microsoft didn't release this function until after SQL 2014 was released. Below are some samples of how this function can be used: 

I don't know if this is still an issue for you, or if you've found a solution, but in case you haven't, a very powerful set of tools, and one specific to your issue, can be obtained from: $URL$ Specific to your issue, use "Copy-SqlLogin" and configure it as a scheduled task on each server (primary and all secondaries) in whatever configuration that will work for your needs. I used this solution at the last place I worked and scheduled it to run every hour, and never had an issue with logins after implementation. If, for some reason, you cannot utilize dbatools, you will need to use , devise some method to pick out the logins you want to "replicate" (store in a table??) and then execute the on all relevant instances, which will have to be hard-coded. So, this second method is only slightly better than manual intervention. However, assuming DBAs are the only ones who can create logins, it would be easy enough to make a procedure for all DBAs to always add a new login to this process whenever a new one is created. One thing to keep in mind, wherever the login is obtained from, the User level permissions will be carried over to all replicas, so make sure the "source" login/user is configured correctly before implementing any sync solution. IMHO, logins and SQL Agent jobs are the only thing lacking from AlwaysOn, and perhaps in a future release, Microsoft will add some automatic functionality--especially for logins, since it really breaks the whole purpose of automatic failover if the logins aren't sync'd. 

You can write all 3 backup types to a backup device, since a backup device is simply a logical location pointer: $URL$ Full, Differential, and T-Log backups can all be written to the device. Think of it as an "alias" or "shortcut" to the backup path. 

When you use Send Test Email, SSMS is using your credentials. When SQL Agent attempts to connect to the mail profile, it's using the SQL Agent service account credentials. That would be a major difference, and it wouldn't have anything to do with time of day...just credentials. You can test it by scheduling a job that has a task that will fail (i.e. Select * from northwind) and let the SQL Agent run it, and find out if it will send the notification. That will at least eliminate the service account permission possibility... 

Ideally, there would be two of these connection managers, one for the primary and one for the secondary, which I could then use in the "Execute SQL Task" objects. Then everything would work perfectly. There very well may be other ways to do this, but I'm not very experienced in SSIS or development outside of TSQL. UPDATE: The above process is done every day...which is why I'm using an SSIS package and SQL Agent. So, the whole process has to be automated and have all the values necessary--especially the determination of the replica states (primary and secondary)--inside the package so that no manual intervention is required. 

Based on your description of the problem, the actual problem is configuring your monitoring software, not the SQL Server replication solution you have in place. Either figure out how to change/fix the monitoring software or throw it away. Never change the functionality of HA/DR for databases to "serve" monitoring software, that by the way sounds ridiculously incompatible with SQL Server. 

The backup device is really just an alias, so you don't have to type out "\server\drive\folder\subfolder...". Now, the different types of backups, 

I'm working on an SSIS package that will refresh dev databases from production backups. The package has been in place for years, but we're deploying Availability Groups on the dev instance, so the tasks have to be changed to work with both the primary and secondary replicas. Background: All instances are SQL Server 2014 SP2. One production instance (PD1), two dev instances (DV3 & DV7) and one utility instance (DV1), where the SSIS package is deployed to SSISDB and where the SQL Agent job runs. In the SSIS package, after the full backups are obtained and put on a network share from production, the next set of tasks (in a separate SSIS package) needs to figure out which node hosts the primary replica. I'm following the steps listed here to go about this work, and everything works great if it's hard-coded (which, of course won't work if/when a failover occurs). The only way I've been able to think about approaching this is, at runtime, evaluate which instance is primary and then proceed with the tasks (which, by the way are all "Execute SQL Task" objects--requiring their own connection definition). I've seen a few examples of how to use expressions in ConnectionStrings and variables, but can't figure out how to set the value returned from the below query in SQL Server to return the correct instance to set the connection string in the package. 

I've used Ola's scripts for quite a while at several companies, and just started a new job at a company who has already implemented MultiServer Agent Jobs to execute backups, DBCC CheckDB and IndexOptimization. For whatever reason, the person who implemented the solution in mulitserver jobs removed the output file "string" (i.e. the path to the Log folder on the instance). When I copied that value from Ola's scripts after I deployed them on my local machine, it caused 2 of the full backup jobs to fail because it "couldn't find" the path. The machine that the failures occurred on has 2 instances, and so far as I know, the path to "Errorlog" is default and based on the installation selection of that default. Both instances are SQL Server 2008 R2 Standard, while all the rest of our instances are 2014 Enterprise (which really should make no difference...but who knows?). I have removed the output file on the backup jobs so they will run successfully, but I'd really like to figure out the best way to implement this on all of our instances. At the very least, I suppose I could remove the 2 instances that are barfing with the path and recreate them on the local instances...but that really kills the benefit of using MultiServer SQL Agent jobs. Anyone have any ideas? 

Finding the job_id is not necessary if the job is named the same on all replicas. You can use the @job_name parameter, and never have to know the job_id. See this link for an example: $URL$ A more specific answer to your question is to use . 

I found the answer already asked about the new variable, releases in SQL Server 2014, "SQLLOGDIR", which makes perfect sense that my 3 instances of SQL Server 2008 R2 wouldn't know what to do with that. Here's the link:SQLLOGDIR 

This way, I can easily write the backups to the correct location, and even more importantly, I can move/copy/purge these files easily based on this file structure. It's much easier in a restore situation to know where all the pertinent files will be located, rather than have to search through hundreds (or thousands) of files in a single folder. So, in conclusion, for ease of administration, I would highly recommend creating a backup device for full backups (up to you whether you want to separate these out between system and user databases), one for differential backups and one for transaction log backups. Also, I know it's common (even Ola's Maintenance Solution does this) to create a top level folder based on the instance name, then next level folder is the database name, and under that is each type of backup. This is a pet peeve of mine (yes, personal bias) because then traversing this structure is unnecessarily complicated. But, make sure to create something that will best fit your needs--and remember that the reason for backups is to recover from a problem...so, don't add to that problem by struggling to find the backups you need. 

I just started a new gig, and have discovered that two instances of SQL 2012 (SP2), installed on Core Server 2012 R2, have a different name than the server it's running on. They are both virtual servers. For example, the server name is Server2 and Server3 (can RDP to it and can connect to it multiple ways using this name) and can even connect with SSMS from other machines. However, when I run @@Servername, it returns "CO-SQLTEMPLATE"--on BOTH servers. The reason this is troublesome is because these two instances participate in AlwaysOn replication, and there are several problems...the most glaring one is automated backups will not work. Using the HADR systables and functions, it either shows that none of the replicas are "primary" or all of them are (!!!). Also, it is not clear that the replication is actually working. In a couple of the AGs, it shows that the databases are synchronized with the Primary (Server1), but I don't trust that since there are essentially 2 instances with identical names. I've been hunting around on Google, and cannot find a source that indicates where SQL Server gets its instance name from during installation. I've never seen this issue before, and it is truly bizarre. This is my last ditch effort to try to find a solution before I just wipe the 2 servers clean and start from scratch (which, obviously, I'd rather not do).