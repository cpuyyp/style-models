But before you clean his house, you should consult with a counselor specialized in hoarding. Several people in my wife's family are hoarders. And from that I've learned a little bit about hoarding. Hoarding is a type of executive function disorder -- meaning that the person has a hard time deciding what is valuable and worthless. Moreover, it is often something that has an onset at some point in life and can get amped up by depression. To put it another way, hoarding things is a symptom -- not the root issue itself. But then cleaning things for a hoarder doesn't work because the function problem remains. Now, all that being said, if the house has become unsanitary, this all seems minor... 

More broadly, the objection isn't too important, because Descartes is not a radical skeptic. Instead, he winds up being committed to just about all the normal things we believe but on the foundation of what Cottingham calls the Cartesian Circle (proof for the self that depends on proof for God; proof for God that depends on proof for the self; plus the magic of ideas). So the memory of being a conscious being is dubitable 

I think your question turns out to be confused. Obviously, there are conceptions of justice that are incompatible with Kant's ethics. But I think the example you raise won't pass muster on this count. If I'm understanding you correctly, you argue: 

I'm going to suggest two answers here or rather one particular answer and one means of analyzing more generally whether the behavior is appropriate. For some religious perspectives in ethics, the answer is going to be a clear yes. The stakes would be heaven and hell (or equivalent concepts), and the value of autonomy / full rationality / comfort is not going to outweigh that. This type of answer might also be shared by Kantians depending on the particular strain of Kantianism (here, the question is going to be the nature of the "reason" in question -- on my reading, Kantians should try to help people to think rationally to the end. Some others, say perhaps Christine Korsgaard, would seem to give more wiggle room). Viewed as a generic philosophical problem for utilitarians and consequentialists, this is a weighing problem. First, you need to calculate the cost of ignorance. Second, the damage done in removing the ignorance. Third, you may need to modify the second by accounting for the potential failure of the damaging attempt to persuade. Fourth, you need to incorporate the probability that you are mistaken in what are trying to persuade about (i.e. the degree of confidence that concerns the claims at hand). So, it's easy to think of a lot of different possibilities depending on the scale of the error you are trying to correct and the damage it will already cause, the damage that occurs from trying to remove it, etc. So, it does not seem an Atheist is much motivated to convince Aunt Ethel who will die within the week from cancer to stop believing in God merely because it's an ignorant belief (high potential for failure, high cost to remove belief, low damage of having belief). Conversely, it might be worthwhile to convince uncle Warren Buffett to donate his money to the best cause (say perhaps, curing all cancer on the planet) when he seems somewhat amenable to it. Those are at least my thoughts on two approaches. They key distinguishing point is that the first set believes they have something of absolute worth they need to convince the party of whereas the second set is making a calculation of how much the organism knowing that or being convinced of that matters versus the status quo (because the change is of relative value). 

At the end of 7d, he bridges it back to his main point by saying that gods would disagree about matters of import which are not resolvable by measurement or simple math. Moving to 7e, I don't think his point is the symbolization you suggest. Specifically, I take the part at 7e to express "discord if and only if disagreement is about substantial things" -- i.e. I take it to express that the gods aren't in discord over something minor but rather they are in discord because they disagree about the nature of piety, etc. in a fundamentally irresovable way. Why then does Plato make this argument (since he already said they were in discord)? I take it that the point is to block out the option of just saying "god A is correct for reason of knockdown argument B or reason of empirical fact C." Instead, it's point out that there's a fundamental incapacity to define piety by appeal to the gods -- since the gods are in discord and this means by definition that they do not agree for empirically and logically non-resolvable reasons about the nature of piety. 

My conjecture is that the quote would be manufactured by a 19th or 20th century school of logic, because it's not really compatible with Plato's system or with Neoplatonism (Plotinus, Augustine) and that earlier nominalist approaches would view Socrates as an opponent rather than hijackable hero for their cause. 

Aristotle addresses roughly the same question (sans the contemporary mathematicization) in explaining why he does not think Utilitarian in right in the Nicomachean Ethics. (Of course I use the term Utilitarian here loosely). The basic answer is that in maximizing our well-being (trying to achieve eudaimonea) there are parts to the puzzle. First, there is the goal that I am bothering to pursue. Second, there is my pursuit of it. According to Aristotle, we all pursue happiness (eudaimonia) a thesis that will go unchallenged until past the time of Kant. The genius of Aristotle's answer is that he maintains that we pursue what we think will make us happy. The problem is that we can be deeply deceived about this question. In your question, the idea that we are mistaken about a risk-reward calculation would for Aristotle demonstrate a lack of phronesis (practical wisdom). In other words, it would mean that we are making a bad particular judgment. Despite how it may appear, the localized version falls under the second question which is my means of pursuing of happiness. My miscalculation refers to what I think will get me eudaimonia. This problem can then repeat itself on the larger scale if one's entire idea of what is good is mistaken. On Aristotle's picture, the more you lack wisdom the poorer both your choices and your idea of what is good to have are. Thus, lack of practical wisdom can compound itself. Interestingly, you can encourage yourself to be wrong because you take pleasure in things that are not able to ultimately give you eudaimonia. For instance, the pursuit of raw pleasure might encourage you to pursue crack cocaine and then this experience might be such that you begin identifying it with the good you want in life thus distorting your idea of the good life and making your judgments increasingly bad. Referencing his view to the language you are using, the utility function can be wrong (= having the wrong vision) OR one's risk aversion can cause one to err greatly ( = failure to pursue the right things vis-a-vis your vision).