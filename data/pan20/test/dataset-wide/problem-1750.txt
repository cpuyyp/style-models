I have a busy celebrity stock photo website and I am trying to hide the photos behind the website root, so they can't be accessed via URL, but my ASP script can read the photo and sends it to he browser in binary. I'm using Windows Server 2008 R2. I would like to know what security settings should be on the folder that contain the photos. My website is sitting at and the photos need to be stored on the D drive here: . I did manage to get this working by simply clicking 'Share' in the properties of and then giving 'Everyone' read/write permissions but I feel I'm doing something wrong. What should I be doing to make this folder safe, but accessible for the server administrator account and my website scripts? What 'Share' properties should I be applying? Should I be sharing? 

Working overly tired caused me to use the wrong web.config file in my application, therefore applying a permanent redirect on the wrong URL!! I was meant to convert: 

We tried copying imagick.so and memcache.so from the old extension directory to 5.6.7's extension directory, but without any luck. How do we install these extensions to our latest version, PHP 5.6.7? Or is there a way to resolve this without reinstalling anything? Edit: To install PHP 5.6.7, I used the steps given in this gist: 

I am trying to build an automated background backup program to backup my entire website and its heavy photo folders, using Amazon's cloud storage service, S3. I am using S3Sync from S3Tools and have successfully tested a dummy backup using only the command line window. When I save the working command line to a batch file (.BAT) and have a Windows schedule call it, it does not work. I can only think this has something to do with the local paths set in the command line. If I go on to my server and open the command prompt from my 'Start' button, the command prompt has a default of: 

No idea what's going on. New to Windows Server 2003. I can see the file in progress in Windows Explorer but then it disappears as soon as the file is finished downloading. What is going on? 0.o 

(Not sure on the model at the moment will update once I know) So we had a a RAID 5 that had two hard drives fail at the same time. Positions 0 and and 1 are labeled as "online". Positions 2 and 3 are labeled as "failed". We had a backup drive (of course) and put it in position 2. The drive is still telling us as position 2 as "failed". Is this usual behavior? Is won't let us rebuild of course since we lost two drives. (To make sure the controller wasn't just the thing that died, we tried switching the drives around. Switched 0 and 2 positions' cords. 0 went to failed while 2 went to online. The problems followed the drives) What should we do? EDIT: Put in the new drive and now on boot it's saying "unresolved configuration mismatch between disk(s) and NVRAM on the adapter" No idea what that means. xD 

Is there a way to get 127.0.0.1 to route to the host computer (the one running the virtual machine, not the virtual machine itself)? I am supporting a web app that sometimes requires 127.0.0.1 to be the ip address, and NOT the 10.222.54.2 number I am getting for the host address at the moment. Thanks! 

Have the above server (got it for free) with the PERC 4e/Di raid controller inside (according to dell's site). I've downloaded the drivers to a floppy. The Windows Server 2003 Install disk recognizes the fact these disks exist and that the drivers on the floppy are newer. I select them to load, I see several screen flashes with "Windows is starting..." at the bottom of the screen and then I get the message saying no hard disks could be found. We've looked inside the machine and there is no IDE or SATA capability to speak of. Any ideas on what we should do? :) 

I have a growing stock photo website. It's currently hosted on a pretty basic dedicated server from WebFusion and I now need to expand, both storage and performance, and to lose their rubbish support team. We have 500k photos online now and reckon we could make the million or two mark quite soon. I'm now stuck on what options there are for expanding, whether to just upgrade the server we have to hold more files, use a third-party storage service, like Amazon, buy our own server or something else. Any suggestions would be amazing, thanks. 

What is the sensible way to get around this? Can I change the default directory on the command prompt processor, when it's first loaded? Or is there a way of changing my batch command code to use the local paths correctly? Maybe this isn't the problem at all and it's something else? Any help greatly appreciated. My command line code: 

I'm fairly new to server administration, so please be gentle with me. On my dedicated server, in IIS6 manager, I've just added a new site called "upload-system", and modified the FTP settings so the home directory is \upload-system\www\uploads\, instead of just \upload-system. This is all okay but have one issue: When I connect to the server using an FTP client, for example CuteFTP, I land in my new home directory, \uploads, just like I wanted, but from there, there's nothing stopping me from going back a directory, using the up-level/back button on the FTP client. I'm actually able to go right back to the c: directory on the server. I created this FTP site so my client can FTP his photos there, I really don't want any of their office staff having access to other parts of the server when connecting via FTP. How do I stop this from happening in IIS6 manager? 

I am trying to migrate an old Windows Server 2003 32-bit machine, running MySQL 4.1, to a new Windows Server 2008 R2 64-bit machine, running MySQL 5.1, and have just got to the database part. I have quite a heavy DB sitting on the old server, and before I try to download the tables and then re-upload them to the new site, I want to make sure I don't have to do a conversion first? The old server is not running the latest MySQL or PHP so using PhpMyAdmin is out of the question, and I don't have permsission to change anything like that, I just have a rubbish, basic, buggy WebFusion control panel. Any help gratefully appreciated. 

Select a disk, then [EFI GPT] partition map. Analyze, and Quick search. It found several partitions. 

Several days ago I found my DS412+ in fatal state. Volume1 crashed, system volume too. Moreover, Volume2 disappeared from the system! It looks like Volume1 had no free space and cannot transfer data from a couple of bad blocks to a new place and that hurt the system data. (it's just a theory). I managed to return Volume1 back to life using the procedures described here (). BTW have to mention new command that simplifies the process! Then I restored system volume using Synology GUI. Everything started working OK except that I cannot restore Volume2. It was RAID1 array consist of 2 disks of the same size. This is excerpt from of the date right before the crash: 

I don't want the phone to receive more that 1 call. So if an operator have one ongoing call, a new incoming call will received busy signal. As far as I understand, there is no option to set this behaviour using Web Admin of the phone. 

Is there any chance to restore RAID volume? Or is there any chance to restore data from the volume? For example, mounting /dev/sdc3 member directly? More mdadm info: 

/dev/sdc Partition Table Next I wanted to restore and check sdc partition table: I used which is not a part of Synology standard distribution, but could be installed from . After installation it can be accessed from console by . 

Eventually - to update system partition table (without need to reboot). mdadm Now it's became possible to restore raid superblock. 

RAID members (/dev/sdc3 and /dev/sdd3) are still on their places, and it looks like they are OK, at least /dev/sdc3. 

This helped me to clear old and probably damaged info about raid array. I think this action is dangerous in many cases. 

So I took the following steps to get rid of situation. Please keep in mind, I'm not guarantee that this way is correct in all details, and probably could lead to data loss, but it helped me. Bad Sectors First of all, I take care of bad disk sectors (I don't know why they didn't automatically remapped). And probably this caused some problems with data on another disk to. Checked several sectors around fault one: