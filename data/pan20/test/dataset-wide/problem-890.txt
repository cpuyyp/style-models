Interferometry isn't as simply as looking at an object with two different telescopes. It's complicated and costly. If we assume that operating the interferometer would cost around \$200,000 per night (is that gratuitous?), we find yearly operating costs of $\sim$\$73 million - assuming that it's used every night, which isn't likely. But even accounting for all the nights when the interferometer wouldn't be in use, that's probably still more than the estimated yearly costs for the E-ELT (50 million euros, or \$54.33 million). The single-dish telescope - again, operating a shorter wavelengths than Keck - would probably cost less per night than the new Keck Interferometer. Perhaps the relatively low construction costs of the third telescope would offset all of this in the short-term (it likely would). Here's the really obvious thing, however, that I've been ignoring: More dish means more light. An interferometer with an $170\text{ m}$ baseline is not the same as a single dish telescope of the same diameter. The three dishes are much, much smaller than the single one. While the resolutions are the same, the size of the dishes really does matter. A dish with a diameter of $10\text{ m}$ has an area of $25\pi\text{ m}^2$. A dish with a diameter of $170\text{ m}$ has an area of $7225\pi\text{ m}^2$ - a difference of a factor of 289! If you want to make true comparisons between the new interferometer and a large telescope, you'll need more than three dishes. And that will make costs skyrocket. Just for fun, imagine that we end up having 50 total dishes, with a baseline. If each costs \$30 to \$40 million to build (and here I'm being generously low), we quickly find that building 48 more dishes runs us to \$1.9 billion, or at least the cost of building our $55\text{ m}$ optical telescope. Okay, so let's again assume that I made an error somewhere, and this figure is too high. Also, if you ended up building this interferometer (Where would you put it, by the way? Mauna Kea's crowded enough!), you could probably make each dish simpler than Keck I or Keck II. You still have to deal with high nightly operating costs - really high operating costs. Science! So, why isn't the interferometer up and running? According to NASA, it's because the interferometer's main target, observing certain circumstellar disks, is done: 

I am not expert of GRBs, but this high-oscillation behavior seems a characteristics of GRBs: you can see few examples here. In fact, the BAT time resolution is very high ($\sim100\mu s$), then you can resolve very tiny details of the source's timing event. About the source variability, this is something more theoretical (so I can not be of much help), and there is no accepted theory, but qualitatively, in some models the gamma rays are produced by clumpy clouds of relativistically ejected material, which could account for the high variability indeed. Other source: Wikipedia classification . 

Not all models of dark energy assume it constant. However, when this is assumed true, dark energy is usually compared to the energy density of the vacuum. In other words, while the Universe expands, the dark energy increases proportionally, so its ratio with the Universe volume (the density) stays constant. Or, better, we generally believe those models where the dark energy is a constant because they fit better our observations of the Universe, in particular the Big Bang model, which describes how our Universe evolves. If you like some math, you can have it here. 

Not really. Quasars do indeed need a SMBH to be powered, and this is a necessary condition. But, Quasar phase only lasts for tens millions to few billions years. This means that, in a more recent universe, Quasars are turned off but the host galaxy... is still there. And the SMBH also do. This is exactly as our Galaxy case ($Sgr A^*$), where the evidences for the presence of a SMBH are among the strongest ones, but still no nuclear activity is present. However, there are tons of study to infer the proper amount of AGNs in the whole Universe by using luminosity functions. 

Or, that is equivalent, you can express your first equation (Stefan-Boltzmann), in Solar units as well (as shown here). Try it out just by your self: choose a mass, or observationally speaking, choose a luminosity. Then trace your line on the HR diagram, and find your star. That star has a defined temperature (spectral class), Mass and Radius as well. If you need the exact equations, feel free to ask please. Nice aim, anyway. Have fun! 

From left to right: Logarithmic density, logarithmic temperature, and x-ray emission. Why does the density drop off so quickly? I would expect that the channeling of more of the wind into a small beam would lead to a rather steady radial density profile along it, as is the case with the temperature graph. 

After inflation, the expansion of the universe did indeed slow down. During the inflationary epoch (lasting roughly $1 \times 10^{-33}$ seconds), the universe expanded by a factor of $10^{26}$. That's incredible! However, the inflationary epoch didn't last long, and that incredible expansion ended pretty soon after it started. The universe is, as you said, still expanding. In fact (like you also said), that expansion is increasing. However, we have to be careful when we talk about the rate of this expansion. Currently, the rate of expansion between two objects depends on the distance between them, which is encoded in Hubble's law: $$v=H_0D$$ where $v$ is the recessional velocity, $H_0$ is Hubble's constant, and $D$ is the proper distance between the objects. This relation proves that objects that are farther away are moving away at a greater speed. We can extrapolate from that that, at a sufficiently far distance, two objects would be moving away from each other at the speed of light or greater! However, this is only true for objects very far from each other. But yes, eventually, any two objects sufficiently far from each other will move apart at the speed of light - and then greater. Source (for length of inflationary epoch): $URL$ Source (for Hubble's law): $URL$ 

Here's my answer. I'll try to make it as comprehensive as possible. It's pretty hard to define the edge of the Solar System. Most people would probably define it as where objects are no longer gravitationally bound to the Sun. That just shifts the question a little, though: Where is that dividing line? To try to answer this, I'll go over the regions of the Solar System. The first region is the domain of the inner planets - basically everything from the asteroid belt inwards. It is comprised of Mars, Earth, Venus, Mercury, their moons, and all the smaller objects that surround them. The inner Solar System is very rocky, as one can imagine. The terrestrial planets are primarily made of rock, as are the asteroids and the inner planets' moons. The second region is the domain of the gas giants. It consists of Jupiter, Saturn, Uranus, Neptune, their moons, ring systems, and assorted smaller bodies, such as Trojan asteroids. The gas giants had a big influence on the Solar System when it was first formed, pulling in chunks of rocks, grabbing moons, and possibly stabilizing or de-stabilizing orbits. Some may have migrated outwards (as per the Nice model), but their orbits are currently stable. The gas giants are made largely of gases, but it is thought they have solid or molten cores. The composition of their moons is familiar - more like objects in the inner Solar System. Next up is the Kuiper Belt. It's sometimes introduced as a cousin of the asteroid belt, but that's not accurate. The bodies that make up the Kuiper Belt are chunks of rock and ice. Notable examples of Kuiper Belt bodies and/or trans-Neptunian objects are the dwarf planets Pluto, Sedna, Makemake and Haumea. There are also lots of smaller objects, including some short-period comets (although these are more properly part of the lesser-known "scattered disk"). While there have been theories for years about another planet out there, it is not considered likely. The Belt extends from 30 to 50 AU. Further out still is the Oort Cloud, named after Jan Oort. Observations of objects in the Oort Cloud are extremely difficult, if not impossible, so its existence has not yet been verified. It is populated by long-period comets and smaller objects. These are also composed of rock and ice. The Oort Cloud is thought to extend up to an incredible 50,000 AU. While the other regions so far mentioned are roughly in planes, the Oort Cloud is spherical. Some consider the far edge Oort Cloud to be the edge of the Solar System, because the majority of the mass of the Solar System is within it, but the boundary between the Solar System and interstellar space is actually thought to be within its inner reaches: the heliopause. This is generally accepted as the Solar System's boundary because it is where the solar wind meets the interstellar medium. This is often placed at 121 AU - which is where Voyager 1 passed through in 2013. The heliopause is the far boundary of the heliosphere, beyond which the interstellar medium takes control. Inside "layers" are bounded by the termination shock and the heliosheath. In summary, while the Solar System is made of many regions, the heliopause is considered to be its outer boundary. Once again, I welcome any and all input regarding this question and answer. 

As far as I know, this is an only theoretical object, it has never been observed. In the original paper from the authors, they provide some observable characteristics of these objects, like some peculiar emission lines. You can imagine the chemistry of such an object would be really unique. Here an article for a possible identification link 1, very recent work (2014). And here some calculations link2. 

It is clear that the star undergoes a change in position. Then usually, the radial measurements go along with astrometrical measurements, to identify the position of the star along the planet's orbit. Of course, you need some conditions are verified to allow this measurement. First of all, you planet must be massive enough to bring a sensible change in the position of the star. Then your instrument must be sensible enough to resolve the tiny effect originated by this change. Possibly, also other conditions play a role, but I am not an expert (you can take a look at here). For a general comprehension, also a wiki for Methods of detecting exoplanets. 

The electron in the atom transits from a level with parallel spin (with respect to the nuclear proton), to the lower state, where the electron spin is antiparallel. When this happens, the atom emits a photon, known as the 21 cm radiation, or hydrogen line. This line falls into the radio domain, which can be observed by radio telescopes. Since this radiation comes from rotating arms, doppler shift of the line can trace the distance of the emitter region. And voilà, you have your map. EDIT: ops, I missed the previous links where the answer was already given. 

This is a tricky question, not immediate. If we talk about Main Sequence stars, yes, you can constrain your fictional star by two parameters. The crucial parameters in the diagram, as you said, are the mass and the radius. This is why the HR diagram well represents the stellar population with two axis. Of course, for your scope, we need to do some assumptions. For example, the metallicity, that for your purposes can be fixed as the Solar one. Or, that the initial mass is already in a condition to contract. You can see it this way: the luminosity is connected with the radius (because it depends on the irradiating surface), while the temperature is connected with the mass (the more is the mass, the more is the pressure at the center of the star). If you have $L \sim RT$ and $L \sim M$, then you also have $RT \sim M$. The degeneracy from one parameter can be overcame if you have your reference star (the Sun), which allows you to trace isoradii lines on the HR diagram. See here for example: 

The page you link to contains what is, to my knowledge, the most descriptive graph of the signal from the RATAN-600 data that is open to the public. Bursov et al. have not yet presented their results, which will be explained at the International Academy of Astronautics SETI Permanent Committee meeting late this September. Chances seem to be good that we won't see much more information until then. Here is the graph at a frequency of 11.1 GHz, as will be presented by Bursov et al. and as used in Croft et al. (2016), who very quickly put together a paper with an analysis of some basic follow-up observations using the Green Bank Telescope: 

Only five pulsar planets have been confirmed or have garnered enough evidence to make a strong case for their existence. None of them are like the terrestrial planets in the Solar System insofar as the way they formed and their orbital movements. 

I think you're misinterpreting the passage. Gas giants form via a process know as core accretion. First, a massive core forms from solid material, initially with a small amount of gas. The envelope then grows, producing an object we would recognize as a gas giant - a large gaseous atmosphere, surrounding a comparatively small "rocky" core. The problem with Hot Jupiters is that gas giants, according to current theories of planet formation, cannot form extremely close to a star. Inside a boundary called the frost line (which changes over time), there is not enough solid material for such a massive core to form and accrete enough gas to form a gas giant before the protoplanetary disk dissipates. Therefore, any gas giants that exist inside the snow line should have formed outside it, and then traveled inward via a process known as migration, which can happen through several different mechanisms. The phrase "spiraled inwards" doesn't mean that the planets will spiral into the star, merely that their semi-major axes will shrink and their orbits will move closer and closer to their parent star, possibly stopping at some finite distance. 

The key for stellar classification is the Hertzsprung-Russell diagram (or HRD for brevity), also know as the color-magnitude diagram. 

(Here $R_e$ is the so called effective radius). For completeness, another illuminating picture from here: 

From this book it seems you can have $\epsilon_{core}$ values raging from ~$30\%$ (a low value) up to $70\%$ (which is more "usual", i.e., requested by theories). More information can be found here and here. 

You have plenty of choices! I am specialized in X-ray astronomy, then I can suggest you many facilities: they usually give at least some of their data publicly available. Tipically, you have data for light curves (photon count rates versus time), and/or spectra (that is flux versus energy). I suggest you to work on the light curves: they are easily available, already reduced (you don't have to play with the data to make them usable, you can directly use them), and they fit your request of conforming to a regression model. Also spectra are enjoying, still I know some theoreticians who are not familiar with spectra, plus they usually need some more knowledge, because of response files, spectral fitting packages, etc. It is up to you (and your available time)! Here a list of some facilities with available data: Rossi X-ray Time Explorer Swift/BAT INTEGRAL Chandra MAXI Also here you can find a list of many facilities with NASA participation, so the list is much larger. Of course you can also use other kind of data (optical, infrared, radio) by the MAST project, but I have no experience on those. I guess, in the optical band, the Hubble Space Telescope will have a huge amount of data! If you need a hand, beyond the SE vote up/vote down neurotic fashion, let me know. Good luck! 

In a homogeneous and isotropic Universe (even if recent observations challenge this hypothesis), you can derive the Friedmann equations, which describe the evolution of the Hubble constant with time: $\frac{\dot{a}}{a} = H(t) = \frac{8 \pi G}{3}\rho - \frac{k}{a^2} + \frac{\Lambda}{3}$ (with $c=1$) (Equation $1$) where $a=a(t)$ is the scale factor, $\dot{a}$ its derivative, $G$ the gravitational constant, $\rho$ the matter density, $\frac{k}{a^2}$ the spatial curvature (a parameter that describes the metric of the Universe), and $\Lambda$ the cosmological constant (an integration constant added by Einstein). It could be useful to rewrite the equation as: $H^2 = \frac{8 \pi G}{3}(\rho + \rho_{\Lambda}) - \frac{k}{a^2}$ where $\rho_{\Lambda} = \frac{\Lambda}{8 \pi G}$ is the "density of cosmological constant". We can also expand the matter density as $\rho = \rho_{matter} + \rho_{radiation}$. So we have a "total" density $\rho_{tot} = \rho_{matter} + \rho_{radiation} + \rho_{\Lambda}$. The destiny of the Universe depends on this amount. In case of $\rho_{tot} > \rho_{crit}$, or equivalently a closed Universe ($k=+1$), the equation $(1)$ becomes: $\dot a^2 = \frac{8 \pi G}{3}\rho a^2 -1$ Which points out that the scale factor must have an upper limit $a_{max}$ ($\dot a^2$ must be positive). This in turn means that the second derivative $\ddot a$ of the scale factor must be negative, when approaching $a_{max}$, that is the scale factor function inverts its behavior: