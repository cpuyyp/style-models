I would like to compile OpenSSL from source. There are a number of configuration options I can use when compiling it. I prefer it to be as secure and hardened as possible, and it will eventually be used when compiling Apache HTTPD. There are some configuration options that seem obvious for this goal, such as and . What other options should I use and why? The options are all documented on the OpenSSL website, but for some of them it difficult for me to discern the effects, or pros and cons, of using each one. What are the pragmatic options to choose that will make OpenSSL hardened? 

I'm trying to use Linux Capabilities to allow a program (httpd) to bind to a privileged port (443) as a non-privileged user. I set the capabilities for the program using this command: 

Not sure if it's relevant, but here is the fstab line for the mounted partition (where this test is being run): 

After digging through a lot more log information I was able to discover that the client machine was not responding properly to the server's ticket. The way you can tell something is wrong on the client machine is that you will see the Apache server's error message "failed to verify krb5 credentials: Server not found in Kerberos database". In the file on the client machine you have to make sure the web domain name maps to the proper Kerberos realm: 

We have a quite urgent issue, where company old SBS server BSOD's right before presenting the logon screen. I ran the mini-dumps via the WinDbg, and got following output: 

We have an IBM server x3650 M3, and I'm trying to install Linux without using HW RAID (ServeRAID), as per cluster storage software vendor requirements. The problem is that the server exposes the physical drives only to WebBios interface, and Linux insallation (RedHat Anakonda) sees only the virtual drives, not the physical ones. If we clear the RAID configuration, the installation doesn't see any drives at all. Is there any way to disable the built-in ServeRaid and expose the drives to operation system? Or the only way is to bypass RAID physically and connect the disks to motherboard directly? Thanks in advance! 

Just moved the machines to second NIC - and magically they started seeing the network. Quite strange but it worked. 

We have a logical RAID1 drive in bad stripes state, which kept that status even after replacement and rebuilding of both drives, and gives errors in Windows logs about failure of writing to disk. IBM support suggests erasing and re-creating the RAID, then re-installing the Windows. The resulting down-time unacceptible for us, so we want to clone the RAID (via Acronis True Image), erase and re-create the RAID, then dump the cloned data back. Following IBM logic where RAID erasing and re-creation resets the whole RAID meta-data, this should clear the bad-stripes status, and start from a blank page. Question is if such strategy is possible, and will produce the desired effect? Any idea is appreciated - thanks in advance! 

If the service is running as Local System or Network Service, or as a specific domain user, it can either access the files via the UNC path or it can map a network drive using the function. In the case of Local System or Network Service, the connection is made in the context of the Active Directory computer object. If the service is running as a local user, UNC paths will not work, but it can still map a network drive using provided it can provide a valid username and password. (If the Win32 API is not available for some reason, running the command in a subprocess will also work.) 

Test Procedure The machine I'm experimenting with is PowerEdge 2970 with a DRAC 5, Hardware Version A00, Firmware Version 1.60 (11.03.03). The BMC Firmware Version is 2.50. The NIC Selection is set to Shared and the NIC is enabled. The static IP address is 192.168.241.100 and the subnet mask is 255.255.255.0. There is no gateway on our management network so I have that set to 0.0.0.0. Auto negotiation is on. None of the other settings are configured. With the management network connected to LOM1 (and the LAN connected to LOM2) I can both ping the DRAC and log into the DRAC web interface from a production machine with access to the management network. (IP address 192.168.241.102/255.255.255.0.) I cannot ping the DRAC from a machine on the LAN (mis)configured to use 192.168.241.29/255.255.255.0, even after clearing the ARP cache. With the management network connected to LOM2 (and the LAN connected to LOM1) I can neither ping the DRAC from the management network machine or connect to it via the web interface. Clearing the ARP cache had no effect. I can ping the DRAC and access the web interface from the machine on the LAN. In both cases the operating system on the 2970 has full network connectivity on both the LAN and the management network (once the network interfaces are appropriately configured). I also tried using WinDump to look for arp replies on both the management network and the LAN. In both cases, I saw arp replies from the DRAC only on the network that LOM1 was plugged into. 

We have a custom Yum repo that our developers upload builds to. The problem is that after some time it becomes cluttered with old versions. Removing the old versions manually is quite annoying, so before we try to automate it ourselves, I wonder if there any script that would clean old RPM's based on version (preferred) or time of upload. Best would be if we could specify to simple save X last versions, and erase anything else. Then we could cron it and just let it run daily. Thanks for any idea. 

We have a file-cluster on servers with multiple disks, and we have created a software RAID1 over boot and / partitions, planning that if a single disk goes down, we still will be able to boot and serve data from the remaining disks. The problem is that when one of disks missing, the server when booting up, displays the following error: fsck.ext3: Unable to resolve LABEL LABEL is one of the missing disks partition - boot and / RAID1 partitions seem to work fine. Is there any configuration to ignore these errors, and just bring the server online? So if there one of disks missing, the server will ignore any errors, and just will continue booting? 

I suggest you look into the Sysinternals tools (now part of Microsoft) in particular AccessChk and AccessEnum. I haven't used them myself, but they sound appropriate to your needs. 

They are related in that UAC relies on the existence of ACLs (and all the related security apparatus) in order to function. UAC works by removing (technically speaking, disabling) the Administrators token from non-elevated processes. This means that if the ACL for a particular file or folder only allows access to Administrators, non-elevated processes won't have access. That's why an installer can't write to Program Files without elevating first. EDIT: See this article for more information about UAC. In particular: "When an administrator logs on to a computer that is running Windows 7 or Windows Vista, the user is assigned two separate access tokens. Access tokens, which contain a user's group membership and authorization and access control data, are used by the Windows operating system to control what resources and tasks the user can access." I suppose you could argue that UAC depends on the Windows authorization model, of which ACLs are only a particular component, and that therefore UAC is not related to ACLs. I don't think that's a useful way of looking at it. Let me put it this way: if there weren't any ACLs, UAC would be pointless. You should also read this article which addresses some common misconceptions about UAC, and in particular the misconception that it is a security feature: "The primary goal of UAC is to enable more users to run with standard user rights. However, one of UAC's technologies looks and smells like a security feature: the consent prompt. Many people believed that the fact that software has to ask the user to grant it administrative rights means that they can prevent malware from gaining administrative rights." 

From the dump it seems as problem in driver, but I can't just get what driver responsible for this. I will appreciate any hint what could be the culprit, or how to hunt for one. Thanks! 

When trying to install requirements.txt (or anything else for the matter), pip just time-outs every time with host reset message. This happens only under VirtualBox (guest CentOS 6.4 64-bit, host Windows 7 64-bit), and only for pip/easy_install tools. Almost appears as pypi CDN just flat out rejects the connections. Anyone knows what can cause this, and how this can be resolved? 

As we were under time pressure, we had to erase the accounts, and first re-imported accounts with Prepare-MoveRequest.Ps1, then re-migrated the accounts via ADMT to import SID history. This eventually worked, but I would appreciate if anyone could advice on this for the future. 

Solved by splitting to two VD's, one small with just enough space to contain the boot partition, and the other with the rest of partitions. 

I'm trying to install CentOS 5.11 on DL160 G5, with 4 bays holding 3TB sized drives. The installation with default partition layout completes successfully, however on boot I get to a blinking cursor screen - it's not even reaching GRUB. I've tried updating BIOS to latest one available (17/11/2011), and even manually sizing the boot partition to 200 MB - it's still has the same effect. I presume a GPT needs to be used (rather than the default MBR), however unable to find how to enable it during the installation. 

However, when I attempt to log in to the website (from another Desktop with username 'Jeff') my Kerberos credentials are not automatically accepted by the web server. It should grant me access immediately after that, but it does not. The only information I get from the mod_auth_kerb logs is: 

Additionally, you will need to edit . Under the section, add the option . See this link for details on the enumerate option. Also, if you are using Kerberos for authentication, you will also need to run: 

When I attempt to start the program, it exits because it cannot bind to the required port. I discovered this using : reveals "permission denied, can't bind, shutting down": 

What should I do to make Linux Capabilities work correctly and allow the program to bind to a privileged port? A quick search suggests that a mount with the flag can prevent Capabilities from functioning, and I verified that it's not interfering in this case. 

Without this the client will reject the server because Kerberos tickets may only come from explicitly permitted realms. I hope this information helps others out there! 

As documented in Description of the Windows Update Standalone Installer in Windows, is designed for installing updates in the form of files. It cannot install updates that are in files. To install an update in a CAB file, use instead, e.g.,: 

This is described (somewhat obliquely) in the Microsoft blog post, How to troubleshoot IE Enhanced Security warning "Content from the website listed below is being blocked by the Internet Explorer Enhanced Security Configuration" ? It may still be necessary to change the corresponding setting (as per Volodymyr's answer) on a per-user basis for existing accounts. 

Based on recent experimentation (with Server 2012, but I suspect earlier versions are similar) on non-domain, statically configured networks the NLA service uses the link-layer (MAC) address of the default gateway to identify the network. The details are unclear, though I suppose they could be worked out with a network analyzer. If the configured default gateway does not respond, NLA does not recognize the network, so it's definitely doing some sort of query. (That is, you can't just put in a dummy gateway address, or even a dummy gateway address plus static arp entry; the gateway MAC address associated with a particular network must actually respond in order for NLA to decide that the adapter is connected to that network.) See also my blog entry on a way of fooling Windows 2012 into assigning an adapter to a unique network. If the adapter is assigned an address by DHCP, the logic might be different. I haven't looked into that yet. The logic on a domain network is documented as per the existing answers. 

I have a website running on a Linux computer using Apache. I've employed mod_auth_kerb for single-sign-on Kerberos authentication against a Windows Active Directory server. In order for Kerberos to work correctly, I've created a service account in Active Directory called . I've generated a keytab for the Linux web server using ktpass.exe on the Windows AD server using this command: 

I've run into a perplexing problem where user permissions are not being respected on a Linux computer. Other users are able to move and delete files they don't own. Is there a way to restrict this? Why is this happening? Here's an example. 

Ended up figuring it out. I'm posting here so it helps future readers! There are two things to be done. Fedora 18 does not have the proper package dependencies for sssd (which controls authentication and user/group look-up). Therefore, if you are using LDAP, run the command: 

I understand that "auth" means this rule is applied to authentication. I also get that "pam_krb5.so" means "use Kerberos to authenticate". The part I don't understand is . What does that mean? 

I am attempting to make a keytab using . I get to choose the encryption type, but the man page does not offer a list of possible choices. I also don't know which encryption method is the best! How can I find out both of these? I want the strongest encryption available. 

We use GnuPG for encrypting data, which we upload to a central storage. The public key is being stored on a web-server, and the encrypting script re-downloads it if it's changed. This was done in order to easily refresh the public key every so often on all the servers. After some security thinking, I got the paranoia, that someone can (unlikely, but potentially), break into the web-server, and replace the public key with his own. This would give 2 very unpleasant effects: 1) The hacker could read the data, if he manages to break out into the central storage as well. 2) Even if he doesn't - we won't be able to read the data as well as the private key got changed, and it all can be considered as lost! Can someone advice how to prevent this threat, or perhaps suggest a more robust, but still convenient, key refresh approach? Thanks! 

We have set up a XenServer, and trying to set-up a CentOS 6 guest VM. The installation went fine (using RHEL 6 template), but I'm unable to properly configure the network. The guest VM is able to ping the host machine, but unable to ping any outside machines or gateway. The network settings look just fine - same subnet range and valid IP. Any idea what else I can check? Thanks!