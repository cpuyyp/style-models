Say I have a continuous function $f$ defined on a compact interval $I$ on the real line. As is well-known, I could approximate $f$ arbitrarily well by polynomials. Given $R>0$, how well can we approximate $f$ as a linear combination of functions of the form $x^r$, where $r$ lies in $\lbrack 0,R\rbrack$? If $f$ is analytic, can we express $f$ as an integral $\int_0^R x^r d\mu(r)$? 

Thm (Kronecker).- If all conjugates of an algebraic integer lie on the unit circle, then the integer is a root of unity. Question: Can one provide a good effective version of this? That is: given that we have an algebraic integer alpha of degree <=d, can we show that alpha has a conjugate that is at least epsilon away from the unit circle, where epsilon depends only on d? It actually isn't hard to do this (from the standard proof of Kronecker, viz.: alpha, alpha^2, alpha^3... are all algebraic integers, and their minimal polynomials would eventually repeat (being bounded) if all conjugates of alpha lied on the unit circle) with epsilon exponential on d, i.e., epsilon of the form epsilon = 1/C^d; what we actually want is an epsilon of the form 1/d^C, say. (Question really due to B. Bukh.) 

Say I have a compactly supported $C^1$ function $f:\mathbb{R} \to \mathbb{R}$. Let $R>0$. Let $\nu$ be some reasonable measure on $\mathbb{R}$ -- take, for instance, (a) $d\nu(t)=dt$ or (b) $d\nu(t)=e^{-t}$ for $t>0$ and $d\nu(t)=0$ for $t\leq 0$. Let $\delta(R)$ be the minimum of $|f-\widehat{g}|_2 = \left( \int_\mathbb{R} |f(t)-\widehat{g}(t)|^2 d\nu(t)\right)^{1/2}$ over all functions $g:\mathbb{R} \to \mathbb{C}$ supported on $\lbrack -R,R\rbrack$. What is $\delta(R)$? How fast does it decrease as $R\to \infty$? Given $R$, can one construct a $g$ that attains the minimum? (A variation on the same question: allow measures, not just functions $g$, supported on $\lbrack -R,R\rbrack$.) Update: for $d\nu(t) = t$ this is very easy by isometry, as mentioned below; the minimum is attained for $g$ equal to the restriction of $\widehat{f}$ to $\lbrack -R,R\rbrack$ -- and so, if $f$ is in $C^k$, $\delta(R)$ decreases at least as fast as $1/R^{k-1}$ as $R\to \infty$. I am really more interested in the answers for the measure $\nu$ given in (b) above. 

Let $S$ be a compact subset of the closure of the upper half plane. (Assume that $S$ is a (Euclidean) rectangular box, if you wish.) Let $D$ be the standard fundamental domain of $\text{SL}_2(\mathbb{Z})\backslash \mathbb{H}$. What is a simple way to construct all maps $g\in \text{SL}_2(\mathbb{Z})$ such that the Euclidean area of $g D\cap S$ is at least $\epsilon$? Is there a (good) a priori bound for the size of the entries of a matrix $g$ satisfying such a property? (Yes, my question is motivated by the need to produce a good conference poster, but I hope that will make it more rather than less interesting.) 

There is something the above posts missed (perhaps because the wording didn't make it explicit): the condition on the function $f(x)$ is one sided (i.e., it assumes something on the decay as $x\to \infty$, not as $x\to -\infty$), and thus, once we take logarithms to make the Mellin transform into a Fourier transform, we end up with a one-sided condition as well. Now, one-sided versions of the uncertainty principle do exist - notably that of Nazarov (1993); see also Bonami and Demange (2006). In the end, it turns out to be best to rework the proofs given there to get an uncertainty principle for the Mellin transform of the shape I was asking for. And yes, one does get something essentially optimal in that way, with no spurious factors of log in the exponent. 

Let me carry out matters using a complex-analytical approach, as Lucia suggests, and then say where the difficulty lies. Let $0<\beta<\alpha\leq 1$. First of all, as Lucia says, $$\sum_{m\leq x} \frac{1}{m^\alpha} \sum_{n\leq x/m} \frac{\log(x/mn)}{n^\beta} = \frac{1}{2πi} \int_{c-i\infty}^{c+i\infty} \zeta(s+\alpha) \zeta(s+\beta) \frac{x^s}{s^2} ds$$ for $c>1$. We shift the contour of integration to the left of $\Re(s)=0$, picking up the main terms $$\begin{aligned}&\frac{y^{1-\alpha}}{(1-\alpha)^2} \zeta(1-\alpha+\beta) + \frac{y^{1-\beta}}{(1-\beta)^2} \zeta(1-\beta+\alpha)\\ &+ \zeta(\alpha) \zeta(\beta) \log y + \zeta'(\alpha) \zeta(\beta) + \zeta(\alpha) \zeta'(\beta)\end{aligned}$$ plus an error term of size $O\left(y^{\frac{1}{2} - \frac{\alpha+\beta}{2}}\right)$ along the way. We are left with the task of estimating an error term $$\frac{1}{2πi} \int_R \zeta(s+\alpha) \zeta(s+\beta) \frac{x^s}{s^2} ds,$$ where the integral is over a contour $R$ of our choice going from $-r-i\infty$ to $-r+i\infty$, say, and satisfying $\Re s\leq -r$ at all points. The error will be clearly bounded by $O(K x^{-r})$, where $$K = \frac{1}{2πi} \int_R \frac{|\zeta(s+\alpha)| |\zeta(s+\beta)|}{|s|^2} ds.$$ The problem does reduces to estimating $K$. Now, there are rigorous-numerics packages that include integration and the possibility to compute the zeta function $\zeta(s)$. (I currently use ARB.) However, (a) computations must obviously be finite (at least assuming mortal mathematicians), and (b) computing $\zeta(s)$ is never a walk in the park, and rigorous integration only adds to the overhead. Integrating an expression such as above from $-1/2 - i T$ to $1/2 + i T$ takes 15 minutes for $T = 10000$ (says a better programmer than I), but we should not expect to go much further than $T = 100000$ programming casually on our laptops. The problem that remains, then, is how to bound a tail $$\frac{1}{2\pi i} \left(\int_{-r-i\infty}^{-r-i T} + \int_{-r+i T}^{-r + i \infty} \frac{|\zeta(s+\alpha)| |\zeta(s+\beta)|}{|s|^2} ds\right).$$ The most obvious approach is to use Backlund's explicit bounds (1918) on $\zeta(\sigma + it)$ (see $URL$ They are of the quality $$|\zeta(\sigma + i t)| = (1+o(1)) (t/2\pi)^{(1-\sigma)/2} \log t$$ for $0\leq \sigma\leq 1$ and $$|\zeta(\sigma + i t)| = (1+o(1)) (t/2\pi)^{1/2-\sigma} \log t$$ for $-1/2\leq \sigma\leq 0$. The problem here is that convergence is painfully slow. If, say, $\alpha = 1$, $\beta=1/2$ and $r =-1/4$ (reasonable values all around), the tails will be bounded by a constant times $(\log T)^2/\sqrt{T}$. For $T=10000$, $(\log T)^2/\sqrt{T} > 0.848\dotsc$ - not exactly small; for $T=100000$, the same equals $0.419\dotsc$ - barely an improvement. Notice, however, that why Backlund's bounds are essentially tight for $\Re s<0$, that is not the case for $0<\Re(s)<1$. Of course, they are convexity bounds, so improving on them explicitly would amount to translating into explicit terms rather non-trivial material. However, as long as we are satisfied with $r>-\beta$, what we can do instead is give $L_2$ bounds for the tails, that is, bound $$\int_{r-i \infty}^{r-i T} \frac{|\zeta(s)|^2}{|s|^2} ds + \int_{r+iT}^{r+i\infty} \frac{|\zeta(s)|^2}{|s|^2} ds.$$ (The integral $\int_{r-i \infty}^{r-i T}$ is obviously the same.) Then we use Cauchy-Schwarz to bound the tail of the integral we were discussing. This is non-trivial, and takes us further afield, so I will make it into a separate question: $L_2$ bounds for tails of $\zeta(s)$ on a vertical line . 

E. Grant, A source book in medieval science, Harvard U Press, 1974. From a quick look at Nicomachus's original, it seems to be almost entirely about properties of integers, which are sometimes given a mystical or moral significance. Primality appears as one noteworthy property among several, side by side with being odd, even, triangular, pentagonal, heptagonal, perfect, superparticular, heteromecic, etc. (Nothing or almost nothing non-trivial seems to be shown about any of these.) As for Diophantus's Arithmetic, (a) it could not have an influence in Western Europe during the Middle Ages, as it was unknown there, (b) at any rate, it is largely about what we now would call the (highly ingenious!) construction of rational maps from n-dimensional affine space to varieties. There's very little in Diophantus about integers, and that as auxiliary material. Hence the fact that he does not really discuss prime numbers as such does not tell us much. 

Let $f:\mathbb{R}\to\mathbb{C}$ be differentiable $k$ times, with $f, f',\dotsc,f^{(k)}\in L^1$. Let $\alpha\in \mathbb{R}/\mathbb{Z}$, $\alpha\ne 0$. In "Every odd number..." (Math. Comp. 83, 2014), Lemma 3.1, Tao shows that $$\left|\sum_{n\in \mathbb{Z}} f(n) e(\alpha n)\right|\leq \frac{1}{|2 \sin(\pi \alpha)|^k} |f^{(k)}|_1,$$ where $e(t) = e^{2\pi i t}$. The proof goes essentially by summation by parts. (a) Are there older sources for this? Somewhat confusingly, Tao credits Gallagher ("The large sieve") and Lemma 1.1 in Montgomery's Topics in Multiplicative Number Theory, but they give only equation (3.1) in Tao's papers, not the inequality above. (b) For $k=2$, this is not in general optimal: one can show $$\left|\sum_{n\in \mathbb{Z}} f(n) e(\alpha n)\right|\leq \frac{1}{|2 \sin(\pi \alpha)|^2} |\widehat{f''}|_\infty,$$ which is no weaker and often strictly stronger, since $|\widehat{f''}|_\infty\leq |f''|_1$. This is Lemma 2.1 in my three-prime book draft on the arxiv; the proof I give goes by the Poisson summation formula, plus Euler's formula for the cotangent. Are similar bounds true for general $k$? (Is $\left|\sum_{n\in \mathbb{Z}} f(n) e(\alpha n)\right| \leq |\widehat{f'}|_\infty/|2 \sin \pi \alpha|$, for instance?) Again, can such results be found in older sources? 

Thanks, GH! Let me have another go. I think the following is the right way to go about things, at least if one wants something self-contained and with good, explicit constants. (The latter more or less implies the former, given that almost all of the literature is non-explicit.) We want to estimate $$\frac{1}{2\pi i} \int_{\sigma-i\infty}^{\sigma+i \infty} \left|\frac{1}{s} -G(s)\right|^2 |\zeta(s)|^2 ds,$$ where $G(s)$ is the Mellin transform of a well-chosen function $g:\lbrack 0,\infty)\to \mathbb{R}$. It is easy to see that $G(s) \zeta(s)$ is the Mellin transform of $x\mapsto \sum_n g(n x)$. We will choose $g$ so that (a) $G(\sigma+it)$ is small for $|t|\geq T$, (b) the "physical-space" estimation we are about to do is easy. By Plancherel, $$\frac{1}{2\pi i} \int_{\sigma-i\infty}^{\sigma+i \infty} |1-G(s)|^2 \frac{|\zeta(s)|^2}{|s|^2} ds = \int_0^\infty |h(x)|^2 x^{2\sigma-1} dx,$$ where $$h(x) = \lfloor 1/x\rfloor - \sum_n g(n x).$$ (We will make sure that $G(1)=1$, so that there is no pole at $s=1$; in this way, the equation above will hold for $\Re(s)>0$, and not just for $\Re(s)>1$.) First, let us show that $h(x)$ is bounded for all $x$. (This part is the same as what I had before.) By second-order Euler-Maclaurin, $$\sum_n g(n x) = \frac{1}{x} \int_0^\infty g(t) dt - \frac{g(0)}{2} - \frac{g'(0)}{12} + \textrm{err},$$ where $|\textrm{err}| \leq \frac{x}{24} \int_0^\infty |g''(t)| dt$. We will work with $g$ such that $g(0)=1$, $g'(0)=0$ and $\int_0^\infty g(t) dt = 1$. Then $$|h(x)| = \left|\lfloor 1/x\rfloor - \left(\frac{1}{x} - \frac{1}{2} + \text{err}\right)\right|\leq \frac{1}{2} + \textrm{err}$$ for all $x$. We will now choose $g$ so that we can give a much better estimate for $x$ not too small. For starters, we will have $g(x)=1$ for $x\leq 1-\delta$ and $g(x)=0$ for $x\geq 1+\delta$. Then $$h(x) = 0$$ unless $n x \in \lbrack 1-\delta,1+\delta\rbrack$. Moreover, for each $x>2\delta$, there is at most one $n$ such that $n x$ is in that interval, since $\frac{1+\delta}{x} - \frac{1-\delta}{x} = \frac{2 \delta}{x} < 1$. Hence $$\begin{aligned}\int_0^\infty |h(x)|^2 x^{2\sigma-1} dx &\leq \int_0^{2\delta} c^2 x^{2\sigma-1} dx + \sum_{n\leq \frac{1}{2 \delta}} \int_{\frac{1-\delta}{n}}^{\frac{1}{n}} |1-g(n x)|^2 x^{2\sigma-1} dx \\ &+ \sum_{n\leq \frac{1+\delta}{2\delta}} \int_{\frac{1}{n}}^{\frac{1+\delta}{n}} |g(n x)|^2 x^{2\sigma-1} dx,\end{aligned}$$ where $c =1/2 + \frac{2\delta}{24} \int_0^\infty |g''(t)| dt$. Obviously $$\int_0^{2\delta} c^2 x^{2\sigma-1} dx = c^2 \frac{(2\delta)^{2\sigma}}{2\sigma}.$$ To estimate the two other integrals, we have to choose a convenient $g$ obeying our conditions. I will simply take $$g(x) = \begin{cases} 1 &\text{if $x\leq 1 - \delta$,}\\ \frac{1+\delta-x}{2\delta} &\text{if $1-\delta <x<1+\delta$,}\\0 &\text{if $x\geq 1 + \delta$.}\end{cases}$$ Hence $$\begin{aligned} \int_{\frac{1-\delta}{n}}^{\frac{1}{n}} |1-g(n x)|^2 x^{2\sigma-1} dx &+ \int_{\frac{1}{n}}^{\frac{1+\delta}{n}} |g(n x)|^2 x^{2\sigma-1} dx\\ &\leq \frac{2 \eta}{n^{2\sigma}} \int_1^{1+\delta} \left(\frac{1+\delta-t}{2\delta}\right)^2 dt = \frac{\delta \eta}{6 n^{2\sigma}},\end{aligned}$$ where $\eta=1$ if $1/2\leq \sigma\leq 1$ and $\eta = \frac{(1-\delta)^{2\sigma-1} + (1+\delta)^{2\sigma-1}}{2}$ if $0<\sigma\leq 1/2$. Now, for any $y\geq 0$, $$\sum_{n\leq y} \frac{1}{n^{2\sigma}} \leq \begin{cases} \zeta(2 \sigma)& \text{if $\sigma>1/2$,}\\ \log(2 y + 1) &\text{if $\sigma=1/2$,}\\ \frac{y^{1-2\sigma}}{1-2\sigma} & \text{if $\sigma<1/2$.}\end{cases}$$ Taking totals, we conclude that $$\int_0^\infty |h(x)|^2 x^{2\sigma-1} dx \leq c^2 \frac{(2\delta)^{2\sigma}}{2\sigma} + \begin{cases} \frac{\zeta(2\sigma)}{6} \delta& \text{if $\sigma>1/2$,}\\ \frac{\delta}{6} \cdot \log\left(\frac{1}{\delta} + 2\right) &\text{if $\sigma=1/2$,}\\ \frac{\eta (1+\delta)^{1-2\sigma}}{6\cdot 2^{1-2\sigma} (1-2\sigma)} \cdot \delta^{2\sigma} & \text{if $\sigma<1/2$.}\end{cases}$$ Now it just remains to estimate how much of the tail we captured. A quick calculation shows that we then have $$G(s) = \frac{(1+\delta)^{s+1} - (1-\delta)^{s+1}}{2\delta (s+1) s}.$$ Not unexpectedly, this is close to $1/s$ for $\Im(s)$ small. Even more to the point, for any $s$, $$|G(s)| \leq \frac{(1+\delta)+(1-\delta)}{2\delta |s+1| |s|} = \frac{1}{\delta |s+1| |s|},$$ and so $$|1-G(s) s|^2 \geq \left(1-\frac{1}{\delta |s+1|}\right)^2 \geq \left(1 - \frac{1}{\delta T}\right)^2$$ for every $s=\sigma+it$ with $|t|\geq T$. Hence $$\int_{\sigma-i\infty}^{\sigma-iT} + \int_{\sigma+iT}^{\sigma+i\infty} \frac{|\zeta(s)|^2}{|s|^2} ds \leq \frac{1}{\left(1 - \frac{1}{\delta T}\right)^2} \int_0^\infty |h(x)|^2 x^{2\sigma-1} dx .$$ Minimizing what will be the main term, we choose $\delta = 3/T$ if $\sigma\geq 1/2$, and $\delta = \frac{1+1/\sigma}{T}$ if $0<\sigma<1/2$. Then $\frac{1}{\left(1 - \frac{1}{\delta T}\right)^2}$ equals $9/4$ for $\sigma\geq 1/2$ and $(1+\sigma)^2$ for $0<\sigma<1/2$. We conclude that $$\frac{1}{2\pi i} \int_{\sigma-i\infty}^{\sigma-iT} + \int_{\sigma+iT}^{\sigma+i\infty} \frac{|\zeta(s)|^2}{|s|^2} ds \leq \begin{cases} \frac{9 \zeta(2\sigma)}{8} \cdot \frac{1}{T} + \frac{9 c^2 6^{2\sigma}}{8\sigma} \cdot \frac{1}{T^{2\sigma}} & \text{if $\sigma>1/2$,}\\ \frac{9}{8} \frac{\log\left(\frac{T}{3}+2\right)+12 c^2}{T} &\text{if $\sigma=1/2$,}\\ \left(\frac{ \frac{1}{2} \left(\frac{1+\delta}{1-\delta}\right)^{1-2\sigma} + \frac{1}{2}}{6\cdot 2^{1-2\sigma} (1-2\sigma)} + c^2 \frac{2^{2\sigma}}{2\sigma}\right)\cdot \frac{(1+\sigma)^{2\sigma+2}}{\sigma^{2\sigma}}\cdot \frac{1}{T^{2\sigma}} & \text{if $\sigma<1/2$.}\end{cases}$$ Oh, by the way, $\int_0^\infty |g''(x)| = 1/\delta$, so $c = 7/12$. No doubt the constants can still be improved, and any suggestions on how to simplify things further are very welcome. I think I can be happy now, though.