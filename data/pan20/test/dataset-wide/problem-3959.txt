One reasonable notion of “smallest” here could be “initial”? So for an object $W$ of $\mathbf{D}$, we would look at the iso-comma category $(F \downarrow_{\cong} W)$, where an object is an object $X \in \mathbf{C}$ together with an isomorphism $i_X \colon F(X) \cong W$, and a map $f: (X,i_X) \to (Y,i_Y)$ is a map $f : X \to Y$ with $i_Y \cdot F(f) = i_X$. Then we could define a “minimal $\mathbf{C}$-object generating $W$” as an initial object of $(F \downarrow_{\cong} W)$. (Or possibly weakly initial?) Idempotent functors of the kind you're describing often fall into one of two classes: reflections or co-reflections. Reflections are more usual: they're functors that come from an adjuntion $\mathbf{C} \leftrightarrow \mathbf{D}$ where the left adjoint goes from $\mathbf{C}$ to $\mathbf{D}$, the free way to $\mathbf{D}$-ify a $\mathbf{C}$-object. The abelianisation of a group, the field of fractions of a ring, the Stone-Cech compactification of a space, sheafification of a presheaf, are all examples of this. The unit of the adjunction gives a natural map $X \rightarrow F(X)$. I can't think of many examples of reflections where $(F \downarrow_{\cong} W)$ will have an initial object for all (or even most) $W \in \mathbf{D}$. In the “field of fractions” case, for instance, $\mathbb{Z}$ is an initial object in $(\mathit{Frac} \downarrow_\cong \mathbb{Q})$, but fields of fractions $k(x)$ will have no minimal generating ring. (High-falutin' explanation: $(F \downarrow_{\cong} W)$ has all connected colimits that $\mathbf{C}$ does, but not other limits/colimits in general.) What about when $F$ (let's call it $G$ now) is a co-reflection, i.e. comes from a right adjoint to the inclusion of $\mathbf{D}$? This situation typically looks a little different: the “group core” of invertible elements in a monoid, for instance; in this case the natural map goes the other way, $G(X) \to X$. In this case, there'll always be an initial element of $(G \downarrow_{\cong} W)$: just $W$ itself! (This is dual to how in the reflection case, W is always a “maximal generating object” for itself, i.e. a terminal object of $(F \downarrow_{\cong} W)$.) On the other hand, here perhaps a terminal object is a better sense of “minimal” (“maximally quotiented”, or something): taking the sheaf of germs of a bundle is a co-reflection where this might be an interestingly non-trivial question? Some examples, of course, aren't quite either reflections or co-reflection, like “algebraic closure”, which is nearly a reflection but not quite, because of the automorphisms. This case will look, I suspect, similar to the reflection case… 

Todd Trimble’s answer makes very good points about representing objects/arrows in general. However, in your specific case — an object $c \in \newcommand{\C}{\mathbf{C}}\newcommand{\D}{\mathbf{D}}\C$ such that $\C(x,c) \cong \D(Fx,d)$, naturally in $x \in \C$ — it is generally known as the cofree object on $d$, as Mike Shulman mentions in comments. This terminology is absolutely standard in the case where $F$ is some kind of forgetful functor; one has for instance cofree comodules over various sorts of Hopf-/bi-/co-algebras (in print, see e.g. Prop. 2.5.8 of Hovey’s book Model Categories), cofree coalgebras, and cofree comonads. For arbitrary $F$, it’s slightly less universal, but I’ve certainly heard it — and if one wants some term for this purpose, it seems like the obvious choice. 

Exactly the same as in the objects-and-arrows presentation of category! Working with the “arrows-only” definition of a category doesn't mean you can't talk about objects, it just means that they're themselves a defined notion. Some constructions can be very nicely given in purely arrows-only language, but for many things — and I think product is one — it seems most natural to define “objects” and then to use them in the statements of further definitions. You can certainly then unfold the definition to give it in a way that doesn't mention objects. But I think it's important to note that you don't need to do this, and a priori, no obvious big reasons one would want to! Edit: Reading Martin B's comment, I realise I may well have misunderstood the intent of your question. I'm leaving this answer, though, as I think it's still a point worth making! 

Yes — by the Yoneda lemma, flasque sheaves can indeed be seen as $E$-injectives, where $E$ consists of the inclusion maps $\newcommand{\O}{\mathcal{O}}\newcommand{\restr}{\mathord{\upharpoonright}}\O_X\restr_U \to \O_X\restr_V$, for all pairs of opens $U \subset V$. Here $\O_X \restr_U$ is the sheaf of modules with $\O_X\restr_U(U')$ taken to be $\O_X(U')$ if $U' \subseteq U$, and to be $0$ otherwise. This is the free $\O_X$-module on the Yoneda sheaf of sets $\newcommand{\y}{\mathbf{y}}\y(U)$, defined by $\y(U)(U') = 1$ if $U' \subseteq U$ and $\emptyset$ otherwise. By the Yoneda lemma, for any sheaf of sets $F$, $F(U)$ is isomorphic to the set of sheaf maps $\y(U) \to F$. For $F$ a sheaf of modules, maps $\y(U) \to |F|$ (where $|F|$ is the underlying sheaf of sets of $F$) correspond to module maps $\O_X\restr_U \to F$; so elements of $F(U)$ correspond to such maps, and restriction $F(V) \to F(U)$ corresponds to composition with the inclusion map $\O_X\restr_U \to \O_X \restr_V$. So this restriction map is surjective exactly if $F$ is injective w.r.t. that inclusion map; and $F$ is flasque exactly if it’s injective w.r.t. the set of all such inclusions. 

Not a complete answer, but a few observations: $\newcommand{\Cat}{\mathbf{Cat}} \newcommand{\dn}{\downarrow} \newcommand{\Ex}{\mathrm{Exact}}$ 

From here on I’m a little beyond my comfort zone, and wouldn’t want to swear that the details hold up: someone who knows realizability toposes better than I do can probably tell better whether I’ve missed some subtlety. A nice way to look at the above argument could be to say: develop the theory of weak $\omega$-categories in $\newcommand{\Eff}{\mathcal{E}\textit{ff}} \Eff$, the effective topos — that is, repeat all the normal definitions in the internal logic of $\Eff$, to get an internal theory $\mathbf{T}^{\Eff}_\omega$. (Possibly $\mathbf{PER}$ or some other category of ‘computably presented sets and functions’ might work better than $\Eff$.) Now, the global sections functor $\Gamma \colon \Eff \to \mathbf{Sets}$ is a left exact left adjoint, so in particular, it will commute with pullbacks and with most ‘free object’ constructions — so, with all the ingredients used in the definition of the theory of weak $\omega$-categories. So when we hit $\mathbf{T}^{\Eff}\omega$ with $\Gamma$, we just recover the original external theory $\mathbf{T}\omega$. That is, $\mathbf{T}^{\Eff}\omega$ is a computable presentation of $\mathbf{T}_\omega$ Intuitively, we’re ‘shadowing’ every construction we do in $\mathbf{Sets}$ with a computable presentation, by performing the same constructions in parallel up in $\Eff$. This approach should also work for most other theories of higher categorical structures — power-sets and non-finite exponentiation are the main logical constructions not preserved by $\Gamma$, and off the top of my head, only the definitions of higher categories which involve topological constructions will require these. 

Since you're familiar with the example of the sheaf condition, I think a nice one-liner intuition is: 

You’re being a bit sloppy throughout about the distinction between numbers and terms of the language of $F$. This is important because two terms $t_1$, $t_2$ can be provably equal in $F$ (i.e. equal as the numbers they denote), while being syntactically different, and hence having different Gödel numbers — e.g. the terms “2+2” and “4”. In particular, in your statement of the diagonal lemma, you refer to “the Gödel number of the formula $A(n)$”. This isn’t quite well-defined, since the thing being substituted into $A$ should be a term, not a number. The first fix one might think of would be to replace “$A(n)$” by “$A(\bar{n})$” (where $\bar{n}$ denotes the standard numeral for $n$). However, your proof doesn’t give this — and indeed, as Emil Jeřábek points out in comments, this version is false for the standard ways of setting up Gödel numbering. Specifically, at the last step of the proof, you’ve proven in $F$ that $n = sub(c,c)$, and that this is the Gödel number of the formula $A(sub(c,c))$. However, that formula is not syntactically the same as the formula $A(\bar{n})$. If you go through the proof being more careful about this distinction, you’ll find you’ve proved: Lemma For any formula $A(x)$ with one free variable, there’s a term $t$ such that $F$ proves that $t$ is equal to the Gödel number of the sentence $A(t)$. 

I haven't however either come up with an argument that no such factorisation exists or found a reference for... but presumably this too is well-known in the right circles, just less widely written-about than the related positive results? (Thanks to Michael Warren for pointing me towards this example.) 

you seem to be following a somewhat common misconception: that one can’t do set-based semantics without having some set theory in mind as a metatheory. But this isn’t the case! The fundamental definition of a (Tarskian) model is just as a set with certain extra structure — just like a group, or a ring, or similar. Not “a set in ZFC”, or “a set in NBG”, but just a set, which we can then reason about using whatever techniques and principles we use for mathematical reasoning in general. Of course, in that reasoning, we’re likely to follow some established principles, like those justified by ZFC or NBG or some other specific theory. (Historically, such foundational theories were developed exactly to try to codify/justify the principles generally used and accepted.) And logicians are, for a variety of reasons, more likely than other mathematicians to be explicit about what principles they’re following in a particular piece of work. But fundamentally, you don’t need an explicit set-theoretic metatheory to study set-based semantics, any more than you need one to study groups or rings or Riemann surfaces. As I said, I’m not especially well-read historically, but from the papers I’ve read from that period, my impression is mostly that most researchers in the period were using the modern (Tarskian) notion of semantics, and that some authors wrote explicitly about what sort of metatheory they were using, while others didn’t. But the lack of an explicit metatheory is not any failure of rigour or clarity in their notion of models — it’s normal mathematical practice, certainly of the time and at least arguably of today as well. 

The lemma has an existence hypothesis; it is this existence hypothesis that allows the proof to “choose” a point when necessary. $\newcommand{\x}{\vec{x}}$Specifically, the lemma assumes that $U \cup V$ is dense. That says (by definition) that for every suitable $x$ and $\varepsilon$, there exists some point in $U \cup V$ within $\epsilon$ of $x$. But then the logical rules for the existential quantifier tell us: if we’re trying to prove some goal, and we have established that there exists some object with some property, it suffices to prove the goal assuming that we have some specific object with that property. Formally, this is the natural deduction rule that says: If $\Gamma,\, \varphi(\x, y) \vdash \psi(\x)$, then $\Gamma,\, \exists y. \varphi(\x, y)\vdash \psi(\x)$ (where $y$ is not free in $\Gamma$ or $\psi(\x)$). (Most other formalisations of constructive logic have some similar rule or axiom.) But in prose, it is often phrased as e.g. “We know there exists some $y$ such that […]. So, choose some such $y$; then …” So the proof is not “constructing” some new point in the sense which — as you say — would be impossible in general. It is just choosing (for the purpose of the proof in question) points whose existence is guaranteed by the assumption that $U \cup V$ is dense. 

If I understand your question right, the term you want is an equivalence (or isomorphism) over Set. Concretely, this means: it's an equivalence in which the categories have (forgetful) functors to Set, the functors of the equivalence commute down to Set, and the natural transformations are identities on underlying sets. More concisely, it means: an equivalence in the slice 2-category Cat / Set. (In particular, between categories of algebras, subcategories of these, and most other categories defined over Set, any equivalence over Set has to be an isomorphism, because of the fact that if $1_X$ lifts to a map between two algebra structures on a set $X$, then the structures must be the same.) 

Concrete functor is established in the literature for the related notion where the natural transformation is an isomorhpism (see e.g. Porst 1996 Concrete Categories Are Concretely Equivalent if…) — i.e. the sub-2-category of the slice 2-category of CAT over Set on faithful functors. Your 2-category is similarly the sub-2-category on faithful functors of the colax slice 2-category of CAT over Set. So it seems very natural to call your notion colax concrete functors, though as far as I can find this term hasn’t been used before. A lax concrete functor would be the same thing but with the transformation in the other direction.