Its possible, but, in principle, most non-financial companies use derivatives to "hedge risk", rather than to "bet". Hedging risk means that the firm will use derivatives to lower its chances of going bankrupt, for example an oil company will buy a put option on its oil output, so that if the price of oil falls after the firm invested in producing it, the firm can still sell the oil at a high price, and avoid bankruptcy. Other times, the bank is an intermediary in futures. futures allow a firm to sell its output forward in time, and another firm to buy the output forward in time. this reduces the risk for both of the firms. Of course, selling or buying forward reduces the chance of making it big if the prices improve in your favor. Also, financial regulation forces banks to consider multiple possible future scenarios and their effects on their balance sheet. These exercises result in a measure of the riskiness of the bank, and in turn let authorities ask the bank to hold more capital or unwind some of its positions if has too much risk of some sort. The exercises include dramatic swings in commodity prices, unemployment, or the failure of large corporations, or large financial counter-parties. There are certainly some financial agents out there that hold tons of risk. They might be indeed betting on one view or another, but because of the regulatory environment, these can't be "banks". This is very important, because if they are not banks, then their collapse does not then create contagion. A big investor looses his money, but if its not a deposit taking, (or similarly, a highly leveraged institution), then the losses, or gains, are in sense expected. Therefore, although you are right in principle when you say that if banks stand in the middle between two firms and one of them goes bankrupt then the bank gets hit, regulation is meant to push banks away from risk. Also, the possible losses to the banks owners move them towards avoiding risk. And "risk" here includes the one that comes from their clients on one leg or another of a deal collapsing... Here's a more detailed analysis: Congressional Research Service article on Financial Regulation. You could also do worse than by taking Nobel Prize winner Bob Shiller's online course. 

It's all about the precise idea these authors are trying to communicate: A) Mankiew is explaining that we are sometimes too stuborn: we sometimes make a bad investment and then feel some vindication in making another bad investment that might rescue the first one, even though we know it's a bad investment on its own. In abstract terms that can be stated by saying that sunk costs should not be taken into account when evaluating whether to increase an investment in a project. Say you put in 100 dollars in a project (A) and got nothing back but you think if you only put in another 100 you will at least get you original 100 back. However, there is another project (B) that pays you 101 if you put in 100. We have the tendency to try to rescue our bad investment and put our money in project A again, but project B pays us a higher return, and we should go for project B. B) Baliga and Eli are explaining that although, as Mankiew says, you should not use sunk costs in your calculation of whether a new investment is good or bad, it makes sense to keep track of sunk costs from an informational perspective. If you tend to forget what you did or how well it turned out, then recording your sunk costs in a notebook might help you figure out which were good investments previously and might be good in the future too, or not. 

There's no magic. What you have to realize is that the result is conditional on the validity of the assumptions: A) Under the assumption that there is measurement error, then yes, the average of two measurements will be on average closer to the truth than a single opinion. This is very believable. We all do this kind of thing all the time. For example, when we actually get 'a second opinion' from a doctor, we think that adding another opinion gets us closer to the truth. B) Under the assumption that there is a smaller incentive to lie to the interviewer about your twin's education than about yours, then one way to get closer to the truth is to use the twin's information about his sibling's education rather than the self-reported one. The authors show that the variances and covariances among the different variables are consistent with this hypothesis. The intuition is that you are less likely to try to hide your sibling's lack of education than you are to hide your own lack of education. Of course that doesn't make the preferred interpretation by the authors necessarily true. It could still be the case that there is a particular bias in the reporting of your twin's education which they did not consider. Say for example that you exaggerate the difference between your education and his or hers exactly when there is a large wage difference. That could break their result I think. Lastly, the precise idea of using it as an instrument is not that it is a second opinion. Instead, the assumption is that the 'error' in this second measurement is uncorrelated with income in contrast to the error of the self reported income which is assumed to be correlated with income. This means that the income effects of education estimated using the sibling report is unbiased, while the one using self-reported income is biased. The authors claim the self-reported one leads to a coefficient that is downward biased, resulting in an estimate of a smaller return to education than the real one. 

People think that inflation is bad when it gets out of control, say when its more than 3 or 4% a year. The idea is that we all make economic decisions based on prices and its harder to make those decisions when the prices are constantly changing! Moreover, we try to avoid holding on to money and committing to a price for a long time, because we know those become meaningless over time. Also people associate inflation with the ills of fiat money, and other such things. Deflation would seem to be not a big deal. You hold on to your cash, it buys more things as time passes! But, it turns out to be a big deal. Deflation turns the real interest rate paid by cash into a positive number. And that means that when the fed wants to lower rates a lot to get you to spend and borrow, it canÂ´t lower them below that real rate. So it can't get you to spend and borrow -> economic fragility! Fed is powerless! So people are now scared to death of deflations! Even small ones seem to be hard to turn around. Japan has been flirting with deflation for a long time, unable to escape from its cold grip.... Therefore, to answer the question: Inflation and deflation can be defined as opposites: inflation is a positive rate of change of prices sustained over several periods while deflation is a negative rate of change of prices sustained over several periods. However, the effect of inflation and deflation on the economy are not opposites from each other, and policy-maker's concern for one and the other are different, but not the opposite of each other either. 

Baby boomers are retiring and have been for a few years already. The financial crisis potentially made a large fraction f them change their retirement plans. Is there some measure / study of this effect? Are there any references to look at? 

There are many possible monetary policy channels. These channels are the different ways that changes in the Fed's interest rates can affect the economy: exchange rate depreciations, business investment growth, consumer borrowing growth, wealth increases, improved firm liquidity, debt deflation, bank multiplier changes ... Is there accepted evidence for any of these actually happening in the US? What are the key references? 

Uber has probably hundreds of thousands of drivers just in the US. There are many other gig economy firms growing quickly, not only lyft, but also Amazon Prime, bite squad, etc. Is there some place in the data that we can observe this happening? Is there a number that has been growing quickly for part time, self employed maybe? Is there a number in the Social Security statistics? More generally, how do we measure the actual size of this relative to the US labor force? Maybe we should look at the fraction of self-employed people in the US? 

It must be pointed out that, over at least a century or two, technology has been improving at the same time that median, mean, and bottom percentile incomes everywhere have been increasing. This seems to be nearly irrefutable evidence that technology doesn't itself make workers poorer. Technology and knowledge makes society wealthier: even poor people all over the world now have enough wealth to own a small device called a cell phone that lets them have a rich life in terms of entertainment, access to services, banking, communication with their loved ones, etc. BUT, that doesn't not mean we all get paid more, because what money does is that it lets you buy somebody else's time. But obviously if you and I both produce more, it can't be the case than now I can buy more of your time than before.... We can both buy lots of things that our parents never even dreamed of, but we can't buy more of each other's time.... Its still definitely true that if your folks work manual jobs, you will get a higher income than they do because you will get a high productivity job. In fact you see a lot of uneducated people being supported by their children with reasonable jobs and being helped with the phone and the google maps and the Amazon shopping thing. The issue is that older people, on average have moved up the command ladder, so they are doing management and maybe managing all these youngsters that are super productive at the basic tasks that they are given. These youngsters are productive, but they are not the managers, and they couldn't be. Technology does not make them better at managing people, only experience and age give you that ability. So despite high productivity, they don't get paid a lot, specially since unemployment has been so high for so long. But, they will be paid a lot when they become the managers.... Of course, there are also differences in the distribution of income over time. Apparently, its true that the fraction of income going to workers (the "labor share") was low over the 90's and 2000's and also that general inequality within countries has increased. Also, young, low skilled workers, during this period suffered the brunt of the crisis, staying unemployed and learning less on the job that other cohorts. So, if you focus on the young, the low skilled, the ones that were looking for their first jobs between 2008 and 2011, you will probably find relatively low incomes. There are also individual skills that have been replaced by technology, like typists, or long distance operators. Still, its hard to argue that the majority of the US young people are worse off in life than their parents. 

Yes, in principle, under a gold standard, the central bank can buy more gold, or build a mine and mine it, which increases money supply. This lowers the short run interest rates. But the issue is that it typically can't fight the market price of gold: when the price of gold increases beyond the parity, people rush to exchange their paper currency for gold at the bank. This happens until money becomes so scarce that ir regains its value relative to gold. This is very different from what happens with fiat currency. With fiat currency, the central bank can buy bonds, or gold, but it can even just print money and give it away. ( The act of giving it for free to individuals is called a "helicopter drop". Dropping it from a helicopter is one way to actually do it...) Even though in a gold standard, the central bank can increase money supply, this is different than buying bonds. This is because since money is backed by gold, it can't loose value relative to gold. In this case, it's really hard for the central bank to lower the value of money if it wants, for example, to stop a deflation. Instead, because bonds are also denominated in the country's currency, making money lose value also makes bonds lose value and vice versa. 

Interesting question. Indeed, Basel/I,II,III-type regulation changes the behavior of banks, thatÂ´s probably the goal of said regulation. Its possible that their market behavior with respect to "notes" (which notes?) has changed. bason on the typical Modigiliani/Miller intuition, it seems that there is no reason why Basel/type regulation will affect a sector or another. The main effects are in changing how firms get financed. If banks are expected to hold senior debt, then firms are more likely to issue senior debt. This changes how funds are intermediated from savers to investors, but in principle it should not change which sectors are financed. It should only affect how they are financed, with equity, preferred, junior debt, senior debt, senior collateralized debt, etc. 

Interesting! My guess is that: A) Fast food places are in the business of solving the masses nutricional needs (low margins!), while other restaurants are more in the business of selling a special experience that you could do without (high margins!): Article mentioning lower margin breakfast foods. B) Because of the above, people will go to a fast food place if it solves a need, like having breakfast, but you won't pay much more than you would for cereal at home, so breakfast has to be dirt cheap at this places. And it does seem to be the cheapest meal on the menu in terms of protein/dollar. C) Now going back home for lunch is usually a pain, so they are able to extract a higher rent from you there, so they sell you fries and bread with some meat instead of a large meal of eggs and sausage. They make a larger margin on lunch items, so they have to shut the breakfast ones down. You are on a budget, so you'll go there again because its cheap, even if you are unhappy with them. If I was on a tight budget I would get the breakfast any time of the day if it were available. D) Other places will sell you a breakfast any part of the day because they want you to be happy and come back, they make a big margin on anything they sell. Moreover, you'd be mad if they didn't have what you wanted, and you don't really need them. Plus who's gonna order eggs for lunch with their boss or with their boyfriend/girlfriend anyway? So even if the margins were lower, few people buy these items... 

It is a reputable journal and the results are surely correct on a "total dollars" sense. I guess the point they are making is that because health care expenditure of old age individuals is very likely to be high, there is some 'social benefit' of dying before old age. However, it seems somewhat meaningless: A) First, by this logic, murders also decrease health care costs. We're not trying to keep smokers form smoking solely because they will be a health care burden. We also want these people to live long, rewarding lives. B) People contribute to society, their families, their friends and so on. They also save and, specifically, they pay health insurance premiums while they are alive. So, while they might require more care in the long run, non-smokers might well be able to pay or it with the taxes on their income and the productivity they bring to society. Similarly, we all invest through our taxes, on public education, and it goes to waste when somebody that has received public education dies. C) There are enormous variations in the amount of healthcare spending that old people receive across countries, so the estimates of how much health are old people will receive has got to be very imprecise. D) Investments pay a positive rate of return, so if we saved the money now we could pay for a lot more care later. Put differently, all the resources that would not be devoted to the care of smokers now would be used to improve our lives meaningfully, potentially even helping us do research into how to take care of old people effectively, which would again reduce the future expected cost of caring for the smokers.