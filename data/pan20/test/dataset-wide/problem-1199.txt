It turns out this issue was due to a restore of a database from an incorrect media set. Since the databases were not exact copies, the package was performing differently on the second instance. After performing a backup with INIT and then restoring that database to the second instance, the package now performs the same on both instances. 

We are currently testing a SQL Server 2012 AlwaysOn HA implementation where we have 2 out of the 3 nodes are synchronous. The third, asynchronous node, does not have a vote in the quorum. There is a scenario in which the first two nodes experience complete failure. When this happens, the third node is up and running but it has it's database in the AG marked as "Recovery Pending". How can I get this database out of this state and make it available? 

And this is the worst scenario with large number of products in chosen category and large offset. When offset=300 execution time is just 0.5 ms. Unfortunately maintaining such a junction table requires extra effort. It could be accomplished via indexed materialized views, but that is only useful when your data updates rarely, cause refreshing such materialized view is quite a heavy operation. So I am staying with GIN index so far, with increased and reduced memory footprint query. 

Note #1: 82 ms might not look that scary but that is because sort buffer fits into memory. Once I select all columns from products table ( and in real life there are about 60 columns) it goes to doubling execution time. And that is only for 4680 products. Action point #1 (comes from Note #1): In order to reduce memory footprint of sort operation and therefore speed it up a little it would be wise to fetch, sort and limit product ids first, then fetch full records: 

How do I handle this situation. This blog post ($URL$ is the only thing I could find for reference and it isn't very clear on the solution. He states adding a second IP address. However, what exactly does this look like in DNS? Do I have one DNS hostname with two IP addresses? 

ID 2 is currently set to the default but cycles after a max 5 files. This trace isn't the one filling up my hard drive. ID 1 path and trace file are the ones filling up. I've already turned off C2 auditing. What other troubleshooting can I do to see why the audittrace files are even being written to in the first place? EDIT: I've restarted the services. It would seem the correct solution would be to turn off this audit trace by using the sp_trace_setstatus 1,0 but when I run that command I get the error: 

Note . Result is much better. JOIN and additional B-tree index As Chris advised I've created additional index: 

Original query I've populated my database with 650k products with some categories holding up to 40k products. I've simplified query a bit by removing clause: 

I've done a lot of experimenting and here are my findings. GIN and sorting GIN index currently (as of version 9.4) can not assist ordering. 

This one helps a lot unless there are too many products in one category. It quickly filters out products that belong to that category but then there is a sort operation that has to be done the hard way (without index). A have installed extension allowing me to build multi-column GIN index like this: 

The only server role it is a member of is PUBLIC. How can I find out what exactly is preventing me from revoking these permissions so I can drop the user? Thanks. 

Running the PowerShell script from this technet article is the easiest and most secure in my opinion. $URL$ 

Unfortunately we have some parcel numbers that were converted to scientific notation. This means they are in the wrong format for Parcel Numbers and should be converted back to regular decimal or numeric format. I am encountering difficulty converting just those values that have the scientific notation. The column is of nvarchar(255) data type but these values need to be manipulated back into numeric or decimal data type. 

Playing with various offsets and product counts I could not make PostgreSQL use additional B-tree index. So I went classical way and created junction table: 

This brings us back to and ~80 ms for 4680 products. Still can be slow when number of products grows to 100k. 

This is in fact quite logical as B-tree index here does not produce direct result, it is only used as a guide for sequential scan. Let's compare with GIN query: 

A product can belong to multiple categories. column holds a list of ids of all product's categories. Typical query looks like this (always searching for single category): 

The following query plan was obtained from smaller test system (4680 products in selected category, 200k products total in the table): 

I am investigating a SSRS 2012 Report which used to return data from an Oracle database. However, recently it stopped returning data. The report will sit there and run forever until something times out. Our report catalog database is also on a separate server which does not show any issues in the logs or while monitoring the performance. I do not see any errors in the Event log, SQL Server Logs, Reporting Services logs or the Oracle database logs. If I strip out the query from the report it returns rows in a few minutes. Is there a method for monitoring what is happening with the communication between the report server and the oracle server? How can I troubleshoot this issue if none of the logs are reporting any problems? Looks like I am now getting Timeout errors in the report logs. 

work_mem Thanks Chris for pointing out to this configuration parameter. It defaults to 4MB, and in case your recordset is larger, increasing to proper value (can be found from ) can significantly speed up sort operations. 

But Postgres does not want to use that for sorting. Even when I remove specifier in the query. Any alternative approaches to optimize the task are very welcome. 

GIN's result is much better. I checked with various combinations of number of products and offset, under no circumstances junction table approach was any better. The power of real index In order for PostgreSQL to fully utilize index for sorting, all query parameters as well as parameters must reside in single B-tree index. To do this I have copied sort fields from product to junction table: 

I'm interested in gathering some DMV data from our SSAS cubes and store it on our management box. When I create the linked server for this effort I run into an error establishing the connection. 

This ended up being a Kerberos problem. We were able to identify through some of the security logs and some network monitoring, that the request was coming in as anonymous. Once we applied the relevant SPNs for MSSQLSVC for the account that was being used to kick off the process, it worked. 

I need to remove records from this table that are older than 30 days. We only have 2 columns in this table. The first date after 'Printed_%' is what I will be using to determine if the record should be deleted. Notice some of the dates are in MM/DD/YYYY format while some appear in M/D/YYYY format in the string. How can extract the date so I can determine which rows are older than 30 days?