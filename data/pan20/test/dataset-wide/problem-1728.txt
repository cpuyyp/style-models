Link local addresses are derived from the MAC address of the device. They are auto-generated as a part of bringing the interface up. Auto-configuration includes a discovery process to ensure that the address is unique on the network. A similar process is used to auto-configure routable addresses when a router advertisement is available. These addresses may be regenerated periodically to provide privacy. RFC 4862 specifies the processes to be followed. 

VNC can serve up a Java-based client. Most browsers have Java enabled. Just make sure you secure access very well. 

Before making changes make sure you have backups of the item you are changing. This will allow you to back out the change if it fails. 

You can substitute the directory path for in all the above commands. Try to limit the number of files and directories your server can write to. These locations can be used to store malware if your web server is compromised. 

If it is not listening on 127.0.0.0, 0.0.0.0, or *, you will need to connect to the address it is listening on. Your hosts entry may have the server name listed with the address 127.0.0.1, so that may be used if you try to connect by name. 

While it might be possible, make sure your mail server identifies itself using the name assigned to your haproxy server. By design SMTP is resilient to network and server failures. I can't see a good use case for putting an email server behind haproxy. It might make sense to put and IMAP or POP server behind haproxy. If you have a single email server, then you can do what you wish much simpler with rules. If you have multiple email servers, each should have a unique IP address. These addresses should have DNS entries that pass rDNS for the domain name they identify themselves as. The mail servers can (usually) use a domain name different from that of the host they run on. 

For closely related servers there are zone transfers. These function much like BGP announcements. For security reasons, these are usually blocked for other servers. If you run a caching name server it will copy the root server list, and very soon have the roots for .com, .net, etc. There is a very good reason that DNS is distributed. Otherwise everyone would be working with obsolete data. The size of the database would be quite large, and the majority of the data of no interest to you. There are options to decrease the risk of DNS poisoning and good software deals with the problems as they become known. There are organization which work at providing sanitized data which can be used as upstream providers. These will filter out some poisoning attempts. Look at using OpenDNS or google as upstream providers. The root DNS zones are now signed, and I am increasingly seeing my mail server reporting that the DNS data was signed. The signing of DNS has been reported as a requirement for IPV6. Signed DNS makes cache poisoning very difficult, but adds to the difficulty of managing DNS. 

You should consider using instead of while testing the ACLs. The ACLs are enabled by adding statements to the main section of the configuration, and the above ACLs to the ACL section. acl_smtp_auth = acl_local_auth acl_smtp_mail = acl_local_mail_from 

What happens you try to send mail to norepy@teltub.com from yahoo.com? It should work, even if it goes to the bit bucket. Also ensure that both abuse and postmaster addresses are valid. 

If you want to add more name servers just add more NS records. They will be served up in a round robin fashion by default. Unless you have lots of traffic two or three name servers should be sufficient. Most requests will be served from cache if you have much traffic. If you have the kind of traffic that Google, Amazon, or Facebook have you should have technical staff who know how to optimize DNS for fast server access. 

They may be using . as a spam filter. A proper email server will try and if that fails then try . Spambots are likely to try only one address. By using two addresses it is possible to use this connection sequence to filter some email. There may slightly delay email deliveries to them, but should not cause you email to be classified as spam. Their broken record indicates they may send email from either server. If you see email arriving from , this does not indicate that the message is spam. If they use a database to track source addresses, it is possible to identify sending programs that do not follow the standard and connect to the mail servers in the correct order. How they handle senders that do not follow standards is up to them, but I would block all such senders that don't pass rDNS verification. Failed addresses can be agressively removed from the database. It would be appropriate to keep passing addresses in the database, flagged accordingly. EDIT: Based on the behavior of their servers they may be failing mail delivered to the backup server and accepting mail delivered to the preferred mail server . This will cause spambots which send to backup mail servers to fail. 

Bounce messages intentionally do not have a sender address. This is to prevent email loops. Sending email without an address has been used to send spam, intentionally or not. If your relay requires you to provide credentials before sending to verify the sender, it will not be able to verify the sender for bounce messages. You can avoid the issue of not being able to send out bounce messages after accepting the message by bouncing the message before accepting it. Bouncing a message after receipt is a source of backscatter spam. It is common for spam to have faked source addresses. By accepting the message before bouncing it, you will be spamming the faked address rather than rejecting the incoming message. One way to avoid backscatter spam, is to use BATV (bounce address tag validation). This adds a signed value to the return path. Only legitimate bounce messages should have this signature, so other bounces from the Internet can be ignored. EDIT: It is no longer unusual to quietly drop emails to invalid addresses. This prevents the receiving system from being classified as a spam source when it sends backscatter spam. Postfix accepts all recipients by default, and is therefore prone to producing backscatter spam. If possible, I would recommend enabling recipient verofication. I prefer Exim, which rejects mail for unknown recipients by default. 

Check permissions from ~sodium/.ssh/authorized_keys all the way to /. If any of these are world writable ssh keys won't be trusted. Run ssh-keygen as the user for whom you need the key. It should be run on the system to which you will be connecting. ssh-copy-id will copy ids from the target machine to the machine on which you wish to use the key. 

Whose spam filters are you triggering? Some sites will greylist on initial contact, but a 10 second delay will not likely help. Normal queue and retry will work with this setup. You might be able to do this with a second EXIM configuration and rate limiting calls between the servers. The queue options might also help, but would impact other users. A combination of queue_only_domains, and a low queue_run_max might help. If your client is compliant, then a condition delay for the client in the configuration might also help. 

The plus 3 second time may indicate a network or configuration issue. A few things that may be timing out: 

As you specified networking, there is an option at the network level, I have provided a network solution below flagged with NETWORK. Only a few protocols are commonly proxied, but most work well with NAT (the network solution). HTTP and HTTPS are commonly proxied, so that is my first response. I am confused by your description of DNS based proxying. It is common of DNS to specify different IP addresses for different addresses, or for related sites to have the same IP address. As you are specifying websites as your hostnames, I believe we can assume you want to proxy websites. I believe the term you are looking for is "name-based virtual hosting" or "name-based proxying" For HTTP or HTTPS many servers can proxy traffic based on IP address and/or the name specified in the HOST header. The Apache Web Server uses VirtualHosts to separate sites. Other sofware which can proxy traffic has the same or similar functionality. In Apache, to do both ip-based and based proxying for the same site you would create a VirtualHost for the IP address add the require name(s) to that virtual host. You would then configure that VirtualHost to proxy the whole site or part of it. NETWORKING: If want to redirect an IP address to a different address this can be done by a router. The mechanism used is call NAT (Network Address Translation). In this case you would need DNAT (Destination Network Address Translation.) Some routers can do NAT on a per port (service) address. In this case you would want the related DNS entries to return the IP address being translated. EDIT: The additional comments provide additional information. As I understand the requirements: - Proxying will only be for users from certain addresses/address ranges, not all traffic to the name/IP will be proxied. - Proxied requests must appear to originate from the proxy not the original host. - Current solution provided different address records depending on origin of the request. (I believe the existing solution is broken here. DNS request originate from the DNS server the client is using, which may not be the client's device. DNS responses are cached, so you can not rely on a DNS request preceding the request.) The solution I believe would most likely work is to handle this with NAT rules on a device in front of the server and proxy. This would NAT all traffic you want to proxy to your proxy device based on originating IP address, and pass other traffic directly to the server. 

It is good to see a provider worrying about these issues. There is no issue with a mail server sending mail for other domains providing the appropriate SPF configuration is done. While it is a good idea for your clients to have a sub-domain dedicated to the mailing list, it is not necessary for them to delegate it to your server. It could just be a base for the SPF, DKIM and DMARC records. SPF can be handled by including your SFP record in their SPF record. This will allow them to send from your IP address. You may need to create a subdomain to contain an SFP record suitable for delegation as you should only include IP addresses in that record. (See how google.com and other large providers handle theirs.) This approach is well documented. DKIM and DMARC will be difficult if your mail servers are not the only ones sending for their domain. If possible, it is possible to have them delegate the and subdomains to your mail servers. You will need to configure the appropriate zones, but they can all use the same zone definitions. It may be possible to handle DKIM by having them CNAME the subdomain to yours. You will need to sign using their domain and your keys. It gets trickier if the client send mail with other servers. You may need to get them to publish your public key or provide keys for you to use. It may be possible tho handle DMARC by having them CNAME the subdomain to yours. This will result in your policy applying to your domain. Also you will get all the reports. Alternatively, you can provide them assistance in setting up their own policy. 

I would be surprised if your sysadmin team are mangling message-ids. To release a frozen email you merely need to run with the option. This takes a list of message ids as shown by the command. You can also get the message id by removing the from the header file name. 

Any of the better routers that will run DD-WRT, OpenWRT or similar firmware should be able handle this. I have seen reports that some of the newer routers are distributed with DD-WRT. Any small computer that can run Linux with two or three good ethernet interfaces (buy and add good cards if needed). I would run Shorerwall as the firewall on either. The OpenWRT solution would require Shorewall-lite with a separate system to compile the firewall rules. You should be considering setting up a DMZ for the Internet accessible servers. 

The periods are unused slot that don't have processes behind them. The other scoreboard entries have or had processes behind them as per the legend after the scroreboard. On recent Apache releases the scoreboard reports all slots. ServerLimit (default 256) sets the size of the scoreboard. Setting this smaller may save some memory and disk space. MaxClients limits the number of processes you can have. Setting it too low can cause clients to get failed connection requests. MaxClients must not be more than ServerLimit. It looks like you have 10 processes, 2 serving requests, and 8 idle servers. StartServers, MinSpareServers, and MaxSpareServers control the number of servers at any one time. Threading servers use SpareThreads in place of SpareServers. These can be tuned to limit the number of processes, but setting the values too low will result in heavy load spawning new servers. It appears apache is using 34% of a CPU. 124 seconds user time and 11 second system time during 6.3 minutes.