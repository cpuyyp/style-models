Also have to note that I like your coding style: domain-specific type aliases and short functions with descriptive names make code easy to read. 

From that nice formula it is easy to see that the process of computing √2 is iterative. You just need to decide what function to iterate. Let us consider this one: 

Thus you get self documenting code and all of functions for free (for each field compiler generates accessor function with the same name). This also leads to more concise implementation of other functions: 

replaces letter by searching for another one positions away. I'll implement this literally by creating cycled alphabet and searching for letters in it. This is inefficient but allows to get taste of laziness. 

( is the result of the last computation in GHCi.) There is a function in Prelude that captures such a process of applying some function to the result of applying that function to the .... and so ad infinitum. 

Now you just squares of digits and get index to precomputed cache of chain results. Here is the full code which on my machine is 15 times faster than the original one: 

(Btw, why "movie"? we were talking about "films" all the way.) I'm using partition from to extract matching movie(s) from database. Also there is funny syntax I'm using to update movies: 

It's a good idea to profile your code (which is easy if you use – instead of , just type , and run your program with the options ) to find out exactly where the bottle-necks are. See the GHC profiling guide for more information. If you do that, you'll find that a significant amount of your program's time is spent splitting up strings into words, and parsing them into s. Remember that a Haskell string is a linked list of characters, and thus not particularly efficient – I found that using the type from the package results in the revised program taking only 40% of the time of your version. (Contrary to the other comment here, the binary search you've implemented seems fairly efficient, that's not where the slow-down is.) Instead of from the standard Prelude, use the version of from ; instead of parsing a line of text using , I'd suggest something like the following: 

(Possibly a hand-coded loop might be even faster than , but I didn't check that.) I'd also suggest splitting out the parsing of input from the actual solving of the problem - no advantage is gained by putting everything into . I'd further suggest that writing makes your intent clearer than ; and that you use s instead of , since this will (a) get rid of extra bits of cruft in the code and (b) allow you to use the package, which already contains a binary search function. It's usually far better to use someone else's de-bugged search routine than write your own. However, if you are submitting for an online competition, that package may not be available. Nevertheless, it provides useful inspiration on how the search may be sped up. This gives code along the following lines: 

Side note 2: Some libraries export functions with quite generic names (like or ), it is easier to read code when you have some explicit pointer about were function comes from. You can import library with alias: 

While generating walkers for the next journey you traverse list of subsequences twice. This could be not very efficient as there are subsequences for the list of length . Here is less readable but more efficient approach: 

'encrypts' each letter of input string independently of other letters. This could be emphasized by using at the top of instead of hiding it in helper functions: 

Now, when you have all of the expansions, you need to filter and count those with numerator longer than denominator. 

I switched arguments in because this allows to define function more concisely and it is also correlates with update/insert from : they have collection as a last argument. Now it is possible to skip directly to and implement it in couple of lines: 

Using is justified only for big numbers, in your case using is enough and could be a bit faster. Here is another solution: 

Nice code: it is readable, well-structured, with consistent style, with self-explanatory function names and data types. 

I tried to elaborate on great answer by Toxaris. After precomputing results for first numbers, most of time is spent on extracting digits and squaring them. It is possible to calculate squares of digits for sequential numbers in incremental manner. If you have list of squared digits for some number then here is how to calculate list of squared digits for . 

For a website I'm working on, I had to get all the unique entries in an array and count their occurrence. It is possible a certain entry is only found once, but it can also be found 20 times. So I designed the following bit of code: 

I'm working on a clone of Hunter Story. You shoot monsters with your bow. Recently I implemented collision detection, this is all working correctly, and I don't think the code needs any dramatic optimisations. The only thing I'm a bit worried about is how exactly I implemented it. I'm not sure if it complies with OOP standards. The relevant code: Level: 

This seems a bit better already :) But I think it would still be better to move the text to .txt files 

(Keep in mind that I've left out all irrelevant code. If you want to see the sources, follow the link below). It's quite a bit of code, but I'm not looking for code optimisations. I only need to know whether this is a good OOP implementation. Would I be better off having a separate CollisionDetector class, where I pass my colliders (Arrow and Monster) in? Should I implement the collision checking in the colliders themselves? Or is there perhaps something I haven't thought of? If you want to see the full project, check here. It's made in Java with the Slick2D framework. 

I'm modelling two processes which have been put into a cyclic pipeline - the output of each feeds into the input of the other - so as to work out when they've deadlocked (i.e., neither can progress since they're each waiting on output from the other). I've used the conduit package for this, as I couldn't see an easy way to do it using pipes, and streaming doesn't really look suited to this sort of task. It looks like monad-coroutine would be another possibility for this, but I didn't investigate it further. Define the problem as follows: 

I think this problem is of interest because pre-emptive concurrency doesn't seem like a good way of solving it -- most concurrency libraries do their best to help you avoid deadlock, not model processes that have got into deadlock. (But perhaps I'm wrong, and this is easily modelled with a standard concurrency library - I'd be keen to hear.) Also it gave me a good reason to look at some of the streaming data packages (conduit, pipes and streaming), all of which I believe are modelled around the idea of processes that can "yield" data "downstream", or "await" it from "upstream", which is exactly what this problem requires. Here's my code: (NB: contains possible spoilers for the Advent of Code 2017, day 18 problem, Part 2 - but this is not relevant to my question, which is about modelling deadlock with coroutines.)