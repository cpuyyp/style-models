An aspect of my research has lead me to believe that I need to distinguish between those bounded functions $\xi:\mathbb{N}\rightarrow\mathbb{C}$ which correlate with the Mobius function $\mu(n)$, i.e. have the property that $$\sum_{n\leq x}\mu(n)\xi(n)\neq o(x),$$ according as to whether $$\sum_{n\leq x}\xi(n)= o(x)$$ or not. I believe this is necessary in order to avoid certain cases: for example, if one fixes a square free natural number $k>1$ and takes $\xi(n)=1$ for $n\neq mk$ and $\xi(mk)=\mu(m)$, $m\in\mathbb{N}$, we have $$\frac{1}{x}\sum_{n\leq x}\mu(n)\xi(n)\sim \frac{6\mu(k)}{\pi^2\phi(k)}$$ and $$\frac{1}{x}\sum_{n\leq x}\xi(n)\sim 1-\frac{1}{k}.$$ Of course such cases are in some sense artificial, none-the-less it seems incomplete to consider the notion of Mobius correlation without a zero mean constraint---at least because $\mu(n)$ itself has zero mean. 

When one looks at the quotient of Euler products $$\prod_p\frac{\sum_{\alpha=0}^{\infty}f(p^{\alpha})p^{-\alpha s}}{1+f(p)p^{-s}}$$ with $|f|\leq 1$, it is observed that the resulting expression contains no $p^{-s}$ terms, so the quotient converges absolutely for $\sigma\geq 1/2+\epsilon$, $\epsilon>0$. Roughly speaking, for $\delta\geq \epsilon$, this amounts to saying that the statements $$S(x)=\sum_{n\leq x}|\mu(n)| f(n)=O(x^{1/2+\delta})$$ and $$N(x)=\sum_{n\leq x}f(n)=O(x^{1/2+\delta})$$ are equivalent. This is just because an absolutely convergent Euler product is bounded above and away from zero in absolute value. I had at first guessed that this kind of inference would break down if we asked for sharper information. For instance, say $S(x)=O(x^{1/2}g(x))$ for some $g(x)=o(x^{\epsilon})$, then I had supposed that it would not necessarily follow that the same must be said of $N(x)$. This guess was based on the observation that, if we could evaluate the inverse Mellin transforms by residues, then the distinction between the two sums would be governed by behaviour in the closed half plane $\sigma\leq1/2$, and this is the region in which the influence of the quotient of the Euler products is not apparent. On further reflection, I am yet to be convinced. If we consider the Fourier transform $$2\pi e^{-\sigma y}N(e^y)=\int_{\mathbb{R}}\frac{F(\sigma+it)e^{iyt}dt}{\sigma+it},$$ with $\sigma>1/2$ say, then it appears that the finer behaviour may be determined by considering the integral on vertical lines close to $\sigma=1/2$. For example, choosing $\sigma=1/2+y^{-1}\log y$ we are looking at $N(x)/(x^{1/2}\log x)$, and for any finite $x$ this integral is within the region where the Mellin transforms have the same large and small values (because the quotient Euler product is bounded above and away from zero there). I would like to know about how the integrals might be compared in order to extend the influence of the Euler product to the finer shades of the behaviour of the transform, if that is possible. In particular, I would like to be able to say something like "If $x^{-1/2}N(x)=O(g(x))$ then the same is true of $S(x)$". 

Let $(a_n)$, $n\in\mathbb{N}$, be a sequence of complex numbers, then formally one has (1) $$\prod_{1}^{\infty}\left(1-a_nx^n\right)^{-1}=1+\sum_{1}^{\infty}\left(\sum_{j_1+2j_2+\cdots +nj_n=n}a_1^{j_1}a_2^{j_2}\cdots a_n^{j_n}\right)x^n=1+\sum_{1}^{\infty}b_n x^n,$$ say. I'm almost certain the answer to my question has been known for centuries, but I don't know where to find it: What is the inverse of the map defined by (2) $$b_n=\sum_{j_1+2j_2+\cdots +nj_n=n}a_1^{j_1}a_2^{j_2}\cdots a_n^{j_n},$$ and where can I find it in the literature? 

Let $d_k(n)$ denote the number of ways of expressing $n$ as a product of $k$ factors, and let $$D_k(x)=\sum_{n\leq x}d_k(n)$$ be the summatory function. During a study of Mertens' function I was lead to consider the zero distribution of the sequence of polynomials $$P(z,x)=\sum_{j=0}^{m}\left(\sum_{k=j}^{m}{m+1\choose k-j}(-1)^{m-k}D_{m+1-k}(x)\right)z^j$$ of degree $m=m(x)=\max \{\Omega(n):n\leq x\}\sim \log_2 x$. 

I am looking for a theorem that guarantees the polynomial growth of a function $f$ defined by a Fourier integral, that is, when $$f(x)=\int_{-\infty}^{\infty}F(y)e^{ixy}dy.$$ I am only interested in one-sided growth, say $x\rightarrow +\infty$. Further, in the case I have in mind, $f$ is almost everywhere continuous, and everywhere defined. It seems to me that all such functions should be of polynomial growth, but I can't see how to prove it (beyond the cases when the integral is absolutely convergent, which is too strong for my purposes). EDIT. In light of the answers given here, it is apparent that I have not defined the function space clearly. Unfortunately, I do not know of a definition for these so I can only state the properties which I may assume, and which seem relavent. Firstly, $F$ is analytic and not $L^1$. $L^p$ results for larger $p$ are definitely of interest to me. Secondly, by "everywhere defined", I mean that $f$ has no spikes, but continuity is too strong- I want to allow $f$ to have jumps for arbitrarily large values of $x$. Further, the improper integral should be understood as $\lim_{R\rightarrow\infty}\int_{-R}^{R}$. 

I remember thinking that this is a Phragmen-Lindelof version of Rouche's theorem, but in fact it isn't because it states only an upper bound on the number zeros, and it doesn't assume anything about the minima on the boundary of the strip. Therefore I suppose there are some obstructions introduced by this lack of information. I would like to know: 

In regard to the characteristics of certain "explicit formulae" arising in number theory, I am pondering the connection between the rate of convergence of series and the asymptotic order of the function it represents, and how this connection might be exploited in order to isolate the significant terms of the series. This is one of the most google-unfriendly topics I have tried to research, hence posting this question. Essentially, I am considering the following notion. Given a pointwise convergent series $f(x)=\sum_{n\geq 1} f_n(x)$, $x>x_0$ say, then of course given $\epsilon$ there exists a function $N(x,\epsilon)$ such that for all $x>x_0$ and $N>N(x,\epsilon)$ one has $$|\sum_{n\geq N}f_n(x)|<\epsilon.$$ So, in principle, one may choose $\epsilon=\epsilon(x)$ and ask: 

Please note that the use of statements like $$\sum_{k=-\infty}^{\infty}k^nz^k=\left(z\frac{d}{dz}\right)^n\sum_{k=-\infty}^{\infty}z^k=\left(z\frac{d}{dz}\right)^n 0=0$$ is acceptable only if you can also prove that the sums of positive and negative powers converge on a common arc of the unit circle. In his answer below, Fedor Petrov has pointed out that the use of divergent series as formal generating functions is justified in some cases, so the last statement is incorrect. 

It appears that this is equivalent to the question of the complexity of the discrete logarithm problem, so I think this question is in general an open problem and ought to be retagged and treated as such. As Maarty Isaacs commented $$f_p(n)=np\mod q.$$ To say that the order in which the elements reappear is of a random nature is to say that $np\mod q$ is of high complexity, which is the same as the complexity of its inverse. In other words, given a cyclic group $G$, a generator $g$ and an element $f$, the question is: 

Landau's Theorem for Dirichlet series with real coefficients ($c_n$) states that if the coefficients are of fixed sign for all sufficiently large $n$, then the point $\sigma_0$ on the abscissa of convergence of the series is itself a singularity of the function represented by the series in the half plane $\sigma>\sigma_0$. One can also show that the conclusion of Landau's Theorem applies in a broader context. For example, if the partial sums $\sum_{n\leq x} c_n\geq 0$, then the real point $\sigma_0$ is a singularity of the function. My question is this: To what extent does the converse implication hold, that is, if $\sigma_0$ is a singularity of the function represented for $\sigma>\sigma_0$ by some Dirichlet series with real coefficients, then under what additional conditions may we conclude that the ($c_n$) are of fixed sign for sufficiently large $n$? 

It is conceivable that ways do exist to express $\log (\lfloor x\rfloor !)$ in an expression involving the zeros, but any apparent relationship will be superfluous because the "explicit formula" for this function comes from $\zeta'(s)$, not something involving $1/\zeta(s)$. When $x$ is not an integer, you have $$\log (\lfloor x\rfloor !)=\sum_{n\leq x}\log n=-\frac{1}{2\pi i}\int_{2-i\infty}^{2+i\infty}\frac{\zeta'(s)x^sds}{s}.$$ The double pole at $s=1$ gives you a residue of $x\log x-x$ and the integrand has no other poles in $\sigma>0$. Thus, you have $$\log (\lfloor x\rfloor !)=x\log x-x-\frac{1}{2\pi i}\int_{\sigma-i\infty}^{\sigma+i\infty}\frac{\zeta'(s)x^sds}{s}$$ for any $0<\sigma<1$. (You can't cross the imaginary axis because the integral doesn't converge when $\sigma<0$. One way to see this is to consider Stirling's approximation $$\log ((x-1)!)=(x-1/2)\log x-x +(1/2)\log 2\pi +o(1)$$ because, if it were valid to cross the imaginary axis, picking up an $O(1)$ contribution from the residue of the pole at $s=0$, we would have a contradiction). To evaluate the $O(\log x)$ terms coming from the integral, you have to do a little more work. I think Binet gave an alternative expression as a Laplace transform, and there are both convergent (Macdonald) and asymptotic (Stirling) series expansions. Try wikipedia as a starting point. 

Naturally one would like to "use" as few terms as possible. To make this more tangible (though not yet satisfactory and clearly less general), one may write $$\sum_{n\geq y}f_n(x)=O(x^qy^{-p})$$ for some functions $p=p(x)$ and $q=q(y)$, where I am implicitly assuming that $p$ is bounded away from $0$ and $q$ is non-increasing. Choosing, say, $y=x^{\delta}$ gives $$\sum_{n\geq x^{\delta}}f_n(x)=O(x^{q(x^{\delta})-\delta p(x)})$$ and so, given $\epsilon>0$, one may write $$\sum_{n\geq x^{\epsilon/p(x)}}f_n(x)=O(x^{q(1)-\epsilon}).$$ 

EDIT: This is not correct. Firstly, the complexity of the inverse (i.e. the discrete logarithm problem) is not necessarily the same. In fact, from what I can gather, this is part of the reason why discrete logs are useful in cryptography at present. Secondly, when the modulus is large (compared to $p$), one gets a string of arithmetic progressions that eventually include the whole set, which is rather predictable. So the only case that may still work is when the modulus is small, but frankly this doesn't look very interesting either! 

Specifically I am interested in the quotients $$-\frac{\zeta'(\rho)}{\zeta'(1-\rho)}=2(2\pi)^{\rho-1}\Gamma(1-\rho)\sin(\pi\rho/2).$$ Obviously they are in $\mathbb{T}$ for all known non-trivial zeros. But how often are these number $\pm 1$? I would find some tables of the derivative at the known zeros rather usefull, or even perhaps tables of the quotients above? I would be very grateful if somebody can provide me with a good reference. Thanks! 

On the Riemann hypothesis one would expect to find the roots---in some sense---closer to the non positive integers as $x\rightarrow\infty$ because these are the only values of $z$ for which $\zeta^z(s)$ is analytic throughout a neighbourhood of $s=1$ and, therefore, the only points at which $f(z,x)\in O(x^a)$ for some $a<1$. However, I am interested in the less-restrictive conjecture that they have negative real parts. I am aware of the notion of 'stability' of linear translation invariant systems and in dynamical systems, and it's equivalence with the positivity of the principle minors of the associated Hurwitz matrices, Routh tables, Sylvester's criterion, etc. I find that these equivalences serve more as a test than to provide reasoning but, if you can say something in this regard, I would be pleased to hear about that too. It appears this may be related to the fact that $\zeta^z(s)$ tends to infinity or zero as $s\rightarrow 0^+$ depending on whether $\Re z$ is positive or negative. However, for small $\Re z$ and $s=1$ the convergence is very slight, and making the distinction appears to be a tricky problem. 

Who first published a proof that $$\sum_{n\leq x}d_{k}(n)d_k(n+h)=O(x(\log x)^{2k-2})$$ for fixed $k$ and $h$ please? I am struggling to find a reference. Thank you. 

By Landau's theorem on Dirichlet series, we know that all the step functions ($k\geq 1$) $$M_k(x)=\frac{1}{2\pi i}\int^{2+i\infty}_{2-i\infty}\frac{x^sds}{\zeta^k(s)s}=\sum_{n\leq x}\prod_{p|n}{\alpha_p-k-1\choose\alpha_p},$$ change sign for indefinitely large values of $x$ (here $n=\prod_{p|n}p^{\alpha_p}$ is the prime factorisation). Since $M_k$ is a non-constant polynomial in $k$ of degree $\leq\log_2x$, certainly no more than $\log_2 x$ of the functions $M_k$ may vanish simultaneously for a given value of $x$. I would like to know anything that can be said about the following: 

Define $l(n)$ to be the least prime factor of $n$ and, say, $l(1)=0$ for simplicity. Obviously we have $2\leq l(n)\leq n$ for $n\geq 2$. There appears to be very little information about the asymptotic behaviour of $l(n)$ available. One may observe that $$\sum_1^{\infty}\frac{l(n)}{n^s}=\zeta(s)\sum_p\frac{1}{p^{s-1}}\prod_{q<p}\left(1-\frac{1}{q^{s}}\right)$$ for $\sigma>2$, where $p,q$ are prime and the empty product is unity. It seems a fair bet that the Dirichlet series on the left has a meromorphic continuation to the region $\sigma>1$ but I haven't proved this. It certainly is singular at $s=2$, thus so is the sum on the right. The type of singularity is not at all obvious, so without further investigation little more information is available from this naive approach. 

That is, is it true that the bound $$\phi(mn)\leq m\phi(n)$$ holds for all pairs of natural numbers $m$ and $n$? It is true on average, in the sense that $$\sum_{mn=k}m\phi(mn)\leq\sum_{mn=k}mn\phi(n),$$ and it holds for every pair I have computed. If it does not hold, what is the smallest counter example? 

This concrete geometric question has arisen out of the problem of counting arithmetic functions with a particular property. The details of the relationship between the counting procedure and this question are quite heavy and in fact unnecessary, so I omit the details for now. My knowledge of geometry and functional analysis is poor hence this post. Consider the vector spaces $V=\mathbb{R}^N$. We are going to let $N\rightarrow\infty$ and pose a question about the size of a particular subset (as a function of $N$). Let $(u,v)$ denote the angle between two vectors so $\langle u,v\rangle=\|u\|\|v\|\cos(u,v)$. For each $V$ let $S$ denote the subset comprising of those $s\in V$ for which $\|s\|\sim N^{1/2}$. Also let $M$ denote invertible linear operators and let $(b_n)\subset S$ be (non-orthogonal) bases for each $V$ (in fact $b_n=(M^{-1})^{*}e_n$ where $(e_n)$ are the standard orthonormal bases). The following is true: