No. All the stars you can see in the night sky are within a few hundred light-years of Earth. That means that you're seeing them as they were no more than a few hundred years ago. Most stars live for billions of years; the Sun, for example, is about 5 billion years old and is expected to live for another 5 billion or so years in essentially its current form. Some of the brighter stars have shorter lifespans (because they're larger and "burn" their nuclear fuel more quickly), but even they have lifespans of at least millions of years. No naked-eye visible stars have "died" in the last several centuries. We do sometimes see stars explode (as novas or, more rarely, as supernovas), but I don't believe any of the stars that have done this were naked-eye visible before they exploded. 

No. Let's say we want to see Earth as it was 1000 years ago. Assume that someone has set up a perfect mirror 500 light-years away, so that we can actually see the light that left Earth 1000 years ago. (That's a really big assumption.) The best telescopes in the world can't see the Apollo landing sites from Earth. We didn't get decent images of the descent stages, which were left on the surface, until the Lunar Reconnaissance Orbiter sent back photos it took from Lunar orbit. See $URL$ 1000 light-years is about 20 billion times as far away as the Moon. There's no way we could see people's faces at that distance with current technology -- or with any reasonable future technology. (There are physical limits on the resolution of an optical telescope of a given size.) And all this assumes that we have that perfect mirror out there. As far as I know, nobody has set up such a mirror for us, and all the light that left Earth 1000 years ago is now 1000 light-years away, badly faded, and beyond our reach. It's conceivable that we could develop faster-than-light travel (which may or may not be physically possible), go out there, build a telescope with a really big aperture, and point it back at Earth. But that's not likely to happen any time soon, and I wouldn't know how to determine how good an image we might be able to get. And going back millions of years just makes the problem worse. 

I have Googled "iridium content of comets" and can't find anything that suggests comets contain iridium in any detectable quantities. Yet, whenever I read an article about the Chicxulub impactor, the article invariably says something to the effect that it may have been created by an asteroid or a comet. But Alvarez and company first offered the impact hypothesis for the K-T extinction by observing an iridium layer in global sedimentary deposits, which could only have come from an asteroid impact, since iridium is extremely rare in the Earth's crust. Later the Chicxulub structure was identified as the probable site of the asteroid impact. While a comet could have caused the Chicxulub crater, it could not have been responsible for the global iridium layer. So why do science writers offer the comet alternative? If Chicxulub was created by a comet, then another site must have been the source of the iridium layer. 

Sunrise and sunset times are based on when an observer at the location in question would see the first or last limb of the sun appear or disappear; they do not take into consideration the light-speed delay between the Earth and the sun. They do, however, take into consideration the average refraction of the atmosphere, so sunrise occurs a bit earlier than plain line-of-sight would predict as would sunset occur a bit later. 

I suspect you're thinking that we'd have a summer when the northern hemisphere, for example, is tilted toward the Sun, and a second summer during the perihelion, when the Earth is closest to the Sun. For one thing, the timing doesn't work; the perihelion takes place in early January, close to the northern midwinter. That probably moderates the effects of axial tilt for the northern hemisphere (and amplifies them for the southern hemisphere), but it's not enough to override them. The other answers have said that the axial tilt is a more significant factor than the variation in distance from the Sun, but they haven't explained why. The following is a rough back-of-the-envelope guesstimate. The difference in illumination caused by the varying distance from the Sun can be computed from the ratio between the perihelion and aphelion distance, which is about a factor of 0.967. Applying the inverse square law indicates that amount of sunlight at aphelion is about 93.5% of what it is at perihelion. Reference: $URL$ At my current location (about 33° north latitude), at this time of year (close to the northern winter solstice), we're getting about 10 hours of sunlight and 14 hours of darkness each day. (Reference: the weather app on my phone.) That's about 83% of what we'd get with 12 hours of daylight during either equinox, and about 71% of what we'd get with 14 hours of daylight and 10 hours of darkness per day during the summer solstice. The effect is greater at higher latitudes. In addition to that, the sun is lower in the sky during the winter than it is during the summer, meaning that a given amount of sunlight is spread over a larger area of the Earth's surface, which makes the ratio even larger. I don't have the numbers for that, but it's enough to show that the effect of the axial tilt is substantially greater than the effect of the varying distance between the Earth and the Sun. 

I was looking at the answer provided by Andy and the comments attached to it, and together they add up to a reasonable answer.There are several ways to measure a day, the two most common are sidereal and solar. A sidereal day is the time it take earth to rotate 360°; a solar day is the amount of time it takes the earth to rotate such that the sun appears at the same meridian as the day before. (Sunrise and sunset aren't really good references, as they are influenced by atmospheric conditions that affect refraction.) The solar day, or more accurately the mean solar day, is the day our calendars measure. The mean solar day is exactly what it says, the average amount of time during the course of a year that it takes for the sun to appear over the same meridian from day to day.Unfortunately, the definition of a sidereal day is very often given as the definition of a day, which is totally inaccurate, and very confusing.The length of the solar day varies during the year because the of Earth's distance from the sun; it is closer in January and farther in July. Because it is closer in January; it is also moving faster, which means that the planet has to rotate more for the sun to appear over the same meridian.If you can get your head around this, the concept really isn't very complicated. 

As indicated in the comments, the is the ISO 8601 syntax for the time zone. Specifically, it indicates a time zone 2 hours east of UTC. indicates that the site is hosted in Berlin, Germany, which is consistent with the time zone. The fact that the data includes the date and time zone but not the time is probably an error. This particular datum is Tom Cruise's birthday; in fact he was born on that day in Syracuse, New York. A data representation that includes a date and time zone but no time is peculiar, and I'm not sure that it conforms to the ISO 8601 standard. The description in the Wikipedia article seems to imply that a time zone can only follow a time. I haven't checked the standard itself. A representation of just the date: would make more sense, and would be more useful. This is probably a bug in the software that runs dbpedia.org. 

During a solar eclipse seen from Earth, an observer on the Moon would see the Moon's shadow on the surface of Earth. I don't know of any photos of such a shadow as seen from the Moon, but here's a photo of a solar eclipse seen from the Mir space station in 1999. 

It's worth noting that elements with atomic mass greater than about 140 were likely created in the collision of neutron stars as opposed to supernovae. There is an interesting article on Physics.org and another on the Washington Post. There is also another here. I too thought that all elements heavier than iron were created in supernova explosions, and when I first heard the theory that elements heavier than gold were likely created in neutron star collisions, I rejected that idea. But after reading these and other articles, I've come to accept it. Apparently, the energy generated in a supernova, while considerable, is not sufficient enough to synthesis the elements heavier than gold.Edit:I found this interesting article on the Smithsonian Magazine's website. The theory that NS-NS collisions create elements heavier than gold came from data observed from such a collision, which only happen, on average, every 100,000 years. Apparently, this theory better answers questions that the supernova creation of heavy elements cannot. The observed NS-NS collision was observed on June 3, 2013 

I seem to recall reading something that said if the density of the universe was off by as little as one atom per cubic meter, the universe, as we know it, would not exist; one less and there wouldn't have been enough gravity to form galaxies and stars, one more and there would have been too much matter. (I don't know (or remember) what would have happened in the case of too much matter.)If I Google the title of this question, all I get is stuff about the expansion of the universe, nothing about whether or not it would exist. I've tried other variations but can't seem to find anything.Did I grossly misinterpret this? If not, does anyone know of any articles that can confirm or refute this? 

It's almost 100% stars. In good conditions, you can see perhaps 2000 stars. (There are about 6000 naked-eye visible stars; of these, 3000 are above the horizon at any time, and about 1000 are hidden because they're too close to the horizon and blocked by the atmosphere.) The number of non-star objects you can see without assistance is tiny in comparison: 

A handful of other artificial satellites might be visible, but only rarely. Comets can be very visible, but again that's rare. Visible asteroids are even rarer. Vesta, a large asteroid, may be barely visible, but I've never seen it. Note that some of these objects are quite obviously not distant stars just based on their appearance. Some galaxies (Andromeda, and the two Magellanic Clouds if you're far enough south) are visible, but they don't look like stars. A few of the brighter nebulas and globular clusters might be visible; the latter are groupings of stars, so I don't know how they'd count. Meteors and aircraft can be visible, but they're within the atmosphere, and probably not covered by your question. 

The quotation is from the Wikipedia article on Tyche. The article gives the following references for the statement: 

(I suppose there could be a third answer. If humans were able to put a colony on the surface of the Sun, using some advanced technology that obviously doesn't exist yet, it's likely they'd still use an Earth-based calendar to measure time.) 

The Effect of Centrifugal Force. It is this little known aspect of the moon's orbital motion which is responsible for one of the two force components creating the tides. As the earth and moon whirl around this common center-of-mass, the centrifugal force produced is always directed away from the center of revolution. All points in or on the surface of the earth acting as a coherent body acquire this component of centrifugal force. And, since the center-of-mass of the earth is always on the opposite side of this common center of revolution from the position of the moon, the centrifugal force produced at any point in or on the earth will always be directed away from the moon. This fact is indicated by the common direction of the arrows (representing the centrifugal force Fc) at points A, C, and B in Fig. 1, and the thin arrows at these same points in Fig. 2.And finally another diagram that the blockquote cites:Yes, one can probably find lots and lots of quotations declaring that the antipodal tide is caused because the moon's gravitational force is much less on the far side than on the near side, but that doesn't make it true. And I believe NOAA ought to be a pretty authoritative source. If they can't get it right...