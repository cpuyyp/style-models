In their equation (5), Kaplan and Menzio claim that the price distribution in their Burdett-Judd market is given by $$ F(p, u) = \{u \cdot A_1 \left[1 - \left(1 - B_1(u)\right)\frac{(r-c)p}{(p-c)r}y_u\right] \\ + (1-u) \cdot A_2 \left[1 - (1 - B_2(u))\frac{(r-c)p}{(p-c)r}*w(u)\right] \}/C$$ For positive $A_i$, $B_i$, $C$, where $u$ denotes the unemployment rate and $p$ denotes the price. They continue claiming that 

Ad 2) Again, you are not being precise enough. What is the government's objective? If government is only about maximizing average productivity, the solution is to let $L\to 0$, as then $F'(L) \to \infty$ (and for Cobb-Douglas, $F'(L)$ is proportional to average productivity). Maximizing total output implies allocating workers to the sectors with highest productivity. I do not understand how the functional relationship between employment intensity and labor productivity affects that premise. Furthermore, unless there is a market distortion, the role of any government intervention is not clear at all. 

In general, you can distinguish theory for a given market with off-equilibrium and on-equilibrium theory. Off-Equilibrium Theory Off-Equilibrium theory basically means that the market is not cleared using prices, supply does not equal demand. This type of theory needs to give a good story why this is the case. One very typical example is old Keynesian theory: due to stickiness of both wages and prices, in particular the labor market is not cleared: supply dominates demand. The story for non clearing wages is a mixture of long-term wage contracts, efficiency wages, observed downward rigidity of wages and similar. On-Equilibrium Theory Asset markets however are typically assumed to be in equilibrium. The reason being that there exists a huge machinery (the whole financial system) that immediately (and mostly automatically) buys and sells assets when it predicts future changes in supply or demand. We just don't think that asset prices are fixed at off-equilibrium values. What could possibly cause them to? 

Have the smallest model that you need to make your point (that contains A,B). Additional features are irrelevant to make your point and will only distract you and your audience. There are many models which are famous for being able to model A, B, or similar. If you need A and C, take a model famous for being good at modeling A, and add feature C. If there is nothing clean (any model that has A, also has A2, A3, A4 - which you really don't need), you might be better off writing your own model / simplifying an existing one). Example For example, 

Not it is not. You're assuming that each selfish player actually has enough market power to keep PWYW firms in the market. Usually, we rather think about buyers as atomistic - each individual's purchase decision has no impact on the seller, which is why they usually do not take into account these externalities. If you had a monopolistic consumer however, he would pay the PWYW firm exactly the marginal cost: Just enough to keep the firm alive, but no surpluses what-so-ever. The opposite of a monopolistic firm, if you will. However, I don't think that selfish and rational preferences will get you a solution that gives rise to PWYW firms: As I just hinted at, even if the buyers had market powers, the firm wouldn't make profits, and should just go for the standard oligopoly pricing strategy. The latter weakly dominates the former in all market sizes, and strictly dominates in markets with positive market power. 

Since there is nothing random on the right-hand side, we know that the left-hand-side must be non-random either. Hence, we can drop the expectations operator $$x_t = \beta x_{t+1} + k$$ $$x_{t+1} = \beta x_{t+2} + k$$ $$x_t = \beta (\beta x_{t+2} + k) + k$$ $$x_t = k + \beta k + \beta\beta x_{t+2} $$ Where we can now see where this equation is leading towards: $$x_t = k\sum_{s=0}^\infty \beta^s + \lim_{T\to\infty} \beta^Tx_T$$ where I have used that the limiting term with $T\to\infty$ will converge to zero. $$x_t = \frac{1}{1-\beta} k$$ Which yields a constant $x$. However, this violates $lim_{t\to\infty} x_t = 0$, as $x_t$ is a constant. To conclude, the given equation has no solution. 

The OPEC scenario is quite well described by a market with Cournot Competition. That is, while collusion would lead the highest total profits to the sum of the participants, each invididual participant would gain by increasing his production a little bit. Without observing the quantity of each participant and proper enforcement, that's the outcome the model predicts - and reality concurs. 

Both quotes my own words. This is a rather historical question, but when did the interpretation switch from (1) to (2)? Was (2) implied all the time, and I just didn't get it immediately from reading the paper? Or was it an implied corollary that the profession came to agree about later on? 

This makes much more sense for me since it is in this environment much easier to find the stationary state in the objective functions rather than the roots of the first-order conditions. However, I'm worried that without two steps, I cannot "first solve FOC, then replace $Y=wn$. How do I ensure that household's are neglecting the externality of their labor/consumption choice? 

First of all, a monopoly literally means that we have a single firm in one market. As economists, we do not really care about the number of firms in a market per se. However, the firm being single means it gets market power. And this is where problems arise. It will, under no regulation, take the demand curve (for buyers of his good) and the supply curve (for intermediate goods it uses) as given and extract rent from both ends. This directly implies that consumer surplus is reduced, since under typical assumptions the monopoly will supply a smaller quantity at a higher price. For Social Welfare, note that free markets with imperfect competition typically yield inefficient outcomes, that is adding up consumer surplus and producer surplus gives you a smaller sum than in the economy with no market power. Finally, Pareto Efficiency is somewhat irrelevant to the market power, as long as market power comes with the ability of perfect discrimination (see the comment). It is relevant for the type of economy, where I have assumed free markets throughout this answer. Under free markets, if there was any resource "free for grabs", someone would have taken it. Hence, the extent of market power does not affect Pareto-efficiency, the general existence of markets and their potential regulation does. Addendum: Note that I have assumed free markets (zero regulation by governments) throughout the answer. If the government was to enforce by law the optimal outcome, the amount of market power becomes irrelevant to both consumer surplus and social welfare in general. It could do this for example by forcing the monopoly to supply the optimal quantity of goods, or creating a subsidy which would incentivize the firm to supply exactly that quantity. 

Lending is very much excludable. To the extent that funds of the ex-im bank are limited, it is also rivalrous. Hence no, the services of the ex-im bank are not a public good. Second order public good To quote you: 

This is one of the issues with Macroeconomics - you usually cannot prove these kind of things, you can only find indicators. That is, because what we observe is always - in the neoclassical language - the general equilibrium, never the "off equilibrium adjustment" (as in the Walrasian Auctioneer). That includes Keynesian logic - these days, the majority of Economists does not think about these traps as off-equilibrium paths, but rather as multiple equilibria [citation needed]. As a comparison, if you only observe the equilibrium outcome, it is hard to say whether a decrease in prices comes from an increase in supply or a decrease in demand. Now, if you could randomize or had a natural experiment at hand (say, randomly shut down half of the firms in the economy), you could actually "prove" the underlying issue with empirical data. But since this is not feasible within many subjects of macroeconomic interest, disproving ideas using empirical evidence is quite difficult. 

Think about two goods that should be independent. Say, $x = $ shoes and $y = $ computer games. Complements imply complementarity: You can enjoy $y$ more, when you have more $x$. Hence a positive cross derivative. One way to phrase that is with non-separable utility: $U(x, 0) + U(0, y) < U(x,y)$. An alternative is what you specified: At the margin, having $x$ allows you to enjoy $y$ more. With our shoes and computer games, certainly the cross derivative is 0. With ice cream and spoons, it most likely is positive: Having a spoon increases the marginal benefit you're getting from ice cream, hence a positive cross correlation. Finally, think about chocolate and ice-cream. One could argue that they work as substitutes (think about desert, for example): You either want the one or the other. If you get them for free, sure, it doesn't hurt having both of them. But if you have to pay fair prices, you prefer to pay the price for one of the choices and stick to that. 

I don't think we have enough data on that matter. They would be irrational, for example, if transitivity of their preferences does not hold. How do we get their preferences? Through the axiom of revealed preferences (WARP). We can never say whether someone is rational, we can only say whether someone is irrational (read: his actions are not rationalizable). That is, if we observe 10 decisions from a person, and they are not conflicting, this is not sufficient to say that he is rational. However, if they do conflict, it is sufficient information to say that he is irrational. You phrased the question about individual terrorists, and not about the collective. Hence, to judge any single one, we would need to observe enough actions to judge his preferences, and see whether we fail to rationalize his actions under a preference ordering. And then, to repeat myself, I don't think we have enough data on that matter. 

I have a general equilibrium problem, where households given objective function $U(c,n)$ solve for working hours and consumption $n, c$, and firms use labor to produce a consumption good - their objective function is $V(n)$. There are potentially profits, which is paid out to the workers through wages $w$. Households spend all their labor income on the production good. There is the externality that working more leads to higher income on the household side, and spending higher income onto the consumption good yields higher profits for the firm - in turn leads to higher wages for the household. These things just happen in my environment, take my word for it - I'm trying to simplify as much as possible. Usual Equilibrium Household optimality, firm-side optimality and market clearing means that all FOC have to hold. Usually, I would solve this taking the first-order conditions for $U(c,n)$, taking firm's demand $Y$ as exogenous, and replace - after taking the FOC - $Y = nw$. Here, instead I want to rather find my equilibrium without FOC. It is $w, n, c$ such that 

If you go down the Macro/Econometrics route, your linear algebra knowledge should be quite profound. Then, you should have (because discrete time is almost everywhere a standard tool) working knowledge in 

How do profit margins vary over "business cycles" in the new Keynesian model? I'm interested in responses of profit margins (actual price markups) to all three standard shocks in NK models: - TFP shocks - Demand shocks - Monetary policy shocks As an example, here is what I came up with for TFP shocks, but I don't really trust my analysis on that. If BC are driven by TFP shocks, a bust implies lower marginal productivity of labor. Assuming flexible wages, this implies a decrease in costs. Since there is an optimal markup that firms are targeting, this implies that firms want to decrease their prices. Those that cannot adjust prices now have higher markups, and too high markups (compared to their desired markups). Those that can adjust prices will achieve their desired markup - their markup is constant through a decrease in prices. So as a response, average markups increase when hit by a negative TFP shocks - but holding the negative TFP shock constant, over time markups will go back to $\epsilon$ as all firms have adjusted their prices. 

It is not. Monetary expansion is increasing the money supply (through whatever method). Quantitative easing increases the money supply / injects liquidity, but also reduces privately hold stocks (and hence can reduce risks from the banks' balance sheets). 

To that end, if you increase the minimum wage, eventually inflation will wash off the real impact. Also, raises in the minimum wage tend to become substitutes for (non-forced) increases in the wage level. Have a look at the following graph, which depicts the relative impact of minimum wages. The author plots the maximum of minimum wages at a time period, deflated by average hourly wage in the private sector among production and non-supervisory employees (no managers). It really looks as if any spike (raise in the minimum wages) gets deflated quite quickly, doesn't it? 

Indexing (e.g. renting) contracts by inflation is called an escalation agreement: If, say, inflation increased a lot, a fixed renting fee would harm the property owner a lot, hence parties often agree on an Escalation Agreement. I also believe but I could be wrong that this subject was partially touched in this EconTalk episode. 

Eichenbaum and Fisher (2005) follow Kimball (1995) in allowing for the possibility that the elasticity of demand is increasing in a firm’s price. Which is not exactly what I was looking for, but it's a start. 

I take from your comments that you are interested in airline seating prices. The subject of airline pricing is very complex: 

Only when all these three coexist, one gets the 90% as a specific intolerance level. Otherwise, while higher debt-to-gdp ratios might correlate with smaller growth, there has been no study that shows a structural break / discontinuity at 90%. 

We have a population of people with different age $a$, time is indexed with $t$. There is a rate at which people die, $d(a, t)$. For simplicity, ignore births. I want to compute the evolution of the distribution of ages over time. Denote the mass of people at or below age $a$ by $F(a,t)$ $$ F(a,t) = \int_0^{a} m(\tilde a,t) d\tilde a $$ Ultimately, I am after some Kolmogorov forward equation, that is, the solution for $$ \partial_t F(a,t)$$ My approach Let $f(a, t)$ denote the density of people at age $a$ and point in time $t$. I will start with a discrete time approximation and let $\Delta$ go to zero. At each discrete point in time, $$ f(a+\Delta, t+\Delta) = (1-P(a, t))f(a, t)$$ where $P(a, t)$ is the discrete time analogue of $d(a,t)$. As I'm going to let $\Delta\to 0$, I can approximate $1-P$ with $1-\Delta d)$: $$ f(a+\Delta, t+\Delta) = (1- \Delta d(a,t))f(a, t)\\ \frac{f(a+\Delta, t+\Delta) -f(a,t)}{\Delta} = -d(a,t))f(a, t)\\ (\partial_t + \partial_a)f(a,t) = \lim_{\Delta\to 0}\frac{f(a+\Delta, t+\Delta) -f(a,t)}{\Delta} = -d(a,t))f(a, t)\\ $$ I can integrate both sides w.r.t. a and get $$ \partial_t F(t, a) = - f(t, a) - \int q(t, a) f(t, a) da \\ \partial_t F(t, a) = - \partial_a F(t, a) - \int q(t, a) \partial_a F(t, a) da $$ I know that $\partial_a q(t, a) = q(t, a) (1-q(t, a))$. However, that doesn't really help me with solving the integral. Is there perhaps another angle to attack this problem? Or did I miss something?