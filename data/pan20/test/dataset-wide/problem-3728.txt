However, classical probability is also a tensor category to model joint systems, and so is quantum probability. Bell's theorem is that there does not exist a tensor embedding (speaking loosely; I'd have to think about how to rigorously define what it excludes) of quantum probability into classical probability. In physics terminology, a non-tensor-preserving construction such as that of Bohm is called "non-local". Here is a description of an optimized form of Bell's construction called the CHSH inequality. Let $a_1, a_2 \in A$ and $b_1, b_2 \in B$ be four Booleans or, more conveniently, four $\pm 1$-valued Bernoulli random variables. Then their correlation matrix $E[a_j b_k]$ in $A \otimes B$ satisfies this elementary inequality in classical probability: $$E[a_1 b_1] + E[a_1 b_2] + E[a_2 b_1] - E[a_2 b_2] \le 2.$$ To prove this inequality, consider that each term is $\pm 1$ if you plug in four values of the variables; if the first three term are 1 then all four are equal and the last term is $-1$. (You can easily make them unbiased so that $E[a_j b_k]$ really is the correlation matrix.) However, if you take $A \cong M_2$ (the qubit system) and $B \cong M_2$, then it is easy to find four such random variables and a state on $A \otimes B$ such that instead, $$E[a_1 b_1] + E[a_1 b_2] + E[a_2 b_1] - E[a_2 b_2] = 2\sqrt{2}.$$ (This is the maximum possible value in quantum probability.) This is a classical impossible set of correlations. You can repeatedly interrogate system $A$ by randomly measuring either $a_1$ or $a_2$, and the same for $B$. The correlation makes you think that $A$ and $B$ are in communication with each other, even when it cannot be true. This is what was actually demonstrated in Aspect's experiment. His experiment directly violated the CHSH inequality, in a protocol in which there wasn't enough time for light to travel from $A$ to $B$. Here are a few more comments about the violation demonstrated in Aspect-type experiments. What is actually measured is $$E = E[(-1)^{(j+1)(k+1)} a_j b_k],$$ where $j$ and $k$ are also random variables taking values in $\{1,2\}$. If $A$ and $B$ (or Alice and Bob) could communicate, then they could easily make $E > \frac12$, or even as close to 1 as they please, because they would both know the pair $(j,k)$ and they could pick a favorable pair of answers. But in the experiment, they are separated, and Alice is only told $j$ and Bob is only told $k$. In this case, they must separately provide $a_j$ and $b_k$, and the CHSH inequality applies if $A$ and $B$ are classical. This is a somewhat formal and blas√© summary of the illusion of telepathy in quantum probability that was first constructed by Bell. I have a livelier description of the same formulas in a colloquium talk that I gave at Berkeley. 

The definitions that you give are very formal and tend to hide the conceptual interpretation of these complexity classes. Imagine putting yourself in the position of the computer or Turing machine that is allowed to work for a polynomial length of time. (It's a reasonable model if you believe that people are evolved computers.) The string h in the definition of P/poly is called an advice string. You can say that it is provided by an angel who wants to help you produce the correct answer. If h could depend on the input x generally, then the angel could simply tell you the answer. So instead h only depends on the length of the input |x|. Meanwhile in the class NP, the string y is called a proof or a certificate. It is provided by a Merlin who wants you to answer "yes" to the decision problem, whether or not it is the correct answer. It can depend on the specific input x and not just on its length |x|. As Andreas says, a problem in P/poly does not even need to be computable. But I can mention a realistic class of problems that are in P/poly and are computable. The class BPP, which is anything computable probably correctly in polynomial time with a random number generator, is in P/poly, by a derandomization theorem. The theorem says that the angel can provide pseudorandom numbers that, together with repeated trials, make the randomized algorithm reliable as a non-randomized (but advice-dependent) algorithm. On the the other hand, an NP-complete problem such as the Hamiltonian circuit is easily seen to fit the Merlin model. If Merlin wants to convince you that there is a Hamiltonian circuit, he only needs to show you what it is. If his certificate y isn't a Hamiltonian circuit, then you should be skeptical and answer "no". 

The algebra $M_n(\mathbb{C})$ of $n \times n$ complex matrices is Morita equivalent to $\mathbb{C}$. Which implies: Every unital representation of $M_n(\mathbb{C})$ is isomorphic to a direct sum of copies of the defining representation. Thus your homomorphism $\rho:M_n \to M_k$ exists precisely when $k$ is a multiple of $n$, and after a change of basis in the target, $\rho(A)$ is just copies of $A$ on the diagonal. This is so for all homomorphisms, whether or not they are *-homomorphisms, but the answer for *-homomorphisms is the same. The only difference is that instead of a general change of basis, everything is equivalent up to a unitary change of basis. The nonunital homomorphisms are not much more general. Up to a change of basis, you can pad a unital homomorphism with extra rows and columns that are all 0. There is a similar result for a direct sum of matrix algebras. It is summarized in the concept of a "Bratteli diagram" to describe a homomorphism between two direct sums of matrix algebras. The homomorphism can be thought of as a bin packing -- packing items in bins --- with allowed repetition of the items. The Bratteli diagram shows how many copies of each item (matrix summand of the domain) goes into each bin (matrix summand of the target). In the unital case, the bins have to be filled exactly. 

I don't know a whole lot about the Langlands program, but if there is one tool that seems to come up a lot in geometric Langlands, it's perverse sheaves. You see a lot of singular algebraic varieties in geometric Langlands, and perverse sheaves are meant as a singular generalization of a vector bundle with a flat connection. Ordinary sheaves are already a singular generalization of vector bundles, but not the relevant one. Perverse sheaves (which are made from sheaves but not sheaves themselves) are a more apropos generalization that incorporates and sort-of just is intersection (co)homology. I can also say that I wasn't going to learn about perverse sheaves until I had to. However, I have now seen several important papers, in the related categorification program, that read this way: "Perverse sheaves + necessary restrictions = a good solution". So now I might be slowly getting used to them. I can also see that even the formalism perverse sheaves or intersection homology is sort-of inevitable. In some of the simpler constructions, the varieties (over $\mathbb{C}$, say) are non-singular and certain answers arise as ordinary cohomology products or intersection products. For instance, the Schubert calculus in a Grassmannian manifold. What choice do you have if the Grassmannian is replaced by a singular variety $X$? For some of these categorification/Langlands questions, you can either propose wrong answers, or ad hoc answers, or you can automatically get the right answer by using intersection homology on $X$. (With middle perversity, as they say.) 

The issue here is that there are really two tasks: (1) Define the algebra of differential forms on a manifold, and (2) implement them as multilinear functions on tangent vectors. The natural way to define them is along the lines of what Donu said: The differential forms at a point are like a polynomial algebra over the vector space $V = T^*_pM$, except supercommutative (or graded-commutative) instead of commutative. The supercommutativity condition is identical to taking a quotient of the tensor algebra, which is the free non-commutative algebra over the vector space $V$. But then for the second task, you would like a monomial, in a standard basis of cotangent vectors, to take values of $\{0,1,-1\}$ if you pair it with a standard basis of vectors. For example, you would like to say $$dx \wedge dy = dx \otimes dy - dy \otimes dx,$$ because that evaluates to $1$ on $(\hat{x},\hat{y})$ and $-1$ on $(\hat{y},\hat{x})$. In order to do this, you have to implement the wedge product with antisymmetrization and with factorials, actually the reciprocal of the factor you give: $$\alpha \wedge \beta = \frac{(a+b)!}{a!b!} \mathrm{Alt}(\alpha \otimes \beta).$$ If I were explaining the subject, I would handle points (1) and (2) separately. It is common to conflate the two concerns. It amounts to either definition forms as a subspace of tensors (the usual solution), or as a quotient space of tensors. The real issue is that they need to be both, and that double role leads you to the factorial factors.