I'm just piling on to other good answers. No it won't stop sexual crime, and no you cannot prevent corruption, including people getting framed, or escaping justice. (Both of which appear to have happened IRL with respect to child pornography, sexual abuse of children by parents, and rape accusations.) Throughout the animal kingdom sexual acts are the most powerful reason to commit acts of violence against others, and although willing females are common, rape is not uncommon. Sexual urges and compulsions have been stumbled upon by evolution because they accomplish reproduction, and evolution is driven only by what works. Morality, mercy and respect is absent. The mental acuity to formulate morals and classify behaviors as right and wrong is very recent; probably arising 250,000 years ago in Heidelbergensis, the common ancestor of Neandertals and Homo Sapiens. Our urges to fight for mates and take mates by force go back hundreds of millions of years. Long before rationality existed to let us perceive consequences, these acts in regard to sex are powerful, primitive emotions that existed before any animal comprehended death or injury or consequences. You can prevent a lot of planned crimes by making consequences severe enough, because those are already engaging the frontal cortex and specifically considering consequences and weighing options. Ironically, the crimes you would most like to prevent, like murder, physical assault and rape, are committed because the frontal cortex has been side-lined by emotions (which remain King in the brain; all that reasoning and deliberation stuff is a recent add on, that is why it is still called the neo- cortex). As others say above, consequences won't matter, they literally are not imagined for consideration when these crimes are being committed. Your consequences might act as a deterrent for planned rapes, just like the death penalty might be a deterrent to planned murders. We cannot be certain of what caused crimes to not happen. We may get a statistical clue by comparing periods when the penalty was light or non-existent or seldom enforced, to periods when it was more severe and vigilantly enforced, but such comparisons must be careful to account for other cultural influences as well. Thus the proper way to look at deterrence is as a probabilistic thing, whether it reduces the chance of somebody being a victim of a crime. In the case of first-time sexual offenders, the answer is probably very little, less than the legal consequences of murder deter first-time murderers. The latter are more likely to plan their murder and consider the consequences: Many murders are impulsive rage responses, but about half of them (I am extrapolating from American crime statistical analysis) are for more rational reasons, cold blooded and planned with potential consequences in mind. It is why about 40% of murders go uncleared, and if the stats on failure to recognize foul play are brought into effect, add 10% or 15%: Murders that look like accidents or overdoses or natural causes that were never even investigated as a murder. In short, the impulses surrounding sex are basically emotional drivers that can sideline rationality, and although severe penalty (like death) can prevent future occurrences, deterrence by the rational consideration of such penalties may be very wishful thinking. 

By request, an example of referendum. This is an example only, a full description would require pages of rules, and I don't want to enter into a lengthy discussion of details or why the rules I present are necessary. Here is one form of referendum: Have a website vaguely like a merger of Stack Exchange [SE] and Kickstarter [KS]. Ideas for laws, in categories like SE, without legalese, can be presented. People can (like SE) point out that they are duplicates or off topic, etc. You can only sign up with a valid voter ID, but then you can vote ONCE on proposed ideas. Up, down, or Duplicate. You can comment; set rules to stop trolls, too. At some thresholds, e.g. after 90 days with at least 5000 votes and at least 67% in favor, taxpayer money hires lawyers (see my ans) to draft a law, in full legalese, within the constitutional rights. They will also state, in plain language, how each element written corresponds to a requirement of the law, or was necessary to close a loophole or address an ambiguity in the proposed idea. Or they can state (again by 67% majority of them) that it is an unworkable idea, would violate a previous law that would have to be repealed first, or is impossible to write as law within the Constitution. In that case, the law gets ONE more chance with a new group of randomly chosen lawyers, if they also agree it is unworkable, it is dead. If it is workable the resultant text is posted. Other lawyers and citizens can comment on it. In the end, this is revised until at least 50% of the original voters vote to ratify the referendum. Alternatively, 50% could vote to fire one or more of the lawyers and have them replaced (by lottery again). I'd only allow that once, however. Once the referendum is ratified, it goes to the general populace. All the website commentary, the lawyerly discussion, and the original idea remain available, permanently, though the proposal is closed and no more discussion is permitted. Then the people vote: If 67% vote in favor, the referendum becomes law. Otherwise it fails. Either outcome is recorded on the website for that proposal; and if basically the same thing is proposed in the future, it can be flagged as a duplicate. I'd let voters sign up to be notified if another proposal like it is flagged as a duplicate; they may wish to vote on it again within the 90 day window. (e.g. if they felt it was a hateful law). I'd make it a mandatory five year prison term crime to tamper with the website, hack it, write code that biases voting, conduct a denial of service attack on it, spoof it, or for any service providers to provide lesser service for it, or charge anything for access to it. Access to this one website is a mandatory public service. I'd provide it in five major languages. As to why 67%: It is a stable vote. It takes only a few votes to go from 51/49 to 49/51 on a law, and the populace is changing, and you cannot count on all interested parties to vote. However, to go from 67/33 to 33/67 requires more than half of the YES votes to change their mind to NO votes, and that is far less likely to happen if you have thousands of votes. For the entire populace, it may take several decades for such a change to happen, making the law far more likely to reflect the will of most of the people. That is what I mean by "stable", that although the exact percentage of people in favor may vary, the fact that a majority remain in favor will not change very rapidly at all. I think that is important for any law. I would say legal modification or repeal should follow the same formula: 67% must be in favor of the modification or repeal. And finally, I would still make it the duty of lawyers to refuse to compromise fundamental constitutional rights that may exist: Like freedom of speech, religion, right to a trial by jury, etc. Unlike the USA, I would demand a much higher threshold to repeal any fundamental rights, perhaps even 90% in favor of repeal. It would also be their job to refuse to pass any law that conflicts or would restrict an existing right or require violation of an existing law or reduce an existing protection. Of course your story is your story, this is just an example to show such a thing is possible. Rich people can run ads all they want, they cannot stop the commentary or prevent people from voting in the first 90 days. Make it illegal to offer either money or gifts for any vote on the website, with the same mandatory five year prison sentence for both the briber and recipient. 

This is a case of suspended disbelief for fiction; because audiences are not moved, emotionally, by the destruction of hardware. They will get bored if both sides use hardware and the result is just a circus of mechanical destruction. If we use robots and the enemy is living beings, we look like exterminators at best if they are insectoid or non-human enough, and like the bad guys if the enemy has any human characteristics, emotions or demonstrates feeling pain or grief. The only way to make the audience identify with our side is to put human lives on the line. Star Wars cannot be about machines going after each other, we need human or human-like pain, grief, suffering and despair, and it must be severe: Luke loses his adoptive parents. Young soldiers with lovers back home, hopeful to start their lives together after the war, are trapped and slaughtered. As Stephen King advises writers: Develop a character the readers will love and care for, then put her in the cooker. In futuristic fiction, in order for us to identify with robots, they would have to be, effectively, human beings with an emotional side able to experience setbacks and frustration and some kind of suffering, perhaps vindictiveness and anger as well. Of course that is not where the question lies: IRL, it is fair to presume that within 50 years or so, robots will be able to do anything a human can do in warfare, better. The "steal command" problem is a non-problem, we can use the same protocols for robots that keep our banking system humming along transferring trillions of dollars around the world without anybody diverting all the money into their own accounts. Long key RSA encryption is easy, fast, and impossible to break by any known means; that is what banks use. The robots in question may be about as self-aware as a self-driving car (which requires a form of self-awareness to navigate its body safely through a fast moving maze, which also requires a self-referential model of what movements it is capable of choosing and how other vehicles will most likely move). The robots do not have to be emotional in any way, they can be rational and intelligent (in the sense of accurately predicting outcomes in novel scenarios). Emotions, like fear of death or reluctance to inflict harm or psychological angst over what they have done, or grief over lost compatriots or anything else are all baggage they don't need. Intelligent machines do what they are told; including if they are told to stop, self-destruct, or conduct a suicide mission that will destroy them: They can be "intelligent" with absolutely zero emotions or "desire to live" that would interfere with or override their commands. As for whether the enemy uses live soldiers: The story of the war is written by the victors, remember? Just as we do now in the USA, we use robots and high tech and drones, but we don't spin that as cowardice: We spin it as saving the lives of our soldiers, protecting the troops, while destroying the bad guys. We say our soldiers are still brave, intrepid warriors, even if they sit all day in a comfy chair a desk safely tucked away in a stateside office building on some Army base in South Dakota, using a 4-screen video-game interface to fly drones over Pakistan. Robots will be just as autonomous and capable of making decisions as humans; should communication be disrupted. They will be just as capable as humans if cut off from command for any reason; but more capable than humans of communications between each other (e.g. they can pass full video of what they see and hear, they don't have to 'describe it'; they can have a group mind). They will also be able to survive better than humans. They don't have to rest, they can use solar power to recharge; if necessary they can hide and shut down all but the most minimal solar powered sensory activity, and survive indefinitely without food, waste, or boredom (boredom is an emotion). This is not something current AI can do; but the outlines of what it will be able to do in the next 30 to 50 years are clear. Just as Moore's Law was clear and has held, with only slight modifications, for 50 years. Today's robotics are like early guns; used in warfare and deadly, but not terribly accurate or reliable. That will change, they will get better, and no politics or shame will stop them, just as our modern automatic guns feel light years ahead of the blunderbuss which was basically a mini cannon, future robots will be far better and more lethal than human soldiers, and the citizens of the countries that own such robots will be appalled at the idea of losing their human soldiers in battle. They won't be hacked, even by up-close surgery. John Conner will not have the 10,000 bit encryption code necessary, and no screwdriver is going to be able to modify the circuitry of integrated circuits: They will have one-way tamper-proof casings anyway, so once they are sealed any attempt to open them destroys them (there is no need to ever get inside and repair them, even now we just replace malfunctioning chips). (Heck our robot can automatically self-destruct its processors if anything every penetrates its casing). In fiction the audience wants to identify with entities in the story that display human emotions and qualities. In real life, and real war, the objective is to subjugate the enemy and force a surrender under threat of death to the humans on the other side. IRL we'd rather not identify with the soldiers we lost, we don't want to share the grief of their families, parents and children and spouses, we don't want to feel the loss of their potential as good people, friends, and citizens. We don't want them to suffer from PTSD or the trauma of war. If we can pay our way out of all those emotions, by dint of buying robots to do the dirty work, we will. Further, in my opinion, we (and our military leaders) will prefer our robots to be distinctly non-humanoid (or even animal) in form and behavior, so as not to accidentally invoke any empathy or sympathy for the robots. A drone doesn't look like a person, a drone getting shot down or crashing doesn't look painful, it looks like an unfortunate loss of hardware, like accidentally dropping a big screen TV down a flight of stairs. A kind of "dammit" for the loss of value, but zero concern for any pain the TV felt; it didn't feel anything. If the animal form with legs and limbs is truly useful for navigating terrain; I suspect we will use insect or arachnid forms with many legs. Losing a robotic soldier reminiscent of a tank-like 3-foot cockroach or spider won't bother us much at all. Sure, it is our cockroach-tank, but if it gets blown to pieces by a missile, no problem. Send two this time.