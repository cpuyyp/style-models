It might be a variant of "No true scotsman" or we could call it an "empirical judgment" fallacy. Why I suggest the former is this: What she's suggesting is a reverse of the No True Scotsman. The No True Scotsman fallacy is to do the following: A: No scotsman would drink vodka. B: McTaggart is a scotsman and he loves vodka [empirical defeater] A: No true scotsman would drink vodka, so McTaggart is not a true scotsman even if blah blah. What you're describing is the inverse: A: I'm an honest person B: well, you did tell lies on occasions P, Q, and R. [empirical defeater] A: I'm an honest person ergo I don't believe you What they share is the following: 

I think Shane aptly describes the concept on a basic level, so I'm just going to supplement that by trying to address how the concept is supposed to benefit us and the value it is supposed to add. Even though Gadamer is the big name for hermeneutics, "horizons" is a concept that we can trace back to at least Heidegger but perhaps further to Hegel and Kant. I will start with therelevant image in Heidegger's Being and Time -- the hammer. There, Heidegger distinguishes between Vorhandenheit and Zuhandenheit often translated as "presence/being at hand" and "read to hand" respectively. The relevant difference is that what is presence/being-at-hand is the sort of objects we think about, i.e. it's the dot in "consider the red dot." What is ready-to-hand by contrast are the tools we use regularly. In "consider the red dot", it is say the computer screen through which we are looking at the example. Whence horizons? Horizons are the backgrounds that determine how something is ready-to-hand for us. For instance, is garlic ready-to-hand as a spice for food or as a vampire-ward? Horizon is supposed to stand for the sort of cultural and background ideas that make this possible. Moving backwards towards Hegel, we could say that horizons are the structures of thought through which we have environment where there are objects at all. Stepping back to Kant, we are working within a framework where each and every object involves the use of our thinking categories (our hermeneutical tools) to appear before us as something. Phenomenology is an inheritor of all of these systems of thought, and the idea of much recent phenomenology is that differences in our experience of the same thing are traceable to differences in the horizons through which we experience them. So for instance what is happening in Crimea and Eastern Ukraine is open to interpretations that will determine what sort of events "riots" "uprising" "rebellion" "revolution" is actually happening. 

Minsky: can't the entire room function as a virtual mind. [Minsky: virtual = it's a mind but not the same hardware / setup as human minds] Searle: Of course not, because ersatz things cannot have real effects [Minsky: what does that have to do with what I'm claiming? !!! I'm not saying it's not a mind by calling it a virtual mind. I'm saying it minds but not physically] 

You're vocabulary on this question is a little weird and backwards insofar as you are projecting AI terminology onto societies, but I don't think your insight is fundamentally flawed. As Einer suggests above in the comments, you might want to look at Hegel. What he's doing can be said in many ways including Weltgeist = "World Spirit." Here, I'll just briefly explain what Hegel (who we could call the grandfather of sociology is up to) with regards to society. To do so, we need to start with Aristotle. One of the most interesting claims Aristotle makes is that the polis is prior to the individual, and the family on a smaller scale is prior to the individual. What he means by these claims is that people function optimally in a type of political society made up of families and the individuals in them. He draws explicit analogy to bees. For Aristotle, we have a type of social unity in which our individuality rests. Hegel agrees -- but adds an interesting modern idea: self-consciousness. Hegel's Phenomenology is a history of epistemology (of sorts). In it, he's moving through several different recognitions in the life of mind (Geist). For our purposes, we don't need all of them. One of the more interesting (and misunderstood) dynamics is the Master-Slave dialectic. At this point, we already have individual selves who are conscious. For Hegel, the master to validate his identity as master needs the slave to recognize him as such. And this ultimately means that he doesn't have full mastery over the slave but rather needs the slave to be anything. (Here's where Marx gets off the train). For Hegel, this is just a middle phase to the point where you get positive mutual self-recognition -- in the family. In the family, the members affirm each other and give each other identity. Moreover, you get action for the sake of the family as a whole and then family-consciousness. From there, things scale up until there's a Volk with its own "consciousness." 

they believe to be a self is to be a relation. both think recognition and self-consciousness are important. both take a dialectical approach to their philosophy -- Kierkegaard with an ironic motivation at times and Hegel with much less irony. Both like Aristotle's work better than Plato (reflected in many similar arguments). 

I think you're misunderstanding the idea behind "Last Thursdayism" on two fronts. First, as can be seen from the selection of "Thursday", the main point of the posit is to point out a problem in proving things that we can only observe indirectly by effects. Or to word it another way, the observer only has access to what they are observing and everything else could be otherwise explicable or at a minimum doesn't prove that such events took place at the times they appear to. (Here, the point is that it's a skeptical thesis -- not that you can't quibble with it on what can / cannot be seen). Consequently, the counter example completely misses the mark in two ways. On one level, the Last Thursday bit is not meant to be take literally -- but rather to point out the degree to which we cannot "know" that things weren't just invented last Thursday. On a second level, what you are observing remains what you are observing, so the person in the time-dilation from traveling near the speed of light won't be able to prove that in fact two weeks have transpired, they will only have the impression and evidence that makes it appear to them that two weeks have transpired... There's of course a trick in that this "know" is the know that most thinkers after Plato have given up on and not something like JTB. 

there's an animal conception where the animal subsumes the object by consuming it. Here, on the basest level, everything is an object for that self to eat. This is supplanted by a more advanced conception where the self comprehends an object -- subsuming it without consuming it, which Hegel considers more advanced. Everything in the world is brought under the categories of the self (Kant is still on board for that and in a weird way so are thinkers like Aristotle and Aquinas). Hegel draws from 2 an interesting idea -- that the most interesting thing going on in thinking is the activity of the self in thinking. 

Moreover, his work is a major source for contemporary work in the philosophy of emotions (in part because there's a giant gap in the study of emotions between Aristotle and post-WW2). 

As above, essence is not a Kantian term nor do I know what it would mean to make "another person the object of our actions." Kantian action works in terms of maxims -- which while difficult to define mean something along the lines of: 

Your source is correct, it's not a fallacious argument -- since as your source points out, it's not an argument. But informal fallacies are not limited to problematic arguments but also to problematic techniques in many contexts of rhetoric and argumentation. Thus, it need not be logically invalid to be fallacious in usage. In the case of a loaded question, the problem is that it's unfair to the person you are asking, because it prejudices the listener by making it so either answer presents the answerer in an unfair light and that refusing to answer places the answerer in an unfair light. The quintessential example which William Lycan uses but so do many others is: 

It's not exactly that Aristotle works in triads, so much as he thinks that certain dispositions of character have known excesses and deficiencies. We begin with the definition Aristotle supplies for virtue: 

Let's start by pointing out that Kant does believe there can be Metaphysics of Morals enough so that this appears in the title two of his works: First, there's Groundwork of the Metaphysics of Morals (German: Grundlegung zur Metaphysik der Sitten) (1785). Second, there's the The Metaphysics of Morals (German: Metaphysik der Sitten) (1797). What does Kant mean by asserting there is a metaphysics of morals? There's a really long answer that relates Kant to the entire history of philosophy, which we'll bypass here. The short answer is that Kant accepts the following claims: 

On a certain level, it's definitely true that the origin of formal logic is an attempt to formalize certain intuitions. But after the process began, it's basically become a set of rules that dictate a certain set of expectations and outcomes. Thinking of sentential deductive logic, the basic idea is that if we begin with (a) bivalence, (b) Aristotle's 3 laws (identity, non-contradiction, and excluded middle) and (c) a limited set of operators defined by their truth functions, then we can provide arguments that are valid. And this has (for those who accept it) a very valuable feature (truth-preserving). When an argument is valid, we no longer need to argue about the legitimacy of the structure of the argument, but can instead merely focus on the truth or falsity of the claims in question. This system and its cousins and children borrow words from their intuitive origins but aren't actually stuck on those meanings or uses. E.g., 

All express the same propositional content but they are different sentences (there can also be difference sentences for the same proposition in the English). The same content can also be expressed symbolically in any of several logics. For this reason, many philosophers would not want to call a proposition a sentence. This point is confusing because a proposition will/can be written as a sentence. But the expression would not be considered identical with the propositional content (the thing that can be true or false). You can find some further explanation here. 

There's a lot going on in your question which makes sense considering you're expressing that you don't get where some people are coming from. I will try to address two of the things you raise and hope that this answers what you meant to ask. Problem 1: Absolute Standards When you doubt the logic of absolute standards in ethics, I think the trick to all such views lies in a rejection of: 

In your question, you state you are "aware" that such drugs are harmful. There's an ambiguity there about what that "awareness" entails. On one reading, it would mean that you have knowledge that this is true but are not moved by such knowledge. On another reading, it means that you don't really fully grasp what it means for such drugs to "be harmful." The latter case would mean that you are not autonomous, because you would fail the knowledge condition. So let's just assume that what you mean is that you have full knowledge of the harm it causes. On such a reading, it's quite possible the government is undermining your autonomy because it is preventing you from taking a course of action you fully understand. But a second possibility still remains. Aristotle identified the notion of Akrasia ("weakness of will"). Augustine also looks at the problem of the will. The basic case of akrasia is that you know what you ought to do but somehow you don't do it. In the case of drug use that you know is harmful but you still do it, this could actually indicate a lack of autonomy vis-a-vis a weak will. This is the best most thinkers in the West prior to the era of Kant would be able to make sense of your action, because the classical idea of action is that you get a practical syllogism, e.g. 

Two thoughts, first not every fallacy has a name. Second, it's more important to show the reasoning is bad than to connect it with a specific name. The fallacy names are just shorthand for this. I can see why you would go with "red herring" which is (roughly speaking) shorthand for "meaningless point or contribution." I think it is closest to a "notable effort" fallacy -- i.e. a confusion between trying and succeeding in terms of cutting one's carbon foot print. But other than formal fallacies (e.g., affirming the consequent), calling "fallacy" just changes it from an evaluation of that argument to an argument over whether the fallacy rightly applies.