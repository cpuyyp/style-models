To answer question 2 first, the <IfModule> wrapper is there so that your config will still work (albeit without the bits that set headers) on an Apache instance that doesn't include mod_headers. Without the wrapper, an Apache instance without mod_headers would fail on startup. For question 3, web servers set both Expires and Cache-Control headers because the history of caching headers is long and muddled, and covering both of them is your best bet for getting as many end users as possible to respect your cache lifetimes. 99% of the time, either one will be enough (in which case you might as well use max-age, and push the CPU workload of determining what is 7200 minutes from now off to the user's browser rather than your server). For question 1, if your .htm and .php pages are really dynamic (contents depend on who the user is or what they're doing), then you shouldn't be allowing them to be cached at all. .xml files are often generated by your code, and if so then they should probably be included in the dynamic rather than static content. And it's only OK to give your "static" files a such a long lifetime if you've taken steps to ensure that they really are static, and you can never change the contents of a file while keeping the same filename. In particular, if you change your JavaScript or CSS files, then users will see unexpected results depending on what they've got cached and what they don't. 

Then have a look at what the subversion client does in that log. To make sure it really bypasses the hosts file, compare to the result of a manual: 

To make sure the problem is really a problem of resolution, you can enable the DNS client log (the DNS client is a service on Windows). To do so, go to: 

I'm in a similar configuration. Don't try the VPN over vboxnet0, what you need is to declare one of the 4 interfaces over eth0 in bridge mode. It works well with Cisco VPN, running over a XP interface, when the bridge is on eth0. However when the bridge is over wlan0 : NO WAY. I think you will find bug reports about this. 

Same thing one d stands for debug (terse), 2 for more debug, etc... When public keys have been exchanged, this often points to file/folder permission issues. 

So I think either something got wrong with the Tomcat Installation (this jar lives in the lib folder (assuming Tomcat version 6+)). Do you have CATALINA_HOME environment variable defined (I have to check this is needed for Windows actually) ? Update: You don't need the CATALINA_HOME system variable for window. When you installed Tomcat, I understand you also checked the service (and possibly) option. One thing I'm thinking also is that you might have a previous (say tomcat 6) installation and have now installed a newer (say tomcat 7) and may be thought the service was going to be the same. Actually no, they don't have the same registry key in \HKLM\System\services, the new one is called Tomcat 7. So may be you are trying to start a new installation with an older tomcat setup. It's better to uninstall everything (if you did not add webapps or config) and reinstall (tick both 'native' and 'system' options (these are the APR, for better perfs and the new service setup respectively). 

The best tool is the scientific method. Form a hypothesis about the cause of the problem. Write it down. Formulate an experiment that will test the hypothesis. Write it down. Conduct the experiment. Write the result down. If the experiment confirms the hypothesis, then you're done. If it fails to confirm the hypothesis then you need a new hypothesis. If it's inconclusive then you need a new experiment. 

The public key doesn't matter. There's no need to keep it secure, it should be widely distributed, and if you lose it you can always recreate it from the private key. It's only the private key that you should be worrying about. And yes, for that key it's a reasonable plan to put it on two or three USB sticks and keep them in separate places. 

Amazon now make available a complete list of their IP address blocks in JSON format here: $URL$ You can use that to create rules to block all of those addresses. How you do that will depend on exactly how your website is set up, but it would be a lot easier if you had your own server or virtual server that you could administer yourself. 

In addition to the answers already given, especially Tim's suggestion about the root account specific settings, let me add a few lines about the basics of a general way to quickly diagnose ssh connection problems. On the client add the verbose options 

It just needs a jar called Bootstrap.jar. Then this Bootstrap looks for an architecture dependent binary library called APR (for Apache RunTime) through this APR lifecycle listener class that is not found. 

One v means verbose, 2 v means more verbose etc... If this is not enough, on the server, if you're the only user (or at 3 o'clock in the morning ;-) stop sshd daemon and run it with full debug flags. 

I believe there are a number of software to do this. Google up for the 'network shaping software` keywords. here is one, random pick (Might not be for 64bits though). This is useful when on a domestic LAN, you want to make sure some long running traffic (P2P, streaming...) do not interfere with response time of other interactive activities (surfing...). 

Start capturing traffic on box 2. Observed that box 2 was seeing and replying to pings from the Barracuda Load Balancer. Logged into box 1 and pinged box 2. Observed that box 2 saw but DID NOT reply to pings from box 1. Observed that box 2 saw but DID NOT reply to pings from the LB for a period of 100 seconds after the first ping from box 1. 

Two boxes with identical loads serving the same sites tend to slow down and stop responding to ping. The slow (or intermittent) ping causes our load balancer to think the servers are offline and disable them. There is a third server with identical content that does not have the issue, so I'm fairly confident it's not the sites. OS is Windows Server 2008. Configuration is a little special: since we're using the Barracuda Networks load balancer in Direct Server Return mode, we've had to configure a number of loopback adapters which "fake" the IP as described here. The physical adapter has forwarding set to enabled as required by 2008 to get the loopback adapters functioning. Symptoms: