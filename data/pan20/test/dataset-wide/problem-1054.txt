We are planning to do an e-commerce shopping site with PHP-MYSQL combination. I read in almost every link related to Normalization & Denormalization : One thing I understood is Normalization is must for good performance , am i right ? We have to do Denormalization only when we face problems of Performance [ the very low page speed ] , otherwise Denormalization is not required. Is for 100% it will hurt - Normalization? can we do anything to prevent [not to hurt.] can we take some steps for performance boost other than Denormalizing & Refactoring complete database again. Can we do Denormalization without doing Normalization before ? 

You didn’t use compression on secondary and applied compression when you took the backup on primary server. As you already mentioned you were using Dell Lite Speed, which has different algorithm and compression level which also make a difference in your backup file size. 

The size of the database is always exactly the same on both primary and secondary replicas. The difference you are noticing on the backup file size could be because one of the two reasons 

You will have at some down time in you application or web (whatever accessing the database). You need to change the connection string. AOA group connection string uses the listener or AoAgroup. When you switch back, you need to use regular connection string FQDN of your server or IP of your address. You might also need to remove the server from the cluster. When you failover databases under your secondary server remain under no recovery state. Databases in your primary server will be online but sometimes (especially if you have really big database) if there is some transaction log left and during the failover, your database will hang up under suspect mode. 

I have many tables of the same length (number of rows) that were previously ordered by some columns as they were being written on disk. My is of the form: 

What I get from a transaction like the one above using the previous bash command are three outputs: , and bash variable. I'll post some extract of them to make it clear what's their content. plog.log 

PART2 - UPDATING In order to update you must specify values, so you have to know them a priori. This works perfectly, but probably there are other naive solutions: 

It subtracts 12 months from and checks if the resulting date is greater or equal to . This query works too: 

That is normal. It is just indicates you that you are on the secondary server and the role is taking care of by the primary node (the one without the question mark). If it was a 3 node or more cluster you might see the question mark on all node expect the primary. When it failover you will see the reciprocal of this on the other server. 

Yes it is possible to do so. However, there are some possible issues you have to consider or expect. 

We had a SQL Server 2008R2 Enterprise edition for our database to support a front-end application. We never had any timeout issues before. Recently the company decided to upgrade the database in to SQL Server 2014 Enterprise edition with 2 node always on cluster setup. The new server has better CPU, Memory than the old server. After the upgrade I made all the necessary modifications, Checking Database consistency, run DBCC UPDATEUSAGE, update Statistics, index rebuilding, recompiling the stored procedures and so on. The database switching and migration all went well. However, our users start complaining about timeout issues. I have been reviewing different articles,blog posts and made some modification like changing the connection string and add MultiSubnetFailover = 'True', which seems helped a lot and minimize the frequency of timeout but still the issue is there. Does anyone know what can cause this issue and how to resolve it? I would highly appreciate your suggestions and recommendation to resolve this problem. 

credits : Vladimir Oselsky Normalization is never for a performance of reads it is for data integrity and performance of writes. You normalize to avoid redundant data and creating problems by having same data exists in different locations. If you want most amazing performance, you denormalize by throwing everything into a single table and create a lot of indexes. That is why for reporting (DW) it is a practice to denormalize to increase the performance of reads. Save yourself a lot of headache and do a lot of reading on how other people solve same problem. I strongly believe in 3NF, but going beyond that is absurd in my book, I have yet to see a valid business case for doing anything above that. Sooner or later you will find a need to denormalize for a specific process, usually it is done for reporting, data warehouse need. A good rule is OLTP = Normalize, OLAP = Denormalize. It is a nature of database design and request from the business. Whenever you are designing a system, you are designing for a specific purpose, and later someone else comes along and request information that you might not have been prepared to give, in that case, you are required to denormalize to provide a best performance. To increase the performance go for "Indexes, query tuning, hardware upgrades, server configuration and etc".... 

The performance issue could be because of different reasons. After you restore the database, make sure to check and if necessary to update the statistics, Index fragmentation level, and the query plan cache which usually has significant performance influence after a database restore. 

That is normal. When you setup a database mirroring the mirror database is on no recovery/restoring mode and copies and run transaction executed on primary server. Then when you remove the database mirroring you just stopped those transaction to be transferred and nothing is happened to bring it back to recovery mode. If you want your secondary (mirror) database to be active you have to execute. 

You can mess around with the various parameters available in . For example, you can export a gzipped file or a CSV with headers and custom separator: $URL$ . You can also issue a to export the entire original database and run to recreate it on the new database: $URL$ . This should work.. I've just dumped an output file of several tens of GB on OS X (linux-like) without any problem. Se also for more selective database dump options: $URL$ 

I hope to have fully understood your request. With this query you get a concatenation of tables (a UNION) with all records. 

As the error indicates you, your secondary database is not ready for log shipping or it is online. Before you start the actual log shipping process, you need to make secondary database ready for the log shipping. Either you can leave the secondary database under restoring mode and then let SQL Server take snapshot of your primary database, or you can take a full and transnational backup of primary database and restore it on your secondary DB using no recovery mode then continue your log shipping process. 

For your first question, yes you can use the same environment (Windows: 2012 R2 Standard and SQL 2014 Enterprise Edition) but the configuration should be changed. During failover clustering, primary and secondary servers shares the same resources or drives, this didn’t work for Always on configuration, and both primary and secondary replicas has to have their own drives. For your second question, it depends on your preference and available resources, if you think that it’s easy just to reset drives on both servers and change configuration you could do that. If you have sufficient resources, space in SAN and feels more confident to start a fresh install you might chose the second option. Concerning about the licensing. Assuming you are planning to use secondary node only for disaster recovery or short maintenance time, you need licensing only for a primary node. However, if you are planning to query from secondary node, you are also required a license for the secondary node too. 

It handles models that has the same rank, displaying more than 5 rows per device type just in case. In order to test it, create a table and fill it with data: 

I know this topic is pretty complex and involves a lot of different factors. Let's say I have several similar queries running at the same time. These queries involves only read operation and several ordering and windowing. If I'm not wrong, with I can get the memory used by some operations like . I need to know how a single query impacts in order to calibrate (and kind of predict) the amount of queries I can run at the same time. Is it possible to get the maximum amount (not the total amount) of memory used by a single query? Should I get it from the output (which gives me only some memory usage infos) or there's a better way? I'm using Postgres 9.5 and 9.6 on different Unix-like environments like Red Hat 6.7, Ubuntu 16.0.4 and macOS Sierra.