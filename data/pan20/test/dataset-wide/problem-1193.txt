I think the problem with your attempt is that you put quotes around the plugin name, along with the fact that you used a suffix to the library name. Step-by-step: Check that your MySQL install is capable: 

Can probably be done with some simple maths along with the source data, but my brain is a little slow this evening ;) 

You have to use Service Names to connect to Pluggable Databases in 12c. It's just one of those things that can trip you up, I guess! SQL Plus connecting OK probably threw you. 

This is very simple and there are many tutorials out there. Here is a sample trigger to demonstrate. 

I suspect you're using multiple sessions and the other session cannot "see" the work performed because it is currently uncommitted. The default Oracle transaction Isolation Level is Read Committed. This means that a session will not be able to see the work a given session has done until it has explicitly committed the transaction. The Oracle Server Concepts Guide explains this in detail. 

Obviously you'll need to add your own database and listener names & change the path to your . You can reload the listener config with: 

Note that tablespaces are simply the place the object is stored in, and have no bearing in DML queries. 

The grant worked just fine. You can't DESC a package or procedure, which is why you're getting an error. Documentation for UTL_FILE is here. It provides sample PL/SQL that shows you how to use the package. A short code snippet that sums up its functionality is here. 

... will only return odd numbers, due to the lower bit in any integer always being 1 when a number is odd. 

The simple answer is.... To enforce an in ANY resultset, not just your specific case, you have to use an clause. The Oracle documentation spells it out clearly: 

The only server role it is a member of is PUBLIC. How can I find out what exactly is preventing me from revoking these permissions so I can drop the user? Thanks. 

I noticed in the last month one of my SQL Server instances is getting a daily SQL Dump saved off to the Log directory. Unfortunately the SQL Dump is getting large and is consuming the majority of disk space. I don't know exactly where to start investigating why I'm getting SQL Dumps. If I run a DBCC CheckDB against my databases it comes back without any errors. Where do I start investigating why I'm getting SQL Dumps into the log directory? What can cause the SQL Dumps? Will reading the SQL Dump help with my investigation? 

It turns out this issue was due to a restore of a database from an incorrect media set. Since the databases were not exact copies, the package was performing differently on the second instance. After performing a backup with INIT and then restoring that database to the second instance, the package now performs the same on both instances. 

I know there are still some SQL Server 2000 installs that exist out there. With Microsoft no longer supporting these versions, how can I check to see what vulnerabilities remain unpatched? This website lists some of the vulnerabilities but I am unable to determine which have fixes/patches to address the vulnerabilities. $URL$ 

What do I need in order to get around this error and make a successful connection to SSAS? Is there a better/easier way to extract DMV data from SSAS? 

This ended up being a Kerberos problem. We were able to identify through some of the security logs and some network monitoring, that the request was coming in as anonymous. Once we applied the relevant SPNs for MSSQLSVC for the account that was being used to kick off the process, it worked. 

The first dpkg execution may ask for you to install dependencies. If you're installing on a 32-bit system, alter the URLs accordingly. Latest .debs are available on $URL$ - Select "Debian Linux". 

BE CAREFUL - emphasis above mine. Obviously you'll need to recreate the schema afterwards. To just drop all tables in the current schema, you can use this script: 

Your question isn't 100% clear, but if you just want to insert the larger of two dates you can use a statement (there are lots of other ways of doing this too!): 

That's the missing row. The view joins with on the signature column - there's no matching row in , which I suspect is causing the problem. 

Given your query, you have the following: Owner (Schema Name): Table Name: The user will not just be able to select from unless there is a Public Synonym pointing to it. So, to select from the table you have to fully qualify the name by prefixing the table with its schema: 

The correct tool to use for this is Oracle SQL Developer. You can download it here. A guide to setting up a connection to a cloud DB is here. 

It's easily tested. There are two possible scenarios. Scenario 1: Scenario 1 is creation of a PK using an existing index: 

You need to use the fully-qualified name of the table, as does not own the table. For example, if the table is owned by : 

... make sure you substitute your listener name for above. You can also use ADR parameters instead - see the documentation. 

The first query will give 2, the second query 1. Your problem will just be a more advanced version of this. Use with the columns of your own choice to workaround this. 

The GUI is probably trying to access an Oracle Data Dictionary View (in order to read the column names & data types) that it does not have permission to select from, hence the error message. Ask the Vendors Oracle DBA to trace the ODBC session so that you can track down the exact cause. 

We use a centralized backup location on a network share. Each instance uses the Ola Hallengren scripts to perform nightly backups. I have a team that requires folder permissions to the same location where backups are stored. While the team has permissions to the parent folder it seems they no longer have permissions to any of the sub-folders where the backups are stored. I have narrowed it down to the command which executes the procedure dbo.xp_create_subdir. However, I am unable to figure out why the permissions are overwritten everytime this command is run. How can I ensure the subfolder permissions are not being changed with the Ola Hallengren scrips? 

I need to remove records from this table that are older than 30 days. We only have 2 columns in this table. The first date after 'Printed_%' is what I will be using to determine if the record should be deleted. Notice some of the dates are in MM/DD/YYYY format while some appear in M/D/YYYY format in the string. How can extract the date so I can determine which rows are older than 30 days? 

How do I handle this situation. This blog post ($URL$ is the only thing I could find for reference and it isn't very clear on the solution. He states adding a second IP address. However, what exactly does this look like in DNS? Do I have one DNS hostname with two IP addresses? 

This error was resolved by adding a second IP to the listener. The IP address for both subnets cannot be an IP address already in use, i.e. the IP address of one of the nodes. A DNS entry is also not needed since the Listener creates the DNS entry as part of the process. 

We are currently testing a SQL Server 2012 AlwaysOn HA implementation where we have 2 out of the 3 nodes are synchronous. The third, asynchronous node, does not have a vote in the quorum. There is a scenario in which the first two nodes experience complete failure. When this happens, the third node is up and running but it has it's database in the AG marked as "Recovery Pending". How can I get this database out of this state and make it available? 

The default database character set/collation values are used for a table if the relevant clauses are not specified at table creation time. 

I don't know how to call an Oracle stored procedure from a DB2 stored procedure, but the syntax for calling an Oracle procedure over a database link is: 

connects directly to the database without using networking (TNS. This type of connection is called a bequeath connection. connects through the listener. 

Your compiled shared library is named , but you've told it to look for one called myprog in the create procedure call (the suffix is a Windows-ism). Rename it from to . 

Edit the generated pfile and remove the parameters, then recreate the spfile from the edited pfile. Bounce the database & all should be well. The database might need to be down when you recreate the spfile from the pfile. 

When you create a new user, you can optionally specify the default tablespace and default temporary tablespace for any objects created by that user. For example: 

Then grant it back to certain users, plus all other internal Oracle users. The 2nd option is to look at the source for the view, drop it, then recreate an altered version that supports your needs. Another option that would trick casual users would be to create a table called ALL_USERS in each schema. Unless the logged in person explicitly qualified ALL_USERS (ie: SYS.ALL_USERS) they would get the resultset from the table in their own schema. This trick could also be done with a synonym pointing to a view that does: 

Yes, WE8ISO8859P1 is a subset of AL32UTF8, though a small bit of conversion might be needed (which CSALTER will deal with & CSSCAN will inform you of when you do a preliminary scan). A must-read for Oracle 10.2 is here. Doing a full export/import will be more time-consuming than using csscan/csalter. Another good, albeit old, read is the Oracle Character Migration Best Practices white paper.