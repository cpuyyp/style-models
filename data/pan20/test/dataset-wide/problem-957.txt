The WMO OSCAR database is a list of all Earth observation satellites¹. The resulting table can be sorted by orbit type, status (inactive/operation/planned), agency, and other aspects. From their own description: 

No, the atmosphere is not becoming thicker. If anything at all, the atmosphere is getting thinner, but only on very long time scales. Planet Earth very slowly loses parts of it atmosphere due to atmospheric escape, either to space or to the solid Earth. Historical atmospheric pressure is hard to determine, but billions of years ago, it might have been much thicker than it is now, in particular with a lot more greenhouse gases. One clue is the faint young sun paradox; we know there was liquid water at a time the solar output was 20% less, which would require so much greenhouse effect that the total atmospheric pressure must have been much higher. But the jury is still out on that one. The atmosphere is not becoming significantly denser, either. The concentration of gases that we are adding to the atmosphere is typically measured in parts per million (ppm) or parts per billion (ppb). The effect of adding to this is small compared to the natural variability in atmospheric surface pressure / density due to weather and other effects. The atmosphere does not act like a lens. 

This has always bothered me during field mapping: A boudin with two stretching directions has the form of an M&M candy (or almond shape). What do I do to measure the two stretching directions if the surrounding rocks don't show any stretching lineations. Does anybody have experience with this? 

I have visited storage- and test facilities that are within salt and clay (Opalinuston) lithologies. What are other lithologies that are considered for the storage of nuclear waste and what are their advantages? 

The liquid outer core and the magnetic field it generates are essential to life. Without the magnetic field we would have no atmosphere. The temperatures would be roughly equal to the moon (Which goes from 123 C on the hemisphere that happens to face the sun and -153 C on the shadowed hemisphere). Source for moon temperatures: $URL$ 

(I had the opposite problem, needing skin temperature, and being tempted to use 2 metre temperature instead, until I realised where the data were). If you encounter a model that really only has the full temperature profile, then I would contact the authors to inquire. Maybe it is a model that really only does well in the free atmosphere, and is not suitable for the extraction of (near-) surface temperatures. The boundary layer can be a hard thing to model! 

In Scotland, the Caledonian Forest has been cut down by humans. According to an unsourced Wikipedia article the tree line in Scotland is at 500 metre (it does not indicate the tree line elevation difference between southeast and northwest Scotland, which should be considerable). That means considerable areas are naturally bare, and therefore arguably less unnatural than the areas where forests have been cleared. When I pass through Scotland, is there a way to tell whether the spot I stand on had a forest before that was cleared, or that it is a naturally bare area? 

I usually tend to think that the shorter a definition is the more it introduces ambiguity and errors. So I would just think about your audience and choose an appropriate length (You didn't mention the level you are teaching for). Similar to the definition of life you can offer to your audience characteristics, which some rocks will conform more or less. This is just a list I thought out: 

It is very likely that there will always be phosphorous for mining, because rising demand will increase prizes, and make more mining sites profitable (This is like the golden rule of mining and seen for example with oil sands suddenly being profitable). From a crystalline-rock perspective (this is just a partial answer) the phosphate minerals are a huge phosphorous sink. Prominent members of this group are Apatite, Monazite and Xenotime, which occur widely in granitic rocks. The problem with these minerals is that they can contain high percentages of radioactive elements and submicroscopic inclusions with even higher radioactivity. This has already contributed to the rise of radioactivity on fertilized fields and rivers that run from them ($URL$ This is relevant to your question because radioactivity and the isotopes that produce it, can be used as a tracer for phosphorous. 

What is a breadboard (retrieval) algorithm? Google Search yields precious few results, mostly from ESA. Another usage I found Albert, Preusker, and Fischer (2012), ENVISAT workshop: 

The 2012 edition includes a very large update on methane measurements, as detailed by Brown et al. (2013), who describe how the number of HITRAN methane lines has increased from 11,803 in the 1982 edition, via 251,440 in the 2004 edition, to 468,013 in the 2012 edition. However, neither Rothman et al. (2013) nor Brown et al. (2013) describe why the determination of methane spectroscopic parameters is so difficult. Why are methane spectroscopic parameters harder to determine (and therefore more poorly known) compared to other common Earth atmospheric trace gases? 

Under the assumption that we don't know anything about sampling, preparation and analysis we have to proceed with caution. Any of these steps can introduce effects that can produce stronger signals than the natural geochemistry of a rock sample. Just to give you an idea of the errors: 

This is probably an observational effect that is quite common in the Earth Sciences. In scientifically progressing societies there is a higher proportion of observations due to a number of effects: 

All you need to calculate the oil production is an estimate of the volume of host-rock that is currently under those conditions in sedimentary basins around the world. 

Clive D. Rodgers, Inverse methods for atmospheric sounding, Theory and Practice. ©2000 World Scientific Publishing Co., London, UK. 

Wikipedia tells me that, in electronics, a breadboard is a construction base for prototyping electronics. The details of the article do not appear relevant for the algorithm usage, but it makes me guess that the meaning of breadboard is related to prototyping. However, from context, it is clear that the job ad or the ENVISAT paper has nothing to do with electronics. What does breadboard mean in the context of Earth observation retrieval algorithm development (which are the only contexts I could find)? Is it simply a synonym for prototype, or does it have a different meaning? 

I can't provide numbers, but a hopefully reasonable outline for your own calculations: All that is required for oil to form is a source-rock brought to the right depths in a sedimentary basin and the oil migrating into a host-rock. If it is economically profitable (See Footnote) it goes into the global reserve calculation. (Petroleum Sedimentology Winfried Zimmerle, H. Zimmerle) 

It seems to me you should draft an analytical procedure first in which you include the compounds (or compound-groups) you want to identify (qualitative) and what detection limits you need. Then get a list of methods or instruments you have access to. Then see which methods / instruments fulfil your analytical requirements. You might need to make aliquots and use two or more methods to cover all the requirements. Complexity is usually the last thing to worry about, because you have to use what instruments you have, and often times the analytical requirements are only fulfilled by one instrument. The methods mentioned on the page you linked also guarantee that your measurements will be comparable to other peoples measurements. Look for advice in books and lecture notes about "analytical chemistry" and "instrumental analytics". Personally I think infrared spectroscopy is pretty simple, but I don't know what your detection limit requirements are ("trace level" is very vague), and depending on your samples there might be a lot of overlap from the different organics (It also depends on how well you have to distinguish them). 

Not a full answer as that is hard to give. But: This is a diagram by Kevin Trenberth picturing energy flows in the Earth climate system: 

Saturation vapour pressure of water. Source: Chemguide. See also the (not very good) Wikipedia article on Vapour pressure of water. 

You can use simple logarithms to calculate the answer. The number of half-lives that have elapsed can be calculated with $$ - \frac{\log{f}}{\log{2}} $$ where $f$ is the fraction that remains. So plugging in the numbers gives $$ - \frac{\log(0.75)}{\log(2)} = 0.415 = 41.5\% $$ 

A controlling factor is a factor that acts as a cause for others. A reactive factor is rather the consequence: that which reacts to the controlling factor. For example, the Sun is certainly a controlling factor. Nothing we do influences what happens on the Sun, but what happens on the Sun certainly influences us very strongly. Fortunately, its total power output is quite stable so as far as climate is concerned, we don't need to worry about it too much as far as the next couple of million years are concerned (although eventually, in hundreds of millions to billions of years, increasing power from the Sun will render the Earth uninhabitable). CO₂ is both a controlling and a reactive factor. We add CO₂ to the atmosphere, so the CO₂ concentration reacts to our emissions (reactive factor). But CO₂ levels are also a cause. If you were to make a simple climate model, you would put in the CO₂ concentration as a fixed value or perhaps an increasing value as a function of time: in such a model, it would be a boundary condition. If you instead made a model of a single factory or car and modelled how changes in the fuel cycle would affect CO₂ emissions, then those would instead be a reactive factor. It all depends on the context. For H₂O, however, it makes no sense to put in a fixed version as a boundary condition. Its concentration varies rapidly on short timescales: today may be dry and tomorrow a wet airmass may get in. Of course, physically, H₂O causes even more of the greenhouse effect than CO₂, but the increase of H₂O is not what is causing anthropogenic climate change; if anything, an increase in H₂O is one of the effects. So, think of it as a system: you add CO₂ (cause), many things happen, including an increase in H₂O in some places (effect). The cause is the controlling factor. The effect is the reactive factor, even though physically, both CO₂ and H₂O are strongly contributing greenhouse gases. 

Can't help with the details, but think about it like this. It is a density current (denser than air, that's why it flows downhill), but the density is less than that of water, so it will flow across it. Compare this to turbidity flows (also density currents), which are denser than water and will therefore flow downhill in the ocean. 

Starting from the bottom of your question I would not compare planets with plate tectonics with planets that don't have this process. During rifting of a tectonic plate a triple junction will be the most favourable way of faulting the crust. After that two arms of the rift are favoured and the third one becomes a failed rift (aulacogen). Because of this process linear features on a planet will be very emphasized. The current geometry of mid ocean ridges and subduction zones does fall into a strong north-south pattern (Exceptions are Antarctica and the Aleutian trench). This might also be due to the fact that the plates form a system that in all its complexity still strives for lower stress and effective heat transport. In this case a parallel system of mid-ocean-ridges and subduction zones might be more favourable than a totally random alignment of those features. The dynamics of the inner Earth are of course not independent of the plates and it is difficult to assign causality. Nonetheless you could again think of a complex system that seeks for efficiency (pragmatism if you will). With subduction plates being plate-shaped, circulation above and beneath them will probably be more stable in a cylindrical fashion. So the heat distribution on the upwelling side of the circulation should also create linear features. In any case we just happen to live in a time where the system went for a North-South oriented minimum. Continuing this thought process we can also find an explanation why features in this tectonic-north-south part of the world are oriented in this way. Many north-south striking islands have north-south striking back-arc-basins that separate them from their main land masses. And peninsulas are sometimes the arms of failed rifts or the tapering of back-arc-basins. Outside of this prevalent orientation we see features like Nowaja Semlja with very different orientations. But be cautious with this theory. Assigning each feature on Earth to a north-south and east-west orientation gives you a 50 % chance that a randomly aligned feature will confirm your theory. Even four directions still give you 25 % chance. So the more directions you consider the harder it is to prove the theory. I am not aware of anybody doing a global peninsula inventory, so it would be interesting to see this.