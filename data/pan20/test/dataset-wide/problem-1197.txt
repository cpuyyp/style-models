You did blunder by restarting SQL Server. You should have not done that.Unless SQL server will recover the database fully and comes to state where database finds itself in same consistent state as it was before the force shutdown it will show in recovery state. Your best bet is to wait and watch you cannot run any transaction on recovering database. Also since you manually killed SQL server process while it was rolling back a query its even more worse. Now when SQL server database will come online the whole rollback process will start from beginning not from point where you killed SQL server process/query. So it might take time and unless it fully rolls back the previous killed query it won't come online neither you can force it to. One advantage you can have is if you have Enterprise edition SQL Server will come online after redo phase of recovery. So that might be little relief to you. PS: Seriously avoid any such random suggesstion given on web. You should take this as a lesson to never kill SQL server process or restart SQL Server if certain query is taking time. You should wait and chec rollback status of query using below script 

This is just a bit of information. There is too much to derive from content of transaction log and it would be difficult to write down all here. But I can suggest you various blogs of Paul Randal where you can find him writing about how to take help of the output of fn_dblog to get various information. Time Pass with Transaction Log Another dive into Transaction Log Read various articles by Paul you would learn a lot about contents of transaction log Tracking page split using Transaction Log How to tell who changed Log file characteristics Using fn_dblog,fn_dump_dblog and restoring STOPBEFOREMARK using LSN 

Paul has explained in his article how much transaction log does full backup includes For more learning TechNet article about Backup internals Couple of myths around backup Depending on edition of SQL Server you are using you can use backup compression to further reduce backup size. 

As per the error message the SQL Server was the one which required huge amount of memory and was paged out to disk but that is not the only component. You need to find out why SQl Server required huge amount of memory. Knowing the limitation of express edition you should be aware to not run memory intensive queries. In the error message I can see which means application is also running on same machine in such case its quite possible windows would face low memory condition. What is total RAM present on the system ?. Since you have multiple appplications running make sure you have enough RAM on system 

Can you also upload complete output on some shared location and post the link here. This would help in understanding what component is taking memory Edit: As per dbcc memorystatus output i can see 2 NUMA nodes and memory utilized by each node is approx 

Before giving information about actual memory distribution it gives information about current status of system. SQL Server 64 bit has theoretically has VAS of around 8 TB this is basically virtual address space. All process which would run on SQL Server would see this much VAS so if system is pointing out available Virtual Memory as almost 8 TB I dont think there is anything to worry about it. This is system pointing to amount of VAS visible to any process running on 64 bit SQL Server instance. Please always use below query to see SQL Server memory utilization because task manager only shows process private bytes and if SQL Server service account has locked pages in memory privilege it would not show correct value. As a fact task manager would not show memory allocated through AWE API 

One cannot accurately say SQL Server has sufficient memory or not by just looking at BCHR, there are other counters to be taken into account 

VM committed is actually Virtual Memory committed by SQL Server and since this memory is committed it has . This again which makes me think SQL Server is using 65 G as set in max server memory This is what is max server memory. So memory is well distributed between both nodes can you also add output of below query jut to check. Please add screenshot 

You cannot upgrade from to . Its not supported and wont allow you please see Supported Version and edition upgarde You should not worry much about upgrading from 2008 Sp4 to 2014. The upgrade would not be a much of problem but how would application behave is something on which you should focus. You can download SQL Server 2014 evaluation edition , which is equivalent to enterprise edition for 180 days. Restore database from 2008 to 2014 and start testing. Don't use any enterprise features. When you are satisfied with application performance do an inplace upgrade to SQL Server 2014 standard Before doing in place upgrade make sure you run upgrade advisor and mitigate all issues(if any) pointed by UG advisor. 

This is happening because you have configured LAB03 listener to listen on port 1433 which is default port of default SQL Server instance, that is why when you connect using the listener it is connecting to SQL Server which is listening on port 1433. While Microsoft allows you to use default port 1433 for listener but this is not a correct thing to do specially when you have multiple instances and listeners. To get around this problem you have to change the port number of listener 

You must say commit instead of hardened.Like I said above hardening of Log records containing commit is done on principal first and at same time it is sent to mirror but transaction actually is considered committed only after principal receives information from mirror that Log records containing commit which it sent to mirror has been hardened. It also records the mirroring failover LSN and then after this it sends acknowledgement to principal. Principal waits for the completion of its own I/O and the I/O of the mirror before considering the transaction complete. When the principal receives its response from the mirror, the principal can then proceed to the next hardening. 

Microsoft does not supports migrating cluster from one domain to other. Their is support article describing this. This support article clearly mentiones that 

As per my findings using this formula even if target server memory is bit greater than total it is fine. And this is by virtue of how the value is calculated. If target server memory is greater that total server memory it does not always signify a memory pressure. You must come out of this belief(if you have one). Like you mentioned other counters have to be taken into picture. SQl Server changes its target and total server memory values many a times and this depends on load on system. Consider a scenario where you run index rebuild for all big tables there would be flurry of activity and PLE would certainly drop increasing target memory but this does not means it is a memory pressure. SQL Server memory just adjusted itslef to current load. In you should have RAM such that it can shold all databases in memory but this is many a times not possible. 

Go to add remove program and remove all components related to SQL Server 2008. Make sure you completely uninstall SQL server from add remove program. Right click on setup file and select Run As Adminsitrator to start installation again. Please read support article and include workaround mentioned in Resolution section 

This is the incorrect thing you are doing. Task manager is not a place to see SQL Server memory utilization we have dbcc memorystatus output and perfmon counters to see SQL Server 2005 memory utilization. If you note task manager show this memory is pageable but memory allocated via AWE API in 32 bit is Locked and non pageable and non shareable. So task manager is not showing you TOTAL memory utilized by SQL Server as it is not tracking memory allocated via AWE. So I guess you got the difference now. Please read AWE how it functions in 32 bit. Now from dbcc memorystatus dump you posted 

For SQL Server 2012 standard edition you do not have option to protect the backups. You would either have to reply on third party tools like one provided by RedGate or you can use WinZip or 7Z to Zip the backups with password. PS: SQL Server 2014 standard edition do have option to encrypt the backups 

No right from SQL Server 7.0 to SQL Server 2016 there is no feature to rebuild index automatically. The simple reason which comes to my mind is rebuild should be done only when index is fragmented. SQL Server internally does not keeps in any system table the fragmentation value so how it is going to decide what criteria to select when rebuilding index, like rebuild when fragmentation is >30, ignore small indexes etc. If you are talking about scheduling you have SQL Server agent which can schedule the script to run at particular time, you can also use windows scheduler to run batch script