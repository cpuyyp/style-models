Noting $\mathcal{F}^c$ the cosine transform and $\mathcal{F}^s$ the sine transform defined on real functions by: $$\mathcal{F}^c [f (x)]=\int_0^{\infty} f(t) \cos(xt) dt $$ $$\mathcal{F}^s [f (x)]=\int_0^{\infty} f(t) \sin(xt) dt $$ What can we say about following integral ? $$\int_0^{\infty} \mathcal{F}^c [f (x)] \mathcal{F}^s [g (x)] dx$$ (with for example $f$ and $g$ continuous functions in $L^2$) Can we express this integral as a simple integral with original functions ? (like in Parseval's equation) 

It is not possible to interchange integral and sum, but it seems possible to estimate the sum and define condition to have the integral null: As by Poisson summation formula we have $\sum_{n=1}^{\infty} f(nx) \sim O(x^a)$ near zero we can split the integral in to: $$\int_0^{\infty}\sum_{n=1}^{\infty} f(nx) dx= \int_0^{\epsilon}\sum_{n=1}^{\infty} f(nx) dx + \int_{\epsilon}^{\infty}\sum_{n=1}^{\infty} f(nx) dx$$ We can chose $\epsilon$ small to have first integral as small as we want, on the second one we can interchange sum and integral and if we note $F(x)$ the primitive of $f(x)$ such that $F(0)=0$ we have (as $\lim_{x \to 0} F(x)=0$ due to the condition imposedon $f(x)$: $\int_0^{\infty} f(x) dx=0$): $$\int_{\epsilon}^{\infty}\sum_{n=1}^{\infty} f(nx) dx = -\sum_{n=1}^{\infty} \frac{1}{n} F(n \epsilon)$$ Now we can apply the Poisson summation formula (assuming $\lim_{x \to 0}\frac{F(x)}{x}=0$) to obtain (we note $\mathcal{F}$ the Fourier tansform): $$ \sum_{n=1}^{\infty} \frac{1}{n \epsilon} F(n \epsilon) = \frac{1}{\epsilon} \sum_{n=1}^{\infty} \mathcal{F}(\frac{F(|x|)}{|x|})(\frac{n}{\epsilon})+\frac{1}{2 \epsilon} \mathcal{F}(\frac{F(|x|)}{|x|})(0)$$ And we see that, as the terms $\mathcal{F}(\frac{F(|x|)}{|x|})(\frac{n}{\epsilon})$ can be as small as we want for $\epsilon$ small, only one term remains and taking the limit with $\epsilon \to 0$: $$\int_{0}^{\infty}\sum_{n=1}^{\infty} f(nx) dx = -\frac{1}{2} \mathcal{F}(\frac{F(|x|)}{|x|})(0) $$ So finally it seems the initial integral is zero only if: $$\int_{0}^{\infty} \frac{F(x)}{x} dx=0$$ Comments are welcome, any reference for a similar treatment of a sum using Poisson summation formula ? 

Can we find on $\mathbb{R}^+$ a real positive function $f(x)$ (in $C^{\infty}$) such that: $$\int_0^{\infty} f(x) e^{\lambda \int_1^{x} f(t)^2 dt} dx=0$$ where $\lambda$ is a complex number (with $0<\Re(\lambda)< \frac{1}{2}$) and where we impose following conditions on $f(x)$ near zero and infinity: $$f(x)\sim x^{-\frac{1}{2}} \; \; \; ( x\to 0) $$ $$f(x)\sim x^{-\frac{1}{2} +a} \; \; \; ( x\to \infty) $$ (with $a>0$) Any idea on the way to handle such a problem ? 

Consider $f(x)$, a rapidly decreasing function, such that $\int_0^{\infty} f(x)=0$ and for $x$ near zero: $f(x)=O(x^a)$ (wit $a>0$). Then I calculated the integral of the following sum (which appears in the Summation Poisson Formula) and I found (noting $F(x)=\int_0^{x} f(t) dt$): $$\int_0^{\infty}\sum_{n=1}^{\infty} f(nx) dx= -\frac{1}{2}\int_0^{\infty} \frac{1}{x}F(x) dx = -\frac{1}{2}\int_0^{\infty} \ln(x) f(x) dx$$ (See my previous post to see that the integral on the left is well defined and how above result is obtained using the Poisson summation formula: Interchange of sum and integral (on a "Poisson summation") ) Is there any known reference in literature with similar result (using Poisson Summation formula or not) ? 

The Fubini's theorem states that if we have $ \int_0^{\infty} \int_0^{\infty} |f(t,x)| dt dx$ well defined (i.e. function is absolutely integrable) then we can interchange order of integration: $$ \int_0^{\infty} \int_0^{\infty} f(t,x) dt dx = \int_0^{\infty} \int_0^{\infty} f(t,x) dx dt$$ but there are other cases for which we can change the order of integration without having this condition fullfield. So my question is : what are the theorem covering these cases ? Any reference/book where we can find the different cases for which we can interchange the order of integration without the absolute convergence of double integral ? One simple example where we can interchange integrals without absolute convergence: Consider for example (with for example $f(t)$ of rapid decrease at inifinity and $\sim t^2$ near zero): $$ \int_0^{\infty} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dy dx $$ the integral is not absolutely convergent, but if we split the integral in two parts (on the $x$ variable), we have for the first one: $$ \int_0^{A} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dy dx = \int_0^{\infty} \int_0^{A} \frac{\sin(xy)}{x}f(y) dx dy $$ as $ \int_0^{\infty} \int_0^{A} | \frac{\sin(xy)}{x}f(y)| dx dy $ is well defined. For the second part an integration by parts gives: $$ \int_A^{\infty} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dy dx = [ \int_0^{\infty} \frac{-\cos(xy)}{xy}f(y) dy]_A^{\infty} - \int_A^{\infty} \int_0^{\infty} \frac{\cos(xy)}{x^2}f(y) dy dx $$ On the other hand we have also by integration by part: $$ \int_0^{\infty} \int_A^{\infty} \frac{\sin(xy)}{x}f(y) dx dy = \int_0^{\infty} [ \frac{-\cos(xy)}{xy}f(y) ]_A^{\infty} dy - \int_0^{\infty} \int_A^{\infty} \frac{\cos(xy)}{x^2}f(y) dx dy $$ And as the double integral on the right is absolutely convergent we have: $$\int_0^{\infty} \int_A^{\infty} \frac{\cos(xy)}{x^2}f(y) dx dy = \int_A^{\infty} \int_0^{\infty} \frac{\cos(xy)}{x^2}f(y) dy dx $$ Meaning that $$ \int_0^{\infty} \int_A^{\infty} \frac{\sin(xy)}{x}f(y) dx dy= \int_A^{\infty} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dy dx$$ so finally putting these results together we conclude: $$ \int_0^{\infty} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dy dx =\int_0^{\infty} \int_0^{\infty} \frac{\sin(xy)}{x}f(y) dx dy $$ 

For $\frac{1}{4}<a<1$ consider the following function: $$f(x)=\frac{|x|^{\frac{1}{2}}}{(x^2+1)^{a+ib}}$$ If $1>a>\frac{1}{2}$ then $f(x) \in L^2$ and the Fourier inversion theorem can be applied ($\mathcal{F^{-1}}$ is the inverse Fourier transform): $$\mathcal{F^{-1}} \circ \mathcal{F} (f)=f$$ But if $\frac{1}{4}<a<\frac{1}{2}$ ? The function is no longer in $L^2$ (and of course not in $L^1$). I did not find a clear reference in literature to justify that the same equality holds for this type of functions. Any reference for such a case ? I am also looking for a justification of Fourier inversion theorem for: $$g(x)= \frac{1}{\sqrt{|x|}} K_{a+ib} (\frac{1}{|x|})$$ for $0<a<\frac{1}{2}$, where $K_{a+ib} $ is the K-Bessel function. Asymptotic at infinity of $g(x)$ is: $$g(x)= k_1 x^{-\frac{1}{2}+a+ib} + k_1 x^{-\frac{1}{2}-a-ib} +o(\frac{1}{x})$$ So this function is not in $L^1$ or $L^2$. 

It is conjecture that under certain conditions a L-function satisfies RH. Among these conditions there is the necessity for the L-function to have an Euler product. (Some L-functions with a functional equation but without Euler product are known to have non trivial zeros with real part between 1/2 and 1). So the Euler product seems to be an essential ingredient to RH but what are the main properties involved by an Euler product for a L-function ? (For exemple specific bound known linked to Euler product ? or new relation for the L-function?) To my knowledge the results are very poor. Note: The equality between L-Function and Euler product holds out of the critical strip but the Euler products directly constraints the non critical zeros to be on the critical line... so I wonder what could be the firts steps of a bridge linking Euler product and RH. 

Defining $f(x)$ as a Cosine transform on $\mathbb{R}^+$: $$f(x)=\int_0^{\infty} S(t) e^{-i \lambda \int_1^{t} S(u)^2 \frac{du}{u^2} } \cos(2 \pi xt) dt $$ Can we find a real function $S(t)$ on $\mathbb{R}^+$ with $S(t)\sim_0 1$ and $S(t)\sim_{\infty} \sqrt{t}$ such that the following derivative is always negative ? $$\big(x^{1 - i\lambda- \overline{i\lambda }} f(x) \overline{f(x)} \big)' \le 0$$ $\lambda$ is a fixed complex with $\Re(i\lambda + \overline{i\lambda })<0$ An obviously equivalent way to formulate is : Can we fix $G(x)$, a real decreasing function, so that we can we solve the following functional equation (and find $S(t)$) such that: $$G(x)=x^{1 - i\lambda- \overline{i\lambda }} f(x) \overline{f(x)}$$ May be providing some condition on $G(x)$ we can always find $S(t)$ satisfying the equality above ?