It's a work around, but you could generate the CREATE PROCEDURE scripts for the database (right click database -> tasks -> generate scripts), find and replace CREATE PROCEDURE with ALTER PROCEDURE and then parse. I hope you get a better answer here - I'm interested too! :) 

I have set up a predefined replication alert (as outlined here) in SQL Server 2008 and the alert for Replication Warning: Transactional replication latency does not appear to work. This is triggered by error 14161. I found a number of posts around the web that indicated this was a bug, but the posts were so old, I'm not sure that it is still the case. Is this still a broken feature? If so, can anyone suggest a work-around? EDIT/ADDITIONAL INFO: I see there are a number of scripts that have been highlighted in similar questions. To refine my question, I'd like to confirm this is a bug and I am looking for a work around that is rather out-of-the-box... that is, just another way to write the SQL Server Agent alert to get it to work... 

Our SQL Sever 2008 application database is replicated from Server A to Server B (push replication). We use the copy, let's call it database_b, on Server B to create reports and run other queries so that our reports do not interfere with the application. Currently we leverage inefficient views to combine data across multiple tables in database_b so that report writing is simplified for our report writers (who have basic SQL skills). 99.9% of the database activity is INSERTS, so we are exploring a way to replace the inefficient views with tables we can optimize. Here is a simplified example: There is an table and a (lookup) table. Every time a new appointment is scheduled, a row is added to the table. Every time this INSERT happens, I want to take that and insert it and its corresponding location name (join on from both tables) into a reporting table. I have accomplished this with a trigger on the appointment table in database_b on Server B. My question is - are there any particular considerations given that database_b is a replicated copy? Do I need to worry about a failing trigger mucking up the entire (push) replication process? Anything else I am missing? Unfortunately it's difficult to test this in our development environment, so I don't have the opportunity for a lot of trial and error. 

I have a table with two partitions and I would like to create two tables, one from each partition. Is there a quick way to do this (a la partition exchanges) instead of a create table as select (CTAS) statement? For what it's worth, this need arose because I want to exchange these two partitions into another table; from what I've read, in order to do a partition exchange the data needs to be in a non-partitioned table. 

This is an ugly solution that may introduce other issues. It is offered as a means to eliminate the lock you are experiencing. Auto_increment is preferable to managing numbers in this manner. The number could be managed in its own table incremented as needed. This table could be locked at no detriment to the main table. When write locked, other sessions are prevented from using the table, the locking session can then increment the number (and store it in a variable - something meaningful like @next_position) then releasing the lock immediately after the update. The number is then used in your main query - no join, simply "LQ.initialPosition = @next_position". You may still have contention on the position number table - but these locks shouldn't be held too long - only during the incrementation to ensure only one process increments the number at a time. The locking scheme could be eliminated, but this would require knowing the current number first which would then be tested in the update's where clause to eliminate race conditions with other sessions. A loop will be necessary to try again if the update doesn't work (another session made the update first). This complicates the use of the table but reduces the potential for trouble. 

In order to benefit from this in an indexed manner, I would need to know the subnet mask (the number of bits to shift). Otherwise, I'll either be systematically comparing bit shifts (i.e., blindly shift for each possible netmask (from 0 to 24 bits)). I have other sources to optimize, but optimizing the IP2Locationâ„¢ LITE IP-ASN Database found at $URL$ would be a proof of concept. The table... 

It seems the most important thing is matching time out with the time in. The query below shows one way this can be accomplished. The approach below attributes time worked to when the individual "clocked" in... there is no attempt to attribute the time to the day in which it occurred (there are other questions on this site that address that need). 

The following is an untested attempt at distilling the problem into its basic components then unions the results together. The last query (with the correlated subquery) can be turned into a join if the introduction of orders does not cause a Cartesian product. I can not test with what is provided to see if this is a valid assumption. 

"show create view" will provide you the DDL to recreate the view exactly as it is (complete with select statement). 

We are having some discussions about partitioning some application tables in SQL Server 2008 based on their quickly growing size. One is an event table that is typically used for INSERTS (80% of the queries) or SELECTS that look for the primary key of the table (20% of the queries). The other table is a "mapping" table that is all SELECTS looking up the primary key. Would partitions along the primary key be helpful here? I've done a lot of reading and all the classic examples of partitioning seem to be data warehouse tables that are partitioned on dates. It also seems that partitioning can sometimes cause more harm than good. What do you think about these tables? 

I am trying to do something that is very simple and am stumped why it is not working. I have a column ( from ) that is a varchar formatted like yyyymmdd. I want to convert that to a datetime. I use the rather straight-forward command but I keep getting the error Arithmetic overflow error converting expression to data type datetime. The three distinct values in this column are 20120802, 20120803, and 20120806. Using that same function above, I was able to successfully convert all three strings. I feel like I must be missing something obvious...? 

If I create a data driven subscription in SSRS and use the query to return some value for the username and password, how "safe" is this password? Let me explain. I am looking to set up a data source on the SSRS Web Portal that uses Credentials stored securely in the report server and Use as Windows credentials when connecting to the data source. This data source, in turn, would be used in the data driven subscription. The user setting up the data driven subscription would not have access to the data source's credential password. I would then like to permit the user to pull a username and password using this shared data source and then use in their subscription as the user/pass to save the file to a shared file area... without the user knowing what the user/pass is. Make sense? If so, is this a risky thing to do, security-wise? (Ultimately I am thinking about using this as a way to consolidate the password for shared file area subscriptions into one place.) Thanks! 

The sum of the days the subscription is set to run is the number in this column. Thus subscriptions that run Monday through Friday have a value in this column of . The end result I want is a view that derives T/F flags for each day based on this number so that I have a column for each day. The method I am currently exploring to get me there is converting this integer to base-2 so then I can convert that to a varchar and parse out the days. In this example, the result would be 111110. The final twist - I do not have the ability to create functions or stored procedures in this database, so my strong preference is to solve this within a statement... (If push comes to shove, I will move the raw data and use a function in a separate database - and have found a number of those online.) 

Try rewriting the query in different ways to see how the execution plan and times change. Changing the order in which tables are accessed, using set operators, indexing, etc... can make a huge difference. The two approaches suggested below are using the MINUS set operator and using NOT EXISTS instead of NOT IN. In both cases, the queries are driven by the SHU_STUD_TERM_SUM_DIV table. This will reduce the number of rows joined to NAME_MASTER. The MINUS set operator works by filtering the results of the first query with he results of the second. This allows the MySQL tables to be joined directly. The NOT EXISTS will behave like the NOT IN (each row will query the MySQL tables) but does have the potential of comparing a smaller set of values (only those that directly match NM.ID_NUM). Using MINUS: 

What is the fastest way to determine if an IP is contained within a CIDR block? At the moment, whenever I store a CIDR address I also create two columns for starting and ending ip addresses. The starting and ending ip addresses are indexed. If I want to see which network contains an address then I look which seems less than desirable. It occurs to me I can store the right shifted number and could match similarly shifted IP address (660510 in the case of @cidr)... 

I highly recommend partitioning your table now. I'd create a new table partitioned by year that looks just like your current table then insert into it. Going forward, you can more easily prune your table. Here are several links to a good partitioning discussions... $URL$ $URL$ I'm not a SQL Server guy - I saw an MS SQL Server 2016 documentation suggests there are some differences in 2014 features - but I can't find 2014 documentation. Here is a link to MS SQL Server 2008... $URL$ Good luck! 

You might have memory that MySQL is not able to address because of a memory leak. Running the following command as Root will free unused pagecache, dentries and inodes. 

You can either recreate your table or use "optimize table" command to rebuild your table. Highly recommend making a backup just in case. $URL$ $URL$ 

This behavior could be achieved programmatically... Create a table of databases and the status you would like them to be.. then your application can test the status of the database prior to use.. the application proceeds if the status is available and returns a message if unavailable. You could also do this with applications in general too (same thing as described above but with application instead)... You can then control applications use of the instance. 

(I fear what I wish to accomplish shall not be easy, but a lot of my googling around about it yielded rather dated results, so here it goes...) I have a Postgres 8.4.x database with over 100 tables. I need to recreate these tables in SQL Server 2008. I'm not concerned about the data, just the structure. Are there any slick tools, shortcuts or suggestions to accomplish this? Heck, I'll even take the find-and-replace values to run on Postgres CREATE TABLE scripts! Thanks! 

We have application database (APP_DB) that creates a "live copy" of itself via transactional replication (push) to a database (COPY_DB) on a separate server. This COPY_DB is used for reporting and troubleshooting. There is now a need for a small subset of the tables (4 tables out of 150) to be placed ("live") in a second database (NEW_DB). What would be the implications of setting up COPY_DB as a publisher of these four tables to subscriber NEW_DB? Good idea? Horrible idea? It seems like a silly idea to me, but I find myself in a situation where I have more control over the server where COPY_DB and NEW_DB live and could more easily implement such a solution rather than setting up a second publication on APP_DB. 

Is there a way to write a check constraint such that values in a column are limited to table names currently in the schema? It appears subqueries are not allowed (ORA-02251), but logically I am looking to do: 

Set up a new dataset to pull back the language value (let's say language_dataset into column language_value). Create a parameter, let's say called language. Set it to internal and set its default value -> Get values from a query and use the dataset and value you just set up. In the Report properties, Language -> expression and set the expression to . 

I have an SSRS report that can I access from the Web Portal but once I try to access it directly through the URL, I get the following error: . I looked at the logs on the Report Server and the error there says . But, of course, it is in the database - I can access the report from the Web Portal. Any ideas? UPDATE The same link now works, two days later. 

I have a fairly simple question that is proving hard to search for. I need to create a table that will be partitioned and into which (lots of) data will be loaded. Is it more efficient to create the table with the partitions or add the partitions after I have INSERTed the data? ADDITION: To make sure I understand the complete picture, if I was to truncate this table to then load (lots of) data again, should I drop the partitions and then add after the load? ADDTION #2: If I can INSERT the data in the order of the partitions, I assume that would be faster than not?