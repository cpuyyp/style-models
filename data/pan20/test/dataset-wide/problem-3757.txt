It is well known, that the characterizing property of Clothoids is, that their curvature is proportional to length; that is also the reason, why they are used as design elements e.g. in road design. 

when reading about the problem, I almost immediately had the idea to define a surface via the combination of two clothoids in a similar fashion as two circles are combined to define a torus: The first clothoid is defined via the $u$ parameter in the $xy$-plane as usual and will be traced out by a second clothoid that is defined via the $v$ parameter and, as the origin of the second clothoid moves along the first clothoid, $x(u)$ corresponds to $z(v)$ and, $y(u)$ corresponds to the orthogonal distance to the $xy$-plane's clothoid after a point's projection into the $xy$-plane. I apologize for this rather coarse description; hopefully the example helps despite. 

When trying to determine the optimal bridgeless spanning cactus graph of a weighted, symmetric graph, I got stuck. What I do not know how to capture, is 

Is there anything reliable known about who actually discovered the Chebyshev polynomials and what the motivation and circumstances were? The reason why I am interested in knowing, is that I needed a solution for a variant of those polynomials: instead of all extrema having the same magnitude, I wanted to have them attain predefined values in a fixed order (I have found a solution for that problem, but involves a system of polynomial equations) and I wonder, whether the definition of the Chebyshev polynomials has been "guessed" or developed for a specific problem. Edit: at the request of @Hans, here is formal definition of my problem: given a sequence $(y_1,\ ...\ y_{n-1}), (y_{i+2}-y_{i+1})(y_{i+1}-y_i)<0$ of values, determine a polynomial $p(x)$ of degree $n$ and, $\ n$-$1$ abszissas $\ \xi_1 <,\ ...,\ <\xi_{n-1}$, so that $\ p(\xi_i)=y_i, p'(\xi_i)=0$ It should be noted that the polynomials that I am looking for, have no special properties, except for the predefined values in the extrema. The leading coefficient can be set to $1$ and the constant term to $0$. $$\ $$ Construction of polynomials with predefined sequence of function-values for its local extrema: we can w.l.o.g. assume that the sought polynomial has leading coefficient $1$, a local extremum in the origin and, that all other local extrema are located at positive abszissas. Then polynomial is $$p(x) =\frac{1}{n}\int x\prod_{i=2}^{n-1}(x-\xi_i)$$ and $$p(\xi_i)=y_i$$ would a be system of polynomial equations for determining the $\xi_i$ and thus $p(x)$; the only problem being that, because of the symmetry, in the current formulation there is no control over the ordering of the $y(\xi_i)$. That can however easily be fixed by defining $$\xi_k=\sum_{i=2}^{k}a_i^2$$ and solving the system of polynomial equations $$p(\sum_{i=2}^{k}a_i^2)=y_k$$ 

I have the task of determining approximations of a 2D function $f: (x,y)\in \mathbb{R}^2\mapsto\mathbb{R}$ from integrals along lines, i.e. from its Radon transform $R(\phi,\tau)[f(x,y)]$ and, because of the greater flexibility, I want to solve it by interpreting it as a least squares problem, which I define as follows: 

After having calculated an "explicit" interpolating function $f:\mathbb{R}^m\rightarrow \mathbb{R}^n$, satisfying $y_i=f (x_i)$, you can calculate the local inverse via evaluation of the implicit taylor series or some other series expansion of implicit functions. If you are however satisfied with very pragmatic solution, you can chose a data point $(x_i,y_i)$ that minimizes $\|y-y_i\|$ and then via the method of steepest ascend or descent identify the "nearest" $x$, for which $f(x)=y$ w.r.t. the interpolating function $f$; that should also disambiguate the calculation. If $f$ is smooth, it can be assumed to be (piecewise) polynomial and thus the gradients that are used in the method of steepest ascend or descent can be easily calculated. 

Dr. Vogler's trick for removing radicals from equations, which essentially amounts to turning a linear equation into a system of equations for a specific set of monomials, each of which is considered a different variable. Of all the monomial-variables that have been determined, all that do not represent a radical of the original equation, are discarded. also related are these questions and answers: 

From a theoretical point of view, a formulation with fewer integer or bilinear variables would be better, whereas from a practical point of view, the tradeoff may be more interesting. The restrictive must be for integer or bilinear variables was used to emphasise that the computationally least "expensive" sufficient type of variables has to be assumed in counting the types; totally unimodular problems yield integer solutions without having to constrain any variables to be integral, the same is true for the primal-dual algorithm for matching problems, so for those problems the count for integer variables would have to be zero. I am hesitant to using the "algorithms" tag, because what I am looking for, is not related to executing a sequence of operations or decisions; "complexity" also doesn't quite seem fit, neither in the temporal nor in the spatial sense. 

Edit: as a clarification in response to Brendan McKay's comment I would ask for the complexity of fixing Sudokus generalized to boards of size $n^2\times n^2$, where each of $n^2$ symbols must appear exactly once in each row, in each column and in each of the $n\times n$-sized subsquares whose disjoint union covers the board's cells; this kind of generalization is depicted in the wikipedia article on generalized games 

let $\mathcal{ABP}$, the set of "asymmetric, balanced permutation matrices", be defined as the set of permutation matrices, that aren't equal their transpose but, for which the number $1$s below the principal diagonal equals the number of $1$s above that diagonal, i.e.: $P\in\mathcal{ABP}\implies$ $$p_{ij}\in\{0,1\}\\ \sum_{i=1}^{n}p_{ij}=\sum_{j=1}^{n}p_{ij}=1\\ \sum_{i<j}p_{ij}=\sum_{j<i}p_{ij}\\ P\ne P^T$$ 

Those graphs can be transformed to binary trees by letting the node that corresponds to the first question be the root and duplicating the node that corresponds to the next question; one for each possible answer to the previous question. These binary search trees are easier to handle, than your representation; if you are worried about duplicating the text of the question, you can also store a pointer to the text in the nodes. 

I just found the paper "In-Place Transposition of Rectangular Matrices" by Fred G. Gustavson and Tadeusz Swirszcz, which provides a solution for the problem. An online version of the paper can be found here: $URL$ 

are there any invariants of matrices, that are not affected by row- and/or column permutations? To me it seems that the sequence of singular values could be such an invariant; am I right, resp. are there other invariants? My guess for the sequence of singular values comes from the observation that a row permutation $P^T$ and a column permutation $Q$ only act on $U$ or $V$ when a matrix $M$ is expressed as its singular value decomposition $U^T\Sigma V$, because $P^T M Q = P^T U^T \Sigma V Q = (UP)^T\Sigma (VQ)$, so $\Sigma$ remains unpermuted when exchanging rows or columns. Motivation for the question is the fact that many combinatorial problems can be interpreted as matrix reordering problems and, having invariants might yield some insight. E.g. the TSP can be interpreted as the task to permute corresponding rows and columns of the cost matrix simultaneously in way that makes the sum of elements adjacent to the principal diagonal minimal (and of course plus the elements in the upper right and lower left corner); the attractive property of that approach being that one doesn't have to be concerned with topological constraints. 

According to $URL$ a special case of the binomial theorem (i.e. for the exponent 2), was already known to Euclid as early as the 4th century B.C. and, as binomial coefficients surface when switching between the product- and the sum-formulation of polynomials, it seems reasonable to claim that summation as a representation of functions is tied to investigations on polynomials. Other milestones were Newton's 1665 generalization of the binomial theorem to non-integral exponents and later James Gregory's and Brook Taylor's discovery, that certain functions can be converted into a series via a combination of interpreting the function as an infinite polynomial with repeated differentiationg and evaluation at 0. 

the answer is yes, simply because there are at least two different paths for $n\ge 2$. Assuming that at least two different paths exist for $n\ge 2$ one can interpret the 1st path as a $0$bit and the 2nd one as a $1$bit, which proves that we can assemble $2^m$ different paths from $m$ of those two "bits". While that construction answers the question as it has been posed, I strongly suspect that the PO had something different in mind. What seems more interesting is the question for the minimal height (i.e. vertical distance between $x_i$ and $y_i$) for paths that contain a given sequence of horizontal permutations of the colors of vertical segments; here the key observation seems to be that the height difference between permutations, that are adjacent in the sequence, equals the maximal "left-shift" of a color between those permutations.