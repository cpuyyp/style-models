Especially when setting up a completely new server from the scratch, puppet tends to start dependant services as soon as all their dependencies are satisfied. This sometimes leads to situation that services are started unnecessarily too early while the setup of other packages (not maybe dependant of a service) is still running. Is there any one-liner definition or recipe that would automatically make all services to start/refresh in the end of the whole catalogue run? I tried to figure out if run stages could be utilized but that would, in my understanding, require that all service definitions are explicitly defined to "last" stage. 

I have a linux router between my private network and an unknown network. The unknown network can be another private network, I do not have control over that at all. Most of the devices in my internal network connect the outside world over an HTTP Proxy residing in the Router, so there is no need for NAT between the private network and the unknown network. However, I have one device (Device 3) that should be able to connect to a set of public IP address directly. Because the unknown network can be also a private network, NATting might not be an option (due double NAT). Device 3 needs to connect a set of known public IP addresses and ports that cannot be changed. Device 3 can be isolated to another network logically (with DHCP configuration from the Router) but not physically. Apparently Device 3 cannot utilize the HTTP Proxy (CONNECT) provided by the Router. Can I somehow configure my router to allow Device 3 to connect any public IP, and if yes, how? 

Yes, it's a straight file-level copy of the template database, so whatever was in there will be in the new database. 

When the crash is related to a storage failure, even momentarily, the kernel sometimes chooses to remount the file system read-only to prevent further damage. You can undo that using 

You can't use pg_upgrade to upgrade from 32-bit to 64-bit, or in general from any OS/CPU/platform to any other OS/CPU/platform. The data files are platform dependent, and pg_upgrade works by just copying (or linking) over the data files unchanged. So this is never going to work. Your options at this point are dump/restore, or using a logical replication system to move your data (Slony, Londiste, Bucardo). 

Also check the option on the man page about this behavior. A reboot is of course also an option to clean this up. 

The error message refers to a Unix-domain socket, so you need to tweak your invocation to not exclude them. So try it without the option : 

I would guess that the server is actually listening on the socket rather than the that your client is attempting to connect to. This is a typical problem when using hand-compiled or third-party PostgreSQL packages on Debian or Ubuntu, because the source default for the Unix-domain socket directory is but the Debian packaging changes it to . Possible workarounds: 

Is there any other way to ensure that I'll get an exact (~5 seconds window) dump from a certain, defined time this way? 

My FastCGI (PHP-FPM) application may encounter a situation where it needs some time to heal itself up. I'd like to tell to nginx that it should wait a few seconds and then resend the request to the FastCGI backend. I have already experimented a hacky setup where nginx is configured with (see docs) with an upstream with same fastcgi configuration twice: 

The PHP application will reply with when it needs some time and space, making nginx to "move forward" to the next upstream that is apparently the same server. Unfortunately nginx does second call in milliseconds. I'd like to delay nginx second call by a few seconds to make sure that PHP backend is fully up and running after the erroneous situation. So, how to add proper delay before the second try? Behind the scenes, I need to recycle the whole PHP-FPM process due how MongoDB driver handles replica set failover. That's why I can't handle the case fully at PHP level but need to release the PHP process for a short period. 

I have a common puppet recipe for a set of our servers. One of the puppet-managed files is that contains the original , and entries. The problem of the common file here is that all cronjobs are run at the exactly same time in all of our servers. For example, daily backups consumed all our backup server resources as all servers are feeding it at same time. What is the preferred way to randomize the exact minute of the daily/weekly/monthly runs between servers, while still keeping the puppet recipe common between all servers? I have been thinking a few different options: 

You can use a and daisy chain the to require the config change(s). If the Exec fails (exit status != 0) the subsequent tasks that require it should fail as well. I do something similar to execute ssh-keygen then set special permissions on .ssh when creating new users. Example: 

As an updated answer, on Ubuntu 16.04.1 I was able to do the following to resize a volume from 1024GB to 1.4TB: 

"Getting the right part number" generally would involve talking to somebody at Dell, or a reseller. You can also troll through the technical information that Dell provides on their website, but honestly when faced with similar snipe hunts in the past, I would have had better luck trolling eBay for keywords; in this case "Dell R710 Backplane". A cursory glance tells me "W814D" is the part#. But I am not endorsing that, YMMV, please do your own research. All of that being said: Generally Dell doesn't ship machines like that. If it has 6 bays open on the front, it will have a 6-bay SAS backplane installed. Depending on how things were originally ordered, they might not have cabled the second upstream port on the backplane; but I would find that suspicious too. I would make sure all the SFF cables are in place, and what they are being cabled to (could one be going to a PERC and another to an onboard port or something equally weird/dumb?) 

We have bought some reserved EC2 instances in different availability zones in eu-west-1 region. When launching a new instance, via API or AWS control panel, we do usually set "No preference" as the availability zone. In case of we have an "unused" reserved instance in an availability zone, does AWS still prefer that very zone even "No preference" is selected when launching the instance? Or, should we explicitly define the availability zone to match the inactive instance reservation? I tried to look for the answer from the AWS documentation, but without luck yet: 

Update 1: Some background to my question. Puppet, during the initial setup of a node, works rather intensively and thus reserves resources of a fairly small virtual machine (in my case, Vagrant on dev machine). When the setup phase came to a point that some of the services, in my case the background workers, were ready, Puppet starts them and the workers start to receive jobs from a queue. This workload slows down the still-going-on Puppet node setup process as well as the Puppet slows down the workers, until the whole setup is done and the box is in a stable state. This is why I started to think that it would be good to let Puppet to work the initial setup to its end before all services on the node are started and why I was wondering whether there is any simple way to do this with Puppet. 

I think this is best answered by trying it out in your particular application. It's not much per individual savepoints, but when you are talking 100k+, the effects will accumulate and other factors can come into play as well. 

Autovacuum is on by default. Reindexing and clustering aren't really baseline maintenance tasks. You can do them when needed to improve performance or (reindex) to fix index corruption, but they are not something you would blindly do regularly. Log rotation is taken care of automatically by the Debian packaging framework. So as a baseline, you don't need to do any of these things yourself. What you should actually be doing is setting up backups (for a start, run daily from a cron job), and monitoring (something like Nagios and Munin, perhaps, for a start). And then based on such monitoring you will regularly tune server settings and try to improve query performance. 

No, this is not possible. Generally, the cache algorithms are smart enough to keep the most used tables and indexes cached. 

As you have figured out, the Debian packaging of PostgreSQL requires to be located in that place, because it starts there to figure out where everything else is located, including the data directory and the other configuration files. Make sure your points to the right places for those. Next time, use , and it will figure all of this out for you automatically. 

Well this is a loaded one...Breaking it down Number of Members You're not going to get that, most likely, given the way the VC is depicted over SNMP. There is no current "member count" value in the OID tree. your best bet would be to walk and count the Serial numbers returned (or use the memberID, or MACs, or whatever). It looks like you're using Icinga, so you're probably going to want to use a script to grab that OID and count the results, since Icinga won't do that for you. I do similar things for dozens of other situations in Nagios. (I beat out a quick script based on some of those situations; use it, or use it as an example to do what you want: $URL$ Status of Members I see of no (easy) way to get present/not present statuses. That one you might just have to punt on, or monitor the VCP interfaces themselves one by one. Role Changes This would be a good one to use traps for; but if you're set on using polling and you are statically setting priorities so that you know what your master/backup will be most of the time, then you can look at the values under ; node .0 will be member 0, node .1 will be member 1, and so on. A value of 1 is Master, 2 is Backup, and 3 is Linecard (that's available in the MIB itself). The problem is that if you leave all that up to the dynamics of a default virtual chassis set up, without setting mastership priorities static member IDs (based on serial numbers), etc, those values could change. 

The instructions you are looking at are for from-source installations. When using APT, just run and everything will be taken care of for you. Note that this will restart the PostgreSQL server, so don't do it when you can't have downtime. 

Each one of the well-known logical replication systems for PostgreSQL is suitable for this: Bucardo, Londiste, Slony. They are not necessarily only redundancy solutions. (Arguably, they are pretty bad redundancy solutions.) Pick the one you like best. Perhaps Londiste is easiest to get started with, but YMMV. (I'm not familiar with SymmetricDS.) 

The package description is "PostgreSQL libraries and clients". So the idea is apparently that you use this if you don't want to install the full server, whose package name is . 

and then look for the processes. Since listening on is the default for PostgreSQL, chances are your package decided to use a nonstandard port. 

I suggest rsync. It's the standard tool for this sort of thing, and I gather it works on Windows as well. 

The tutorial only works when you install PostgreSQL from source. On your Ubuntu installation, access control was already set up, so not everything can log in (hence "authentication failed"). To follow the tutorial, try logging into the user () and then follow the steps in the tutorial.