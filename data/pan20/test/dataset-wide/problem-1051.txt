Normalise the table so there is 1 question per row. Then you are also not limited to a number of questions per survey. 

There is no information on the definition of your table (what foreign key?) but based on your SQL you should use a to enter it: 

To me it does. This way you do not have to change the table nor your applications every year. If you would use the same 'layout' as your Excel sheet then the years would become repeating groups which does not comply to the first Normal Form ($URL$ If you need to store specific information on your indicators the You could create a table for the indicators with that information. In that case you can replace the column with the of the indicator. 

If they have access to the tables directly with insert, update and/or delete rights then they can corrupt your data. If you prevent this by limiting the access-rights or by an MS-Access application then they can/should not be able to corrupt your data. About business rules. According to Wikipedia: A business rule is a rule that defines or constrains some aspect of business and always resolves to either true or false.. These rules can be defined in the database as but are more often checked by an application. For example a company can give a discount to a customer only in special cases. Or a client can only be deleted if it has no outstanding payments. If the business rule is checked by an application then giving somebody access directly to the tables with update and/or delete rights can corrupt your data. 

Select the user information from and look at the . If the status is then the user was deliberately locked. If it is then it is locked because of multiple wrong passwords. If you have set the then the user will be unlocked after this time is reached. 

In the second one only the field names are needed. No use to give them an alias. Or write 5 SQLs in the form: 

The goal of a role is that you grant all grants that you need to it. After that you only need to grant this role to a user (or other role). If you remove the role then all grants to that role are 'revoked' so you need to do nothing else. The information on the roles can be found in : 

The second option should be the fastest. It was made for this. Also it should have no bugs since it is used a lot and already for a long time. If you go for this then you do not even need to use a composite primary key. In my opinion the only reason to use the first option is if you need a numbering starting from 1 per client. 

One of the of goals of a relational database is to eliminate double storage of data. If you can find the right for the through the then you can leave out the reference in one of the tables (they are always the same as you mentioned in a comment). Keeping it in both tables makes your application more complicated. 

You do not use the in your query. This must be a/the reason why the index is not used. Also, the optimizer decides. It is not because you create an index that it will be used. All depends on the statistics for the table. How many rows? How many different unique values? What is the expected percentage of returned rows? 

Check on the theory behind the definition of the objects that you got. There lies the answer to your second question and even your first question could be answered by that. There is no difference between the keys for left and right tables. If you think about the order? Depends on how you use them. Which is the 'direction' in which you want to access them? That is the first one of the composite key. 

Solution 3 is the best solution provided that you move the from the table into the table. The reason why it is better is that when you need to add a variable to one device you can do this without changing your and tables in solution 2. If you want to query the data in the solution 2 way then you can create views that look like the and tables in solution 2. 

Read the article Configuring PostgreSQL to Accept Connections From Computers on Your Network where it is explained with screen shots. 

Normally RMAN takes care of this. It will only make a backup of the archivelog files of which it does not have a backup. The restore just reads the archivelogs that it needs from tape. 

You should be able to resolve this by copying over since the first one has a higher version number. Make a copy of in case it does not work 

Oracle 'takes care' of the conversion between different NLS settings. As long as both NLS settings can store the same characters the there should be no problem. It is the same as the difference between the database and a client. If for example the database of the customer is in UTF-8 and you create a database in ISO8859-P1 then you will loose (some) characters with accents and from non-western alphabets. The other way around gives no problem. 

It shows you how many sessions are there at this very moment. If you need it for statistical/historical reasons then you need to create a procedure, using this SQL, that runs every x-time and store the result in a table. You can also install the Oracle Diagnostics Pack. This has the Active Session History feature that logs every second and 'dumps' the active sessions and relevant information about each of them. This is however an extra payable option. 

This will make it easier to enter or remove a from a / combination. All 3 fields should make up the primary key to prevent a double entry. If you need the in an array then you can always create a view for that purpose. 

If you migrate from RDBMS to NoSQL then you will also have problems. They are not interchangeable for all types of usage. When you start a project then just before you start the creation of your data objects you must choose the one that suits best to your needs. Changing later will nearly always cause problems as soon as you use more then the 'standard' options. When you choose to use a third-party extension then there is always the risk that: 

We also have a lot of MVs that are refreshed with data coming over a database link. Do you do an atomic refresh? If you do then switch it off. An atomic refresh does a while the other option does a . The last option is faster but (nothing for free :-)) when the refresh fails you end up with no data in your MV. 

They are different. In the first option you get 2 times into your query. Once as and once as . Both have a different content and you must put them somehow back together. To me this is more an OR instead of an AND. In the second option you get only the rows that meet both criteria. Suppose you have with the following content: 

On the machine where you installed your database you should have SQL*Plus installed. For your question. Create a database link from to and use your Read Data user. Now you can query the data. 

Is quite simple. Make sure that oracle can write on a folder on the NAS and run the following RMAN job: 

The is not correct. You must create 2 of them. One the table for the field and one on the table for the field. 

You want information based information that is in the field. Not even the whole field but just on and . Unless you have an index on that information the database will always need to read every row of the table to see if the row fits the criteria. Adding an index on as a whole will not help too. The can be bypassed with (if it exists) but the needs a specific index. 

Replace the with the schema for which you want to create the primary keys. You only need to write the output to a file and check and execute it. 

You can have only one Flash Recovery Area defined by the . If you do not want to use one directory then you can go for where you can create and use a disk group that can span multiple disks/partitions. You can also go for if you use Linux. This is simular to . Create a physical group that contains multiple partitions. On that physical group you create a logical volume and mount it to a directory. 

Based on the replies you gave to my comments you must figure out how to resolve the duplicate keys issue. Also I do not think that master-slave replication is appropriate in this case. I would, after making sure that there are no duplicate keys, use to transfer your data into AmazonRDS one by one. Perform checks after every database that you do. If you have time and space then first do a test. During this test the 5 machines can remain active. For master-slave you should check the Replication page of PostgreSQL. The problem remains the duplicate keys as mentioned there as: 

In my opinion you should use the only if you do not need the result of a function that forces the usage of . For example if you have a table with and and you only want to know which s are present and you are not interested in how many (most of the times a sub-select). If is there to 'fix' a problem then you are likely to get a bad performance in return.