WaveSurfer lets you display spectrograms in color, and it's free. Once you record or import a sound, right-click (or the equivalent) on the waveform pane. Select Create Pane > Spectrogram. The spectrogram will appear in black and white as a default. Right-click (or the equivalent) on the spectrogram and select Properties. Here you can play with all different parameters, including the spectrogram color. Below are two versions of the same spectrogram produced in WaveSurfer--one in black and white and the other in color: 

You need to switch the "focus" of the commands to the editor. The way it's written now, it's trying to apply the "Select" command to the object in the object window. Try: 

The above issues apply to all segments in the vicinity of nasals, but since schwa is by definition unstressed in English and therefore short in duration and not very loud (relative to all the segments around it) it is even more susceptible to variation and "non-committal" articulation. From a perceptual perspective it is reasonable to suppose that this is because listeners don't rely as much on the information they are given in unstressed syllables to parse speech. 

Borrowing: The Japanese word gaijin is borrowed by the English-speaking community in Japan Blending: The combination of two words "fly" and "gaijin" (both are in-use words) to form flyjin (similar to how the words "wiki" and "encyclopedia" are combined to form "wikipedia"). 

It is said that the adoption of Sumerian cuneiform by Akkadian and other languages in the Middle East imposed constraints on those languages (due to the limited number of sounds represented in Sumerian). Is this true? In what way does the adoption of cuneiform constrained those languages? How is this possible, while in logographic system like the cuneiform, a symbol corresponds to a word as opposed to a sound? 

Using these tests, there are only those two ways to mark the passive: synthetic (some kind of marking on the verb which is different from the active, like Latin) and periphrastic or analytical (using some form of auxiliary and the participal form of the verb, like English). The linked pages also listed several ways that languages which do not have passive can have constructions which manifest some (but not all) of the five properties, for example 

Perhaps precisely because nasalization is not contrastive in English, there is a lot of variation when it comes to the degree to which (and consistency with which) pre-(and post-)nasal vowels are nasalized in that language. If I take a rendition of 'restriction' in which the schwa is nasalized and splice in a non-nasalized schwa instead, native listeners will still hear it as 'restriction'; in fact, most listeners won't even notice a difference if all other acoustic properties of the schwa are appropriate. Traditionally, phonologists characterized nasalization as a phonological (and therefore categorical) phenomenon, but phonetically the facts are more "messy". Articulatorily speaking, nasalization is not an all-or-nothing, binary thing (in any language). If one tracks nasal flow during speech, it becomes clear that it takes time for the velum to lower and raise, and especially in continuous speech it is common for it to be only partially lowered during the realization of segments abutting nasals. Abby Cohn showed this in her dissertation and later papers. 

Darja (a group of Arabic dialects used in the Maghreb) uses second person pronoun, but with a twist, 

The vast majority of alphabetic writing systems are part of the Phoenician lineage (e.g. Latin, Cyrillic and friends) or Brahmic (Devanagari and friends). Is there an active alphabetic system outside these two families. I found it surprising if there are only two families, while other types of writing system seem to have a lot more families. Is there any explanation to this? 

To make @jogloran 's answer more generic, one of the "easiest" way to generate an English (declarative) sentence where the verb is not the second constituent is to have an adverb in front of the sentence, e.g. Yesterday I read this book or Suddenly, a bird appears 

The (Modern Standard) Arabic "qaf" is an voiceless uvular stop [q]. It is pronounced like a plain [k], except that to make the [q], the back of the tongue touches the uvula, instead of the soft palate (to make [k]). The Georgian sound is an uvular ejective [q']. It's also pronounced as a voiceless uvular stop, like the Arabic qaf, except that it is an ejective consonant, meaning the air is created by pumping the glottis upward. [q], like most of our "normal" sounds, is an pulmonic one, meaning the air is created by solely pushing air with the lungs and the diaphragm. 

UPDATE: I've realized, after looking at the above examples, that syllable structure might play a role. The reason is that I have a very strong intuition that the raising is obligatory in monosyllabic words that end in a voiceless coda. Give me a nonce word with one syllable and a voiceless coda, and the vowel can never be realized as the non-raised /aÉª/. Further, if you look at the apparent exceptions in the "no raising" group above, such as Pythagoras and bifocals, what they appear to have in common is that the syllable following the diphthong-containing syllable always appears to be stressed (either primarily or secondarily). In words like python and bicycle (and of course writer) I have the intuition that the following syllable is unstressed and therefore the voiceless consonant is ambisyllabic (i.e. behaving both as a coda and an onset). This doesn't explain the exceptions that go in the other direction (i.e. raising occurring before voiced consonants), but at least it allows us to formulate the raising rule (or constraint) in a way that makes it exceptionless! This would also explain why I would raise the diphthong in polysyllabic nonce printed words like griter but not in those like gritatious. 

According to this WALS page "Passive Constructions", there are five necessary properties of a passive construction. 

it contrasts with another constuction, the active; the subject of the active corresponds to a non-obligatory oblique phrase of the passive or is not overtly expressed; the subject of the passive, if there is one, corresponds to the direct object of the active; the construction is pragmatically restricted relative to the active; the construction displays some special morphological marking of the verb. 

I'm not familiar with Japanese words that you are describing, but it seems to me that there are two separate process here: 

source: wikipedia Homograph homophone venn diagram.png I believe your first example is called heterograph and the second case is a heteronym. 

In computer science (especially computational complexity theory), problems can be classified to some complexity theory. For example, we say the travelling salesman problem belongs to NP-complete. Parsing of a human-language text (e.g. English text) is also a computational problem. Can it be analyzed and classified to some complexity class? If yes, which class does it belong to and why? 

This happens a lot in neutralizations and mergers. In languages with word-final devoicing, for example, maybe /d/ is realized as [t] word-finally but as [d] elsewhere. But /t/ would also be realized as [t] word-finally. If one encounters a [t] at the end of a word, one cannot be sure without additional information whether it is a realization of /t/ or /d/. In your example, [w] is probably an allophone of some phoneme that can sometimes be realized as [w] and sometimes [l] (in some sense the "naming" of phonemes is arbitrary, but I'd probably call it /l/ since that seems to be the clear "elsewhere" realization) and [w] is probably also an allophone of a different phoneme (one that I would call /w/). Now, it is true that allophones of the same phoneme must be in complementary distribution, but the two [w]s and the [l] in your table are not actually all realizations of the same phoneme. So, here is a revised assessment of their distribution, taking their underlying forms into account: 

When we read the news related to dying languages, normally this is painted as bad news and it's really important to preserve the language, see Language at risk of dying out (Guardian) or Digital tools 'to save languages' (BBC), for example. Is this view shared by most linguists, or is it mainly the view of news reporter or anthropologist? If we think about it, maybe human communication would be better off if we have fewer languages. The diversity of languages cause communication difficulty, and in some cases can even cause conflicts, war, etc. So what are the scientific reason for preserving dying languages, if any? 

How does a linguist determine whether a pattern is grammatical in a language? Is there some kind of standard test? This is assuming that there is little documentation of the language and no authority. For example, without documentation, corpus, or authority, how can one determine whether S + [be] + V+ing is valid in English? Just make an example to a speaker and ask if he thinks it's grammatical? But there are dialects and individual dialects (idiolects), how can the linguist be sure that the grammaticallity is not just the test subject's dialect? How can the linguist know that the example sentence he gives can be generalized and is not an exceptional case (for example, some verbs cannot have S + be + Ving such as words of emotion). 

Meanwhile, exemplarists cite experimentally confirmed frequency effects and "neighborhood density" (i.e. degree of proximity to similar sounds) effects on production as evidence for exemplars and claim that purely abstractionist approaches cannot explain such effects. Recently, some researchers have supported a middle-ground approach in which insights from both camps are integrated into a model that allows for both the storage of phonetic detail and the manipulation and categorization of abstract units in the internal grammar. 

But in other contexts it might cliticize to a neighboring word, like a noun that follows it (as @jogloran mentions in a comment under the original question): 

Yes! What you are describing is often referred to as the calling contour or the vocative chant, and it is very common, especially among European languages. Bob Ladd talks about it in his book, Intonational Phonology (first edition 1996, second edition 2008). The tune is characterized by a sequence of one or more syllables on a relatively high level pitch followed by one or more syllables on a somewhat lower medium level pitch. Ladd notes that the interval between the two notes is often, but not necessarily, three semitones, i.e. a minor third (p.117 in the first edition, p.136 in the second edition). Some other languages that have been noted to make use of this tune are (not an exhaustive list): English (North America and UK), French, and Hungarian. French is a language that is analyzed as having final stress; nevertheless, the tune goes down at the end, not up. Stress does play a role in some languages in determining when the note changes. In German and English, the higher pitch starts on the stressed syllable of the name (examples adapted from Ladd 2008):