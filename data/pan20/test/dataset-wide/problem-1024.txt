The best is to use a special field like you do for the Person data. As soon as you need a value that is not defined by yourself as PK then you should think twice on using it as a PK. About your ZIP code. Not all countries have a single ZIP code for a single city. As long as you only need cities in your country then this is not a problem. 

Test it is the answer. Minor upgrades should not give problems but if you do not test your application you will not be sure. 

The function creates a date with a time. If I remember well this is 12:00. If the date in your table has a different time then this is also taken into account. When you want to test dates then you better put the function around your date like: 

This is not really database administration. The way you do it cannot be done in most programming languages too. Calculate the discount as 95% of the drink price: 

Create the new empty table as table1. Make the ID an 'auto-increment'. Insert a union of table1 and table2 with all fields except the ID and insert these in the new table. 

Instead of WW you can also use IW. The last one gives the ISO Week. Here the beginning or the end of the year might end up in the week of the previous/next year. Look for it in Wikipedia ($URL$ for more information on this. 

You can only to a database that is defined in your tnsnames.ora or OID. If I understand well then FIHOST is a server. To see if that is up you must use a common . 

Oracle 'clears' the deadlock by killing the session that caused the deadlock. This is fully automatic. You only get message in the logfile and the user gets an error message. 

Check the file. The parameter is defined there. On windows I found it in the data directory so I guess it will be the same for Mac OSX. 

The attributes should be split in 2 tables because the configuration details are not depending on the user but on the configuration of an external system. If a user can have only 1 configuration then you must use an 1-1 relation. If a user can have multiple configurations then you must use the 1-M relation. This is the theory. If you want (in case of a 1-1 relation) put all in 1 table than this is also 'allowed'. Remember well that if one day the relation becomes 1-M that you are in problems. This is also why it is preferred to split the information into 2 tables. 

First of all you cannot create a datafile by . Always create the datafile with the command. You misplaced the datafile so you should follow the procedure that is described on $URL$ I hope that you have a good backup to get back the right version of the datafile that you removed. 

The is the name of the user that runs the application. The is the name of the user defined in the database. Suppose that is logged on his desktop as and runs an application to modify the data. When he is asked to connect he enters the credentials of . In the audit you will find as and as . This explains while you find as since this is the user that is used to run Oracle itself. 

Give the right to create tables in the database and connect yourself as to the database. Then all the tables that you create there are owned by . PostgreSQL has a different approach on this then Oracle. The schema and owner are 2 different 'things'. 

The most 'flexible' way is to store the periods in a separate table together with a type field (Working days, Private off days, etc.). This makes it easier to generate overviews of days present/away because there is no need to check the 32 bits for zero's for each type of day. Also no problem with the different length of the months. There is an other type of days? Just allow it to be entered in the database. No need to change the table. If you need to transfer it into a 32 bit field the I am sure that C++ is capable in doing so. 

In your view you do not fetch all the key fields from both tables. Oracle needs that to be able to do the update. In your case you do an insert so I suppose that you do not provide the primary keys for both tables. Since you did not gave the structure of both tables I cannot be more specific. 

I would go for the second approach. Like you said it can be cached. When a database is much used it will process a hundreds of SQL per second. Do not think that these SQLs will badly influence the overall performance of your database. The only 'problem' you can get is that you update too many rows and keep to many locks. Do a commit every, let's say, 1000 updates to keep the risk of blocking locks small. 

Normalization is not the holy grail. Normalize as much as possible. In a data warehouse you can group some data to get better performance. Also a data warehouse is about querying data. Less on users maintaining the data. Go for a design that will give the information in an easy and quick way. Normalize if you can but in my opinion this is not the first goal. 

All files that were backed up to tape and are older than 1 day are removed from the directory and freeing up the . When I do a restore the tape storage delivers to me the archivelogs that RMAN needs. 

If (like you said in your remark) has 2 phone numbers then it is a 1:n relation. In that case you need to store the phone in a separate table. You end up with: Person 

I do not know exactly what you mean by 'updated many times' but I presume that you mean that the same can be present in multiple entries. In this case I would split it but put the in the entity. This way you are sure that all is the same everywhere it is used in . The rule is that you put all fields that are identified by a single primary key in a separate entity. This way you minimize the number of updates when one of the fields that 'belong' to this primary key changes. If 1 entry has only 1 entry and 1 entry has only 1 entry then the separation is not necessary. The only advantages are: 

Why do you do an update on ? Anyway you must add a where clause with the primary key of the row to the update. You are now updating all rows in . Also the insert is inserting for every row already in . Why don't you rewrite the insert into something: 

I assume that you run this on the server that hosts the database and that you have set the to the one of the database that you want to access. You must run the application. This generates a file that holds the password. Check the documentation for the exact syntax. It depends a bit on the OS on which you host the database. 

When you are not connected then the SQL will fail and the other SQL statements will not get executed. 

Postgres is a database system that can very well store your aircraft data. If you already use it for your geo-spcial data and you want to query this with the aircraft data than it is easiest and fastest to store them in the same database. This will also make your life easier since you do not need to know 2 database systems and you need no (difficult) configuration of a link between 2 database systems. 

Check the documentation for more information or type . There is a parameter (TABLE_EXISTS_ACTION) that defines if you want to overwrite existing objects or if you want to append. 

You can start by measuring the size that this table has and the number of rows. If you do this every hour/day/week then you get an idea on the growth of this table. 

Add the fields that you need to the first 2 tables. The third () will hold the primary key of and for every combination that you need. You are now as flexible as you want. No double coding of a or and when a new arrives you just add it to the table and you can join them to all s that you want. No need to change anything. 

Replace the with the field names (with alias if you need to change the name) you need. You can put in the other 5 tables as : 

is able to create the tablespaces. You can even change the location of the datafiles if needed. Check the documentation for more information since there are many parameters with this tool (REMAP_DATAFILES and REUSE_DATAFILES for example). 

If I understand well then you read the information from the database and display it. The user has the possibility to change it. The fastest way is to compare the information that you read with the information that you get from the user. If there is a difference then you update the information in the database. 

If all columns except the ID must be unique and the ID does not need to be preserved the way to go could be: 

Just keep one table. Then replace the other table with a view on the table. Now you should be able to insert/update/delete a row in either the view or the table. Normally this should work. If the insert/update/delete in the view cause a problem then you can always create triggers on the view that replace insert, delete, and update (). Check the oracle documentation for more information about the triggers 

The script expects just 1 row. Not the 26 you get. You must use a cursor and loop through the rows that you get: 

I would go for a 2 step solution. I use simple SQL. You can use the right names and fields. First I would update the existing rows: 

Should work when the directory structure is the same. Check you directory to see if you have other SID related files. If your database does not need recovery then no archivelogs are needed. Do not forget to change at least the DBID if you need to integrate the database in the RMAN backup process. If you use RMAN for backups then you can also clone your database to another server. This way you can place the files in a different location and the DBID (and DBNAME) will be changed during the cloning.