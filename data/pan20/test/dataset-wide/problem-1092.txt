Slightly unimportant but it's piqued my curiousity. I've just logged into an Oracle 10g database for the first time using the Oracle SQL Developer Tools. I used a generic user login which isn't my name (nottstest2), from a machine that is called something that isn't my name (courgette). My name is nowhere in the database and isn't associated with the login. Yet, the server logs show a connection from "Jon Hopkins". How does it know who I am? Is it being pulled from my Windows login in some way (though I'm not using single sign in)? 

We're analysing a deadlock situation on a SQL Server 2005 database and have set the trace flags 1204 and 1222. In the resulting logs we're seeing the following line repeatedly: "Log Viewer could not read information for this log entry. Cause: Data is Null. This method or property cannot be called on Null values." Can anyone tell me what's likely to be causing this? There's nothing particularly wrong with the queries that I can see (they're generated by Hibernate so are a bit messy and full of aliases but are fundamentally sound). Is it something I need to worry about or something that can be ignored? 

The idea is that the script can be run multiple times without modification so the person running it doesn't have to know what's in place and what's not. My issue is that in SQL Developer if the sequence doesn't exist, the script errors on running claiming that the sequence doesn't exist. Create the sequence and the error goes away but that rather defeats the point. What's the best way around this? 

But then I get an error on he slave about some missing WALs. I found alot of tutorials with using WAL archive, but I don't have a WAL archive. Can anyone give me the correct steps? 

This process seems to work, but I've got the feeling something is wrong, because it's been a few hours now and there are still and processes on the slave. The slave should be up after a few seconds because it already consists of all needed data... I don't archive my WALs. Do I have to use before copying the files to the slave? I tried this: 

I'm setting up a pair of PostgreSQL servers. Because cash is short I can only afford one high class server and some crapy backup box. If the expensive high end box should catch fire, operations can live with the slower backup system for a while. I was wondering how much performance does the backup server need? It receives WAL and only has to apply it (I prosume that is the way syncrhonized commits work?). Is WAL always easy to apply, or would for example a delete with many checks on foreign key constraints, also have to do these constraint checks on the slow backup box? Is the PostgreSQL WAL logical or image based? I'm not looking for absolute numbers, more a kind of answer like: "Applying WAL over TCP in sync commit mode on the hot backup will be cheap in any szenario, except for blahblah". 

I'm looking at educating a team on writing better SQL Server queries and was wondering what people's best hints were for improving performance. For instance I once had a DBA who insisted that count(*) would perform worse than count(1) (I have no idea whether she was right or whether it's still valid against the latest query optimisers). What simple things should I be telling the team to try and always use or avoid? I'm ideally looking for things which (a) might make a reasonable difference and (b) are straight forward, 1 - 2 lines to state. 

SQL Server developer working on Oracle so apologies in advance if I'm fundamentally coming at this incorrectly from an Oracle perspective. I've got a script I've written which: 

So, I've been writing a script which creates a sequence (if it doesn't exist) then copies some data including a value from that sequence before deleting the original source data. As the sequence can't be guaranteed to exist when the script runs, the insert seems (I really don't know Oracle) to have to go in an EXECUTE IMMEDIATE statement. While this works (abbreviated section of code below), it feels like a horrible cludge. Is this bad practice in Oracle? If so then how should it be done? 

and then it worked, which deals with my issue. It is notable that I have the same security setup against my own login and that still doesn't work. Odd... but that isn't really a problem for me now - I don't know why it that doesn't work though. Note that I'm aware that giving the login db_owner is a bit of a sledgehammer approach, but now that it works I'm able to make the security a bit more fine-grained. Thanks! 

I moved dba_indexDefrag_sp and its associated objects into a 'HouseKeeper' database, rather than putting them in the Master database. (I note Michelle Ufford recommends this, saying: 'Itâ€™s up to you where you create it. You could technically create it in the MASTER database, but I recommend creating a utility database for your DBA administrative tasks.') I created a new 'SQLJobRunner' Windows login, then added it to SQL Server, setting it as db_owner on the dbs I'm defragmenting. I also applied to same to the HouseKeeper db, to give the login full access to that database. I changed the defrag SQL Agent job to run using the 'SQLJobRunner' login. 

If I run this from SQL Management Studio, on the server, the procedure executes to completion, doing its work and recording its activity, taking about an hour and a half. If, however, I create a SQL Agent job for it, using the same login account (my own) to run the job then I see the job execute successfully BUT I see that the job completed in 0 seconds and the job history indicates an issue: