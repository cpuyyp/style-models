Mirror your backups, for starters. Have more than a single recovery sequence. Check the backups and take action when something does go wrong so that you're not exposed to risk. Disks die, things go wrong. While it shouldn't be happening often, it will most likely happen to you at some point or another in your career. Having a good restore and backup strategy to take care of this is what will help. 

A hidden snapshot is taken and crash recovery run on the databases to bring it to a consistent state so that checkdb can run against the hidden snapshot copy of the database. This is how it works when checkdb is run online. There is the tablock option which is called 'offline' as it takes locks where the online way doesn't. 

I've seen this with earlier version of SQL Server where rollover happened and you'd get negative numbers because the values are signed. I took a look at the source code and indeed these are 8-byte signed values. Since this is all C++, I created a simple repro: 

This won't help the blocking, it could lessen it but only if the secondary is in commit mode and only if the workload on the secondary is causing extra waits. If it isn't, then it's not going to help the primary for blocking. What turning off readable seconaries will do, is stop the workload on the secondary allowing it to have the most speed in keeping up by not having any other workloads to contend with. It may also help with redo blocking on the secondary since you're running DML and could lessen the send queue/redo queue. If you had replicas you may want to look at making them for the time being depending on if the schema changes are size of data operations or not. 

If you have a copy of the master database which holds the then you'll want to restore that and grab the copy of the certificate, then import it into your current instance for use. 

New in SQL Server 2012 and also in 2014 are two new encryption functions that will return a binary stream as you are describing. CREATE CERTIFICATE was also updated to take BINARY input for public and private keys. CERTENCODED will return the public key portion of the certificate in BINARY form. CERTPRIVATEKEY will return the private key portion of the certificate in BINARY form. this is encrypted so the password to decrypt it would also be needed. The above could be saved in a binary form and written to a disk, or stored in textual representation of the binary form and written to disk. Should you need to create it again, use the BINARY options of the CREATE CERTIFICATE function. Edit: There is nothing in 2008R2 that can do the same that I know of through system functions. 

Suspended isn't a database state - suspect is, not sure which you meant. Also, the key with this is that it may "attempt" to failover but doesn't mean it will be successful. 

I would consider taking a serious look at SQL 2016 if these are your concerns. Parallel redo (coming soon), better network utilization, distributed AGs, direct seeding, etc. If you're intent on using 2014, then the best recommendation is to make sure the server hardware and infrastructure are up to the rate of change you'll be creating. Additionally watch when you do DDL against objects as it could pose potential problems with redo. If you're worried about the replicas catching up in time, just remove the replicas from the AG, restore the transaction logs to them and then bring them back into the AG. Remember, your primary won't be able to have the log file re-use any VLFs while an AG is "behind" as it'll only be able to mark for re-use up to that LSN. 

File copies and crystal disk mark are using multiple threads to read and write data combined with buffered I/O. They use completely different flags when opening/writing to files on disk, among even more differences. What's applicable to these tests isn't applicable to other applications or services. It's not that one is good or bad, just they behave completely different. How can you speed this up? 

This assumes there also isn't anything like dynamic sql, SMO, etc., where there isn't an actual plain text query. 

The connection string is not setting something called which handles the way a connection is deemed to have timed out or failed. This is in seconds. The default is 15 seconds. Knowing this... Assume SQL Server failed and we needed to fail over. The fastest this application would connect is the time it takes to failover. This is a combination of a few things: 

The one I use to see the active log is sys.fn_dblog (Link to Remus's log post). Note that this function isn't documented and can/will change and doesn't show things such as Hekaton logs which need to be cracked using sys.fn_dblog_xtp which again isn't documented. 

Correct, the password is encrypted and stored in the master database. When the account needs to be used, the password is decrypted and passed in. 

Creating a snapshot of a database causes the snapshot to run recovery - just as if you were to start up any database in SQL Server. Since there is 10 GB of log to go through... it's going to take a while to run recovery. Pair that with adding of more log to an already behind database and you have yourself a great recipe for never catching up and always being behind. From BOL: Uncommitted transactions are rolled back in a newly created database snapshot because the Database Engine runs recovery after the snapshot has been created (transactions in the database are not affected). 

No. you can make many, many mount points. In fact, you'll generally have an issue with your device interfaces before you hit any appreciable limit inside of Windows Server (Assuming you're not using a version of Windows Server that is over 17 years old...). 

No, there are no changes in SQL Server. There is a change in .NET 4.6.1 that will use logic if the initial connection doesn't happen in the first 500 miliseconds if was not added to the connection string. 

The scenario is called out and supported on the link you've provided. Availability Group with One Remote Secondary Replica If you have deployed an availability group only for disaster recovery, you may need to fail over the availability group to an asynchronous-commit secondary replica. Such configuration is illustrated by the following figure: Availability Group Upgrade in DR Scenario In this situation, you must fail over the availability group to the asynchronous-commit secondary replica during the rolling upgrade/update. To prevent data loss, change the commit mode to synchronous commit and wait for the secondary replica to be synchronized before you fail over the availability group. Therefore, the rolling upgrade/update process may look as follows: 1.Upgrade/update the remote server 2.Change the commit mode to synchronous commit 3.Wait until synchronization state is SYNCHRONIZED 4.Fail over the availability group to the remote site 5.Upgrade/update the local (primary site) server 6.Fail over the availability group to the primary site 7.Change the commit mode to asynchronous commit 

Admin Overhead - if automation is not used and scripts created for re-use... it's going to make completing tasks manually a large effort. If automated or scripted properly, there should be little administrative overhead. Backups - now there are more databases and your restore strategy has to take that into account. The backup routine that is being used needs to automatically understand that new databases should be backed up. Disk Space - sure, using individual databases could lead to lower space utilization efficiency. I find this to be a very small downside, almost non-existent but depending on implementation could represent an impact, especially if in the full recovery model. 

Since you're staying with 2008R2 (both source and destination) there is nothing stopping you from just backing up and restoring all of your databases including the system databases. As Shanky pointed out, this would save a great deal of time: 1) Backup and Restore Databases - Is this the best option? It's an option. If you need the downtime to be less, you can use mirroring or log shipping (or do it by hand) to keep the databases in sync and then migrate during a fast downtime or cutover. Please note that system databases cannot be log shipped or mirrored and would need to either be frozen or copied right before the cutover. 2) Migrate Logins - use Microsoft KB? kb/918992 If you restore the master database to the new instance, no migration should be needed. All server level logins are stored in the master database. 3) Migrate Credentials/Certificates - what is required for this? If this is inside of SQL Server, these would be held in their respective databases (and possibly master as well). The one difference would be the service master key (SMK) that would change. You make want to back that up and restore it on the new server if you're relying on automatic key decryption. 4) Migrate SQL Server Agent Jobs - (Object Explorer Details > Select All Jobs > Script Job; Is this process the best option?) If you restore the msdb system database, all agent jobs will be held in it. There would be no need to script->restore. 5) Migrate SSIS Packages - (How to do this?) If the SSIS packages are on the filesystem (not default) it would be trivial to create the same location on the new server and copy. By default the SSIS packages are held in the msdb system database and restoring it would get you to the same place, just like #4 and previous. 6) Migrate Database Mail Accounts/Profiles - (Create a script or recreate in SSMS?) This is also stored in msdb. See #4, #5. 7) Recreate assemblies These live in their respective databases. If backup and restore is used, this should not be a problem. Any assemblies outside of SQL Server would need copied to the new server. 8) Recreate Linked Servers These also live in the master database, see #2. 

No idea, you didn't tell us the attack vectors you are looking to secure. In the rest of my answers, I'll assume the only attack vector is on disk at rest. 

There is no reason to move the cluster core resources. They are NOT part of the availability group and function entirely on their own. There is no need to even have these on the same server as any of your AG resources. The core cluster group provides the administrative point for the cluster which is completely independent from any other resources on the cluster. Leave it migrate on its' own. 

There is a good bit of "it depends" here due to the question being asked about both size and speed. I'm going to take the size out of it, either you have enough memory or you don't. Talking just speed from now on and assuming DDR3 for the memory type. The difference in transfer amount (theoretical) between the two is as follows: 

Use it where you need it, it's just another tool in the collection. You may find that connecting directly to the secondary is better for your use cases and scenarios that using ROR... or you may write your own health checks for the external load balancer (if it supports it) to only route to secondary servers that take into account locality of the user. 

Yes, you do want to use the listener. The fact that it is working is either because there is some document that says "always have this on node3" or you've been getting lucky that it stays working. They might have used the replica name directly in the connection string also... that would allow it to connect. Depending on the settings for the secondary role it may or may not still connect and work properly... just depends on said settings. 

I would totally expect that, there would be more latency to get to the SAN than DAS. This probably (other than latency) won't effect the outcome too awful much, assuming the SAN has the same or more cache than the local disk controllers and the latency isn't too terrible. 

In that case I'd do maintenance on a node at a time and keep it within DC, not immediately go out to SJC. You could also ADD a node at any time in DC just for the purposes of that. If you application or user base is mostly in DC, the added latency to SJC might not be palatable. I can't tell you if it will or won't be. Summary: First I would try to keep the AG in DC and only use SJC as DR, unless all replicas are Synchronous commit, then it doesn't really matter. Taking away the votes would be beneficial in the case for keeping the cluster up, but still wouldn't help all that much. 

It may show the old collation, but it's been changed. Please note that changing the collation at the database level does not change it on any of the items underneath until it is specifically changed, however all new items will use that by default. If you don't trust me (I'm a random internet person!) and you have a test system you'll see that this data is cached. Change the collation, then restart the secondary replica. Now check the collation. I do not know, though, why the metadata cache is not refreshed. 

The output is similar to what I experienced in previous versions of SQL Server, the signed value is rolled over. Note that if you compile this, you should get a compiler warning that there will be rollover - I received compiler warning 4307. Output of above: 

AlwaysOn Health extended event session SP_Server_Diagnostics output Polling the DMVs and recording changes Scraping the cluster log 

Since you can't make it happen every time a backup occurs, I'd run procmon and filter against the folder you're sending the log backups. When it occurs, stop the procmon and investigate what applications are taking locks on the file. My guess, though, is going to be antivirus or some other filter driver filesystem watcher. The fact it happens more frequently on larger files is a giveaway. If you know it's going to fail, or is currently having issues you could use process explorer and search for the file in the handles and see what processes are touching it. This is happening at the windows/driver level, not the SQL Server application level.