The irony is that those who believe in Objectivism actually coerce their opponents into seeming like they are Relativists, and irrational at that! After all, if you disagree with The Powers That Be, surely there is something wrong with you. For more, see Foucault's Madness and Civilization (from the Wiki page): 

Feyerabend could be said to have taken Kuhn's claims even further. He is purposely polemical, intentionally a grouch who does not "fit in". However, he's really making the same objection: there is no One Method to Rule Them All: 

I suggest reading at least a chapter or two of Charles Taylor's Sources of the Self (1989). He aims to "[trace] various strands of our modern notion of what it is to be a human agent, a person, or a self." (3) On your "what we do", see: 

You may enjoy Romanticism, which was in part a reaction against cold rationalism. You may also enjoy looking into Existentialism, which has a bit of the same reaction element. I would characterize your observation as people being very good at identifying what is, but not so good at identifying what ought to be. The naturalistic fallacy states that ought cannot be derived from is, which might leave the strongly analytical mind floundering. The analytical mind is great at moving from known point A to known point B. But what about when B is not known? Consider when a friend is having relationship troubles. What ought to be done? This has two basic answers. Under emotivism, the answer is one's desire, perhaps modulated by others' desires. Under teleological accounts, there exists a telos, or final purpose, and the answer is whatever advances that purpose. One form of a telos is a dikē, or 'social order'. Anyhow, if I am allowed to model some emotional responses as a comparison of the perceived is to the perceived ought ("I did X and he responded Z when he should have responded Y!"), then some of the counseling will be based on the counselee's perception of what ought to be. There is also the issue of being able to get someone from point A to point B in sufficiently small steps. I claim this holds both in the intellectual realm and the emotional realm. How does emotional reasoning work? An example theory is Spinoza on the Emotions. Some people appear to be natural at 'emotional reasoning' (feel free to come up with an alternative to 'reasoning'), while others find it very hard work. On the principle that it is increasingly hard to find someone who is an expert at 2, 3, ... things, I think it is natural that those with extremely high IQ would not have as high of an EQ. Finally, I'm not sure your sampling of the population is very good. Are there "restorative forces" at play around you, which punish empathy? Examples are the idea that empathizing is weakness, that if you exploit people it hurts to empathize with them, not to mention the whole "not fitting in" factor. 

This, I suggest is virtually a tautology. Something is considered 'scientific' when it has been shown to model reality sufficiently well. That is, when the amount of time the model is wrong passes below a certain level, it is considered 'science'. This also says nothing about whether scientific claims are Absolutely True. That is because they are not: too much 'accepted wisdom' has been disproved, time and again, for very many good scientists to make claims to absolute truth. Stephen Hawking and Leonard Mlodinow coined the term model-dependent realism, in a sense capitulating to possibility that there isn't One True Way to describe How Things Are. 

? I suggest consulting the evidence for what 'religion'† is. † Note that 'religion' isn't necessarily even a natural kind; see William T. Cavanaugh's The Myth of Religious Violence: Secular Ideology and the Roots of Modern Conflict. 

Your friend is in danger of justifying that it is acceptable to drive while under the influence. Here is why: 

You can see how this would be utterly unacceptable if the 'unacceptable behavior' were drunk driving instead of being a potty mouth. Our societal conventions on that matter are clear: ignorance is not an excuse. So, your friend wants to use ignorance/inability as an excuse for his behavior in a situation with lower stakes. Is this valid? Is it valid because the stakes aren't as high, and nobody 'really got hurt'? You and he will have to decide what rules you choose to live by. My own $0.02 is that people are generally terrible at estimating how much harm their behaviors can inflict, but many people think that their estimation algorithms are just dandy—except when others hurt them, of course. 

There is a weird asymmetry:     fact ↔ theorem     truth ↔ axiom At least, I expected it to work the other way around. The convention in this thread has facts being possibly wrong; we are much more used to axioms being possibly wrong, for we only call something a 'theorem' if it has been logically demonstrated to flow from the axioms. Then again, if we are trying to approximate the world with a formal system, we are essentially searching for axioms that generate theorems which match the facts. In pictogram format: 

Compare the complexity classes BQP (quantum) and BPP (classical). You might be more acquainted with P vs. NP; note that BPP ⊆ BQP and we don't know how BPP relates to NP. BPP is a probabilistic version of P. According to the BQP model of quantum computation, quantum computers are merely faster at solving some kinds of problems. I mean two things by using the very computer-sciency term 'merely faster': 

But wait, what is being pointed to by "This sentence"? The substitution did not bring any clarity! The problem here is that there is an infinite regress, caused by self-reference. This kind of paradox shows up elsewhere, like Russell's paradox, which attempts to construct the set R, with membership criterion: "all sets which do not contain themselves as a member". 

Perhaps. Consider unstable Lagrange points, which have the property that objects traveling through them have an undetermined aspect to their ultimate trajectory. This is because at such points, the forces of gravity cancel, and infinitesimal differences can make all the difference. This means that infinitesimal forces can have a non-infinitesimal effect. Now, must our universe allow true unstable Lagrange points? My don't-have-a-physics-degree hunch is "no", either by simply disallowing certain starting configurations, or quantizing space somehow. We could then consider whether allowing the forces of gravity to cancel merely allow randomness to rear its head, or actually allows another causal order to manifest itself. Something to be wary of is an implicit identification of 'determinism' with general causation, over against singular causation (comparison). In my experience, compatibilism is defined against general causation, not against any and all forms of determinism. For example, from the Stanford Encyclopedia of Philosophy: 

This is a pretty standard enlightened self-interest stance. It says that I will live for a finite period of time, and therefore there are ways to optimize my experience in life over that finite time period. While helping an orphan in India may have benefited Einstein, there were likely higher pay-offs closer to him, ways he could spend his time which would more likely benefit his short timespan for here. In this way, it is easier to understand the seeming insanity of Jesus': 

When not observed, the state of a quantum system is a probability distribution over the allowed [eigen]states. (superposition) When observed, the state of a quantum system is a discrete value (or eigenstate), and further evolution of the system reflects that this observation occurred and produced said value. (wavefunction collapse) 

Something I find particularly fascinating is that there is empirical science which might point toward something closer to Tooley's conception of time and causation than the major alternatives. See the 2010 article Back From the Future: 

First I will pick a scientific version: suppose that God were to write "God's Big Book of Facts", and attempt to communicate it to us. How would he do that? The Computational Theory of the Laws of Nature is an exploration of the question, and asks how God would communicate the grammar and sematics of the book. One possible conclusion is that a simulation might be the best way. A simulation, of course, has means and ends. Alasdair MacIntyre in After Virtue argues that you cannot have morality without teleology; a given morality without a telos inescapably reduces to Emotivism he claims (which he maintains in the third edition), and Emotivism is nothing more than a façade for the Nietzschean imposition of power of the strong upon the weak. MacIntyre thinks you need both virtues—means—and teleology, which can also be describe under the rubric of 'common good'—this is your end. Note that Aristotle, with his Four Causes, had no problem seeing the need for means and ends. If you do not know all four causes of a thing, you do not fully understand it, according to him. One would be moving, of course, toward eudaimonia. 

Many people seem to think in terms of #1, but I want to argue that this is not a helpful way to think. Instead, I say we should think of an infinite being as not being describable by a [finite] computer program. That is, no longer how many lines of code you right in your simulator of the infinite being, you'll always be in error. You could get closer and closer to describing that infinite being, but you'd never 'finish', except as t → ∞ (which may be what John 17:3 claims). Solomonoff induction plays on the idea of simplicity, which is notoriously hard to define. We may, however, be able to use Kolmogorov complexity, as argued in The Computational Theory of the Laws of Nature (I suggest reading the section "God's Problem" and "God's language"). When we want to explain a sequence of observations, per Ockham's razor, we want to pick the simplist explanation. That would be the algorithm with lowest Kolmogorov complexity. So, I can rephrase the question: 

Why can BQP be faster? Well, it turns out that we can exploit physically computable 'functions', such as period-finding, which is what allows prime factoring to be in the BQP complexity class. For more, see quantum algorithm. It is not correct to view quantum computation as "trying every answer simultaneously"—this would allow solving NP problems in P time—for there is no known physical model of computation which would allow this. Now, computer scientists do talk about "what if we could solve NP problems in constant time?"; see oracle machines. What would be a more powerful kind of computation than Turing machines? Take a look at undecidable problem. In case you're not quite familiar with decision problems, you can think of a computation which produces some complex output upon some input as, instead, a computation which takes two inputs—the input and 'attempt' at a solution—and simply gives you a 'yes' or a 'no' as output. For examples of problems that something 'stronger' than classical or [known] quantum computing might address, see list of undecidable problems. A characteristic of undecidable problems is that the problem requires us to find whether there exists some arbitrarily long sequence which solves our problem. Remember those problems where you have to get from one word to another through a few steps, each involving a single letter change, and each intermediate 'word' being valid? Imagine if you can have as many steps as necessary: it won't always be the case that a Turing machine could tell you whether some set of steps exists in any known time/space bound. This is because the time/space bound is a function of the input, not the output. If the output can be arbitrarily large, 'all bets are off', as it were. If we step past 'quantum' to "true description of the universe", we might find that our universe is more powerful than Turing machines. For example, we might be able to somehow perform infinite (or arbitrarily large) computations in bounded times—times that don't 'explode' in the way that makes certain problems undecidable under the Turing machine model. The classical → quauntum transition doesn't get us this, but if we perform induction on that step, we could expect future transitions that are equally as unexpected; one of them might shatter the Turing machine model of physical reality. 

Ask the conspiracy theorist to make predictions which he/she can then verify. It is extremely easy to come up with just-so stories of extant evidence. It is much harder to predict new, unexpected things. "Based on what I think I know, I should find this over there." If that thing is found, then there appears to be some knowledge in "what I think I know". A possible exception to the above is if a wide variety of evidence can be systematized with a very 'small' model. The trick is to properly evaluate a model as being 'small'. Karl Popper's ideas on falsification are probably helpful, here. What makes a theory powerful, in his mind, is that it rules out a lot of possibilities. That means that plenty of logically possible observations will never be made, and therefore there are many ways for the theory to be disproved. Contrast this with conspiracy theories, which appear to be able to absorb and explain just about any observation.