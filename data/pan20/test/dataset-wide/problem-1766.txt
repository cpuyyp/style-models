They might turn themselves off. Check to see if thermal shutdown is enabled (if you can get to that setting without rebooting.) 

I've only done this via SNMP set commands and I've only disabled it so the ports DON'T power on after a power failure as I've also been in the power-off/power-on/power-off situation. 

I don't think it's a matter of size, but a matter of the number of files in the Maildir. The performance of some very common file systems degrades rapidly when the number of files gets 'large.' What is the size of those directories? 

I just did something similar and it had no discernible effect on the remote host. I say: go for it. What I did: 

Also enable the server-status module and visit that to find out what's happening. You might be swapping. Have you checked out vmstat while this is happening? 2GB of RAM for 80 MaxClients is only 25 MB for each (assuming the box isn't doing anything else.) Your MaxClients might be too high. The solution for this is obvious: add more RAM or lower MaxClients. If the command line is slow to respond when you restart apache, that's one indication of this situation. It's also possible that you're spoon feeding some mobile clients (or other clients on slow connections) with 'large' files thereby consuming all of your available apache slots. Maybe you have too few MaxClients. Checking out the server-status will tell you what each of those clients are doing at that time. One solution for this situation is to increase MaxClients (but that might also turn into the situation above.) A better solution for this is to install an HTTP accelerator in front of apache (one free option is perlbal.) If your command line is normal speed when you restart apache, that's one indication of this situation. 

If the host is up you can also run: to reboot the BMC which will then do the port test again. If you use the dedicated port, it will then start using it. 

You could do that pretty easily with procmail (and formail.) You could also inspect the contents (message body) at that stage as well. See: $URL$ 

The problem with a site like that is: I don't trust Joe Average to 'know' data centers as well as I do. I also hugely distrust data center sales people. I had one tell me that they were 'practically Tier 4!' Yet I found many disqualifications to Tier 2 status on the tour. Some of those that buy data centers (or data center space) don't really know what makes a DC. Not to mention that we all have different qualification for a 'good' data center. It depends on what you value. Do you highly value technical remote hands? Do you highly value the robust power infrastructure? Do you highly value a robust cooling infrastructure? For me, I want a really robust DC and external remote hands. If the remote hands don't live up to my expectations, I can swap those out over the term. 

Yes, they certainly can. From $URL$ Run yes in an xterm, and you will see a lot of "y" lines swooshing past your eyes. Naturally, the yes process is able to generate "y" lines much faster than the xterm application is able to parse them, update its frame buffer, communicate with the X server in order to scroll the window and so on. How is it possible for these programs to cooperate? The answer lies in blocking I/O. The pseudo terminal can only keep a certain amount of data inside its kernel buffer, and when that buffer is full and yes tries to call write(2), then write(2) will block, moving the yes process into the interruptible sleep state where it remains until the xterm process has had a chance to read off some of the buffered bytes. The same thing happens if the TTY is connected to a serial port. yes would be able to transmit data at a much higher rate than, say, 9600 baud, but if the serial port is limited to that speed, the kernel buffer soon fills up and any subsequent write(2) calls block the process (or fail with the error code EAGAIN if the process has requested non-blocking I/O). 

I would look at external services that these apache processes connect to. Maybe you have a DB backup scheduled hourly at that time and maybe that locks all of the tables. Overall it doesn't sound like a problem on the apache server itself. 

If a user clicks the 'this is spam' link you can get an email reply from the mailbox provider (except gmail, they have their own thing) that will tell you that the user clicked that button. BUT you'll never receive those messages unless you sign up for feedback loops (FBLs) from the major email box providers. You might also need libraries from certain companies that can easily parse all of the bounce messages From the myriad providers on the Internet. 

Make sure you set the BIOS so it can't boot a USB stick or PXE boot or boot from anything BUT the installed HD. But this is probably best handled contractually with a severe penalty for copying the software. 

I added some postfix stats to ganglia. These are not daily stats, but by the minute stats. Here is my blog post about it. 

I'm not sure if that will work or not, but I'd go for something a bit different. Setup another LogFormat and CustomLog just for your metrics gathering. 

I'm going to guess that thus is an ssh key problem. Either backup's private key has a pass phrase or the public key isn't in the remote users keychain. Maybe your previous attempt used a key that was already loaded in your keychain? 

I help send millions of emails every day from my employer. I'm not sure the problem is solved by adjusting your instance size. What is your bottleneck? Do you have dedicated IPs from AWS for sending email? Have you asked Amazon to add reverse DNS for your sending IPs? Are the major MBP (MailBox Providers) limiting your sends? Have you signed up for their FBLs (FeedBack Loops)? Do you have a bounce email processing system? Some people don't know how to unsubscribe and some don't trust the links in the email. This is why it is important to have the FBLs. There are also headers you can add in the emails to help people unsubscribe. I look forward to your reply. 

Instead of piping email directly into your script, pipe it into procmail first. Procmail can look at the headers and route it accordingly. 

You can have a check do anything you can program. The only thing you need to do is craft the output of your check such that Nagios can parse it. In this specific case, I might implement this as a passive check. 

This is a difficult problem to solve. There are companies (like $URL$ out there which can help you with this, but it won't be cheap. Given that you said 'my server' in your question tells me that your site is on the smaller side and you might not have the resources to engage a company like them. Do you know how they are attacking you? Can you get to the console of your server and setup iptables (assuming Linux) to drop traffic from the offending IPs? If Linux, have you enabled TCP syncookies? . Are you sure this isn't a server misconfiguration? If you have your MaxClients set too high in Apache this can cause the machine to swap which would effectively be a DDOS given enough connections. (Combine that with a memory leak and disaster will be the result.) It is pretty common for major DDOSes to saturate incoming network links. Given your provider isn't really concerned about this, it's not really that large of an attack. Does your site come back online after a reboot only to get overwhelmed shortly thereafter? That might just be a config issue with your MaxClients. 

If you're brave, cron that. If not, run it frequently to keep your system up to the latest patch level. 

You do need some form of configuration management. Puppet, Chef, CFengine, one of those. Basic setup of each is somewhat trivial, but they get complex very quickly. There are many different How-To's out there for each. Do NOT go distro agnostic. It's nice to be able to use different distributions, but don't expect compatibility. Different distros have different versions of apache, php, mysql, etc., etc., etc. To be distro agnostic you need to be willing to package AND maintain those packages for each distribution (to keep your critical software at the same version across distros.) I know you are asking specifically about your dev environment here, but it is also important to keep your production environment in sync with your dev environment. No one likes to push code to the production environment only to find out that you've been developing against a library version that hasn't yet seen the light of day in production. Keeping the different environments in sync is critical to reduce downtime. 

I doubt this would work. It will be as difficult to get setup as faxing over VoIP. Then there's the problem of finding your modem equivalent. Asterisk comes to mind, that's ... weird. Analog to digital to analog to digital? If you do get it setup, let us know how you did it. 

It sounds like you're looking for something like MogileFS. It's a distributed, replicated file share based on webdav. Mind you, this is not POSIX compliant and your application needs to be 'mogile aware'. It was built to share images for a website. 

man ssh_config will give you all of the necessary options. Replace 'webserver' with the hostname of your final destination. Replace intermediatehost.edu with the hostname of the first hop on your way. Then you'll be able to ssh (and scp) directly to 'webserver'. 

If you have more than one data center why not just copy the data over the network to a different data center each night? If bandwidth is expensive, look into a private link between all of your facilities. Or use the area under your 95th percentile in your trough. :) 

Having an exit of 2 makes this service critical according to nagios (see below for all nagios service states.) Sourcing is another way, then you could . But the above works even if you don't have that. This gives the added notice of "Is NSCA running" because it might be the case that the service didn't check in properly OR it might be the case that NSCA has failed. This is more common than one might think. If multiple passive checks come in at once, check for a problem with NSCA. Now we need a passive check to accept the results. In this example I have a specially crafted cron job that knows about all of the different types of raid controllers in our environment. When it runs it sends in a notification to this passive check. In this example, I don't want to be woken up in the middle of the night (edit notification_period as needed.) 

If I recall correctly the Cobalt Raqs used IDE drives. Those were fun little boxes, back in the day. I think a better project would be to get those systems running on new hardware. If you did find drives that worked, you'd have an interesting time getting the OS on there. Are they still supported? I bet there are security holes that haven't been patched on those. No fault of yours, of course! I think they lost support many years ago. I'd look into something like a dual core Atom 'nettop' with large drives as a replacement. Less than $500 in hardware and it'll draw less than 50 watts. Plus you can migrate the services off at your leisure. This is, of course, assuming that they aren't greatly dependent on the custom admin interface. If you really are determined to get new drives in there, here is one resource: $URL$ 

I hooked up a WattsUp! meter to our R710 and I couldn't tell much of a difference between the two either at idle or at full tilt. So I left it at Maximum Performance. At idle they only draw 185 watts, full tilt I got it up to 295 watts (in our config.) -Dave 

That will give you a list of non x86_64 rpms currently installed. You can remove all of them with this: 

If these IPs are certified by Return Path, ask them what you can do. They are very helpful in this sort of situation. 

I would setup identical (or even upgraded) hardware along side it and move the services over one by one. But I live in the world of non-stop production environments. Can you run the CentOS installer over the Fedora installation? Yes. Is it recommended? No. It's not supported and you might end up needing to wipe the disk to get it working properly in the end. For the best result, wipe the disk and start over. Either over your existing or on a new server next to it. In either case, make sure you have a good backup before starting. 

That's the Dell Poweredge C1100 Look at the second pic. I don't know why someone scratched off the Dell logo on your pic. 

Check the init script to make sure it's daemonizing properly. Did you install it via a package or from source? 

CERC == "Cost Effective Raid Controller" which I'm learning means something along the lines of "driver-based software RAID implementation." Are you sure it's a RAID0? Given the sizes you mention of your partitions, you have 297GB of usable space. Dell didn't ship that with 300GB SATA disks, at least according to this. I'm going to bet that you have 3 160GB SATA disks in a RAID5 with one disk failed. A failed drive in a RAID5 array with a "driver-based software RAID implementation" would peg the CPU on your machine to the point of pain during reads. I bet if you tried the same file transfer to remote disks you'll have the same performance problems. -Dave 

I use nagios for alerting and ganglia for metrics gathering. Often times my tool that sends data into ganglia (via gmetric) also sends alerts into nagios (via send_nsca, aka passive alerts.) If you write your tool properly it can detect changes from the last period to the current period. This way you can, for example, detect changes in certain metrics. Is the average response time at this time X% higher/lower than the last time? Did the queue size increase/decrease X% more/less? I used munin for a while, but it didn't have the granularity of ganglia. Also, creating a new metric in ganglia is as easy as calling gmetric. BAM, you have a new graph. I also find it useful to have the last deploy time displayed on our metrics graphs (just a vertical line showing the time of the deploy.) That way you can better visualize what's going on and when. 

If you care about the data (and it sounds like you do) do NOT move them. Buy new hosts somewhere else and migrate the data. Those machines are beyond their usable life expectancy. Do some calculations on the power savings that you'll get by purchasing new R710s. You'll likely only need to buy 7 of them to replace all 55 of those 2850s. 2850s were power HOGS, Dell's capacity planner says they draw over 500 watts each. My real world experience with the R710s (dual L5520, 72GB RAM and eight 73G 15k 2.5" drives) are drawing 220 watts when in use (120 is common when idle.) 55x500 = 27,500 watts, 7x220 = 1540 watts. If power is $.15/kwh, you'll pay $2970/mo for the 55 servers or $166.32/mo for the 7. Plus cooling factor (which can easily double that cost.) If you can get a decent Dell lease those new servers, you'll come out ahead over the life of the R710s.