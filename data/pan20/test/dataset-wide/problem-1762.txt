The TFS Build Controller is designed so that it can be run on a workstation in small environments (See this MS article). Obviously this comes with the usual caveats about running anything on a workstation (lower performance, has to be online all the time, not backed up, liable to conflict with things), but it's a documented configuration that MS expects small teams will use. The build controller should be kept separate from the TFS server itself for security and stability reasons - It's a host that builds and executes a changing code base and as such, that role should stay away from your code repository. Regarding the lack of domain - Yes, TFS will install in workgroup mode. 

2 Tb of images which I assume don't change very often? A monthly backup to a few LTO3 tapes, which are then stored at someone's house, is appropriate for a small firm. If you can provide more info about what's currently in place for backups, and how the data is stored and how often it changes, we can probably generate a more specific solution. 

You need to ensure that the domain object for your server is deleted from AD when you remove it from the domain. To ensure this, either use a domain administrator account when asked for credentials as you sever the machine from the domain, or manually jump onto AD Users & Computer, and delete the corresponding computer object from AD. Once you've done this, make sure to wait 15-20 mins so the change gets propogated around any local domain controllers, then re-join the computer to the domain. Also try renaming or new-sid the server before rejoining it. 

James, why not configure the ESX hosts at the remote location so that their guests are in a DMZ, but the ESX service console etc are in a back-zone subnet that you can establish a VPN with? That way, your hosts are isolated from web connectivity (a good thing) but your guests can continue to operate front-facing. As for the remote site problem... you really need a site-to-site VPN link going on here, between your internal LAN and the remote (non-DMZ if possible) subnet. 

If I've misread your question and your website is currently hosted entirely on Server A, but you want only a specific subdomain to redirect to server B, then you need to create a second A Record, and set it to subdomain.mydomain.com pointing at the IP for Server B. Then you install IIS on Server B and setup the subdomain web content. 

Well, what do you want/need to achieve with the script? This'll determine how involved it needs to be. In our setup, our requirement is merely for a few mapped drives on the clients, and a BGInfo on the servers. For that, we have a couple of WSH VB scripts on netlogon, and call them from GPOs attached to the appropriate OUs (servers OU on server startup, and users OU on user login). Scripts are maybe 20 lines a piece. Powershell is a logical next-step, but I'm not impressed with it so far. It feels inelegant and clunky. 

The mechanisms for doing this are now built into the bittorrent protocol: $URL$ However as mentioned in the article, to date no specs have been released to allow support. 

The command you need is either of these: w32tm /config /syncfromflags:MANUAL /manualpeerlist:"dcbox_ip_here" (sets to manually sync from a chosed source) or w32tm /config /syncfromflags:DOMHIER /update (sets to automatically sync from your domain's heirachy) Then follow the command with both of these: net stop w32time net start w32time You must also ensure that your guest additions installed within the VM is not causing your VM to sync from it's host. If it is, you must ensure the host's time is highly accurate (again,configure it's NTP settings using it's native NTP client, as a script is not a suitable subsitute as Rainy mentioned). You may also need to increase the frequency with which NTP on the guest checks it's time source, and increase the value of 'max drift until I give up and stop syncing'. 

If your switch will support a regular old network fail-over for a single server (with 2 nics in an active/passive configuration) then it'll support vMotion just as well. The only thing you have to ensure is that all the networks/VLANs you make available on one ESX host, are also available with the same names and VLAN IDs to the other hosts. With 3.5, you'd typically see the VM drop a single ping when flipping between machines during a vMotion. With vSphere, we're not even seeing a single dropped ping - It's practically seamless. 

For doing a 'Connect' to his session, you're literally taking over control of that session and punting the user out of it. In this scenario, you need to provide the user's own credentials, possibly including the logon domain like DOMAIN\username. If on the other hand you want to connect alongside the user to help them out, you should be going via the 'remote control' option, rather than 'connect'. To do this you will need to be a local administrator of the server, and possibly configure GPO here: Computer Configuration -> Administrative Templates -> Windows Components/Terminal Services -> Sets rules for remote control of terminal services user sessions = "Full Control without user's permission" 

You cannot install 2008 TS CALs on a 2003 licensing server. They must be installed on a 2008 TS Licensing server. You can however install your older 2003 CALs onto your new 2008 license server, so you don't have to keep running your old 2003 license server. 

You can scale in a few different direction here depending on your budget and hardware availability. Consider these steps, probably in this order but whatever suits your situation: 

Presumably you can access your Production servers from work, when you're in the office. In which case, you need to configure your VPN connection and access rights so that, when you're VPNed from home to your office, you can reach your production environment via your office network. Quite how you achieve this is down to your network topology, choice of VPNs and firewalls, IP ranges and route configuration. Are you in charge of these things, or is there a network administrator in control of the system? 

WSUS computer groups are not the same as AD groups. In WSUS a computer can only belong to one group at a time. So Group:Computer is 1:M (one-to-many) This differs from AD where Group:Computer is M:M (Many-to-Many). You can put many computers into a group, and any computer can belong to many groups at any one time. 

We're hoping to solve a need for a low-cost SAN at one of our sites by deploying an OpenFiler on a DL360 strapped to an MSA70. We've been running a similar setup for 18 months at our locel site, so we're happy with the performance and compatability. The problem is that this new unit with be a remote data-center which we rarely visit, so we need to know if a disk has failed in the unit via some kind of notifications. I'm assuming I have to get the HP agents operational within the OS in order to get SNMP notifications of a disk failure and tie the server to our SIM server. OpenFiler's built on rPath Linux and while there are HP Linux agents for the DL360, I don't know what kind of package I'd have to use for rPath. I looked at having the iLo forward alerts, but that appears to require the agents on the OS, just the same. Can anyone recommend a way to fix this issue? I can't deploy the unit without knowing that we'll receive disk failure notifications. Would FreeNAS be a suitable option? 

Try opening up perfmon and when it (eventually) loads up, add counters in for disk queue length. If you have large queues building up, you know there's a problem with some element of the disk subsystem. First guess would be the array battery, then the array card, then the cabling and disks. See if the server will boot up OK from a Linux LiveCD or if that takes an extended period also. It'll mostly leave the disk subsystem alone and run from RAM. 

Could be. Then again it could also be an application trying to log on under credentials where the password has been changed or expired. You should look closer at the events and establish: - What kind of logon is occuring? See if it's RDP, or some other kind of access - What account names are being attempted (If it's random account names you don't recognize, or running through A-Z of names, then definitely an attack) Outside of that, verify that RDP to your server is accessible publically. If so, do you really need that? If your virtual server is within your organisation, lock down your public firewall to prevent this (or ask the admin in charge of the firewall to do so). If it's out in the cloud, the provider should provide interfaces for controlling network access (virtual firewalls). You have a pretty major security problem if you have servers available on the net that are not sitting behind a proper firewall. The boxes should be available exclusively on only the ports that are needed for operation, so a basic web serving box should only have firewall rules outbound for ports 80, and 443 if SSL is served. Security should never be approached from the other direction (start all-permissive, then lock down only specific items). Likewise, moving to a non-standard port gives only a very minor increase in security.