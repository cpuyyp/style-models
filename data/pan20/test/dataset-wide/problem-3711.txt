The first of these is a general graduate text in statistics, but the author gives uncommonly complete coverage of both Bayesian and frequentist methods. The second is a smaller volume and, as I recall, is devoted to some of the more delicate issues surround finite versus countable additivity as relates to using probability distributions as priors in a Bayesian approach. The final book is more general, but the style is more formal than the Bernardo and Smith book mentioned by PaPiro. (This is, in my experience, true of the style of French Bayesians :) As I said, the distinctive elements of the Bayesian perspective are more philosophical than technical, but there are some technical areas that have received attention in the Bayesian community that may be of independent mathematical interest. One would be the role of so-called "improper" priors as mentioned above. Another is the role of conditional distributions as a primitive rather than derived notion, leading to the idea of disintegration, as in this manuscript of Pollard. Also, because of a keen interest in the application of Monte Carlo methods, Bayesian statisticians have to a lot of work on various aspects of computational methods for sampling from various distributions. Christian Robert is a prominent researcher in this area, and he has a blog. The current post happens to be about Bayesian foundations. Finally, at the heart of a many arguments in favor of a Bayesian approach (early chapters in Bernardo and Smith and Robert are dedicated to it) are de Finetti type representation theorems, which sanction prior distributions via appeals to exchangeability. You can start with the wiki entry for de Finetti theorems and then look at the work of Persi Diaconis on the topic. In this vein see also Lauritzen's monograph, which (for me anyway) is the last word on the matter. 

You could try a moment-matching approach. In particular, define $\hat{s}$ to be the value of $s$ such that $$\mbox{Pr}_{s}(-1 < r < 1) = \frac{\sum_i I(-1 < r_i < 1)}{N}$$ where $N$ is the number of observations. You can calculate the left hand side explicitly as $$\mbox{Pr}_s(-1 < r <1 \mid S = 1)\mbox{Pr}(S = 1) + \mbox{Pr}_s(-1< r <1 \mid S = -1)\mbox{Pr}(S = -1)$$ which simplifies (I think) to $$\Phi(2/s) - 1/2,$$ where $\Phi(\cdot)$ denotes the cumulative distribution function for a standard normal random variable. Inverting this gets $$\hat{s} = \frac{2}{\Phi^{-1}\left(\frac{\sum_i I(-1 < r_i < 1)}{N} + 1/2\right)}.$$ I'm not sure if this differs much from your Solution 3 in terms of complexity, but one evaluation of the inverse CDF of a Gaussian isn't so bad. 

Maybe something like this will work. Consider $U_1$ and $U_2$ drawn uniformly at random on the unit circle. Because they are uniformly distributed, we may rotate the circle until $U_1$ is at the ``north pole" without altering their distributions. Now, stereographic projection takes $U_1$ to $Z_1 = 0$ and $U_2$ to some point $Z_2$. Then $\frac{1}{2}(Z_1 + Z_2) = \frac{Z_2}{2}$, which is Cauchy distributed with scale $\frac{1}{2}$ by your point (1). However, noting that we had two directions we could have rotated -- corresponding to two distinct projections of $U_2$ -- we recover our factor of 2, giving the result (2). 

Consider the joint Gaussian distribution of $(Y, Z, f(x))$. Observe that knowing both $Y$ and $Z$ together is equivalent to knowing $f(\mathbf{x})$ (the noiseless version of $Y$). Then we can compute $\mbox{Var}(f(x) \mid f(\mathbf{x}))$ as $\mbox{Var}(f(x) \mid Y, Z)$. Furthermore, we can compute $\mbox{Var}(f(x) \mid Y)$ via the law of total variance: $$\mbox{Var}(f(x) \mid Y) = \mbox{E}(\mbox{Var}(f(x) \mid Y, Z)) + \mbox{Var}(\mbox{E}(f(x) \mid Y, Z)).$$ Or, using your notation, $$\sigma^2_n(x) = \tilde{\sigma}^2_n(x) + \mbox{Var}(\mathbf{k}^t(x)\mathbf{K}^{-1}(Y - Z))$$ where the second variance is with respect to the random variable $Z$. Simplifying further yields $$\sigma^2_n(x) = \tilde{\sigma}^2_n(x) + \sigma^2 \mathbf{k}^t(x)\mathbf{K}^{-2}\mathbf{k}(x).$$ Accordingly, it seems that $C = \mathbf{k}^t(x)\mathbf{K}^{-2}\mathbf{k}(x)$. 

Many hold that Bayesian statistics "from a purely mathematical point of view" is entirely coextensive with probability (however it is that you want to define its boundaries as a mathematical discipline). Nonetheless, if I interpret your request as being for a mathematically sophisticated and rigorous exposition on why the Bayesian approach is a worthy one, three book spring to mind. 

This paper addresses a similar problem I think, although I believe they consider binary outcomes only: Ramsahai, R.R. (2007). Causal bounds and instruments. In Proceedings of the 23rd Annual Conference on Uncertainty in Artifical Intelligence, 310-317. The main result is a way to produce the sorts of upper and lower probabilities that Douglas Zare mentions in his comment. They additionally note a freely available software package that they use, called polymake. 

I will expand on this answer later if there is interest and when I have some references handy. But for now you may be interested in the following way of thinking about the problem. One way to characterize the Gaussian distribution is as the unique distribution on $\mathbb{R}$ satisfying spherical symmetry. More precisely, for $N$ observations, consider the two-dimensional statistic $$T(X_{1:N}) = \left(\sum_{i=1}^N X_i, \sum_{i=1}^N X_j^2 \right).$$ Assume that the conditional distribution of the vector $X_{1:N}$ is uniform on the hypersphere with center $(T_1, \dots, T_1)$ and radius $\sqrt{(T_2 - T_1^2/N)}$. This implies that the density for $X_{1:N}$ may be written as $$f(X_{1:N}) = \int \prod_{j=1}^N \left[(2\pi)^{-\frac{1}{2}}\sigma^{-1} \exp{\left\lbrace\frac{(x_j - \mu)^2}{\sigma^2}\right\rbrace}\right] dP(\sigma, \mu)$$ for some density $dP(\sigma,\mu)$. (This sort of representation theorem motivates the use of prior distributions in Bayesian statistics.) Note that as $N \rightarrow \infty$, $T$ converges to the true first and second moments, which gives back another common characterization of the normal distribution as being specifiable using only them. So, when you say that "usually 'exchangeable normal random variables' means jointly normal random variables" it makes me wonder what is the more critical property, the permutation invariance -- which does not uniquely define the distribution -- or the underlying symmetry -- which in the case of the normal distribution does. The reason I brought up the copula earlier is that I think getting your necessary marginals to be whatever is not much of a barrier, because you can always transform things elementwise. This makes me think that you are really asking whether or not there are other forms of exchangeable distributions of real-valued vectors, and there definitely are. Following the example of the spherical symmetry, the basic recipe is to specify a statistic and then specify a uniform transition kernel given the value of that statistic. This approach has been systematized by Steffen Lauritzen in a monograph S. L. Lauritzen. Extremal Families and Systems of Sufficient Statistics. Lecture Notes in Statistics, No. 49. A good textbook treatment of this is given in section 2.4 of Mark Schervish's Theory of Statistics (available on Google Books, but my toolbar for providing links seems to have vanished). Apologies if you knew all of the above and I missed the point of your question, but your comment to Yuri makes me think that this stuff would be of interest. The keywords you'd want to include to dig around more include "de Finetti theorems", "extremal families", and "partial exchangeability". 

This question occurs to me every time I go jogging. I suspect every runner probabilist in the world must have thought of it (though I'm no probabilist), but I could not specifically find it online. I hope some MO readers will find it worth thinking about. Here's the basic set up: 

Total variation and Hellinger distance are two standard ways to measure this. Kullback-Leibler divergence is another standard way, as would be general $f$-divergences. The Earth-Mover's distance (also called the Wasserstein metric) is another option. Bear in mind that your data gives an empirical cdf, so you can use any of the standard metrics for probability distributions notwithstanding the fact that you have a data sample in hand rather than a formula. (Wiki has decent entries for all of these, which I may link to later.) 

Incidentally, finding the factor decomposition for a given covariance that minimizes the rank of $B$ is known as the Frisch problem and is computationally demanding. PS. I hope this isn't merely a restatement of your remark that "PCA accounts for all variance, while FA accounts for only common variance and ignores unique variance". 

I just came across these BBC podcasts the other day. These are almost certainly more populist than you had in mind, but given the title of your question I thought I would throw it up here anyway. The are ten podcasts. Some expire in a day or so, which made me think posting it for those interested was a decent idea. 

To keep things simple I don't mind working with probability distributions over the real line with continuous density with respect to Lebesgue measure, a class we can call $\mathcal{P}$. The restriction to parametric models can be done by assuming that $\mathcal{G} \subset \mathcal{P}$ can be indexed (smoothly) by a compact subset of $\mathbb{R}^d$, for $d$ finite (so that $\mathcal{G}$ is a smooth manifold as per ArthurB's comment). We can call the parameters $\theta \in \mathbb{R}^d$. Finally, we have that the Bayesian machinery will converge to the so-called "pseudo-true" parameter values, meaning that we eventually converge to the value $\theta^*$ minimizing the Kullback-Leibler divergence $$\int_{-\infty}^{\infty} \log{\left(\frac{f(x)}{g_{q,\theta}(x)}\right)}f(x) dx$$ for true distribution $F \in \mathcal{P}$ with density $f(x)$. 

Consider a set of $n$ real-valued number pairs: $(x_1,y_1), (x_2,y_2), \dots, (x_n,y_n)$. I want to find a permutation $p$ of the indices which minimizes the sum of consecutive absolute differences: $$\sum_{j=1}^{n-1} |x_{p(j+1)} - x_{p(j)}| + \sum_{j=1}^{n-1} |y_{p(j+1)} - y_{p(j)}|.$$ I suspect this is reducible to a well known problem, so I'm looking for pointers to literature mainly, but would be happy to see a clever algorithm for doing this from scratch. Intuitively, I want to shuffle the observations so that the graph of $x$ elements against the index is smooth looking and the same graph of the $y$ elements is also smooth looking. If I cared only about one or the other, I could simply sort with respect to those elements. I want to shuffle in such a way that I compromise between the two coordinates. My motivation is a statistical problem of estimating a smooth curve in the plane by assuming that the coordinate dimensions are each smooth functions of an unrecorded "time index". The above problem is maximizing the smoothness of the observed data under the assumption of evenly spaced observations in time. 

In mathematical statistics people often have experience about some method that works well in practice even though it "shouldn't" in all generality. The game is then to ask what conditions need to be satisfied to explain why the method works. Here is an example which I was not personally involved in, so I can only speculate. This paper by Bickel and Li considers local polynomial regression methods and shows that they works as well as possible (in the sense of asymptotic optimality) when the data it is being used on has low dimensional structure. The idea is that people were finding that certain regression techniques were giving reasonable generalization performance in prediction problems even when the data was high dimensional so they figured that maybe the data wasn't actually high dimensional in some relevant aspect. But which relevant aspect, that's the challenging part. To my mind, figuring out how to explicitly articulate the minimal conditions under which some ``obvious" fact is true is where the discover and understanding come in. It is a very different process than what a student does on problem set, where the statement and all the relevant conditions are laid out and the main job is deriving the stated implication. Put another way: research has degrees of freedom on both ends -- you can find/create the answer and the question as pairs, rather than being handed the one and being asked to complete the set. This perspective of course doesn't cover all cases -- notably, that of people chasing down famous open problems. But it is a way in which one can develop a rigorous understanding from ``non"-rigorous reasoning. When one first starts thinking vaguely about a problem there is nothing there about which to be rigorous. 

This has always bothered me. "One should use the price of tea in China to obtain a better estimate of the chance of rain in Melbourne" is not a good characterization at all. One should use the price of tea in China and the chance of rain in Melbourne to obtain a better estimate of the vector which includes both the average price of tea in China and the chance of rain in Melbourne. The Stein result only obtains if you care about a vector-valued parameter; that is the observations are assumed independent probabilistically but clearly interact with one another via the loss function being use. The idea behind the quote is that you can hedge your bets on any given coordinate dimension by "shrinking" back towards the "global" mean (across all elements of the mean vector). But observe that the "shrinkage" need not in fact be towards the overall mean for the result to hold...you can shrink back towards any value at all and still get the result, which has to do with the definition of admissibility used. My favorite description of what is going on is here. 

The ridge estimator corresponds to the posterior mean under a Normal linear regression model with a conjugate Normal-inverse-gamma prior on the regression coefficients: $\beta \mid \sigma^2, \lambda \sim \mbox{N}(0, \lambda^{-1}\sigma^2 \mbox{I})$ and $\sigma^2 \sim \mbox{IG}(a,b)$ for known hyperparameters $a$ and $b$. One may additionally put a prior distribution over $\lambda$. If you consider a discrete number of possible values for $\lambda$ then one may compute posterior probabilities for each of these values or compute Bayes factors to compare different values. As BIC and AIC and other such "information criterions" can be viewed as approximations to Bayes factors, this may answer your question. Usually, as you probably know, one simply checks prediction error for the different values via cross-validation (at least in prediction contexts) and selects lambda that way. 

The difference between PCA and FA can be thought of in terms of the underlying statistical models (regardless of estimation methods, although these will change depending on the model used). Consider $n$ iid observations of a $p$ dimensional (column) vector $X$. Suppose that for each $X_i$, $i \in \lbrace 1, \dots, n\rbrace$, we also had a $k$ dimensional vector $f_i$, with $k \leq p$. These are our "latent factors". A (linear) factor model assumes that $\mbox{E}(X_i \mid f_i) = Bf_i$, where $B$ is a $p \times k$ "factor loadings" matrix and $\mbox{Cov}(X_i \mid f_i) = \Psi$, a diagonal matrix. If we further assume that $\mbox{V}(f_i) = \mbox{I}_k$ so that the factors are independent we see that the marginal covariance is $\Sigma \equiv \mbox{Cov}(X_i) = BB^t + \Psi$. Roughly, you can think of PCA as making the assumption that $\Psi$ is the zero matrix. In both cases the goal is to find/estimate rotations ($B$) that explain covariance patterns. If we remove the estimation part of the problem and assume we have $\Sigma$ in hand, the difference is between two ways of decomposing a covariance matrix. We either want a "factor decomposition" $\Sigma = BB^t + \Psi$ or a principle component decomposition $\Sigma = BB^t$. 

The Borel-Kolmogorov paradox refers to situations where non-uniqueness in the notion of conditioning on a set of measure zero leads to apparent contradictions. As a formal matter, one requires instead to condition on "the" generating sigma algebra, which vanquishes non-uniqueness by fiat. For a technical explanations see this paper. Billingsley's measure theory book has a nice treatment as well. 

Newton and Leibniz Leonard Euler Joseph Fourier Evariste Galois Carl Friedrich Gauss The Mathematicians Who Helped Einstein Georg Cantor Henri Poincare Hardy and Ramanujan 10.Nicolas Bourbaki 

It is possible to develop probability theory taking conditional probability as one of the basic definitions; see section 3.2 in this book and the references mention there. Renyi was one of the first mathematicians to favor this approach, which is described in his book Probability Theory. Part of the motivation for this approach is to directly build in the ability to condition on measure-zero events without having to make a limiting argument. Another key word related to this idea is disintegration. So, as Kjetil mentions, it all depends on what one takes as axioms. But certainly it is possible to develop theories that take conditional probability as the centerpiece.