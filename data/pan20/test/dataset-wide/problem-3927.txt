To elaborate on the comments of Will Sawin and fedja: The question isn't a sorting problem, but it is a matching problem. If $S$ is your arbitrary set and $G = [n]^2$ is your grid, then you are marrying elements of $S$ to elements in $G$, where the happiness of each marriage is your dot product $p \cdot f(p)$. Any happiness function on $S \times G$, not necessarily one that is bilinear in the plane, can be maximized in polynomial time. That's because the convex hull of the set of permutation matrices has few facets: It's the Birkhoff polytope of doubly stochastic matrices. You can apply the general theorem that linear programming with polynomially many facets can be done in polynomial time. For the specific case of the Birkhoff polytope, there is an optimized linear programming algorithm, the Hungarian algorithm, that was discovered and known to be fast before the result that LP is polynomial time in general. The Hungarian algorithm is already much faster than generic optimization strategies (which generally aren't polynomial time at all). The remaining question is whether you can devise a sorting algorithm that's even faster, maybe even quasilinear time like linear sorting. It's difficult to rule that out, but the setup is sufficiently complicated that I'd be surprised/impressed. 

At least in the case of isolated singularities, the possible topology of the link of a singular point has been studied in the language of complex analytic geometry rather than complex algebraic geometry. I found this paper by Xiaojun Huang on this topic. The link of the singular point is in general a strictly pseudoconvex CR manifold. This is a certain kind of odd-dimensional analogue of a complex manifold and you could study it with algebraic geometry tools. (I think that strict pseudoconvexity also makes it a contact manifold?) But the analytic style seems to be more popular, maybe because a CR manifold is not a scheme. Sometimes, for instance in the case of a Brieskorn-Pham variety, such a CR manifold has a circle action whose quotient is a complex algebraic variety. At a smooth point, this quotient is just the usual Hopf fibration from $S^{2n-1}$ to $\mathbb{C}P^{n-1}$. In the famous Brieskorn examples, the link is a topological sphere with a circle action, but the circle action yields a non-trivial Seifert fibration over an orbifold-type complex variety. On the other hand, I don't think that this circle action always exists. 

If I can take only the finite covers, then yes, I think. (After all, Swan's theorem is a characterization of finite-dimensional vector bundles, not all vector bundles.) This is easier to do over $\mathbb{C}$ than over $\mathbb{R}$. In addition to the entire sheaf $C_X(-)$, let $C(X) = C_X(X)$ be the algebra of global continuous functions. Since the module $M$ is locally free, what you want to do is to choose a basis for $C(U) = C_X(U)$ for enough open sets $U$, and such that the bases agree when you restrict to smaller open sets. You could just ask for this directly, but there is an indirect algebraic condition that comes to the same thing. Namely, you can ask for $M$ to not only be finitely generated and projective, but also a semisimple commutative algebra over $C(X)$. This gives you the unordered basis in each fiber. Over $\mathbb{R}$, it's not quite enough to require that $M$ be a semisimple algebra, because you could end up creating $C(Y,\mathbb{C})$ for a finite cover $Y$ of $X$. So, you could also impose the condition that $f^2 + g^2 = 0$ has no non-trivial solutions in $M$. 

David is right about one thing. Scott had a discussion about this on his blog and I was also involved. On the one hand, many complexity theorists simply also assume that BQP does not contain NP, just as they assume that P does not contain NP. The evidence for the former is not as dramatic as that for the latter, but there is at least an oracle separation. I.e., there is an oracle A such that BQPA does not contain NPA. Now, there are some famous cases where two complexity classes are equal or there is an inclusion, even though there is also a credible oracle separation. But the oracle separations for BQP vs NP seem realistic. Besides, apart from tangible evidence, I for one consider BQP to be surprisingly powerful but not incredibly powerful. It's my intuition partly because I expect BQP to be realistic and I don't expect the universe to be perverse. I think of BQP as an extension of randomized computation based on quantum probability. On the other hand, P vs PSPACE is already an unfathomable open problem. The two main barrier results for P vs NP, Baker-Gill-Solovay and Razborov-Rudich, apply to P vs PSPACE equally well. Since PSPACE contains both NP and BQP, if you were to show that either one does not equal P, then in particular you would show that PSPACE does not equal P. Actually, I don't know a good reason to try to prove that P ≠ NP rather than to first prove that P ≠ PSPACE, since the latter is at least formally easier. 

I have used the notation $\vec{1}$ in a paper. I think that it's a good choice if you help the reader by defining it. I did a Google Scholar such of "vector of all ones", and I found a lot of so-so notation such as $e$, $u$, $\mathbf{e}$, $\mathbf{1}$, and even just plain $1$. I don't think that the literature is loyal to any particular choice. Confusing $\vec{1}$ with a matrix would be a little strange, because a matrix is suggested by a two-headed arrow, or $\stackrel{\leftrightarrow}{1}$. 

A clearer and more correct way to do the second calculation is to look at the volume of the preimage of $S_r^{2n+1}$ in standard $S^{2n+3}$. The preimage is a certain torus $T_r$, and one has $$\mathop{Vol} T_r = 2\pi\mathop{Vol} S_r^{2n+1}.$$ At the same time, $$\mathop{Vol} T_r \propto (\cos r)(\sin r)^{2n+1},$$ because $T_r$ is the Riemannian Cartesian product of a circle of radius $\cos r$ and an $S^{2n+1}$ of radius $\sin r$. If you calculate when the derivative of this expression vanishes, you get agreement with your first calculation. Addendum: You can also directly check that the scale of the $\mathbb{C}P^n$ quotient of $S^{2n+1}_r$, if you want to do the calculation that way, is $\sin r$, which yields a factor of $(\sin r)^{2n}$, in addition to the factor of $\sin 2r \propto (\sin r)(\cos r)$ from the Hopf fiber. So it all fits together. 

I agree that the difficulty in the question is that you are relying on the homological definition of an orientation of a manifold. As Ryan implies in the comments, the solution is undergraduate-level mathematics if you define the orientation of a smooth manifold as an equivalence class of bases of its tangent spaces. But actually, in the question itself you said that you already know this. What's left, if you press the point, is to prove that this definition of an orientation in differentiable topology is equivalent to the homological definition. This is not an easy theorem! You either have to work with singular homology, or if you want geometric simplicial homology you need the theorem that you can triangulate manifolds. After that, I would use the de Rham theorem, that de Rham cohomology is isomorphic to simplicial or singular cohomology. It's easy to see that the orientation class in de Rham cohomology is equivalent to a class of tangent orientations. You can argue similarly in the PL category, using a triangulation of a PL manifold. You can ask the question again for topological manifolds, and then...maybe it is the most in the spirit of your question. I think that indeed, the exact sequence solution that you sketch is the best one. In a sense, even that is the easy end of the question. It is not easy to distinguish the boundary of a manifold from the interior, and it is not so easy to prove Poincaré duality for topological manifolds either. 

It was so that Legendre could do with the gamma function what the Catholic church did 170 years later: He put a simple pole at the origin. 

For a problem of this size, you should consider which algorithm before you consider which computer algebra system. In floating point arithmetic, there is an excellent algorithm for solving a sparse system of linear equations. Even for dense matrices it is more robust than Gaussian elimination; for sparse matrices it is better still. This is the conjugate gradient method. It is available in certain packages and certain computer algebra systems, but it is also not very hard to implement from scratch. For instance, to me it feels simpler to code conjugate gradient than to code Gaussian elimination. If you find floating point solutions to high precision, there are algorithms to convert them to elements of a number field with bounded complexity. (See the Inverse Symbolic Calculator, etc.) Some of these also exist in computer algebra systems. If you use one of these solvers, you can then check that it is an exact solution to the original system of equations. If the solution space is low-dimensional but not 1-dimensional, then you can run conjugate gradient repeatedly after adding constraints to eliminate the kernel found so far. Conjugate gradient is an algorithm to minimize a positive-definite quadratic form. (If the system is not positive definite symmetric, you have to square or make some other change to fix that.) Thus it still works if you add constraints. 

I've written the codimensions of these constraints in parentheses. As before, you can combine these constraints. Certain pairs, such as 3 and 4, can't combine. You also can't use 4 three times. If you go through all of this properly, it is not all that hard to make a list of axioms that resembles the ones in 2 dimensions. (Possibly I made a mistake in this list or missed something, but it is not hard to go through this properly.) However, there is a possible subtlety that I don't know how to address. Namely, suppose that you do make some complicated configuration using combinations of these constraints, at first. Can you create a configuration with the property that the codimensions don't simply add? For instance, ordinarily you can't use condition 7 twice to define the reflection $R$, because the total codimension is 4, which is too large. However, if the lines and planes in this condition are related to each other, is the true codimension sometimes 3? I would guess that you can make this happen. If so, then potentially you'd have to add "unstable" construction axioms to the list. But then it is not clear whether an unstable construction axiom is actually needed, or whether an unstable axiom can always be replaced by a sequence of stable axioms. 

There are reasons that any modern example is likely to resemble the status of Legendre's constant. Most (but not all) interesting numbers admit a polynomial-time algorithm to compute their digits. In fact, there is an interesting semi-review by Borwein and Borwein that shows that most of the usual numbers in calculus (for example, $\exp(\sqrt{2}+\pi)$) have a quasilinear time algorithm on a RAM machine, meaning $\tilde{O}(n) = O(n(\log n)^\alpha)$ time to compute $n$ digits. Once you have $n$ digits, you can use the continued fraction algorithm to find the best rational approximation with at most $n/2-O(1)$ digits in the denominator. The continued fraction algorithm is equivalent to the Euclidean algorithm, which also has a quasilinear time version according to Wikipedia. Euler's constant has been to computed almost 30 billion digits, using a quasilinear time algorithm due to Brent and McMillan. As a result, for any such number it's difficult to be surprised. You would need a mathematical coincidence that the number is rational, but with a denominator that is out of reach for modern computers. (This was Brent and MacMillian's stated motivation in the case of Euler's constant.) I think that it would be fairly newsworthy if it happened. On the other hand, if you can only compute the digits very slowly, then your situation resembles Legendre's.