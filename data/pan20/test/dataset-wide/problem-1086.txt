And the list under "If you do encounter a full-table error, there are several reasons why it might have occurred:" 

Alternatively you can manage the delay of a replica using the MySQL Delayed Replication, note that this feature is available only on 5.6.x + MySQL version. I think that a good idea where to start (but there are many configuration for your scenario) is to have 2 node attached in replica, one standard replica and one delayed replica: 

A good starting point to make a decision in order to use or not this kind of value is the MySQL official manual. In short: Optimization 

Source: 5.1 Driver/Datasource Class Names, URL Syntax and Configuration Properties for Connector/J Running my java code using the above connection url the table are correctly converted (I have tried only with an empty table): 

performs the preceding optimization automatically if the MyISAM table into which you insert data is empty. The main difference between automatic optimization and using the procedure explicitly is that you can let myisamchk allocate much more temporary memory for the index creation than you might want the server to allocate for index re-creation when it executes the LOAD DATA INFILE statement. In order to obtain better performance from the myisamchk you have to tune some params like : 

Depending on your hw architecture Note When using with , a copy of the file is created in the server's temporary directory. This is not the directory determined by the value of tmpdir or slave_load_tmpdir, but rather the operating system's temporary directory, and is not configurable in the MySQL Server. So, you you have this kind of problem and your file it's a csv, you can split you "huge" file into chunks 

You can take a look into MySQL Fabric (Official Doc) but it requires more db server I have tried this tool only in R&D env for testing a basic HA It supports some sharding scenarios Here some high level pros and cons Pros: 

In this configuration you have all the advantages in case of a master crash(promoting the standard replication) and all the advantages for checking your "past" :) and/or a point in time recovery 

Another test you can try... "probably" in your table the cardinality of 'domain_id_resource_type' index is lower than 'domain_id', you can try to skip the optimizer choice and declare the usage of 'domain_id_resource_type' instead of 'domain_id' 

or by using the by pulling up the Table's Design and then just updating the name for the column and saving the changes. What I need to know is if either of these drops the column in question. I don't want to lose any of the data, I just want to rename the column name to something else. 

I'm wanting the best way to add a column to an existing table in my database. I'm using . I don't want the data that is in the table to be affected, I just want to add a new column that has a default value of . The only ways I'm aware of for adding a new column is by using: 

I'm needing to update a few column names in some tables I have in my database. I'm using . I'm aware of using the ability: 

update would the above query work if say the columns between the two tables are the same, but are in a different order? 

I need to generate either backups or data dumps for about 30 tables. I want to generate a file of some sort that contains the data for these tables and transfer them to a different system. Each table has 3.8-4.5 million rows. also a large number of these rows have columns with text that has newline characters which need to be handled correctly. I'm using and have . Due to security and other particular reasons I cannot just use for simply exporting tables from one database to another. I have a requirement to get a dump of the data to transfer to a remote system. I have tried capability, which does appear to handle the newline characters, however There is another issue. In some of the fields the text is similar to "something blah \". that slash causes a problem with the script that gets generated, because the process wraps that text in and with it basically escapes the single quote which corrupts the remaining data. I have also tried to generate flat files via and this doesn't appear to handle the newline characters correctly and again corrupting the remaining data. Any help would be greatly appreciated. and I can clarify any information that is missing. 

and the other way of adding a new column is by going into , bringing up the for the table I want to update, and adding the new column's information to the design. 

Putting your query into the function, cleaning your general query log for this kind of process require a bit of work Here a simple output of a "personal" file, like the above, with 9 query, 7 insert and 2 select, +2 BEGIN/COMMIT: 

For MySQL and PostgreSQL you can use the Snapshot Backups in order to obtain full or incremental backups: Some file system implementations enable “snapshots” to be taken. These provide logical copies of the file system at a given point in time, without requiring a physical copy of the entire file system. (For example, the implementation may use copy-on-write techniques so that only parts of the file system modified after the snapshot time need be copied.) It is available through third-party solutions such as Veritas, LVM, or ZFS. 

However before proceed check the documentation of your MySQL 5.1 version and make a backup copy of your ,, and file in order to avoid loss of data 

In order to synchronize(check database, object and data) the dev database with the production env you can take a look into the MySQL Utilities on these tools: 

In my previous response I have not taken into account behavior, so I have tried your test, first using the mysql native client and all works fine, column are automatically converted, and then using a jdbc connector and actually I got the same error... but after some test and some research I have found the solution. You have to add in your jdbc connection url the parameter and set it to 

See the sql_log_bin to turn off logging for the current session This condition is true only if you are sure that there is a single point of insert/update (your software with the dynamic declaration of sql_log_bin), on the contrary this condition fails if there may also be interventions by third parties, such as manual insert direct on the table. 

UPDATE 2015 FROM MY PREVIOUS POST 2012 :) You can take a look into MySQL Fabric (Official Doc) I have tried this tool only in R&D env for testing a basic HA It supports some sharding scenarios Here some high level pros and cons Pros: 

If your table is a MyISAM engine you can try to specify in your statement. Load data ref. Concurrent insert ref. 

UPDATE FOR FREE BLOCK EXPLAIN When you delete a row a free block can occur, if you have free blocks in the "middle" of your insert, for example if you replace deleted rows(index and/or primary key) with your load data, concurrent insert do not work, when free blocks are filled in future insert become concurrent again.