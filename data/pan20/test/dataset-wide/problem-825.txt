Whilst awaiting clarification, I'm going to assume that your question is asking about calibrating the reference frame within which the motions of stars at the Galactic centre are measured. The process is described by Ghez et al. (2008); does not involve observing quasars at infrared wavelengths; and the study does not suffer as a result. The Galactic centre adaptive optics images are 5-10 arcseconds across, but contain thousands of stars. Only a fraction of these are close to the Galactic centre. The ensemble can be used, iteratively, to define a relative reference frame by minimising the displacements of thousands of stars, excluding those very close to Sgr A* and those with large motions. This is really all that is required to do the orbital analyses of the black hole. To put the coordinates in the International Celestial Reference System, a wider field is observed that contains a few infrared-bright giant stars, that are also bright maser sources at radio wavelengths. The positions of these are used to bootstrap the coordinates onto the ICRS, and this is important if, for example, we are interested in the relative motion of the Sun around the Galaxy. The maser sources have ICRS positions by virtue of their radio source positions versus the radio coordinates of distant (but still bright and point-like) background quasars.The issue of background sources, extinction and confusion does not arise at radio wavelengths. 

No. There is no consensus. The discrepancy between the predicted big bang nucleosynthetic abundance of Lithium 7 and the measured value can be summarised as follows. If we take what we know about the the baryonic mass density of the universe and the Hubble constant, we get a self-consistent picture between the cosmic microwave background, observations of galaxy recession etc. and the estimated primordial abundances of Helium and Deuterium. The problem arises because these same cosmological parameters predict a primordial lithium abundance of $3\times10^{-10}$, when expressed as a ratio to the hydrogen abundance. On the other hand, measurements of the Li abundance present in the photospheres of the oldest stars (a.k.a. "halo stars") in our Galaxy suggest that the primordial abundance was about $1.2\times10^{-10}$. The factor of 2-3 difference between these numbers is about 4-5 times the measurement precision. This is the so-called "Lithium problem". The potential solutions are reviewed by Fields (2012). They fall into the following categories. 

Let's be generous and say it is a perfect reflector, but we can't assume specular reflection. Instead let's assume the reflected light is also scattered isotropically into a $2\pi$ solid angle. Thus the radiation we get back will be $$ f = \frac{L}{2\pi d^2} \frac{\pi r^2}{2\pi d^2} = \frac{L r^2}{4\pi d^4},$$ where $r$ is the radius of the thing doing the reflecting. To turn a flux into an astronomical magnitude we note that the Sun has a visual magnitude of $-26.74$. The apparent magnitude of the reflected light will be given by $$ m = 2.5\log_{10} \left(\frac{F}{f}\right) -26.74 = 2.5 \log_{10} \left(\frac{4F \pi d^4}{L r^2}\right) -26.74 $$ So let's put in some numbers. Assume $r=R_{\odot}$ (i.e. a reflector as big as the Sun) and let $d$ be 1000 light years. From this I calculate $m=85$. To put this in context, the Hubble space telescope ultra deep field has a magnitude limit of around $m=30$ ($URL$ ) and each 5 magnitudes on top of that corresponds to a factor of 100 decrease in brightness. So $m=85$ is about 22 orders of magnitude fainter than detectable by HST. What's worse, the reflector also scatters all the light from the rest of the universe, so picking out the signal from the earth will be utterly futile. 

Stellar encounters are very rare outside dense stellar environments. Such dense stellar environments are only found in a star's birth cluster, where all the stars are coeval to a close approximation. Thus the switching and capture you refer to is probably common in the first few million years of a star's life, but would occur with stars of a similar age. Thereafter, once a stellar system is "in the field", encounters with other stars hardly occur at all, but are not impossible. I am not aware of any binary where the components are thought to have a very different age. 

The Hertzsprung-Russell diagram is an observational tool. The axes are things that can be observed, or at least estimated reasonably well, for most stars (well, those with known distance anyway). We cannot in general measure the masses of stars - only those in some binary systems. The schematic that you show, with an arrow indicating that mass increases with increasing luminosity and temperature is valid for stars on the main sequence. It is not generally true. Whereas the arrow showing increasing size to the top right is always correct, since it merely depends on the other two axes as $L \propto R^2 T^4$. If one were to add a third axis to the HR diagram - and this is not a bad idea at all - then the possible axes I would choose are: (i) Something representing photospheric chemical composition, probably overall metallicity [M/H]. This has the advantage of being measurable for large numbers of stars, and increasingly so given the very large spectroscopic surveys now taking place on many telescope (SDSS, Gaia-ESO, RAVE, LAMOST etc.) On the other hand, stars with similar masses but different compositions already separate in the luminosity-temperature plane reasonably well, so another possibility might be: (ii) Surface gravity. You are correct that stars of different mass but similar radius can end up appearing in more or less the same place in the HR diagram. However, they have different surface gravities. This can be measured from detailed analysis of spectra and would provide an interesting third axis. 

The semi-major axis can only be estimated (a lower limit), from a single image, and only then if you have a good distance to the star/planet system. The angular separation is converted to a projected linear separation. A perfect example of the above is the estimate of the mass and orbit for the exoplanet GJ 504b (Kuzuhara et al. 2013). With more images spread over an appreciable fraction of the planet's period one can be more accurate. The projection of the elliptical orbit can be mapped, yielding the orbital inclination and thus a better semi-major axis measurement. The orbital period can then also be roughly estimated and checked for consistency with Kepler's third law and an estimate of the stellar mass. Note though that currently imaged planets have orbital periods of at least decades. Wang et al. (2016) give an example of this approach for beta Pic b. A dozen precise images constrain the semi-major axis to a few percent and give the total system (star plus planet, but dominated by the star) mass. 

If you also have photometry, then there is a reasonably accurate conversion between the apparent magnitude and the continuum flux (per unit wavelength interval) at the wavelength of the photometry. Once you have this conversion factor, you multiply your equivalent width by it to get a flux. 

It doesn't work like that. An observer at the light source (and indeed any observers anywhere else) will always see light travelling (in vacuum) at the speed of light locally. There is also a major problem with your thought experiment. It is not possible for you to have a stationary light source within the event horizon of a black hole. It, and everything else in its vicinity, must be moving inwards. This is as inexorable and unavoidable as is the passage of time for an observer outside the event horizon. In my opinion, the best "visual" way of thinking about the situation inside the event horizon is to imagine your photons of light like salmon trying to swimming upstream, whilst you are on a boat flowing with the stream and releasing the salmon into the water. You will always see the salmon swimming at some speed with respect to your boat. Unfortunately if the stream flows fast enough then the salmon will make no progress and you will both be swept over a waterfall (the singularity) a little further downstream. Likewise, your common-sense fails with the situation of firing light towards a black hole. Light is always measured to have a speed of $c$ locally. It is following through with the consequences of this principle that leads to all the weird behaviour that black holes exhibit. 

It is possible that you have not understood the definition of inclination angle. This is the angle between our line of sight and the orbital axis of the star-exoplanet pair. Maximum amplitude radial velocity variations are seen when the inclination angle is 90 degrees. No radial velocity variations are seen when it is zero. The answer to your question is just that if the inclination angle is close to 90 degrees you will see transits. If not, then you won't. Nothing definite can be ascertained from the radial velocity measurements alone. 

The scenario you describe may occur. On the other hand it may actually be that neutronisation in a white dwarf is the trigger for a thermonuclear type Ia supernova. You may be misunderstanding the Pauli Exclusion Principle (PEP).The PEP states that no two fermions can occupy the same quantum state, not that they cannot occupy the same space or be compressed to whatever density you like. The quantum states here consist of two spin states for every possible momentum state. In a degenerate gas, all these states are filled up to the Fermi energy. All that happens when the neutron star gets smaller (or collapses), is that the Fermi energy just keeps increasing as the neutron density climbs, and the neutron degeneracy pressure just keeps increasing as a consequence. However, in General Relativity, pressure (like mass/energy) is a source of gravitational curvature and actually increases the required pressure gradient needed to support the star. At a certain threshold radius - a small factor larger than the Schwarzschild radius, a point of instability is reached where increasing the pressure is actually counter-productive. Beyond this, you can make the pressure as large as you like and it will not prevent the formation of a black hole. Even inside the BH there is not necessarily a problem with the PEP. You can compress fermions to infinite density so long as they can have infinite momentum. 

I could offer a couple of speculations - but there is no "theory". Incidentally, I was looking at the refereed journal paper by Baumann et al. (2010). 

A single direct image of an exoplanets can give an estimate of the mass and orbital period of an exoplanet. For the former, you need a model for how the luminosity of a giant exoplanet (which all the directly imaged ones are) evolves with time, as a function of mass, and an estimate of the age. One simply looks up what mass of planet would have cooled to its current luminosity at the age of the star that hosts the exoplanet. The luminosity measurement needs an accurate distance to the system and benefits from observations at multiple wavelengths. Realistically, these masses are uncertain by a factor of two at least, because of cooling model uncertainties. Here is an example of this applied to various directly imaged exoplanets. Evolutionary tracks for various masses are shown in the luminosity versus age plane. Note the size of the age error bars and that is before you factor in uncertainty in the models (two flavours, "hot start" and "cold start" are shown as solid and dashed lines respectively - from Bonnefoy et al. 2013). 

Solar flares are observed at wavelengths right across the electromagnetic spectrum, not just H alpha. The basic model for a solar flare starts with the magnetic field in the corona. You can think of the topology of the magnetic field to consist of loops that poke up out of the photosphere and extend into the corona. However, the photosphere of the Sun is turbulent and constantly in motion due to convection and differential rotation. Whilst a loop may be formed in a minimum energy state, it can get twisted and stressed by these motions. At some point an instability is reached and the magnetic field can undergo a "reconnection" event, to flip back to a lower energy configuration. During this event, charged particles are accelerated and travel down the magnetic field lines towards the photosphere. Before they get there, they encounter the chromosphere, which is where the bulk of the particle kinetic energy is deposited. i.e. the density increases as you go down towards the photosphere and once a certain column density is reached, the accelerated electrons are stopped and deposit their kinetic energy. This results in heating and excess H alpha emission from material at about 10 thousand kelvin in the flare footpoints. Any hotter than this and all the hydrogen is ionised. The H alpha is in emission because the only material above it is optically thin to the H alpha radiation. There is hotter, ionised material produced too, and much of this is evaporated such that it fills the magnetic loops with X-ray emitting plasma at temperatures of more than a million kelvin. Some of the flare energy may also be used to accelerate material away from the Sun in "coronal mass ejections". 

The answer is yes. As the Sun ages, it will become a red giant and the mass loss rate from its surface will increase. This effect will increase (dramatically) further when the Sun enters the asymptotic giant branch phase, where thermal pulsations drives a cool wind that may carry away a millionth of a solar mass per year, eventually leaving a burned-out core in the form of a white dwarf with about half a solar mass. At any point in this evolution we can model the evolution of the Earth's orbit using some simple approximations - that the wind from the Sun escapes to infinity, that a negligible proportion is actually accreted by the Earth and nor does it exert a torque, that the mass loss takes place on a timescale much longer than the Earth's orbit and that the mass of the Earth $m$ is always much less than the time-dependent mass of the Sun $M(t)$. In which case we consider the orbital angular momentum of the Earth: $$ m a \omega^2 \simeq G\frac{M m}{a^2},$$ where $a$ is the semi major axis. So the angular momentum $J = m a^2 \omega$ is given by $$ J^2 = m^2 a^4 \frac{G M m}{m a^3} \propto M a$$ As the angular momentum of the Earth's orbit is conserved, the $M(t) a(t)$ is constant and as the Sun loses mass, the semi major axis increases by the same factor. Coming to the specifics - when the Sun is a half solar mass white dwarf, the semi-major axis will be 2 au (assuming the giant Sun did not quite engulf it - it will be a close-run thing) and Kepler's third law $(P^2 \propto a^3/M)$ can be used to estimate an orbital period of 4 years. The tidal effects of the Sun on the Earth's orbit are quite negligible compared with these mass loss effects. 

There is a predicted cosmic neutrino background, analogous to the cosmic microwave background. Neutrinos decoupled at 1 second after the big bang, filling the universe with neutrinos that should have now cooled to a temperature of about 1.9 K. Confirming this would be a(nother) spectacular validation of the big bang model. However, there is a wrinkle; now that we know neutrinos have mass, it turns out that these neutrinos are non-relativistic at the present epoch. That means they are capable of being diverted and concentrated by gravitational structures - potentially making them fantastic probes of such structure and perhaps more sensitive than photons. So neutrino telescopes would make a fantastic contribution to our understanding of cosmology. Neutrinos arise from energetic processes in the cores of stars. These processes are otherwise invisible, we certainly can't see them directly with light and can only probe them indirectly using techniques such as asteroseismology or looking at the mixing of chemical elements from the core to the surface. Neutrinos potentially tell us much more; for instance giving a direct estimate of the number of nuclear reactions taking place per second. Neutrino emission is also the predominant way that cooling takes place in supernovae, and in hot neutron stars and white dwarfs. A neutrino telescope could therefore be fundamental for a deep (literally) understanding of stellar evolution and particularly the late stages of stellar evolution. 

The first supermassive black holes must have been formed earlier than about 750 million years after the big bang, since there is evidence for luminous quasars at redshifts of up to 7 and with likely black holes of a billion solar masses or more at their centres (e.g. Momjian et al. (2013). The candidate mechanisms to produce such objects in a short period of time are hyper-Eddington accretion onto stellar black hole seeds; the direct collapse of large, primordial gas clouds into black holes; or the merger of stellar-sized black holes in dense clusters, followed by gas accretion. These possibilities are accessibly reviewed by Smith, Bromm & Loeb (2017).