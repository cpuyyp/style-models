How you deal with infinity depends on what your priorities are. If you care only about sheer cardinality — as Frege did, as he was considering set theory — you can quite easily have an infinite set, with a proper subset having the same size. But to have this, you must ignore most if not all structure in the infinite set, and define "size" by considering bijections in a very flexible way. It's quite possible to consider a notion of "size" for subsets, where you consider not whether you can describe a bijection between the subset and its superset, but just whether the set-difference has any non-zero elements. But how then to compare two sets for which neither is a subset of the other? It depends then on which functions you consider to be "size"-preserving. In measure theory, we consider sets not by cardinality, but by how we may describe it as a (limit of a) union of disjoint intervals; and the mappings which preserve "size" are just translations by positive or negative shifts. Removing individual elements may be seen as infinitesimal decreases in size. But in any case, this requires a commitment to certain priorities in how to describe infinite sets; so that an uncountable set such as the Cantor Set has the same measure as a finite set, i.e. zero. There are multiple formalised ways to describe and consider the infinite. None is obviously "truer" than the others; they are all merely tools which are better or worse for considering different questions. So what is most important is to make sure that you are asking the right question about infinity, and then to identify the right tool to solve your problem. 

then I would say that yes, it is straightforward to have something which is logically impossible but actually possible. The reason for this is that you do not specify which concepts — or models — of reality you are concerned with. For a half-serious example, consider the dramatic revelation in Star Wars: Episode V (The Empire Strikes Back). Luke's reaction to the revelation that Darth Vader is his father is disbelief: that it is impossible. Whatever emotions drove this reaction, it is likely that this was his reaction to the fact that the assertion contradicted his mental model of Darth Vader and Anakin Skywalker being seperate individuals, one of whom literally killed the other, as Ben Kenobi described in Episode IV. Relative to this model of reality, it was logically impossible for Darth Vader to be Anakin Skywalker, because it violated an assumption used in constructing the model. But if we accept what is asserted or demonstrated by the later Star Wars films, it was in fact actually possible, and indeed true. More seriously, discovering things which are actually possible but which are logically (more accurately, theoretically) impossible, is a good approximation to how science works according to Popper: by falsification. If a theory predicts that something should not happen (or is impossible to make happen), but which subsequently does happen, this invalidates the theory. For this reason, I would prefer to call this "theoretical", rather than "logical", impossibility, because it places the fault clearly where the failure of the model can more easily be remedied — by improving or replacing the theory. In modern science, where we accept that probability may be an unavoidable feature of physical theories, we are presented with a more complicated situation. When a theory predicts one probability distribution, but experiment produces another, has the theory been falsified even if we assume that the experiment was "executed perfectly"? With probabilities, there is always of course a non-zero chance of freak occurrances in which events drawn from one distribution resemble another. This is of course less likely, the more random samples you take, but in most cases you cannot actually rule out the possibility that one distribution will in practise, with a finite number of samples, produce the curve of another. We then move from impossibility to improbability — where we might ask whether something is actually probable while being theoretically (or logically) improbable. This is a somewhat more nuanced, but still essentially Popperian notion of falsifiability: we accept that there can be such events, and that when they arise they indicate a failure of the theory. 

Predicate logic is somewhat like propositional logic, except that where propositional logic only works on the level of whole sentences (e.g. A = "Socrates is mortal", B = "All Scottish people eat their porridge plain"), it allows you to talk about individual objects (e.g. "Socrates", "porridge") and consider properties of these objects in any relationship to one another to try and get at other relationships that the objects might have. But predicate logic also involves things called "quantifiers", which are written " ∀ " and " ∃ ". They're called the "universal quantifier" and the "existential quantifier", and have some sort of connection to sentences starting with every X, any X, some X, and no X, where X is some noun like "person", "pie", and so-on. How do we use them to describe statements like "No true Scot adds anything to their porridge", "One of the people in this room is a murderer", or "I'm the one and only Elvis Presley"? 

The question of how A can prove to B that she is indeed an atheist is quite similar to the problem proposed by the Turing Test, for A to prove to B that she is human. Of course, a clever enough electronic computer can in principle fool B, if he is incautious or not sufficiently sophisticated, that A is human. (Indeed, this has happened already; we just don't take tests involving Eliza, and the people that she can fool, very seriously.) For the same reason, any sufficiently sophisticated theist A can convince an insufficiently skeptic enquirer B that she is an atheist. Indeed, the Turing Test is in practise a scheme not for testing human-style intelligence, but whether or not the person you're speaking to is in some measure a social peer: whether their behaviour is in accordance to some mental model of someone like you. More generally, it's a scheme for testing whether someone conforms to some mental model that you have of a kind of person or other interactive system. What can be learned from Turing-style tests is whether or not your interlocutor fits a certain mental model for someone who more or less conforms to some standard of behaviour, whether that is human-like or atheist-like. As with Turing's own position on the Turing Test as applied to intelligence, the question of whether or not A actually has human-style intelligence, or an atheist — which is beside the point — but whether their observable behaviour is close enough to being so, however that behaviour arises, that it is parsimonious to treat them as having human-style intelligence, or as an atheist. This is what we do in everyday life with emotions, political positions, etc. Ultimately, only through their acts can you know them. 

At issue here is how specific one wants to make the metaphysical argument. Do you want a priori principles, or not? Suppose however that you are indeed attempting to justify this old principle on new grounds. The question then arises as to what sort of continuous changes you admit. After all, quantum mechanics is a continuous theory dealing with discrete changes: how is it that it admits the possibility of change with time? The answer is: by continuous change in amplitudes, the quantities which give rise to the probabilities of various outcomes in a physical process. How this plays out, for instance in nuclear decay (a process in which we may smoothly transition from having none of some nuclear decay product, to some of it) is that there is a continuously evolving probability of some process occurring in the nucleus, which causes some particle(s) to be ejected. If you imagined continuously observing some atom in a non-disturbing way, the transition would appear to be discontinuous; but it nevertheless came about by a continuous process to the best of our knowledge. You might complain that this is still at its root discontinuous, as evidenced by my description of continuous observation. Setting aside the fact that this seems anyway to be how quantum mechanics works (by continuous evolution of amplitudes between configurations which seem discrete) and that it's up to oneself how to come to grips with it, there's also a problem with the "continuous observation" description that I gave. That is, no observation is non-disturbing; and in this case the effect of continuous observation would be to prevent any change. This is known as the quantum Zeno effect, and leads me to the second criticism. At issue here is that there are changes which seem discontinuous to us at first glance, but may be an artificial distinction of our own making. A similar, but more poignant example than nuclear decay is simple motion through space. Achilles stands to my left. He shoots an arrow at a target, to my right. (I stand outside of the line of fire for the purposes of this argument.) If Achilles aims truly, the arrow — specifically the tip of the arrowhead — eventually changes from being on my left to being on my right. Is this not a discontinuous change? Even if you grant that for some time between it is in front of me, that just replaces one discontinuity (left/right) with two (left/front, front/right). Indeed, if space is made of distinct points, then there is a continuum of discontinuities, as the arrowhead passes between points. Then how is motion possible? The modern answer is that the points in space are distinct, but not equally so: points which are closer together are "less different" than points which are further apart. This is after all the root of the concept of the continuum. Similarly, the distinctions left/front/right are artificial: not meaningless, but nevertheless ones introduced by ourselves, and coarser than the reality we attempt to describe. Not all points "in front" of me are equivalent, so I should not be shocked when the arrow comes to be in front of me when previously it was on my left. Even in quantum mechanics there is a puzzle to be solved with respect to the nature of time: it is not possible so far as we know to define "the point in time that the arrow passes in front of me" as a crisply defined physical observable, because continuous observation of a sharply defined region of space in front of me would actually prevent the arrow from entering that space! (Here I obviously don't refer to casual observation with the eyes, but a hypothetical apparatus which instantly detects any intrusion by the arrow into the space — which, in doing so, ironically creates an impregnable barrier to entry for the arrow.) One simple solution is that such rigorous and acute observation is impossible; which may well be described as a consequence of the (infinite) energy demands necessary to make observations of unlimited precision, to distinguish sharply between two "régimes" which meet at a thin boundary. Similarly, the transition from "nothing" to "something" is a binary distinction which we are making about possible worlds, in which not all amounts of "something" are equally distinguishable from "nothing". As my example of Achilles shows, if you impose such binary distinctions too dogmatically, you may have to accept an apparently discontinuous description of the world as the price of your insistence, in order to avoid paradox.