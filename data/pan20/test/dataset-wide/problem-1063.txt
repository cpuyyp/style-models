I'd start with querying AD directly. If the feature was heavily used, slow, or placing a strain on AD servers, I'd consider caching the entire data set in memory. Its a pretty small dataset, does it warrant the effort of setting up a database and the necessary ETL to load regularly? 

Edit: @AlexKuznetsov's comment prompted my re-reading the question and removing the very obvious error in my answer. Note to self on late night posting. 

The syntax Aaron suggested would also function as you require at . The same would be achieved by specifying a hint on : 

Or, if you aren't clustered go the tempdb route and drop your state database, by re-running with the option . 

In a similar vain, if you were to suffer corruption to the database metadata (a rare occurance compared to corruption in data structures but not impossible), you would only need to restore the very small primary filegroup to get up and running. The availability benefits this can bring to a large database are so significant, I try design partial availability in from the outset on new projects. A 500GB database restoring at 50MB/s will result in at least 3 hours of explaining why it's taking so long to the non-techs. With forethought and planning, it could be a fraction of that to get the business up and running again. 

Further to my comment this is, putting it as politely as possible, a moderately crazy approach to getting the job done. 

If you can format the output of this into a readable form and add to your question, someone can make a more educated guess at the best use of your 18 disks. If I was doing this blind, I'd probably start off allocating: 

There is rarely any need, point or benefit trying to micro optimise star schema queries with non-clustered indexes laden with included columns. Fact tables are built to be scanned. The indexes you've created in your examples are subset copies of the parent table, which are being scanned (no seeks). The minor performance improvements come from scanning marginally fewer pages than the parent table. Given that star schemas are built to support ad-hoc query patterns it is not viable to create the indexes to support every possible enquiry. 

My guess is that you would want to use an Oracle wallet so that you don't need to embed the username and password in your application at all. Depending on the architecture of your application, there may be other options as well-- if you're building a Java application that is deployed to an application server, for example, most application servers have a way to configure connection pools such that only the encrypted password is stored in a configuration file. 

Can (and do) people successfully deliver projects that do this sort of thing? Unfortunately, yes, they do so reasonably often. Is this a good approach? No, it's not. You're basically taking your relatively expensive database and turning it into a relatively slow file system. If you really want to build a system that saves its state by serializing and de-serializing objects, you may as well use a file system rather than using a database. If you build systems that store data by serializing objects into the database, you won't make friends with your DBA. You'll end up storing redundant data. You'll end up with terribly inconsistent data-- any time shared data is updated, some objects will end up with the new values and some objects will end up with the old values. You'll make it impossible to do any sort of reporting on the data-- everything that anyone wants to do with the data is going to require someone to write additional code. That's a huge, huge issue in most enterprises because they want to do things like extracting data from one system to load into another system or to have a reporting system that can deliver reports from multiple front-end applications. Plus, as you point out, you're constantly going to have to deal with issues when you're evolving your data model. Are there advantages to this approach? I guess you can argue that it's pretty easy to implement the first version of the app. And it lets the developer completely ignore anything related to properly interacting with a database. I'm hard-pressed to imagine many cases where these advantages outweigh the numerous downsides to the approach. As for how you should deal with this particular professor, that's a separate issue (and one that's probably out of scope of this forum). If your professor is actively developing projects in the real world, he's probably not going to be terribly receptive to any argument from a student that his approach is fundamentally wrong (even if the approach really is fundamentally wrong). You may be better served doing your project the way the professor wants and learning the proper way to save data on your own (or in a different course). 

Intent-Exclusive lock on MyTable Intent-Exclusive lock on the page 1:211 RangeInsert-NullResource on the clustered index entry for the value being inserted Exclusive lock on key 

There is a do-not-ever-do-this-in-a-live-environment hack you can use where space is limited, by restoring the log file to a compressed folder. Attempt this by compressing an existing folder and restoring to it will result in an error, so you have to cheat with a symbolic link. 

Back to the original question. If you're measuring time taken to do work plus the commit, rollback is winning hands down because the majority of that work is spent finding the row to update, not actually modifying data. If you're looking at the commit operation in isolation, it should be clear that commit does very little "work" as such. Commit is "I'm done". 

Appropriate size for the log is of course dependent on your observations of log usage for each database. 

Despite your approach not being the fastest way to do this, it should work. Can't explain what's going wrong but can suggest a different method. Can you try the following: 

Are they really transferring the mdf file to the DR site? If so, stop, now. If thankfully backups are being taken, or you can persuade them to start taking backups instead of shifting the mdf, split the backup to multiple files. 

For performance data you'll want to look at installing the Management Data Warehouse alongside your Central Management Server. It isn't as useful as the various 3rd party tools for collecting SQL performance data but it's an improvement on roll-your-own Perfmon/SSRS/Excel solutions. 

Of course, this may be a really bad idea. All we've achieved is swapping a clustered index seek with a non-clustered index seek. Without seeing the full query, its impossible to say whether its the "right" thing to do. My initial thought is that a clustered index seek (key lookup) for 500 rows in what appears to be an analytic type query is likely to be reasonable. You refer to this lookup as being slow but in what context? Is it just the highest estimated cost operator in the plan? If ultimately this query is looking at data across a timespan, it may be that DateForValue would be a better choice as the leading key: 

That depends-- are your data files set to autoextend? If they are, they'll just grow themselves up to whatever limit you may have set (or to the size of the available disk). If not, whenever the database tries to allocate the next extent in the tablespace, the operation will fail and whatever is trying to write data to a table in the tablespace will fail. There are many products that you might install in and any one of them might be the unlucky one that needs to allocate the next extent so you can't really predict what impact that would have. I'd guess that you'd stop being able to write audit information since the audit trail is commonly in and commonly the most prevalent user of space among products that are commonly installed in . You can check whether your data files are set to autoextend by looking at the attribute in . 

Assuming you are creating the index in the same tablespace that it was previously in, the size of the data files associated with that tablespace on disk should not change and the free space in the tablespace should not decrease. Of course, normally you are dropping the index so that you can do a large data load, and then rebuilding the index. If that is the case, assuming the table (or the partition you're loading into) and index are in the same tablespace, it is likely that the bulk load will use the space in the tablespace that the index had previously been using so when you go to recreate the index so the data file may need to grow when you build the index even if the index is no larger than it was. If you are doing a bulk load, it is also likely that the index will be larger when it is recreated simply because the underlying table is larger and the size of the index is proportional to the size of the table (of course, the size of the index increases as ) 

I've been tempted to bypass that flag also but have come down on the side of your co-workers and now try to deal with these issues "correctly". The (marginally) less clunky route is to use pre and post deployment scripts to do the work with a rename. 

There are a couple of trace flags that can help with statistics on ascending keys, TF2389 and TF2390. Since 2005SP1, SQL Server has identified and "branded" ascending keys. If TF2389 is set and the leading column of a covering index is branded, the statistics for the column will be updated automatically by identifying the highest key value and updating the existing histogram. Enabling TF2930 causes the same update to occur where a column hasn't been identified (branded) as ascending. Keep in mind that the statistics update occurs during query compilation, so if recompilation is rare you may want to test a RECOMPILE hint on some procedures or queries to force an update. Alternatively, a periodic sp_recompile on the procedure may help if the cost of compilation is high. Statistics on Ascending Columns is a great article that covers the mechanics. NB: Usual caveats to using trace flags apply... test, test and test some more. 

The optimiser detects star schema query patterns and has strategies to deal with them efficiently, utilising scans and hash joins in Standard Edition or bitmap filtering in Enterprise. Follow the indexing strategy outlined above and let the optimiser deal with the rest. 

Mirror/snapshot combinations can also be beneficial if you want to run ETL over an OLTP database to load into a data warehouse. Example architecture in this article on SSC. The advantage in both cases is removing the overhead of running a replication feed, if you can convince your users that an hourly lag on reporting data is acceptable. In the vast majority of cases it is perfectly reasonable but the perception can be tough to change. 

It depends on why you are creating the temporary tables in MySQL. Frequently, people that are creating temporary tables in other databases are doing so in order to work around limitations that don't exist in Oracle where readers don't block writers and writers don't block readers. In other databases, you commonly copy data from a permanent table to a temporary table so that your process doesn't block some other process that needs the same data. Since Oracle provides multi-version read consistency, however, this isn't necessary (or beneficial) in Oracle-- your process can process the data sitting in the real tables without worrying that it is going to block someone else. If that's the situation you're in, the proper response is simply to remove the temporary tables and process the data from the permanent tables. Assuming that you really need a temporary copy of the data, you can create global temporary tables. You would create these tables outside of your code just like a permanent table and use them just like a permanent table inside your code. The global temporary table ensures that each session can only see the data that session has inserted. The only difference is that you're not dropping and recreating the structure of the table inside your procedure. Another alternative would be to pull the data into a PL/SQL collection that you work with rather than using a temporary table. PL/SQL collections are stored in the server's PGA (one of Oracle's memory structures) so you generally want to limit the size of the collection particularly if there is a lot of data to process or there could be many sessions processing data simultaneously. You can do something like 

Technically, you could create a Java stored procedure or a external job that you invoke from your APEX process. Doing so, however, would almost certainly be a mistake. First, you'd have the issue of concurrency. If you did invoke your Python script from within your APEX process, for example, that process would start immediately and would not wait for your transaction to complete. Assuming you made a synchronous call, when your script ran and accessed the database, the row you inserted into the table would not be visible because your transaction would not have committed yet. If you made an asynchronous call, the row might or might not be visible because the transaction may or may not have been committed yet. Additionally, your APEX process might encounter an error later on in some other page process that would cause the transaction to be rolled back which would also cause the script not to be able to see the row. Breaking up the transaction so that you commit before calling your script would ensure that the row was visible but would probably create a number of other data consistency and data quality issues in your application. It would almost always make more sense to implement some sort of queuing mechanism instead. Whether you use Oracle AQ or whether you just write into the table and have separate job that reads from the table and runs your Python code is less important than the existence of some sort of queue. That decouples the two pieces of code-- the code that writes requests can have proper transactional boundaries while the code that reads requests doesn't have to worry about trying to process requests that haven't been committed yet or that may have been rolled back. That is not convoluted and fragile-- that is a much more robust approach. Yes, you potentially need to monitor the job that is processing requests (you may be able to rely on existing monitoring of the Oracle alert log or of the log of whatever scheduling tool you already use). But that's generally much easier than trying to debug why some requests didn't get processed or why the external script keeps failing to find rows.