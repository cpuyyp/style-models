Install .net 4.5 on a server running a .net 2.0 application and what happens? Nothing, you're application continues to use the 2.0 framework. Update your LastIndexOf function on a server hosting 3 applications databases (as part of an upgrade to one of them) and what happens? All three are now using the latest version. The alternative is the approach adopted by SQL#. This is installed to a schema in each user database, so you can safely upgrade the database for Application-X without risking the stability of Application-Y. If you're working in a tightly controlled change management environment you'll have no choice, you can't upgrade a shared component without testing all consumers of the component. If you're working somewhere a little more "fast and loose", you're free to take your chances with breaking something unintentionally with a patch/upgrade. 

Security through obscurity is not security at all. Edit: then again, some say it is! Personally, I'll continue to adopt my original point. 

For SQL Server we have the option of the FORCE ORDER hint. The only comparable I'm aware of for MySQL is STRAIGHT_JOIN. 

In the installer select Maintenance/Edition Upgrade to upgrade your existing instance. Run the installer again and select Installation/...or add features to an existing installation/Add features to an existing instance. 

The MSDN/BOL topic for DECLARE CURSOR contains example syntax for cursor usage. That said, as I had 5 minutes to spare on the train this morning... 

The locks are then released in reverse order. At no point has an exclusive lock been acquired on the table. 

You can use DDL triggers for this. There doesn't appear to be a DDL event raised for attach but there definitely is for CREATE DATABASE. You could work around this by denying rights to sp_attachdb and force everyone to use CREATE DATABASE FOR ATTACH instead. The following example feels like a bit of a hack, so hopefully someone with more DDL trigger experience will propose a neater way of doing this. 

I agree with @RemusRusanu, a move to 64bit is pretty much guaranteed to take the pain away. As that move to 64bit might not be something you can JFDI tomorrow, I'd be inclined to invest a little more time investigating while planning the upgrade. You might be able to get your head above water by alleviating the issue temporarily. Good reference post for virtual address exhaustion on 32 bit is How to find who is using/eating up the Virtual Address space on your SQL Server. In particular pay attention to the list of components that require allocations outside the buffer pool. I'd also eyeball the 3rd party monitoring/backup components you mentioned. 

If you're evaluating VS2010 for database development, your bible will be the Visual Studio Database Guide from the Visual Studio ALM Rangers. Any quotes that follow which don't have references will be from this document. Off we go then... Why is the database development process different from application development? Data. If it wasn't for that pesky data, database development would be a doddle. We could just DROP everything on every release and forget about this troublesome change management. 

IIRC it may be necessary to disable the features at the card driver level in some circumstances, it certainly won't hurt to do so. 

Index maintenance (rebuild/reorganize) and DBCC CHECKDB activity most likely, possibly statistics updates. Any scheduled maintenance configured? If there is no user access, bin them. Just be mindful of the time frame over which you decide they are no longer used. Are there any weekly or monthly reporting tasks for instance? While you're looking, dig around for duplicate indexes as well. Edit: regarding SSC link From a quick scan through the thread, looks like the SSC folk had similar thoughts. They are however taking a more cautious stance on the possible "occasional" use of these indexes, taking the position that someone put them there for a reason, a perfectly reasonable argument. The counter argument is that all too often it's the exact opposite, someone put them there because they thought it was the right thing to do but through a lack of understanding or lack of testing, it wasn't. I've brought a couple of systems back from the brink by doing nothing other than dropping unused and duplicated indexes. Over indexing can cause chaos. It's your system, you need to understand and weigh the risks of leaving these indexes in place or dropping them. If you decide to go ahead with the drop, document what you do, why you're doing it, script the indexes and publish to all interested parties. 

Your intuition serves you well, they are indeed probably useless. You can confirm whether they are being used or not via the sys.dm_db_index_usage_stats DMV. Kimberly Tripp's 'Spring Clean Your Indexes' articles are as good a place as any to start. 

While there is variation across drive models, you can apply a rough and ready figure to each of the common rotational speeds. 

reports a count of statements, not active transactions. From a different perspective, it is reporting the depth of a nested transaction. 

Daft as it may sound, try pushing either the [id] or date predicate into the query. See SQL Server 2005 Full-Text Queries on Large Catalogs: Lessons Learned - Consider embedding filter conditions as keywords in the indexed text. I don't remember where but I recall reading an article or blog post some time ago that flagged big full-text queries as problematic. IIRC the suggested hack/workaround was to issue a query instead. 

Stop/start the service, nothing else will release the memory back to the OS. Obviously not something you'd ever want to do with an operational server but perfectly reasonable for a local sandbox. With 3 different instances on my laptop, its the only viable way. Edit following @Nick's comment. 

Assuming your intended option B is to have UserKey in Alerts and for UserKey to be an INT rather than VARCHAR(50)... you might save some space and improve performance marginally if you expected there to be a very large number of alerts per user. But it's going to be minimal so I'd probably stick with option A. The inefficiencies of GUIDs are due to their size (16 byte) compared to an INT (4 byte) and the fragmentation they inevitably lead too, unless sequential. This is magnified where a GUID is used as a clustered index key (as is the case for your User table?) because all non-clustered indexes contain the clustered index key. Kimberley Tripps series of articles on the topic are good grounding for understanding this. Option B 

I have a stock of scripted trace definitions that I use for different levels of diagnostics, none of which filter by HostName. I needed to filter traffic by host today so: 

I've tried this on 2005SP3 and 2008R2 so far, same results on both. Any thoughts as to what might cause this? 

Don't. Design your API according to RESTful principes, design your database according to normalisation principles. One does not need to impact upon the other. Your database should not contain a table, it should contain a (or purchase/order) table. That table will include a primary key that uniquely identifies a Sale and foreign keys to related User and Customer tables. You REST api will translate a request for the resource identified by to the appropriate database query, retrieve the row, construct the resource that represents a Sale and return it to the client. Be mindful that you are currently exposing what appears to be internal database identifiers (UserID/ClientId/SalesID) to the outside world. It may be appropriate in your case but generally feels off in a RESTful API. 

If it were a query that returned more than 1 row I'd speculate that someone at the vendor (way back when, given the version of SQL Server) stumbled on the query optimiser producing a preferable plan when was specified as a hint. As it's returning just 1 row, the explanation probably has more in common with the infinite monkey theorem than reasoned judgement. A junior saw a hint for and decided that was preferable to his query not being fast. 

In this situation I'd be very tempted to design a new schema that fits the model you now require and create the necessary scripts to migrate data across (your option 4). 

If you're a Microsoft shop and your developers are MSDN licensed, you might want to expand the scope of this idea and take a look at Visual Studio 2010 Lab Management. 

Preferably, don't do that. VPN and (as AceCTO suggested) linked servers if you must but if this is a query you want to run regularly, move the data. BCP it, replicate it, log ship it... just move it. 

Might get the odd spurious result but it'll narrow the field. Add SQL:BatchCompleted if you have a mix of procs and statements. 

If the server is installed as the default instance, you should be able to connect with DNS name or IP Address. The "\SQL2008" you've added to the address would be used to connect to a named instance called "SQL2008". Try specify the port in your connection string e.g. "123.123.123.123,1433". Without the port specified, the client will query port 1434 initially to determine which port to use. Alternatively you could open port 1434. SQL Server Browser Service 

IO affinity masking is a rarely used optimisation, which offloads IO completion activity to a dedicated CPU. When set, a hidden scheduler is created that handles only IO operations for that instance. If you configure identical CPU and IO masks, the two schedulers will battle it out for CPU cycles and cause chaos. The masks you've set are creating exactly that scenario with specified for both. If your intention is the more common requirement to dedicate CPUs to particular instances on a shared server, use just the CPU affinity mask and leave the IO mask as 0 (disabled). I've encountered a mis-configured server with matching masks only once. I was put in front of it because the logs suddenly started filling up with the message we all dread to see: 

Restore the PRIMARY filegroup (instantly, as its tiny). Retore the filegroup containing the smaller supporting tables. Restore the filegroup allocated to the current quarter order data (again relatively quickly compared to restoring all history). Set the remaining partitions as offline. Bring the database online. You can now accept new orders and process existing orders. Gradually restore the remaining partitions and bring online in turn. 

Preferable would be to ensure the optimiser is given the information it needs to generate the best plan, without using the FORCE ORDER hint. By doing so, it should cope better with changes to the underlying data distribution without requiring manual intervention. That said, if the nature of the data is such that cardinality could vary significantly hour by hour or day by hour, consider using a plan guide to ensure the plan is fixed. 

Indexes are rebuilt to remove fragmentation. There a thousand and one articles and blog posts on the nature of index fragmentation but @BrentOzar recently posted a particularly concise explanation in Stop Worrying About SQL Server Fragmentation. 

Alternative approach for pre-SQL2008 is to use a CSV splitter. Jeff Moden has carried out exhaustive testing of various approaches to this. Your example would become: 

None of the pages required to satisfy your query were in memory until read-ahead put them there. As to why online/offline results in a different buffer pool profile warrants a little more idle investigation. @MarkSRasmussen might be able to help us out with that next time he visits. 

Short answer, use a single array, there is unlikely to be any performance gain from separating logs from data across 8 SSD drives. See SQL on SSDs: Hot and Crazy Love for a more detailed (and entertaining) commentary on SSDs. Pay particular attention to the notes on correlated failures of SSDs. Separating logs from data on SSDs is more an RPO (recovery point objective) than performance issue. The notion being that you could reduce your RPO by separating logs from data such that in the event of the data array failing, your log array should/could remain accessible. The cautious would consider a different make/model of drive in each of the two arrays to mitigate the correlated failure issue if RPO was critical. The comments regarding bus bandwidth are irrelevant. If you need to shift that much IO, you've got bigger issues to worry about. 

Filtered indexes were new to SQL2008 so this wouldn't be an option for SQL2005. The SQLCat article Using a Low-Selectivity BIT Column First Can Be the Best Strategy would be applicable reading for an approach to this in 2005 (edit: article has been archived to the eBook SQLCAT's Guide to Relational Engine). And just to address the title question bit fields in an index are ordered same as per ORDER BY bit_field i.e. NULL, 0, 1 (credit @MartinSmith). 

You haven't specified the database platform your considering but at this size/scale, it's unlikely to matter. 5kb per record is trivial. 1 million 5kb records is < 5GB, still trivial. 10 million 5kb records... still not something to lose any sleep about. If we were to get platform specific, a typically exhaustively researched white paper by Paul Randall on SQL Server filestream storage suggests that it outperforms table storage where files are 1MB or greater in size. Below 1MB file sizes, the positives are primarily around filestream bypassing the buffer pool. The positives for database storage: 

Yes, it is available in the installer for development edition. Without firing it up, I'm not sure if the installer has changed between 2008 and 2008R2 but in 2008 there are two options for installing client tools.