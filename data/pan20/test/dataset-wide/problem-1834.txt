I think most any option will be "manual stuff". Under UNIX, it's pretty standard to unmount/remount a device before each benchmark run, often with a "newfs" thrown in for good measure. I don't know if you can use command-line tools under Windows to unmount/mount devices, but if automation is your goal, then it would be worth looking for such utilities. 

Not 100% certain about the first two questions, but there are lots of options for #3. I personally use CCleaner to scrub the cruft from the family PC automatically once a day. If you run it by hand, it should give you list of files found, depending on the function you're using. For #1 you could also try running "dir /s" while standing in that "Temporary Internet Files" from the command prompt. For #2 it could be from any software that does automatic updates (such as Adobe Acrobat viewer, Sun's Java, and MS's own Security Essentials and Automatic Updates). This is just a guess, as I'm not 100% certain where these apps store their downloads. 

Have them fix it. Any solution other than that will cause problems down the road. Tell them its bad for SEO. If you cannot, you might want to look at something like $URL$ 

Normally, you set up an LDAP server such as OpenLDAP and then tell boxes to authenticate against it. Alternatives are Kerberos and Samba. 

On paper, storage is one thing you can judge on; storage in VPSs (in my experience) tends to get expensive past, often being cheaper per gb. on some dedicated servers on the same provider. People often comment on lousy disk performance on VPSs. My extra low end VPS's disk, according to hdparm is nearly 9x slower than the hard drive in my 5-year old Thinkpad... 

Basically, all "server" rack systems have VGA out (except hardcore-UNIX stuff such as Sun servers), so there's no hard reason not to use them as "workstations". However, there's a big cost difference between a Windows desktop OS and a server one. And (at least according to my experience with Dell), you will have a hard time running a desktop OS on most rack systems (lack of support and drivers). I'm not aware of any big-vendor such as Dell, IBM, etc. offering rackable systems with a "desktop" server OS- or "desktop hardware". You might want to consider building your own box from vendors such as Supermicro et al., which offer rack cases and parts. 

I maintain a site with a crusty old version of "Links" by Gossamer Threads. It's written in perl, gets 99.99% of its submissions from bots, and is just plain out-dated. Now, I realize that Gossamer has newer versions, but I was hoping to find something that's open source, and maybe in PHP (since 95% of the site's functionality comes from this language). Does anyone have any opinions on other software to manage a link directory? 

Have you looked at Linux's network block device (nbd) driver? I don't know how well it handles high-latency (it's been years since I've played with it), but it may be worth looking at, assuming the project is still around. 

I'd brute force this one: run tripwire on the entire device for a baseline, then run a check some time later and the offending directory will stick out like a sore thumb. 

Someone could be throttling your HTTP traffic (at the application layer) between your home and server. I'd be curious if any other protocols (besides SSH) have fast transfers while HTTP does not. You should try https, ftp, and maybe even something like rsync, git, or svn. Between A and B and the VPS, you should also try other protocols? From what you've said so far, it doesn't seem like a problem with the http server itself. Is your home connection also in Sweden, or does it cross any national boundaries? 

You could make it work using your current method, but it's probably more work. I know by certain that these two methods are more easily "scriptable". If you choose /etc/fstab, you just need to distribute the line required to mount your network share to all your hosts. If these are not too much, you could do it by hand, but as the number of hosts grows, or the maintenance required increases, you should automate it. You can also distribute the required files to make fusesmb/smbnetfs to work across a network easily. You might want to look into either: 

Use Ant or a similar tool to build your web application and package it into a war. Drop war in webapps folder. Note that from time to time you will have to restart Tomcat due to PermGen leaks. Packing your application as a war is neat and keeps things tidy and nice (i.e. if your Ant build is sane, your webapp will be easy to deploy for other people). However, this is slow for development. I would look for ways to run your webapp inside your IDE. 

This may sound like sort of a bad hack, but on several past occasions when copying huge directory structures, I used WinRAR to archive (with compression) to a file and then extract it to the destination drive. Not the most graceful solution, I know, but it worked in a pinch. These days, I'd probably try to use rsync or tar from the cygwin utilities. 

It depends on the application, the response time needed, and what you're willing to do to meet those goals. Recently, I was working with a 10+ GB, 50+ million line text file and had a need to search for specific strings in each line. Standard Unix tool "grep" did the trick, but took an unacceptably long time (multiple minutes). I imported the text into a postgreslq DB (it was a CSV file, easily imported), and once indexed on the key I needed to search on, it took under 1 second to find my record. Granted, my workstation is single-core, with only 4GB RAM, a 4-year-old 2GHz CPU, and a top-heavy filesystem (ZFS) using 5+ year-old consumer PATA drives. Your mileage will certainly vary. Still, the time difference between the two methods is staggering. If your data is free-form text, you might still consider importing into a DB which supports full-text search and indexes appropriately to support such searches. Even if you have the RAM to have the entire file cached and a fast machine, doing a linear search of files this size will be time inefficient, depending (once again) on the application. 

Keeping your system patched should be easy. I suggest you use "stable" distros with long term support (meaning you get no updates to software beyond security patches and major bug fixes). These mean that their package manager 'update all' operation will probably be smooth and easy. You should also subscribe to the distros security mailing list and evaluate all messages concerning software you have installed. You should also audit all means of entrance to the box, make sure that there are no unnecessary net-accessible apps running and that necessary net-accessible apps are properly secured (i.e. use encryption as necessary and have strong authentication). Watching log files is somewhat overrated, but you might find packages that simplify this. E.g., Redhat Enterprise (and CentOS) install by default logwatch which sends you a daily report by email of your log files. Also, for systems that need to provide services 24/7, you should set up monitoring and, if needed, fail-over measures. Also, backups! 

A couple of other things to try would be to compact the database itself (I assume Access still has this function) and defrag the actual database file on the machine doing the sharing. For defragging single files, I recommend the sysinternals contig command line utility. You could also test for a bad network, by running ping for an extended time (I believe "ping -t" is the correct Windows incantation of the command), and seeing if you're dropping packets or seeing high network latency. 

You should check out asciidoc. I've made a few short things with it, and the output it pretty sharp (and customizable, of course). The plain text is very readable by design, and you can have it output docbook, HTML and PDF easily. Using any number of other converters you can transform it to other formats, too, such as CHM. Very versatile package, though, being a UNIX-centric package, I don't know how the Windows support is. 

Yeah, most people would think that 30 requests per second is a very low number, but most sites would get by with that. 

OVH has absurd pricing on bandwidth, take a look at $URL$ and $URL$ which I don't really understand. I also do not know if they really follow through on what they offer. 

That's very, very difficult. It's very difficult to predict what impact optimizations will have. And the interactions with other parts of your system. You need to experiment. 

Well, you could proxy requests to company.com/us/* to randomserver/* without much trouble (see Apache httpd's mod_proxy), but performance would probably suffer perceptibly and you would be introducing an unnecessary point of failure. If you really want company.com/{country}/* you should really push the case of non-separate servers, strongly. Either a single-server which serves everything to everyone, or replicated servers with GeoDNS... If you can't to that, and the US server is going to be independent, us.company.com is probably your better option, or company.us. Just make sure to choose one of them, and redirect everyone to the "canonical" URL.