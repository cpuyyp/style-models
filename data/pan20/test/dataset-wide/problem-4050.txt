Hi, I am interested in learning a bit more about this space. I have exhausted all the books available at my disposal, and none of them explain much of the basics for me. Here's a definition of this space. The seminorm is $$[u] = \sup_{(x,t), (y,s) \in Q} \frac{|u(x,t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}},$$ and norm $$ \lVert{u}\rVert_{{C}^{k, \alpha}(\overline{Q})} = \sum_{i+2j \leq k} \lVert{\frac{\partial^{i+j}u}{\partial x^i \partial t^j}}\rVert_{C(\overline{Q})} + \sum_{i+2j = k} \bigg[\frac{\partial^{i+j}u}{\partial x^i \partial t^j}\bigg]. $$ Would someone please explain to me why the parabolic Holder space norm is chosen in the way that it is? For example, why aren't we interested in the quantity $u_{xt}$? Because it doesn't pop up in PDEs very often? Why only take the highest order seminorms in the norm? Also, in the denominator of the expression for seminorms, usually we have the spatial $|x-y|$ term to a power higher than the $|t-s|$ term (eg. $|x-y|^2 + |t-s|$). Why is this? Also, there are a number of different definitions for the norm of these spaces. Since these are norms we equip these spaces, are they somewhat equivalent? Does it really matter which one we use? 

Define the seminorm on the space $S=[0,1]\times[0,T]$ $$\mid u\mid_{\alpha} = \sup\frac{|u(x, t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}}.$$ Define the norms on the same space $$\lVert u \rVert_{C^{0, \alpha}} = \lVert u \rVert_{C^0} + \mid u\mid_{\alpha}$$ and $$\lVert u \rVert_{C^{2, \alpha}} = \lVert u \rVert_{C^0} +\lVert u_x \rVert_{C^0}+\lVert u_{xx} \rVert_{C^0}+\lVert u_t \rVert_{C^0}+ \mid u_{xx}\mid_{\alpha} + \mid u_t\mid_{\alpha}.$$ Suppose that $\lVert u \rVert_{C^2, \alpha} \leq C$ where $C$ is a constant. Let $a, b, c \in C^{0, \alpha}$. How can I show that $$\lVert au_{xx} + bu_x + cu\rVert_{C^{0, \alpha}} \leq K\lVert u \rVert_{C^{2, \alpha}}$$ for some constant $K$? Or equivalently, want to show that $$\sup_{\lVert u \rVert_{C^{2,\alpha}} \leq C_1}\lVert au_{xx} + bu_x + cu\rVert_{C^{0, \alpha}} \leq K_1$$ (ALL the above norms are over the compact set $S$). Thanks for any help 

(I asked this question on MSE but I did not receive an answer so I hope I can post here.) Let $S$ be a compact set in $\mathbb{R}^2$ and let $C^{k, \alpha}(S)$ denote the usual Holder space with $k$ continuous derivatives and finite $k$-th order seminorms with exponent $\alpha$. 1) Is it true that if $f \in C^\infty(S)$ and $u \in C^{k, \alpha}(S)$, then $f(u) \in C^{k, \alpha}(S)$? I don't know how to show that the seminorm part (which involves supremums over the composition divided by a distance involving the arguments) is finite. 2) Is it true that if a sequence $u_n \to u$ in $C^{k, \alpha}(S)$, and if $f \in C^\infty(S)$, then $f(u_n) \to f(u)$ in $C^{k, \alpha}(S)$? I think so, since this is true for ordinary $C^k$ space so the "norm part" of the $C^{k, \alpha}$ norm converges, but again I am not sure how to show that the seminorm part of the $C^{k, \alpha}$ norm converges. And I guess if this works for Holder space, it'll work for parabolic Holder space too. Parabolic Holder space is defined as follows. The space $\widetilde{C}^{k, \alpha}(S)$ has the seminorm $$u_\alpha = \sup_{(x,t), (y,s) \in S} \frac{|u(x,t) - u(y,s)|}{(|x-y|^2 + |t-s|)^{\frac{\alpha}{2}}},$$ and norm $$\lVert{u}\rVert_{\widetilde{C}^{k, \alpha}(\overline{S})} = \sum_{i+2j \leq k} \lVert{\frac{\partial^{i+j}u}{\partial x^i \partial t^j}}\rVert_{C(\overline{S})} + \sum_{i+2j = k} \bigg[\frac{\partial^{i+j}u}{\partial x^i \partial t^j}\bigg]_\alpha.$$ I'm grateful for any help. Thanks. 

The full detail of this is of course a complex matter but I can build out some structure and connect the problem to some powerful tools for you; namely that, like the Collatz conjecture, this structure descends linear combinations of Lucas sequences. The floor function of dividing by two descends the sequences $x_{n+1}=2x_n+1$; e.g.: $0,1,3,7,15,31,63,\ldots$ Which should be fairly obvious. Furthermore if you divide alternate numbers in this sequence by $3$ you have the immediate odd predecessors of $1$ in the Collatz graph; namely $\{1,5,21,85,341,\ldots\}$ so the connection is fairly obvious. Numbers just below any descending sequence converge to the same path. In fact the catchment gets wider the higher up the sequence you go, so e.g. $\{62,61,60\}$ go to $15$ then $\{62,61,60,59,58,57,56\}$ go to $7$ etc. Of course your function will descend these sequences and their neighbourhoods until it hits some highest prime so to build the graph it's necessary to break apart the descending sequences at the prime numbers and graph those upwards to $x^2$ instead of down, connecting the next descending sequence. I happened to choose the Mersenne numbers, and there are likely infinitely many prime examples although like all Lucas sequences of the first kind this is a divisibility sequence and therefore only a number with a prime index can itself be prime. But this isn't generally the case in all of your function's descending sequences. The Mersenne numbers are the Lucas sequence $U_n(3,2)$. You can generate every such descending sequence which your function descends, by the linear combinations of $U_n(3,2)$ with its companion $V_n(3,2)=2,3,5,9,17,33\ldots$ $U_n$ is the sequence $2^n-1$ while $V_n$ is the sequence $2^n+1$ so they converge in $\Bbb{Z}_2^{\times}$ to $\pm1$ giving you a set dense enough in $\lvert\cdot\rvert_2$ that perhaps intuitively hints at them covering a set $\{z_1,z_2\in\Bbb{N}:\lvert z_1-z_2\rvert_2\leq\frac{1}{2}\}$ i.e. having an integrality gap of 2 - the odd numbers. To fully index your descending sequences, and graph the vertices where they stop descending and go up, you need to identify the set of linear combinations of these such that the least value in the sequence is a prime number. To do that, you need the set of primes $p$ such that $2p+1$ is not prime and define the sequence $S_p=a\cdot U_n(3,2)+b\cdot V_n(3,2)$ by setting $b\cdot V_0(3,2)=p$ and choosing $a$ such that $S_{p+1}=2p+1$ That gives you the set of sequences: $S_p=(\frac{p}{2}+1)\cdot U_n(3,2)+(\frac{p}{2})\cdot V_n(3,2)$ Next you need to build the successor relation between these sequences; i.e. from the prime at the base of one, to the next descending sequence via the function $x^2$. A (fairly obvious) observation is that the floor function of an odd square halved is equal to $\frac{n^2-1}{2}$. All odd squares are of the form $4n+1$ so the function $p^2$ will always be followed by at least a division by $4$, so we will always have: $\dfrac{p^2-1}{4}$ before possibly more divisions by $2$. The next part of the exercise is to show that the function $x^2$ totally orders these sequences $S_p(3,2)$. I could go on but you are probably bored (and answering Collatz-related questions can be risky for low-rep users!) Hopefully I have built out a good amount of the structure which others with greater skills than me may be able to take further. Another critical structural note to bear in mind is that once you have eliminated unnecessary structure such as perhaps the even numbers, the leaves of this graph, if there are any, will initially be among the primes $p$ for which $2p+1$ is also a prime since these $p$ are the primes which cannot be descended to down some sequence $S_n$ (as obviously any such descent would stop at $2p+1$ and ascend, if $2p+1$ were prime). But if I were a betting man I would predict that the "unnecessary structure" is actually pretty complex and there is a vast amount to be whittled away, and that in the final construct of this graph, the Mersenne Primes may actually be the leaves of the graph, and that the proof this converges to a cycle for all inputs is largely equivalent to there being infinitely many Mersenne Primes. But that is conjecture. There is a vast array of research into Lucas sequences and numerous algebraic structures underpin any set of linear sequences of them as per the link I gave above. The next part of the exercise I would suggest is to take a look at that structure and find how it determines that the function $p\to p^2$ preorders the sequences $S_p=(\frac{p}{2}+1)\cdot U_n(3,2)+(\frac{p}{2})\cdot V_n(3,2)$ 

Let $A$ be $p\times p$ symmetric positive definite with distinct eigenvalues and $x_p\in \mathbb{R}^p$ and consider the problem Minimize $x'Ax + b'x$ Subject to $x'x=1$ Most of the information I've found is is either very general/theoretical or specific to linear constraints, although I'm largely flitting around optimization texts and crossing my fingers since I don't know exactly what I'm looking for. Anyway, my first pass was to use a Lagrange multiplier; $f(x, \lambda) = x'Ax + b'x + \lambda(x'x-1)$ Taking derivatives and setting to zero gives $x = -\frac{1}{2} (A+\lambda I)^{-1}b$ $\frac{1}{4} b'(A+\lambda I)^{-2}b = 1$ I've got my system in $p+1$ equations and I can go about solving them. Analytically I haven't gotten anywhere, except simplifying things a little with the eigendecomposition of $A$. When $b=0$ the solution is trivially $x=e_1$, the first eigenvector of $A$, so let's ignore that case. So my first question: is there an analytical solution that I'm too mathematically challenged to see? If not, what is the best way to solve this problem? (To help quantify "best", I have potentially many such problems to solve for smallish $p$, say 5-10, and $A$ is the same but $b$ changes. An approximate solution is OK, in fact an approximate solution near the correct global solution is better than an exact local one.) 

Suppose that $x\sim N(0, V)$ is $p$ dimensional with $V$ diagonal having elements $v_i^2$. Then $f_x(x)\propto (\prod_p v_i)^{-1} \exp(-\frac{1}{2}\sum_p \frac{x^2_i}{v_i^2})$ $\propto (\prod_p v_i)^{-1} \exp(-\frac{1}{2}\sum_p \frac{||x||_2^2x^2_i}{||x||_2^2v_i^2})$ Now let $y_i = x_i/||x||_2$ and $u=||x||_2$. Making the transformation gives $f_{u,y}(u,y) \propto (\prod_p v_i)^{-1} u^{p-1}\exp(-\frac{u^2}{2}\sum_p \frac{y^2_i}{v_i^2})$ where $u\in (0, \infty)$ and $y'y=1$ (with $u^{p-1}$ coming in through the Jacobian). The density doesn't factor (unless $V\propto I$), so $u$ and $y$ are dependent. This is perfectly sensible to me; informally, in the 2 dimensional case if $V=diag(10000, 1)$ then clearly if the direction is near $(1,0)$ the magnitude will be larger than if it were near $(0,1)$. Similarly, it's intuitive that the dependence disappears if $V \propto I$ (in which case $y$ falls out of the density entirely). My question is as follows: First, is my reasoning (and math!) correct? Second, in the first case where $V\not \propto I$ is it possible to reparameterize in terms of independent quantities analogous to the direction and magnitude ( maybe something like, for example, requiring $y$ to lie on an ellipsoid determined by $V$)? It seems like there should be but it's eluding me. 

Let $\Sigma$ be a symmetric positive definite matrix. Then the Cholesky decomposition gives us $\Sigma=LL'$ where $L$ is lower triangular and unique. Under what conditions (if any) does there exist a second symmetric positive definite matrix $\Omega$ which is NOT diagonal that satisfies $\Sigma=\hat{L} \Omega \hat{L}'$ where $\hat{L}$ is lower triangular and not diagonal? 

This is a fairly substantial rewriting of my original answer. Sharkovski's theorem, which unfortunately only applies to $\mathbb{R}$ is the definitive theorem in this field and one thing it states is that all cycles will be of order a power of 2, else there will be infinitely many. If it could be extended to $2\mathbb{N}-1$ (or to some suitable extension of $2\mathbb{N}-1$) such that it applied to the Collatz conjecture then the existence of any nontrivial cycle would imply the existence of infinitely many nontrivial loops of certain orders; including a cycle of length 2, contradicting Lagarias (1985) result that there are no nontrivial cycles with length $<275000$ (and therefore proving the weakened Collatz Conjecture; that the are no non-trivial cycles). ST states that a continuous interval to interval function having cycles on $\mathbb{R}$ of a certain order must also have cycles other orders. The orders which must exist are arranged in a hierarchy called Sharkovskii's ordering. Only by talking of loops in the Collatz Conjecture directly from one odd number to the next, i.e. of the function $f(x)=\dfrac{3x+1}{2^{v_2(3x+1)}}$ is it possible for ST to apply. This is because the existence of the trivial $3$-cycle in the conventional formulation is immediately contradictory, while the $1$-cycle in the $2\mathbb{N}-1\to2\mathbb{N}-1$ formulation is not. Since $\mathbb{R}$ is uncountable it seems likely such a proof would require a morphism from an interval of $\mathbb{R}$ to some uncountable superset $S$ of $2\mathbb{N}-1$ such that $f(x)$ in $S$ is a continuous function in $\mathbb{R}$. Sequences and cycles in $2\mathbb{N}-1$ are of course isomorphic to a wide range of sequences and cycles which are isometric in some valuation $\lvert x\rvert_{2\times}$. The true, possible, extent of $S$ therefore is governed by our capacity to define some valuation $\lvert x\rvert_{2\times}$ which is sufficiently expressive in measuring powers of $2$ to project every $x\in S$ down to a unique element $n$ of $2\mathbb{N}-1$ and the valuation $\lvert x\rvert_{2\times}$ such that $x=n\lvert x\rvert_{2\times}^{-1}$. The 2-adic valuation over $\mathbb{N}$ is such an example. There's a high probability we require here some extension of the 2-adic valuation to some uncountable superset of $\mathbb{N}$ which is capable of measuring non-integer powers of $2$ to sufficient degree that it captures the full structure of $\mathbb{R}$. The morphism to $\mathbb{R}\to S$ would probably require the property that numbers in $S$ of the form $x\times\lvert x\rvert_{2\times}\in(2\mathbb{N}-1)$ are mapped to an interval in $\mathbb{R}$. This is necessary because proper fractions which are not dyadic, DO have nontrivial cycles in this extension of the Collatz conjecture. Therefore the morphism would need to isolate the integers, proper dyadic fractions, (and any extension thereof satisfying $x\times\lvert x\rvert_{2\times}\in(2\mathbb{N}-1)$ to some interval of $\mathbb{R}$ and map the other numbers to other segments of $\mathbb{R}$ Furthermore, for the function $f(x)$ to be well-defined $2^{v_2(x)}$ must be extended so as to retain isometry as measured by $\lvert x\rvert_{2\times}$ of all orbits of $f$ in $S$. The appropriate extension of $2^{v_2(x)}$ is of course the inverse of $\lvert x\rvert_{2\times}$ and the successor relation defined by the extended form of $f$ can be defined by: $x_{n+1}=\lvert x_0\rvert_{2\times}^{-1}(3x_n+1)\lvert 3x_n+1\rvert_{2\times}$