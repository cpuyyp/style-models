Apparently so. There is the Bofors HPM Blackout built by BAE systems, which is described as being capable of destroying a wide range of consumer-grade electronic devices. It weighs "less than 500kg", I'm no expert on helicopter airframes/payloads but it seems like a viable helicopter mounted EM weapon. There are a range of other systems that have been developed, or which are in development, towards the aim of disabling electronic devices (mainly missiles) but this is the most portable one I could find - unless we include the so called "HERF guns" that hobbyists have been constructing and posting to youtube. I'm not sure I'd call any of these people an entirely credible source, however the idea going around the internet is that the magnetron from a microwave oven can be re-purposed to create a jury-rigged RF weapon, capable of inducing current and thereby destroying electronic devices, not to mention causing thermal damage. You might want to watch some of their videos to get some ideas about how your street racers might try and build something to shoot back at the helicopters. This might not be quite the kind of 'pulse' you're thinking of. The other technique, which has been around for a while now, is the explosively pumped flux compression generator. Instead of using a high voltage source and/or capacitors to create a reusable device, these human-portable single-use devices use explosives to provide a pulse of "millions of amperes and tens of terawatts". These are likely more powerful than the more modern reusable weapons, and they're apparently significantly more portable. Edit: I appear to have misunderstood — explosively pumped flux compression generators are more like bombs than generators. They'll definitely act as a deterrent to street racers, however, but so would regular bombs, once we've escalated this far.... 

In other words, from a certain simplistic perspective, it was already a "program" of sorts, one that was to be executed by humans instead of computers. The problem that's immediately apparent, and which other answers have already described, is that the application of these rules has not itself been operationalised. What is murder? What is robbery? Who may legally be made a slave in the first place? And so on. In other words, if statements are an imperfect mechanism for operationalising ethics; you end up requiring a potentially infinite series of clarifying definitions and decisions. My suggestion would be to return to first principles, ideally, and create an artificial intelligence that is capable of making moral decisions, using structures and methodologies that are more powerful than simple if-then constructions. We would want this AI to have the same fundamental morals as the majority of the humans who are planning to create it and subject themselves to its will, while hoping that it would uphold a purer version of these morals, immune to bias and corruption, and incapable of being manipulated or tricked into making an immoral decision. In other words, you'd be creating a god – a perfectly Good god, at that, as opposed to one of the fallible, relatable ones that exist in religions such as the ancient Greek. I'm not pretentious enough to claim I have any definitive ideas as to how this can be done, but I'm fairly confident it can't be done with nested if statements. What might work: "Moral calculus" One fairly acceptable basis for moral reasoning is utilitarianism. Assuming that all individuals are of equivalent worth, then it's optimal for the largest number of individuals to experience the greatest possible satisfaction while experiencing the least possible discomfort. Loosely define what is good and what is bad at the most fundamental level; death and pain are bad, joy (perhaps measurable in humans via endorphins, serotonin, and so on) is good, and so on. Now we have the kind of optimisation problem that AIs are already getting moderately good at trying to solve. Now we're barely dealing with ethics at all, we're dealing with causality. An action that causes another human to die, or to experience pain, or to be denied their 'fair share' of pleasure is bad, and should be prevented/punished. A person's 'fair share' of pleasure can itself be defined as what they can experience without causing death, pain, or excessively diminishing the ability of others to experience their own fair share of pleasure. I find it hard to disagree with any of the judgements that my limited human mind can predict arising from decisions made according to this kind of "moral calculus". This kind of reasoning not only determines how humans should behave, but also how the AI and it's agents should behave – punishment/deterrence should take a form that prevents wrong by inflicting the bare minimum of death/suffering/deprivation to offenders, actual or potential. There's one catch here – if the system is counting deaths, and measuring pain and pleasure, it's only capable of deciding retrospectively. This works for 'delivering justice', but it doesn't necessarily help in terms of guiding people as to how to make moral decisions as to how to act in the first place. The system could of course make general guidelines based on the collected observations of past decision-making processes, but the better (and more interesting and/or terrifying) approach would be if it were capable of accurately simulating all possible decisions, and the outcomes of those decisions. Now we're really talking about a god – without deviating too much from the topic at hand, consider that an accurate simulation of a human consciousness is considered by some to have equivalent moral rights to a natural-born biological human; but if our AI god wants to test the effects of various actions to determine whether they are immoral, and to what extent, it's going to need to simulate victims as well... Is this permissible according to its own moral reasoning? Maybe it is, since it would enable it to justly govern an indefinite number of real humans. But it's a lot easier for the super-AI to create humans than it is for humans to create humans, and it can create more of them than the physical Earth could hold – so maybe their rights, in the end, outstrip your own? Totally unnecessary extension, with apologies to Eliezer Yudkowsky and friends How do you know you're not already an agent within the simulation of an AI attempting to determine how humans should behave? 

I decided to do a little research into neck injuries in sports (especially contact sports) to get an idea of the ways in which people can (accidentally in these cases, we hope) break each other's necks. It looks like one common way is via whiplash, rather than twisting of the neck – in this video (warning, a wrestler dies) you can see that it's either the blow to the neck or the whiplash caused by the force of the blow which caused a broken neck in this case. As IndigoPhoenix wrote, if the person's body is immobilised, then their neck is much more likely to be broken – e.g. if a person is on the ground and someone steps/falls on their neck, as experienced by this person during a game of rugby. The other means by which a fighter could break an opponent's neck with (relative) ease, which I left until last because it's so obvious, is via a "piledriver" or similar move that involves driving the opponent head-first into the ground. These moves incur a foul in professional Mixed Martial Arts, and are banned in professional wrestling, because the risk of a broken neck is simply far too high. Lifting an opponent off the ground so that their centre of balance is high enough to flip them head-first before they hit the ground is also an illegal tackle in rugby (not sure about gridiron, sorry, but it might be legal over there, the armour makes those guys crazy). In the context of fighting narratives this seems to me to be a "power" move rather than a flexibility and dexterity move, so it might not be quite your character's style, but perhaps instead of "catching the opponent's head with their legs" and twisting to break, your character could instead grab with their legs and somehow flip/drive the opponent head first into the ground? Alternatively, maybe your character could wrap their legs around the opponents neck and then fall with them to the ground, so that when they both hit the ground the force of your characters fall is directed in a way that puts their full weight/force on the opponent's neck.