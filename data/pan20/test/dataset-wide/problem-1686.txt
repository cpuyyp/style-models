Both Ubuntu ($URL$ and Debian ($URL$ support upgrading. For Ubuntu, my personal preference is to upgrade from LTS to LTS every 2 years on servers, and if time permits upgrade to every new release on a desktop. People have mixed experiences upgrading both these systems, but with reading the release notes and planning carefully, upgrading never broke anything beyond repair for me (and often, nothing ended up broken at all). 

There still is "example.com" in you config, is that correct? Also, the .net nameservers tell me that ns01.ispeed.it and ns02.ispeed.it are configured by the registrar as the nameservers for your domain. These nameservers respond for elfoip.net, but not with the data you show, these seem to be the nameservers of an Italian provider and not yours. Your registrar needs to change the NS records for your domain, or you need to start using their nameservers. 

Putty uses its own format for the key files, not a standard format. ssh can not use ppk files. I believe puttygen should be able to export your key to something more usable for ssh. 

Are you able to ping the IPMI IP (192.168.3.164)? Is there a dedicated IPMI port? If the ethernet cable is not connected to the mgmt port when the machine first powers on it's likely that the IPMI board will 'share' the eth0 port. If you issue this command: it will renegotiate and choose the proper port. 

This seems wrong on so many levels. You are making it more difficult to maintain (by installing from source you lose all upstream QA and updates) and you are moving things around that don't need to move around. Is it valid? Yes. You can make it work. Should you so this? Probably not. 

I would recommend any other configuration management system over puppet. Puppet will re-order the configuration steps on each run. Even on the same host. Proponents will tell you that you can setup your requires appropriately so that it works well. I'll tell you that I'm human and I make mistakes. If you have a puppet recipe of any complexity you'll want to test your work. When you do and it succeeds you'll assume that it works on all of your other hosts. This is not necessarily the case. Any system that assumes I'm perfect is, itself, not. 

Did the varnish process maybe restart? There's an uptime counter in varnishstat. Under certain circumstances the varnish worker thread can die, but it gets restarted immediately. When everything is working fine, this might go unnoticed, but with (planned) backend down time it can be quite inconvient. 

The "before" metaparameter indeed only says something about the order of execution of the resources, not the ordering of the lines in the file. If I were you, I would aim to manage resolv.conf with first class puppet constructs: a seperate module that manages it as a file-resource (there probably are several on puppet forge), or write your own small template that explicitly orders the specified name server parameters. Another option would be to specify both name servers in one file_line resource using to seperate them: 

NFS is from 1 client to 1 server, so the overall performance is limited by the performance of that 1 server. Adding more servers does not help. Lustre splits the data, the data gets requested from 1 server, but can be sent from one or more other servers. So adding more servers does help (which is why "Lustre scales"). This is an important bit from your first link: 

iLO and DRAC are just layers built on top of IPMI as well. HP and Dell want you to get hooked on using their products so they can charge you extra for the added features. 

The most secure PHP version is the one you keep updated. Which version (and associated libraries) are maintained by an upstream provider (your Linux distro, assuming you're running Linux.) Are you building the binaries yourself? If so, make sure that you allocate the time needed to keep up with all security patches, not just in PHP, but also in libraries required by your application. 

Google isn't helping me find out anything about a Sun NPR900R Server Cabinet. What is it? Can you provide a link to the documentation for it? 

I like to keep track of everything I do. One command that I learned in college was 'script'. This takes any output on your terminal and logs it to a file. What I didn't learn in college is how to make every terminal a script. Now I have this in my .login file: 

I want to buy a server 4 cores Intel Xeon E3-1220 v5 (16 GB RAM) but without GPU. Is it OK to use as a remote desktop computer? I know that we need GPU to show images on the screen but I don't know on which side do we need a GPU. Do we need GPU on the server side to normaly show desktop screans via remore desktop or we need GPU on the client side? Or on both sides? 

and so on. I don't want to have 16,581,375 records. It is better to use a simple programming logic. Is it possible to realize? 

I need to forward traffic from clients to a VPN server only for specific subnet i.e. 10.10.10.0/24 For example, if clients send requests to 123.123.123.123 then they will use their own Internet. If clients send requests to 10.10.10.123 then they will use a VPN connection. Is it possible to configure with strongswan? Right now all traffic from clients are proxied through the VPN server. Here is my strongswan configuration: 

See for options, but the important parts are 'nagios' is the name of my nagios server and the string that is the printed at the end of this script. expects a line on stdin of the form (perl here) 

Setup a server on your internal network, copy your content over (you might also need to make sure you're running the same CMS internally.) Then figure out how to allow access to that server on your internal network (maybe even put it on a DMZ.) Then change the public DNS record to point to your server. Given how you are asking this question, it sounds like you should hire a consultant for this. I'd also ask this question: Do you need to move the whole website or can you create another sub-domain and use that? www.example.com is your public website, mobileop.example.com runs your internal services. mobileop.example.com could be run on a separate server on your internal network and wouldn't necessarily touch anything on your public one. So many options. Don't tell the consultant exactly what you want done, tell them what your end goal is. 

$URL$ has an explanation. This command (re)sets the argument variables ($1, $2, $3, $4 and $5 in this case). gives you a line with some numbers, feeding the output to maps those numbers to the $N-variables. See for instance: 

It's likely because you are not benchmarking varnish at all, but are benchmarking for instance the CPU, the scheduler or threading model of your operating system, or your virtualisation platform when several machines are using a lot of CPU. If run at pretty much the same hardware, ab and varnish might be fighting over the same resources. One of the authors of varnish has a nice writeup about benchmarking varnish, and ab is most likely not a useful tool: $URL$ 

Are you sure it's not cached at your client? Have you checked with a different browser or a cleared cache? I've found that at least firefox is pretty stubborn in caching the cpanel default redirect. 

Are you sure the filesystem is on /dev/sdc? That would mean the disk would be unpartitioned with the filesystem taking up the entire disk. While that's perfectly possible, it's not that usual. Does mount /dev/sdc1 perhaps work? What does cat /proc/partitions say? Are you sure the disk shows up as sdc? If it's connected with USB, you can check the output of dmesg for instance. 

That's the linux version, but there are Windows equivalents. Graphing that in your favorite tool is left as an exercise for the reader. It should be noted that this gives the power draw into the motherboard. Power supplies are not ever 100% efficient, so add about 15% to that number to get the input into the power supply. Or connect it to a watt meter and measure the efficiency yourself. PSUs are most efficient in the middle of their stated range, somewhere about 50-60% of the rated capacity. If you are concerned about power usage you might consider using an L-series processor. What happens when you draw more? That depends on the provider. You'll likely just get a warning (if they even notice at all.) And that's also the scary part. What if everyone draws just over and the circuit breaker trips? How closely do they monitor those circuits? Is it active monitoring or passive monitoring (is there a meter on the circuit or do the building engineers do spot checks with a clamp on meter?) If there is a meter is it per power port or per circuit? Overall, it's just best to monitor the draw yourself. How do you know before you order the server? Well, that's a guessing game. Unless you're really cranking on the HW you won't get near the peak. 

Do you absolutely need to use varnishncsa? Varnishlog (with some extra command line options or shell piping magic) can give you the cookies (and their contents), and the XID, easily. I doubt the full content of the POST requests is available to log. 

In addition to the comment of BÃ²ss King, you can also simply specify several addresses seperated with a comma: 

Is mod_status enabled? $URL$ is an example output, and it has requests/s since startup and grand totals. 

If your out-of-band management does not allow you to flash the indicator, you could try ethtool if you have a spare/empty network interface 

Ubuntu-1004-lucid-64-minimal is not a valid global name, tell postfix to use your "real" domain name, using the myhostname setting: $URL$ 

EDIT You have a certificate only for "master", but your client connects to "puppetmaster". So either the client needs to expect "master", or you need a certificate for "puppetmaster" on your master. A "certname=puppetmaster" in the [master] block in puppet.conf will change the CN on the server ($URL$ You may need to remove the old certificates, but I am not sure about this. Or, you can have the client connect to "master", either by adding it to /etc/hosts, or to your DNS zone if you're running one. 

Your upstream distribution (in this case Ubuntu) provides and supports a particular set of packages. It would be much more advantageous to upgrade your whole distribution to get a newer version of grep (or really any other package.) The way to do it, if you choose to go this route, is to create your own .deb package with the newer version. Place that package in your repo, enable your repo on the system. Then you can install that deb with apt. 

Also note that Dell's fiscal end of quarter trails the calendar year by one month (specifically Jan 31, Apr 30, July 31, Oct 31.) If you are buying servers in any quantity, that's when you can get the best deals. ;) 

I don't know of one tool to do it all, but .. Smokeping will do some nice graphs. And you can setup nagios to do the connection monitoring and then setup an event handler to execute your command(s) on failure. 

I wonder to know if it is possible to install and remove packages when we change a state of node? To clarify what I mean here is an example: Groups: Load balancer Web server Database Nodes: Minion1 Minion2 Minion3 If we add Minion1 to the group "Web server" then we have to install Java and Tomcat server on it. If remove Minion1 from "Web server" group then we have to remove Java and Tomcat server from it. If we add Minion 2 to both groups "Load balancer" and "Database" then we have to install Nginx and MySQL. If we remove Minion2 from the group "Database" and add Minion2 to the "Web server" then we have to remove MySQL from it and install Java and Tomcat on it. And so on.. Is it possible to configure Salt to act like this? Maybe some alternatives? 

I am using as an authentication method. It requires to store plain text passwords in . I.e. I have a password like this: