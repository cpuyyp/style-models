I can think of two main factors which would motivate such a decision. Social Prestige A diglossia is any situation where two dialects (or languages) exist along side each other in a single region/community. The most obvious example of this would be the co-occurrence in many parts of China of a local Chinese dialect (Cantonese, Hakka, Hokkien, etc.) with the standard Mandarin Chinese. Generally the dialects in a diglossia are split along socio-economic lines, with the upper class' dialect, considered more prestigious, being called the H (high) dialect and the lower class' being called the L (low) dialect (not to be confused with High/Low German, which is an isogloss). Consider the L Birmingham English and the H RP, or the L Black English Vernacular and H Standard American English. Since the H dialect has more prestige, it's natural that humans may [incorrectly] consider this dialect as some how "better" or "more correct" than the L dialect (while linguists view these dialects as merely different). As such, one of the reasons for banning slang in a school is to force children into using the "correct" H dialect. Employability The UK is hardly the first country to attempt to ban a specific dialect from schools. Since end of the US's racial segregation in the 1960s, many black families have attempted to give their children every advantage possible in a society with lingering racist tendencies. Whether it be by giving them stereotypically "white" sounding names (black comedian Reginald D. Hunter comes to mind) or forcing them to conform to "white" Standard American English. Sociology and economics indeed show that "sounding black" is a disadvantage in the work force. I do not have any data on regional UK accents vs. earning potential but I suspect a similar trend takes place. Thus, another possible reason for banning slang in school is not necessarily to force children to use the H dialect but to at least make them "bilingual" in the H dialect, giving them an advantage in the work force. While it is possible that communication barriers may exist between the H and L dialects (look at BEV or how US TV tends to subtitle Scottish English speakers), I fear that this is probably not the reason speakers of the H dialect receive an advantage in the workplace. Generally there is enough interaction between the H and L speakers in a diglossia that they can understand each other readily. Unfortunately, I suspect this is simply a special case of the "social prestige" factor I described above. Will it Work? It is difficult to say. On one hand, China's heavy emphasis on Mandarin appears to be slowly eroding the use of many smaller regional Chinese dialects, such as Shanghaiese. In fact, this trend isn't even limited to areas controlled by the Peope's Republic of China. On the other hand, in the controversy surrounding BEV in US schools, academics (although not necessarily the general population) are starting to favour the embracing of local dialects, proposing "bilingual" approaches as briefly mentioned above. Similarly, the BBC, after years of forcing reporters to use RP (also called "BBC English" for now obvious reasons), is starting to embrace regional accents. 

To be honest, generative notions of word classes don't seem any less whimsical to me than the classical ones, as they are no less biased. Of course, this will be a matter of hot debate, but I side with Haspelmath (and a lot of other typologists as well, see e.g. Bickel (2007)) who claims that there is no such thing as true cross-linguistic categories. To ask whether Japanese does have the same linguistic category that a completely unrelated language, English, has (maybe, if 'determiner' even is a valid category for English) seems absurd. The question would be easier to answer if we had a clear, operationalised definition of "determiner" that can be readily applied to all sorts of languages (but I doubt anybody could come up with that). 

I think you got that wrong. Syncretism in a number of forms (as typical in the neuter in IE languages) does not mean that the structural categories themselves merge. And a language that "fails" to distinguish nominative and accusative case everywhere, cannot really be said to have either of them. (which would mean that arguments would have to be differentiated on some other basis, e.g. head-marking, word order, direct-inverse marking or so) If you have to tag a form that could be either nominative or accusative you'd usually employ whichever is appropriate in the context; if no context is given or you need to be explicit you can also indicate the syncretism e.g. as "nom/acc" edit: and you (mostly) got that case relationship wrong. with respect to their prototypical usage, nominative, accusative and dative are closer to each other as they all express argument roles while the genitive is typically used for possessor constructions (although in a number of IE languages some verbs do actually require a genitive argument, but this is a minor pattern) 

The only way I can think of to treat an adjective as a noun is using (literally a noun modifier + thing ). Verbs also follow the same pattern: 

Please see the comment I left on the question about intelligence vs. IQ. I am assuming the OP meant "intelligence" and was simply referring to IQ as a convenient measure. Language alone is not an indicator of intelligence. Most introductory Linguistics courses will at least briefly cover Williams Syndrome, a form of developmental delay that characteristically presents with exceptional language skills. While it might not make sense that something that causes exceptional language skills could be classified as a developmental delay, you need to remember that when people talk about "intelligence", they are often talking about a wide range of independent skills (math, induction, memory, expertise on a specific topic, etc.). However, you did not ask about the link between language and intelligence, you asked if one's native language can affect their intelligence. I couldn't find any research on that topic but I did find this paper which found that bilingualism has no noticeable effect on intelligence. Another problem is that it would be almost impossible to attribute any differences to language alone. There are too many variables between different language speaking areas such as culture, education, and health care. I have found this paper which found evidence that quality of education can noticeably affect intelligence test results. In summary, although I could not find any academic sources explicitly addressing your concern, I find it highly unlikely that one's native language affect intelligence levels and any differences that may exist cannot be reliably attributed to language as other factors have greater effect. 

*y* is all As Assuming x is "the cat", y is "the dog", and z is "chased died" then for n = 1 we get: "the cat the dog chased died", which is obviously valid (i.e. can be parsed by AnBn-1died). However, for n = 0 we see "the dog chased died" which is obviously invalid. Similarly, for n = 2 ("the dog the cat the cat chased died") or higher, the output is obviously invalid. More generically, if y is all As and the number of times y appears can be variable then it's impossible to ensure that there for exactly one fewer B than As. Therefore there is no possible y such that y is all As. *y* is all Bs Assuming y is all Bs (e.g. x is "the cat the dog the man", y is "admired", and z is "chased died"), we see a similar problem to the above where we cannot ensure exactly one fewer B than As *y* is a mixture of As and Bs Assuming y is a mixture (e.g. x is "the cat", y is "the dog chased", and z is "died") seems to work a bit better as both n = 0 and n = 1 are valid ("the cat died" and "the cat the dog chased died" respectively) but things start to fall apart at n = 2: "the cat the dog chased the dog chased died". More generically, if y is a mixture of As and Bs ten as y repeats some B must occur before some A, which is banned by the regular language AnBn-1died. Conclusion There is no possibly y such that xynz is valid for AnBn-1died across all values of n. Therefore xynz is not regular, therefore English is not regular, therefore English cannot be [fully] expressed by a regular expression. Obviously, this only applies to English and I cannot say that there is no natural language that can be fully expressed by a regular expression, but I highly doubt it. For any natural language one could repeat a similar test to prove it is not regular. Finally, note that I am talking about describing the language fully. That is not to say that under certain conditions a regular expression cannot describe a subset of a natural language nor that regular expressions cannot approximate a natural language in limited contexts. It depends on the scope you're working with and if you can justify the loss of accuracy for increased computability. Natural Languages as Context-free Grammars Here is where the thoroughness of my answer takes a drop as I am less familiar with examining and proving context-free grammars. However, I was able to find a few articles which address the issue of natural languages as context-free grammars (usually to the negative). Here is an article proving English is not context-free. Here is another article making a similar argument for Swiss German. Both these articles seem to take a similar approach to the regular language process above where they user the closure properties of context-free grammars to generate a subset of a natural language then prove that that subset is non-context-free thus proving the full natural language is also non-context free. 

These data are usually used to support or weaken the argument in favour of a particular model. In the case of the models discussed, they are designed to address predictions stemming from assumptions about the stages of speech production, and the order (if any) in which these stages are processed. For instance, WEAVER++ assumes that syntactic and semantic information is accessed prior to phonological information. Thus the TOT effect occurs when phonological information is difficult to access. Harely and Bown (1998), showed that words with an unusual phonological form are more susceptible to TOT, evidence that supports WEAVER++. As an aside, the 'priming' studies that Nathan refers to are in fact uses of the masked prime paradigm with a lexical decision task. These are used to investigate the processes involved in visual word recognition (i.e. reading), and are a great way to investigate the information we can access very quickly from written language. For instance, that we compute phonological information from brief (50ms) presentations of non-words (Kinoshita & Norris, 2012). What such information tells us about the mental lexicon is unclear. This isn't meant to be an exhaustive account of speech production. I've undoubtably presented some contentious information, and excluded some important information. Regardless, hopefully I've given you enough resources to make a start on your own research. Most of the articles I've mentioned are accessible through google, at the very least, Dell (1986) and Levelt et al (1999) definitely are. *Don't be put off by the length of Levelt et al (1999). Behavioural and Brain Sciences articles often include commentary by researchers in the same field, so the article itself is only about 35 pages long. The commentary is a great way to a get a feel for how a theory fits in with the rest of the field. Personally, I think it's a great idea. Dell, G. S. (1986). A spreading-activation theory of retrieval in sentence production. Psychological Review, 93(3), 283-321. doi:10.1037/0033-295X.93.3.283 Harley, T. A. & Bown, H. E. (1998). What causes a tip-of-the-tongue state? evidence for lexical neighbourhood effects in speech production. British Journal of Psychology, 89, 151. Kinoshita, S., & Norris, D. (2012). Pseudohomophone priming in lexical decision is not fragile in sparse lexical neighborhood. Journal of Experimental Psychology: Learning, Memory and Cognition, 38, 764-775. Levelt, W. J. M., Roelofs, A., & Meyer, A. S. (1999). A theory of lexical access in speech production. Behavioral and Brain Sciences, 22(1), 1-38. doi:10.1017/S0140525X99001776 Meyer, A. S., & Damian, M. F. (2007). Activation of distractor names in the picture-picture interference paradigm. Memory & Cognition, 35(3), 494-503. doi:10.3758/BF03193289