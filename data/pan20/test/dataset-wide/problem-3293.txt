Not all languages have adjectives; some use adjectival nouns ("red.one" instead of "red") and/or stative verbs ("be.red" instead of "red"). Among languages that have adjectives, not all allow comparison of adjectives, and not all adjectives take agreement suffixes. See $URL$ What I haven't been able to find on the Net is which kind of inflections for adjectives are the most common across languages that have a word class of adjectives that is morphologically distinct from, say, genitives and relative clauses. No inflections? Inflection for comparison? Agreement? Something else? 

As we all know, every language has open classes of morphemes. If we discovered a new mineral whose natural florescence captured the public's attention, there would be no difficulty coining a new name for it in either technical or popular vocabulary. Odds are, the new name would be derived from existing morphemes, yielding something like "glo-stone." But nothing theoretical could prevent the coinage of a new morpheme like "fraz." I have often heard that the number of morphemes in a language is finite because there are only so many morphemes in a language at a given time. However, only so many sentences are being spoken in a given language at a given time. It simply isn't possible for there to be an actual infinity of sentences in a given language. But because of recursion, we can rightly characterize the number of sentences in a language as non-finite in principle. Can't we say the same about the number of morphemes? There may be practical and cognitive limits on the lengths of morphemes, but not theoretical limits as far as I know. If the numbers of both sentences and morphemes in a language are actually finite but non-finite in principle, then how could any language be characterized as having only a finite number of sentences in principle even if said language lacks recursion? True, new morphemes are uttered with far lower frequency than new sentences are, but what theoretical difference would that make? 

What is the difference between "or" and "either...or? Obviously, one comprises one phonological word and the other comprises two. I have yet to find an analysis of "either...or" in which "either" is considered to be an adverb. The Summer Institute of Linguistics glossary of linguistic terms indicates that "either...or" is a correlative conjunction, which the SIL defines as "either of a pair of coordinating conjunctions used in ordered fashion." (See $URL$ ) I'm not sure that this definition makes sense for English, because "either" is not a coordinator by itself AFAIK. This definition may apply to other languages. But I've been having a hard time finding examples on the Internet. Anyway, my chief interest is in the semantic difference between "or" and "either...or". Although I'm asking about two English coordinators, I believe that this question is appropriate for this list because other languages also have a similar contrast. Because I'm a monolingual English speaker, examples of sentences in which "or" would be acceptable but "either...or" would not be--and vice versa--would be helpful. 

What do the terms "exponent" and "formative" mean in linguistics? I've seen the term "exponent" used in linguistics texts, and found a definition at Wikipedia. "An exponent is a phonological manifestation of a morphosyntactic property. In non-technical language, it is the expression of one or more grammatical properties by sound." The article goes on to give examples of the different types of exponents: "Identity (e.g. deer + PLURAL = deer) Affixation (e.g. look + PAST = looked) Internal Modification (e.g. sing + past = sang) Reduplication (e.g. toó ‘man’ totóo ‘people’ (from Pangasinin, cited in WALS)" But the article cites no references or sources, I have been unable to find authoritative references and sources elsewhere, and I have been unable to find a definition of linguistic "formatives" and how they are related to linguistic exponents. 

Suppose that you have a language, let's say it's SVO, has a clause pattern in which the subject typically stands for an agent or experiencer and the object typically stands for a patient or stimulus, and in which neither NP is overtly marked for case. Now suppose that the language has a different clause pattern in which the first argument in the clause takes an overtly marked case, let's call it "case-B," and the subject typically stands for a patient or stimulus while the object, which has no overt case-marking, typically stands for an agent or experiencer. This second clause pattern is like the passive, except that there's no valency reduction, and the second argument must be an indefinite pronoun if its referent is to be unspecified. My question is, is there a natural language with such a scheme? 

In R.M.W. Dixon's book, "Ergativity," I read that ergative-absolutive marking is generally morphological. IIRC, that goes for split-S alignment and fluid-S alignment as well. For those who came in late, split-S alignment occurs when the subjects of some intransitive verbs are marked with absolutive case & do not stand for agents (e.g. with verbs 'die,' 'fall,' etc) and the subjects of other intransitive verbs are marked with nominative case & do stand for agents (e.g. 'jump,' 'blink,' etc.). Fluid-S alignment occurs when the subject of an intransitive verb is marked with nominative case if it stands for an agent and absolutive if it doesn't. So one verb could mean 'drop to the ground' or 'fall' depending on the case of the subject. My question is, do isolating natural languages ever exhibit non-nominative/accusative morpho-syntactic alignment. e.g. Could an isolating language have semantic marking (e.g. arguments occur in order of prototypical agency)? 

For those unsure of terminology, "analytic" refers to how many morphemes group together to make a word. Some languages will have lots of morphemes together in a word (Australian and North American languages are famous examples of this) and they are called 'polysynthetic.' A language that has few morphemes together in a word is called 'analytic.' Mandarin is often cited as an example of such a language, where there is often only one morpheme per word. English is relatively analytic, but not the most analytic. While I can't find any stats for languages as a whole, the ever-reliable WALS database has a feature called "[Inflectional synthesis of the verb]"2. The verb is not a terrible place to look - although it does deprive us of the kinds of polysynthesis in German where adjectives and nouns act as morphemes in larger words. In this we see that English is, across the world's languages, relatively analytic - being one of 24 languages with only 2-3 morphemes per verb. There are only 5 languages with fewer (0-1 morphemes) as opposed to the remainder of the 145 language sample that have anywhere from 3-13 morpheme slots per verb. Looking at the 24 languages that have only 2-3 morphemes, we see that there aren't many in the Euro-area. There's Finnish, but that's not Indo-European, but Uralic. This leaves Hindi on the map - a member of the Indo-Aryan branch of the Indo-European family. I have not learned much Hindi, but I have learned Nepali, and I would say that these Indo-European languages have, at the most, only a slightly higher number of morphemes per word. This area would be your best candidate for finding another analytic language of the Indo-European family that is similar to English in terms of morphological density of words. 

I know WALS (World Atlas of Linguistic Typolology) www.wals.info has a chapter on the "Order of Adverbial Subordinator and Clause" $URL$ You could use this as a starting point because you know that all 660 languages in this survey cover a good area and genetic spread - and WALS almost always point you to a reference grammar. Might take some of the grunt-work out of your task! 

@jlawler in the comments of your question is right - but I'll try and expand a bit because I think it's a lovely example of how we often under-estimate the complexity of the languages we speak. A dictionary is a useful tool for what it's good at, giving people a basic idea of what a word means and its basic function. To integrate the data from a dictionary into a parsing machine requires the addition of a while lot more information. Firstly, a dictionary gives the parts of speech (which is a good start) but nowhere in a dictionary will you find sentence-building information like "subjects go before verbs in basic declarative sentences," or any of the hundreds of other syntactic rules that allow speakers to produce plausible utterances. So that's your syntactic limitation. Secondly, there's a lexico-semantic limitation. Think about a word like sand. We know form the dictionary that it's a noun, but we need more. We need to know it's a mass noun, not a count noun so putting a number with it is not good unless there's something to turn it into a count noun (eg. buckets of sand). Also, dictionaries don't include Proper Nouns so they're not going to be good at recognising large chunks of text ("Lauren mentioned Chomsky on Stack Exchange" - for example), not to mention the incredible creativity English-speakers show in creating neologisms ("I Chomsky'd that post"). Thirdly, there's a phonological limitation. To give a dull but illustrative example, when do you use a\an? You'll have to build a rule for that on top of your dictionary, but you'll need to include inter-dialect and inter-speaker variation (in fact, the same goes for all of the above). Dictionaries are great at what they do, and sometimes can be absorbed into computational processes in interesting ways, but it's just a small component of what you'll need to create a sentence checker! 

So by the seventh colour term they basically concede that there is no way to predict order of inclusion in a language. Given that their constraints have been even further relaxed since this analysis I would not find it surprising if there were a language where a separate lexical item for 'light blue' were found before others in rule 7 above. 

Using epidemiology as way towards understanding language use and spread is a good start! See "Linguistic Epidemiology" (Amazon link) by Nick Enfield - he's an excellent field linguist using features of epidemiology to look at contact situations. There are many other ways sociology can help you in field linguistic, at all levels. Any grammatical description worthy of attention these days will include a fairly detailed description of the social context in which the language is spoken. That includes social dynamics, power structures and other features. From there, it really depends what you're looking at. These days field linguists can do a whole lot more than just study the grammar of a language. We're also interested in how migration affects language use, or the power relation between the local language and the national language (or even in some cases, the local dialect and the more common one). You may want to look at the rise of the use of small minority languages on the internet, in which case social networking theory might be useful. You might find there are less direct benefits, for example some areas of sociology put better emphasis on quantitative methods than most linguistics majors do, which might give you a better grounding in statistics, which might help with corpus analysis or phonetic analysis. Even if the study of sociology doesn't directly relate to any future linguistic study you do, the grounding in critical thinking, research methodology and the ability to think from the perspective of cultures other than your own are all going to help make you a better linguist!