The green bug you're seeing (look closely) means the package have been compiled with DEBUG option. It is also seen on bare procedures and functions. It is a coincidence they don't expand - maybe a bug (duh) in SQLdeveloper :) On mine, these expand without problem. 

In case you specify each block is read once and written two times to backupset copies. The two backupset copies are supposed to be bit-to-bit identical. Both copies have the same backupset key (BS_key) in RMAN. You cannot mix tape and disk copies - either both copies go to or both to . 

This is a full database import which also includes tablespace definitions. Find out from the original Solaris database what are all the target tablespace names and sizes. Pre-create the tablespaces manually using the datafile paths of your choice () before performing the import. You will see which you can ignore. 

In Oracle starts a PL/SQL block. In other words, after you ought to provide a text of a program that is written in a procedural language that is somewhat different than SQL (although it bears some similarities). Your sqlplus had read everything but it was not yet parsing or executing anything, it was waiting for an and a line containing only a slash like this: 

Shameless plug: I wrote about this in a blog post. A couple of jobs ago I was using this to log/serve ~1 billion ads/month. 

What you are doing is called denormalization. The rule of thumb is "normalize till it hurts, denormalize till it works." Denormalization should follow the access pattern of your queries. If you have a common query that goes from joining on 10 tables to just a few with just a small bit of duplication, go for it! 

MySQL will not serve you stale data (if that is your question). The index is maintained and kept up to date as part of every operation (whether be INSERT, UPDATE, DELETE etc.). 

There is no footprint, and you will likely not see overhead. Sure, there are hypothetical cases: If you have many virtual columns and from a client then more data will be sent across the network (since rows are sent in full; clients don't know they can reconstruct certain data from virtual column definitions). 

I can't vouch for their credibility, but I did manage to find 4.0 RPMs with a Google search for "mysql 4.0 rpm". The obligatory disclaimer of course is that MySQL 5.5 is now the minimum supported version of MySQL. But that will be the same case with using Red Hat Linux 9 (Shrike). 

The "device" in RMAN is a misnomer, it should be really called "storage". The "sbt" (synonym of "sbt_tape") is a misnomer again, as it has NOTHING to do with any tapes, it should be simply called "non-rman". This is just an empty placeholder, to be filled with any "plugin"; the plugin is called by Oracle either the "Media Manager library" or SBT_LIBRARY. This plugin allows rman to store and retrieve files through it, so rman only tells that it needs a file handle "xyz" (file is identified by a string handle) and doesn't need to know how the file is delivered, from tape or anything. The plugin is normally a part of an independent backup software, such as IBM TSM or Symantec NetBackup or many others. Oracle provides a simple emulator SBT_LIBRARY=oracle.disksbt for testing. Since you didn't fill that placeholder with any "Media Manager library", you receive an error message as expected. 

What is the most costly thing for you? Prioritize. Usually the most costly thing is confusion of users. Ordinary users very rarely use a TNS name. They usually use the data through a dedicated application, and know just the name of application, like CRM. Power users connect to TNS names (think SQLdeveloper), but they also connect to the ordinary applications. Why would you want application CRM use a TNS name of ORION? Power users see TNS name and all they care is TNS name; not SID, not hostname. They talk to other users in terms of TNS name (get that report from FINANCEDB John!). The state of minimal user confusion is when TNS name is the same as the name of application using it. Either exactly the same of with "db" appended. So TNS name is like CRM or CRMDB. I prefer the latter. The next costly thing is changing anything inside tnsnames.ora. You don't know where it is distributed. You put the file in one's client machine or an application server, and voila three months later it magically appeared on dozen others. Can you prevent it? (No, you cannot.) So in practice this means once you give any user a TNS name, its definition is set in stone. So, don't put SID there, put a SERVICE_NAME. Don't put IP address there, put a hostname. And those two would stick to TNS name "forever", so there is no reason for them to be different than TNS name (Occam razor). 

With mysqldump you can only safely use if all your tables are InnoDB, otherwise your backup is inconsistent. If you have the requirement for a hybrid backup, then you need the on all tables in the backup (default), which will be safe for all engines. It's also worth mentioning that the default options will make sure your backup is safe, you don't need to turn any special flag on. Note: If you do have a hybrid mix, perhaps look at xtrabackup. It will only be locking during the MyISAM phase of the backup. 

You have to understand where most of the tools you are using are getting their data from - and . This data simply is not available broken down on a database level inside MySQL. MySQL 5.5, 5.6 and Percona Server have been doing a great job of improving the diagnostics available to you with features like performance_schema and userstats - but I don't know of any GUI/monitoring tools that are taking advantage yet. I recommend installing Percona Server, and taking a look at table_statistics: 

The next thing in terms of cost is an OS (machine) and its IP address. You cannot afford a separate system for every TNS name. So crmdb.mydomain.local is not the only name for the IP address; the same IP address would have more names, like financedb.mydomain.local. Your OS admin would decide how to do this best, and how to determine the main hostname of the OS. They have the same problem with many other systems - multiple names referring to one OS - so they should have a solution at hand. The only people who are confused now are DBAs and OS admins, they see multiple hostnames leading to the same IP address. But users don't care about that and are not confused by that. (By the way this approach is coherent with SCAN. ) The next thing in terms of cost is either one of the two: an Oracle instance or "administrative cost of separating schemas out of instance". The tradeoff is for you to decide. 

Fan in (multi-source replication) will be supported from MySQL 5.7. A labs release is available here: $URL$ 

So it looks like the time increased because there has to be a comparison to confirm that the value itself has not been modified, which in the case of a 1G longtext takes time (because it is split across many pages). But the modification itself does not seem to churn through the redo log. I suspect that if values are regular columns that are in-page the comparison adds only a little overhead. And assuming the same optimization applies, these are no-ops when it comes to the update. Longer Answer I actually think the ORM should not eliminate columns which have been modified (but not changed), as this optimization has strange side-effects. Consider the following in pseudo code: 

I believe the background threads are fixed in number (the actual count will depend on some configuration settings such as and the number of etc.) The FOREGROUND threads are one per connection + a potential of on top of that. 

Don't use bare because without SET UNTIL it doesn't work as you'd expect in some scenarios. I wouldn't say any of these two solutions are inherently safe, both have as many pitfalls as any other Oracle's advanced features, so you need to do some research upfront. 

Because for some strange reason, although regexp_like looks like a function on a first glance, it is not a function in reality, but is a condition (an integral part of SQL syntax). But, more confusingly, it is a function if used in PL/SQL: 

Verify here you have had only a single control file and not two or three of them. If you have had more than one control file, then this instruction is not for you. 

In some versions of Oracle, you cannot put space between the beginning-of-line and the WALLET_LOCATION keyword, and you must put space between the beginning-of-line and the definition of a wallet. Your snippet indicates that you failed at one of these things. I think they removed this silly requirement starting from some Oracle version, but better safe than sorry. Good: 

requires setting triggers on a table. MySQL (prior to version 5.7) only allows one trigger per event (before insert, after insert etc.) This error is informing you know that a trigger is already defined, and is prevented from running. tl;dr: You need to remove your triggers so the tool can run. With MySQL 5.7+ this will not be required. 

Small starting clarification: the article you linked to on InnoDB text/blob storage is a little out of date with MySQL 5.5, and the barracuda row format. This article is more up to date. On to your question: In the schema you have, each row will be less than ~8K, so you can guarantee across both antelope and barracuda row formats that all data will be stored in-line - not requiring external/overflow pages. If you were to require overflow pages, they are never de-duplicated (which is what I would probably describe your 'pooling' mechanism as). Even worse than they are never de-duplicated, they are never shared... If you could have a record too big to fit inline (~8K limit), each text/blob that needs to be moved out will take a minimum of a 16K page to itself. 

You don't want your test database to retain the same internal id number as the production database. Hence it would be best to use RMAN's command DUPLICATE, because it sets a different id (and also a new database name). This command is specifically designed to do what you require. 

Jay, this isn't officially documented, so I'm speaking only from my own experience. In RMAN, the command is synonymous with . Also the command is synonymous with . I'm not sure about ; it might be also a synonym of , although I've never tested the latter. In your scenario, the former would work as expected. In particular, neither or require all the datafiles to come from "a single backup of database" (from a single run of ). Actually, RMAN doesn't even have a concept of "a single backup of database". 

Beware the OS authentication is done by client machine, not by the database server. I think that within reasonable pessimism to Oracle tools you could expect that it boils down to this: database server receives a TCP connection from whichever IP address that might pass the network path, and that connection just claims "I promise I've done OS authentication and, trust me, this connection is made on behalf of OPS$JohnSmithCEO." Neither the database client or database server is given OS password for additional OS authentication! And you can't even trust that this connection came from a valid Oracle software. It can be man-in-the-middle in reality. It's worse than telnet. Whatever "Windows-specific" checks are done by Oracle, they seem contrived and you can't really trust they are complete and secure. 

Views and virtual columns are similar, in that neither are materialized. i.e. neither store any data or indexes, hence why your + remain the same. Where they differ is: 

There's really risks associated with both approaches: Option a) Index from the start, but not realize you have created a number of indexes which are never used. These add some overhead (most noticeably to queries that modify data, but also with optimization of SELECT statements trying to identify the best index). You will need to discipline yourself to identify indexes no longer being used and try and remove them (PostgreSQL can do this; unfortunately MySQL by comparison is very weak at this out of the box.) Option b) Don't add indexes until people start complaining, or your diagnostic tools trigger that certain queries are slow and could be improved. The risk that you introduce is that you don't have a big enough time window between when you notice you need the index, and when you have to add it. PostgreSQL does support building indexes , which does reduce some of the stress from this sudden-index-add-requirement, but there are some caveats noted in the manual. 

XE does not support Streams, as officially documented. SE and SE1 support Streams but without redo capture. EE and PE (Personal Edition) fully support Streams, and also support Logical Standby. 

The script creates certain objects, and it will put them in the current schema. Oracle wishes that these objects be created on SYSTEM schema, hence the requirement. There are two Oracle schemas, SYS and SYSTEM, because they have two purposes. In short, SYS truly is the "special" user in respect to database internals, while SYSTEM works normally. The SYS is the owner of the database, the only user with access to X$ tables, the only user which acts as SYSDBA (internally), that bypasses logon triggers, and that, for some obscure reason, cannot obtain read-consistent view of data. As a schema it holds crucial Oracle stuff, mainly the data dictionary. The SYSTEM is fairly normal schema with DBA privilege (database administrator, not the same as SYSDBA), only that it is built-in and contains some additional (but also quite important) Oracle stuff. You shouldn't put your own stuff in this schema, if not instructed so by Oracle.