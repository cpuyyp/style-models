I recently found out, that a server got a 32 bit installation of SQL Server 2012 rather than 64bit, and it is running out of memory now. Can I have this 32 bit installation use more memory using locked pages? I do not know much about this. I've read this $URL$ bit I am still not clear if this will help, what needs to be done etc 

SYSTEM: I have a system with about 150 databases, each of about 2gb in size. 130 of those are mostly inactive but need to be online. Those are set to simple recovery, active dbs are set to full. I have a daily full backup and hourly tran log backups. I am using sql server maintenance plan backup and I am backing up all user databases PROBLEM This (the full backup) generates a large backup set that, for various reasons I am finding it hard to deal with. QUESTIONS I am looking for a back strategy that would not result in unnecessary backup size. I am not using differential backup (which I think would reduce the size of the backup of the inactive DBs) because I am afraid of having to deal with large set of files in case of having to rebuild from backup. I know I could maintain different backups maintenance plans, and update it as a db goes inactive, and as I add new active databases, however, this is manual process and we add a few databases a month. I've done this before and mistakes were made... Is there a way to take advantage of the fact that inactives are simple recovery to threat them differently? How about the backup compression? I have never used it, not sure what this will do to my CPU usage (currently the DB server is typically <15% CPU) Thank you! PS, i am not a DBA, but a developer. 

SAP/Sybase ASE uses a slightly different conceptual model than PostgreSQL, Oracle & SQLServer, which all have the concept of a schema. 

You should probably create a .sql script that can run and return the value for multiple commands. A script can be easily created using the following format: 

In the above query is the flag for User defined tables. Also because is a single character wild card in T-SQL, we have to escape it to find the literal . T-SQL allows almost any character to act as the escape, but it must be defined after the clause. Finally is the multi-character wild card, the T-SQL equivalent to in *nix and DOS. It would also be possible to use the above query to build a sql script. We start by telling the server not to print out the number of rows affected by the query using . This allows us to create a script that will run error-free, without needing additional editing. 

In Advantage/SQLAnywhere, the database names are stored in sysdbspaces To access the name of the database you are currently in use the function. 

It seems that the 5GB limit is per server, so you would not be able to have multiple 5GB databases. As for migration, it should be just a matter of shutting down the Express Edition, and using the Developer Edition binaries to start your existing data server. It may be as easy as copying then RUN_[servername] file from the old directory to the new one, if all of your system and user databases exist outside of the installation directory. The link above is worth checking out, as it details the restrictions of the different versions. It's also a great resource for ASE knowledge, as Rob Verschoor is one of the most knowledgable Sybase/SAP database guys around. 

What are my options if I need to move a database from SQL Server 2012(32bit) to SQL Server 2005(64bit)? I know I cannot: 

A production server has accidentally been installed with SQL Server 2012 32bit version, while it needed a 64bit version. How best to fix this issue? Is it possible to simply UPGRADE from 32 to 64 bit version? Should I just install a new instance of 64 bit version of SQL Server 2012 and then simply restore the backups? 

My SQL Server 2012 Standard edition, 64bit has a total virtual address space of 4GB. Why is that? it is a 64bit installation: print @@VERSION : 

I know this is a hard question to answer without more details, but I am hoping for some general guidelines or rule of thumb ideas, or perhaps a how-to determine what would be best for my set of databases. I have a system of about 100 databases, that since its creation 8 years ago, i did index reorg, stats update, check integrity task on all databases, every night. most databases are about 1GB in size, one is 10GB As the databases grew, this task takes more and more time, and now has adverse effects on performance, and there is no good time when I can handle the performance effect. I am afraid of just turning this task off, and I am looking for some guidance - I don't even know if doing such maintenance task is necessary! Should I be doing such maintenance job? how often? Thank you! 

This is the root cause of your problem. There is no such thing as a parent table in relational model; foreign keys are constraints, not navigation paths. You are dragging OO terminology into a relational DB and these two do not match -- paradigms are different. 

This is simply not true, you should modify your belief to something like: "Often it is beneficial for a table to have a single-column primary key because ... " 

P1 Course named (C_NAME), assigned a course number (C_NUM), exists. .. and constraints c1.1 For each course name, exactly one course has that name. c1.2 For each course number, exactly one course is assigned that number. The predicate leads to relation; the constraints to -- well, constraints like: PK, AK, FK, CHECK etc. 

| Teacher (TeacherId) teaches in school (SchoolId), in district (DistrictId). Each teacher may teach in more than one school in a district. For each school in a district it is possible that more than one teacher teaches in that school. If a teacher teaches in school in a district, then that school must be located in that district. If a teacher teaches in school in a district, then that teacher must be licensed to teach in that district. 

First thing to notice is that the PK on the LineItem table has three attributes , as opposed to just two in your example. Second thing to note is the confusion resulting from the use of the generic name for an attribute. The should ideally be (1,2,3..) for each customer and (1,2,3 ...) for each order. Well, this is nice if possible, but requires a query looking for the previous max value, like 

Sybase ASE does not support a direct upgrade from version 11.5 to version 15, so you will have to export your database from the ASE 11.5, and import it to ASE 15. From the $SYBASE/$SYBASE_ASE/scripts/ directory in your ASE 15 installation, run the installupgrade file into your ASE 11.5 installation, to install some utility stored procedures to assist with the migration. 

Sybase ASE retrieves port numbers for the listeners from the file. On *nix systems, this is typically in the Sybase Home directory ($SYBASE/interfaces) On Windows systems it's called and can be found in %SYBASE%, which is likely to be c:\sybase (I think..been a while since I've run on Windows). I believe you can launch the GUI interfaces editor through Sybase Central, if you are using that to manage your ASE databases. and are the two utilities that can be used to edit the interfaces file. You can also manually edit the interfaces file using a text editor such as but be sure to pay attention to the format of the entries and permissions, so as not to accidentally muck it up. 

Databases will typically issue a checkpoint prior to dumping the data to ensure all commits are written to storage. The checkpoint can cause the database to truncate the transaction log, depending on database settings. According to Microsoft, the following conditions will automatically trigger log truncation: 

Sybase ASE will not allow you to directly delete rows from multiple tables using a wild card, but it's pretty simple to create a script to find the table names, and loop through them. You can find the tables names by querying within the database. To find all the tables with the prefix you would do: 

| School (SchoolId) is located in county (CountyCode), district (DistrictId). School is identified by SchoolId. For each school, that school is located in exactly one county, district. For each county, district; more than one school may be located in that county, district. If a school is located in a county, district; then that county must be located in that district. 

P2 Course number (PRE_NUM) is prerequisite for course (C_NUM). c2.1 For each prerequisite course that course may be prerequisite for more than one course. c2.2 For each course, that course may have more than one prerequisite course. c2.3 A course can not be prerequisite to itself. c2.4 If a course has a prerequisite then that course must exist. c2.5 If a course is a prerequisite then that course must exist. 

If you prefer single-column then you can ADD them to and tables, but you must keep the existing ones as (unique) and reference them in foreign keys where applicable. 

| Student record (RecordId) was generated for student (StudentId) by teacher (TeacherID) in school (SchoolID). Student record is identified by RecordId. If a student record was generated for a student by a teacher in a school, then that student must attend that school. If a student record was generated for a student by a teacher in a school, then that teacher must teach in that school. 

This is not about natural and surrogate keys, but about concept of independent and dependent entities. Here is your original example 

It's typically good practice to seperate your OS installation from your database installation to isolate OS disk issues from database disk issues. The primary reason for this is to reduce the change that a problem with the OS could prevent recovery of the database, or vice versa. If your database fills up the free disk space, it can crash both the database and the OS. This also allows you to have different recovery options available for the different pieces. We typically run RAID 1 (Mirroring) on our OS disks, and RAID 5 (or some other type of parity + striping) on our Database disks. Since the OS disk has fewer writes, we can take the performance hit of mirroring, to reduce recovery time in a crash situation. But on the Database side we want to maximize the performance of reads/writes at the expense of recovery time in a crash situation. 

If you execute this from and using the flag to supress headers, and flag to redirect output to a file, it will build a script that can then be executed directly. 

The first name is the table name and the second name is the column name. You can use '%' as a wild card if you don't know the exact name you are looking for. 

The transaction log can be dumped indedpendantly of the database using the BACKUP LOG command: Backing Up the Transaction Log (full and bulk-logged recovery models)