Since you're open to using .fbx, you may want to check out this sorta recent article on MSDN to skin your model, add bones to it, and export the animations to XNA 4. It actually summarizes this Codeproject article but it's still up-to-date with the newer Blender 2.5 interface. However there's a gotcha because of a difference of exporting in 2.59 as shown from a comment in the CodeProject article - 

For simple scenes, use an aggregate of geometric primitives for collision testing. Your example can be broken down into a finite plane, box and rectangular prism. Since the only object interacting is a single sphere, your testing can be kept very simple. If your scene is considerably larger, an quadtree or octree approach to organizing collision shapes is sufficient enough and can ensure that you only test what is close to the sphere. Convex hulls would apply to the moving sphere, for representing the space that the sphere moves within a given time frame. This space is best envisioned as a short capsule with round ends. For collision detection, you can break this into one cylinder and two half-spheres and test for those. Going back to the quadtree, you will first recursively check which leaves/nodes the capsule shape is occupying, not the sphere (capsule-box intersection). Then iterate through the collision shapes that are in them and do a test case for each. It's probably not the most efficient method for collision checking (sweep and prune handle many more scenarios) but for one sphere this is good enough. 

This method stores the first value in the integer part (by multiplying by 1000) of the float, and the second value in the fractional part. Using the magic number allows you reliably to store values from up to and for texture coordinates this is more than enough. For a 2028 texture there is almost no precision loss using this method compared to the classic approach. The computing cost if the unpacking is unnoticeable. 

on IOS as far as i know you can't create a framebuffer with a different resolution than the screen so the only approach is to render everything into a texture and draw it afterwards on the screen. Also targeting different resolutions is quite hard and there are a couple of things to take into accound: Aspect ratio of the screen: The texture you create should have the same aspect ratio as the screen otherwise thing will look stretched afterwards. If you don't want to do this you can fake the aspect ratio of the game from the projection matrix but in this case the pixels from your texture will be stretched unevenly creating aliasing artifacts that will just look bad. Aspect ratio again: It is important that the projection matrix takes into the account the screen also because on a wider screen you will see more on width so the projection has to be wider otherwise the content will look differently. Menus: This is a really hard topic but the general approach is to have the elements scaled evenly on width and height but this is not possible if you have different aspect ratios unless you split the menus into parts and apply uneven scale only on salable elements(like the empty space between buttons). Much like how html pages are made , you have the content that is fixed(or scaled evenly) and the borders are stretched until it fill the whole screen. Artifacts generated by scaling: When rendering to a texture and scaling it up you will get aliasing artifacts and they are hard to remove. You can use an upscale filter, but this can be expensive on mobile devices. 

You might get some added attention from the XNA community by uploading your project to CodePlex. It's Microsoft-hosted and thus you can expect a lot of C#/.NET stuff. A lot of open-source XNA games, engines and frameworks are easily found there. 

When you're dealing with vertex buffers, it gets real tricky with doing cross-platform or cross-API code, especially if you want to use the best approach particular to each API. I would look at some open-source cross platform engines such as OGRE to see how they do things at the lowest level- don't try to implement more complex ideas right away, like quadtree heightmap generation or cube mapping. A good first step is to start porting your XNA code to DirectX 9 first. XNA really just hides many things of DX9 behind the scenes, and you will just have to learn how to work with unmanaged code. When you have the basics down of loading and reading resources in DX9, you can begin wrapping it around more general functions. You have one benefit with OpenGL, though. It handles resources in a more managed way (just imagine all of them are in a managed pool). With DX9 you have to handle lost devices to take care of your resources. 

Move to the scope of the state machine and set the 'blocked' flag to be true by default. When input is received in either state, calculate and check if it's blocked. Therefore, will be in a different location from the player when input is received. 'Blocked' should also be true if (not receiving any input). In both states: 

the easy option to integrate is to store 2 texture coordinates into one float using the int part and the decimal part: 

interleaved: if is easier to understand and to manage memory wise and code wise. Instead of having 4 buffer you have just one and that's it. separate: there is no practical advantage in sharing resources, managing 3d stuff is difficult as it is and by having the separate streams shared would only create a nightmare. You might gain some memory by doing that but it's not worth it. on performance there might be a difference , at least on some Android GPU i know that you will have different results. 

I would not call this a that simple but here is now you can do it: Let's first have some notations (given the picture you provided): 

The application is usually tested on the targeted platform with the worst case scenarios and you will always be prepared for the platform you are targeted. Ideally the application should never crash, but other than optimization for specific devices, there are little choices when you face low memory warning. The best practice is to have preallocated pools and the game uses from the very beginning all the needed memory. If your game has a maximum of 100 units than have a pool for 100 units and that's it. If 100 units exceeds the mem requirements for one targeted device then you can optimize the unit to use less memory or change the design to a maximum of 90 unit. There should be no case where you can build unlimited things , there should always be a limit. It would be very bad for a sandbox game to use for each instance because you can never predict the mem usage and a crash is a lot worst than a limitation. Also the the game design should always have in mind the lowest targeted devices because if you base your design with "unlimited" things in it then it will be a lot harder to solve the memory problems or change the design later on. 

In Blender 2.5 and later, select the face or edge you want to measure in Edit Mode, and turn on the Properties shelf by pressing 'N'. In here, scroll to Mesh Display > Numerics. You can select to display the edge length and the face area of the faces. To get the size of an entire object, the Properties shelf in Object Mode will list the X, Y and Z dimensions. It's right in the Transform section. 

Exception handling is a cleaner way to handle unexpected errors from any point in the game. But the beauty of it is, in your codebase, it won't matter how deep you are in the code to handle it. Without exceptions, some kind of error handling routine would be returning a bool or int for some kind of status, then unwinding the nested subroutines till you got to a top-level area (your game class) and exit from there. It will get very cumbersome to write your code to error check from any possible point, wheras using exceptions requires little to no refactoring. Since your question is XNA specific, it will probably be of good use to know how to handle exceptions in an Xbox game, because when a game in there doesn't catch one, you are not left with a clue as to why it happened. This article shows you a clever way to work around that by running your entire game in a try/catch block. It will launch a new "ExceptionGame" if something happens to go wrong, passing the details of the error to display in the ExceptionGame. 

So basically you want to know if any line , , , or intersects your polygon The naive way to do this is to define the polygon with a a set of segments you can use line-line intersection to test this: 

To simplify the problem i think you want to check if any point ,, is visible from the players's perspective and in this case you don't have to take a reference point you can just do , 'BD' and . You would basically have to do this for each polygon in your scene which is not that efficient in the end (if you have a big scene). The best approach is to use spacial partitioning like a BSP tree (best for your case) but this is not that trivial to implement. If you scene is small or relatively small you can use the approach described above and you can even improve this by adding a 2d Grid to store references to polygons that you want to test. 

There is not ideal way of doing it, this is a common problem with meshes. To solve this there, are two different approaches: Considering that you have a vertex that has to be used with two different textures coordinates here is how you can approach the problem: 1:Duplicate the vertex and assign to each one the different texture coordinates. As a result you will have two vertices with exactly the same position but two different texture coordinates. How you store the vertex data is not really relevant at this point (interleaved or not). There is no way i know right now (someone correct me if i'm wrong) to be able to represent an indexed vertex buffer in order to share vertex position and different texture coordinates. 2:Separate the geometry in multiple parts and draw it with two (or multiple) draw calls but this has a couple of drawbacks. First need to create extra code to be able to share the vertex position, second you need to make multiple draw calls and this hurts performance especially on mobile devices. I think the first approach is the industry standard because in the end the extra memory used is not much of a problem. One way to overcome the memory usage is to use streaming and it's much easier to use that (not to mention that you can significantly increase the amount of geometry) instead of the second approach in which adds a lot of code complexity. 

I am guessing your class actually represents a vertex buffer (and not a collection of thousands of Vertex objects that make up your Mesh). When I started out making a low-level rendering engine, I had a class only require exactly one and class, because I didn't see a need where I would have to swap index buffers with a different Mesh after the Mesh is fully built. (This terminology reflects DirectX which I was using) The buffers were initialized with separate and classes, which inherited a base class. A class read the mesh file and spit out structures used by the Loaders. In hindsight this might have been overengineering it a bit, but I wanted to keep the loading stuff separate from the rendering. A pools the Meshes for updating and rendering. has a reference to a scene, it can be swapped with a different Scene if you want several rendering layers going on. I wanted to introduce some basic culling for the scene, so I kept both an ordered list and an unordered list of Meshes for pooling. Every Mesh created goes to the ordered list first, and the unordered list keeps pointers to the ones that needed to be drawed in that frame. Insertion time to the ordered list was linear * log n I believe, because I used string handles for the Meshes ordered to make binary search possible. This made it possible to quickly access the Meshes that need to be drawn (in log n time) and copied to the unordered list. The SceneRenderer iterates through this list in linear time when the scene is drawn. 

Here is a simple solution: Instead of calling everywhere , replace that with a function what has the following code: 

In general i don't think you will ever need to fiddle with the values inside a matrix unless you are writing a math library. So for this you should take a function that creates and orthographic projection and works (or take a math library that has everything) The orthographic projection is like a box has two main components and (your magic numbers i think) and those represent the size of the view frustrum(or box in case of orthographic) in world space. That's why if you have fixed values there the picture will be the same on all screen sizes, but it will be of a different resolution because the content that fits in 480x320 units (inside your world) gets projected on a bigger/smaller surface. So now to make rendered content size(in pixels) match the screen size you must first know how big is your world and how many pixels you are fitting inside a unit. For this i will take you are rendering one sprite with 1024x1024 pixels over 2 world units. For a device that has the resolution 1024x768 the size of the view projection will be: 

Requirement: and must be normalized, and must be in the same space(radians or degrees) Also for 8 directions you must specify all 8 directions vector and the angle_threshhold must be 

Setting the position before you destroy an to 'infinity' will handle all the appropriate collisions calls. 

These techniques don't super-sample or multi-sample, so lines that appear less than 1 pixel in thickness will appear with gaps and not be anti-aliased correctly. This is the downside to using a non-MSAA approach. Since you're only working with a raster image at full resolution, you can't create additional information from these empty gaps. Take notice that all of these techniques are dependent on sampling adjacent luma (brightness) or chroma (color) values. Calculating luma and optional gamma correction requires additional instructions on the AA shader, though it's pretty straightforward. You can offload this by calculating the luma in the previous shader that provides the un-retouched image, storing the luma in the alpha channel. Then in the AA shader, you will simply sample the alpha. 

It's hard to visualize whether the ring is supposed to just expand, or both move away and expand, but it seems like you would want to set ringWeight according to the color mask 

You might want to set weights to the colors of the ring and the ship's texture so that they can cancel each other out and don't blend additively. Make a white ring for the ring texture which would serve as a color mask, and use a float3 uniform variable to change it's color. 

I also used that blog link for reference on importing models. I had a similar problem with importing animated models for this reason. Some models came out sideways in the game, they will animate properly but turned sideways. For instance the Dude model would appear correct using the default import setting for the pipeline, but then I made a custom animation in Blender from a mesh I downloaded elsewhere and on export was turned 90 degrees to one side. Applying rotation in Blender's export settings didn't work either because the bones will be misaligned and animations will look all wrong. I managed to solve the problem by making a modification to the content importer and applying the custom rotation during that step. That part of the article with the RotateAll function, I made the parameters editable in the Properties window. The code isn't much, here's what I added to the model prep code in the model processor class: