however later than the 30s when Turing wrote his initial paper, he did appear to become aware of Babbage/Lovelace. 

Babai has reputedly repaired his proof of graph isomorphism in quasipolynomial time.[1] the proof hinges crucially on Johnson graphs. 

this is nearly the same core question that is driving something like hundreds of millions, or possibly billions of dollars of QM computing research initiatives both public and private worldwide. the question is being attacked at the same time both experimentally and theoretically and advances on each side carry over to the other side. the question does attempt to neatly separate the theoretical and pragmatic/ experimental aspects of this question, but an experimentalist or engineer would argue they are tightly coupled, inseparable, and that historical progress so far on the challenge is evidence/ proof of that. the following point is certainly not going to win any popularity contests (possibly due somewhat to the well-known/ observed bias that negative results are rarely reported scientifically), but it is worth noting that there is a minority/contrarian opinion promoted by various credible, even elite researchers that QM computing may or will never materialize physically due to insurmountable implementation challenges, and there is even some theoretical justification/analysis for this (but maybe more from theoretical physics than TCS). (and note that some may have doubts but are not willing to go on record questioning the "dominant paradigm".) the main arguments are based on inherent QM noisiness, the Heisenberg uncertainty principle, and the fundamental experimental messiness of QM setups, etc. there are now a fairly solid 2 decades of both theoretical and experimental research and the minority faction would argue that the results so far are not encouraging, lackluster, or are even now verging on a definitive negative answer. one of the most outspoken proponents of the negative view (bordering on extreme/ scathing!) is Dyakonov but who nevertheless argues the case passionately based on all the angles: 

here is a nice general survey with a brief overview of diverse (recent) CS applications for p-adic theory, p3 What are p-Adic Numbers? What are They Used for? / Rozikov 

Fred Cohen is an authority & early researcher on the theory of computer viruses. see that wikipedia page for references. his 1987 paper is given credit as maybe the 1st analogy of the virus checking problem to the halting problem. the basic idea is to create a program X that calls a virus checking subroutine with a program code as parameter. then, if the subroutine returns "is a virus", exit. if it returns "is not a virus", infect the system. such a program cannot exist by diagonalization/contradiction, passing its own code as the parameter. therefore there is no perfect virus checker. but it would seem an easy counterargument to this statement could be, program X contains a harmful section of code, and that its irrelevant whether it is called or not-- the program is potentially harmful if it contains any "harmful section of code". as I recall this result was published separately in a mathematical journal but cant find the reference right now. a more recent/advanced topic is detecting polymorphic viruses that change their code in equivalent but random ways. another promising approach that seems to avoid the halting problem issue (in a way that demonstrates abstract theoretical "no-go theorems" can be misleading or even inapplicable in practice) is to create a secure "sandbox" in which a program can run but cannot do anything harmful. the modern web browser can be seen as an attempt to build such a system. the complexity of securing it arises mainly with Javascript. Google is building the NaCL[3] framework that partly originated in academia and is the current leading contender for a high functional sandbox system integrated into the modern browser that still allows machine code. a provably secure software checker validates candidate programs. there are recent dramatic improvements announced[4]. a novel recent idea is to use graph based analysis of execution traces[5]. a more recent topic of virtualization has various security implications/applications as you note eg virus vendors building virtualization systems to find/detect viruses etc.[6] the sophistication of the recent stuxnet virus, apparently the worlds 1st state/govt-sponsored, military-agency-developed virus for cyber/espionage/sabotage purposes, has led to serious/heavy academic study, see the extensive references on wikipedia. there is a recent/new variant discovered targeting the financial industry called flame. [1] An Undetectable Computer Virus David M. Chess and Steve R. White [2] Trends in computer virus research Cohen, 1991 [3] Native Client: A Sandbox for Portable, Untrusted x86 Native Code by Yee et al 2009 [4] NaCl to give way to RockSalt: Computer scientists develop a tool to improve software fault isolation 2012 [5] Graph-based malware detection using dynamic analysis by Anderson et al [6] Detection of Metamorphic and Virtualization-based Malware using Algebraic Specification by Webster, Malcolm 

perfect graphs were first motivated by information transmission theory originating with Shannon ie Shannon Capacity of graphs. they are called "perfect" by Berge because they can be used to model a noiseless or "perfect" information channel wrt transposition errors in transmission called "confounding". from intro in [3] which also has a very detailed history in the 1st chapter cowritten by Berge. 

there is some research showing undecidability associated with various aspects of computation of the Mandelbrot set, a famous, prototype fractal which is computed using complex numbers and counting the number of iterations associated with the equation $z \leftarrow z^2 + c$ to reach an unbounded increasing sequence. a detailed account and survey can be found in [1], which appeared in a physics journal but with heavy use of TCS concepts eg Turing Machines etc. an early ref [2] by Blum concludes that the Mandelbrot set is not decidable. [1] Inaccessibility and undecidability in computation, geometry, and dynamical systems Asaki Saito, Kunihiko Kaneko [2] A theory of computation and complexity over the real numbers Lenore Blum, 1990 

apparently lacking an exact known answer or a better one than this, heres a near/recent ref on research specifically on the subj of minimizing REs (which is an apparently uncommon angle): Minimizing NFA's and Regular Expressions (2005) by Gregor Gramlich, Georg Schnitger 

it is a 902pp abridged version of the complete encyclopedia, Encyclopedia of Computer Science, 4th Edition, 2064pp 

see e.g.: N-Dimensional Volume Estimation of Convex Bodies: Algorithms and Applications by Sharma, Prasanna, Aswal for an example/case study in economic forecasting, ie supply chain management. 

arguably thread safety is a more abstract concept that would be difficult to formally/strictly define although there are some definitions with variations in the literature depending on the specific context. thread safety also fits in highly with "best practices" and "design patterns". loosely defined, a thread safe program does not have bugs related to multithreading. this definition is intentionally vague because defining thread safety exactly would almost be as difficult as defining what constitutes a "bug". heres another way to approach it. generally thread count $n$ is the variable in multithreaded system. thread safety means that the code "runs the same" or "gets the same results" regardless of $n$ including $n=1$, or for both $n=1$ and $n>1$. here is a taxonomy of "degrees of thread safety" outlined by a java practitioner/authority/author that would probably be general across languages: immutable, thread-safe, conditionally thread-safe, thread-compatible, and thread-hostile the general trend is to create high level abstraction libaries for multithreading (see intel threadable building blocks, java concurrent library) and use the higher level object abstractions instead of lower-level language features. (eg in java this would be "synchronized" code, special thread-related keywords like "transient" etcetera). there is a lot of research in this area in papers & one paper I recall attempted to create and prove that a simple system built out of "pipes and filters" design pattern (similar to unix) was both thread safe and that many alternatives were likely not threadsafe, but cant locate it at the moment. 

the paper you cite by Ercsey-Ravasz, Toroczkai is very crosscutting; it fits in with/ touches on several lines of NP complete problem/ complexity/ hardness research. the connection to statistical physics and spin glasses was uncovered mainly via "phase transitions" in the mid 1990s and that has led to a large body of work, see Gogioso[1] for a 56p survey. the phase transition coincides with what is known as "the constrainedness knife edge" in [2]. the exact same transition point does turn up in very theoretical analyses of computational complexity/ hardness eg [3] that also relate to early studies of transition point behavior in clique problems by Erdos. [4] is a survey/ video lecture on phase transitions and computational complexity by Moshe Vardi. [5][6] are overviews of phase transition behavior across NP complete problems by Moore, Walsh. then there is scattered but maybe increasing study of the diverse connections of dynamical systems with computational complexity and hardness in a variety of contexts. there is a general connection found in [7] possibly explaining some of the underlying reasons for frequent "overlap". refs [8][9][10][11] are diverse but show a reoccuring theme/ crosscutting appearance between NP complete problems and various dynamical systems. in these papers there is some concept/ examples of a hybrid link between discrete and continuous systems. chaotic behavior in NP complete systems is analyzed in [11]. A somewhat similar ref to Ercsey-Ravasz/ Toroczkai in the area of quantum algorithms in that the dynamical system is found to run "apparently" in P-time [12] 

another key area/ possibility you mention is AI which has generally broken off from TCS research as practiced in academia and is now regarded as either more applied or more abstract/ speculative, and few researchers cross that gap, but there are many books on the subject by respected researchers verging on the philosophical. eg, recently 

yrs ago when I asked about this elsewhere, there was an assertion that "fractals are not technically defined". think there is some validity to that. since then Ive been thinking that maybe fractals are best defined as a computational sequence or "computation tableau" eg via a turing machine. this would be a very broad definition but seems to fit & dont see obvious alternative. (worthy of another question here maybe) or at least there seem to be multiple plausible definitions of fractals. also in line with this def of fractals in terms of computational tableaus, one major contribution to study of fractals is via cellular automata patterns, heavily studied by Wolfram in New Kind of Science.[1][2] [1] New Kind of Science/wikipedia [2] New Kind of Science/Wolfram online version 

the claim follows from constructions in [1] where basically a regular expression is constructed using exponentiation that simulates a TM computation on a specific input iff it is not equal to the "full language" $\Sigma*$. the exponentiation is used to reflect the maximum tape width used in the TM computational tableau accepting the word in the language. this construction can also be found in [3]. a halting computation can be found iff there is a finite $n$ tape width for that computational tableau accepting the word. now, to tie this in more with the question, while this is not widely noted (considered trivial by some), many open problems in TCS/mathematics are tightly connected with undecidability in that given an oracle for the halting problem, they can be "solved". therefore, in a sense, tying this all together using this basic problem about DFAs that is undecidable, there will always be open problems about DFAs, because there will always be "open" problems about DFAs (such as this one) equivalent to undecidable problems. in fact using Rices theorem in reverse as this construction does in some ways, basically any relatively "simple" yet nontrivial computational property in TCS can be used to construct undecidable problems. [1] Word problems requiring exponential time / Stockmeyer & Meyer [2] Meyer, A.R. and L. Stockmeyer. The equivalence problem for regular expressions with squaring requires exponential space. 13th IEEE Symposium on Switching and Automata Theory, Oct 1972, pp.125–129. [3] Introduction to languages, automata and computation / Hopcroft/Ullman. 

it was found as a ref in this survey of CAs which might have other helpful leads on the inquiry (eg see sec 7, Reversibility and Universality). (at 17 pgs & 86 refs the title is verging on ironic.) UNIVERSALITIES IN CELLULAR AUTOMATA A (SHORT) SURVEY Ollinger 

there is a fairly natural way to map most open problems onto questions of (un)decidability. most open problems generally are not known to be provable or unprovable. on the web there is some informal confusion about the undecidability of the P vs NP problem, which is not strictly a decision problem, therefore to talk about its undecidability is not technically correct. but on the other hand there does seem to be a close/natural link between undecidability and provability as follows. for example consider 

there are some new modern attempts to build the Babbage machine, one by John Graham-Cumming. he says in this New Scientist article: 

something close to what you are requesting seems to be proven in Thm 2.10 p6 of these lecture notes by O'Donnell, Lecture 16: Nisan’s PRG for small space but it does not cite the original ref for the proof. a simple statement of the theorem in terms of FSMs is not given in this ref but is translatable. (volunteers?) in the theorem $M^n$ is a transition matrix defining a FSM. there are other related theorems in the notes. this apparently same proof is also cited by RJlipton on his blog "the warranty on Nisans generator". the proof apparently originates from the paper How strong is Nisan’s pseudo-random generator? David, Papakonstantinou, Sidiropoulos (2010). also note a near deeper question & better bounds are tied with a major complexity class separation: 

one of Einsteins 1905 "miracle" papers was on brownian motion, a classic physical example of a random walk and yields a formula (ie, basically an algorithm, if the physical process is the "computer") for estimating/calculating particle (molecule) diameter given other known physical constants and the observation/measurement of the (random) particle displacement over time. this paper also served as early theoretical/experimental/foundational evidence for the atomic theory of matter. 

seems like an active, even central/core area of current research under the heading of "exact power of derandomization". its basically an open question with various open complexity class separations whether randomization adds power, or doesnt. theres also a deep connection to the $\mathsf{P \stackrel{?}{=}NP}$ problem in the natural proofs result of razborov/rudich which shows that, loosely, a $\mathsf{P \neq NP}$ proof would likely allow one to "break" what are now conjectured as "secure" random number generators. [1] is a broad survey on derandomization literature by Impagliazzo. (think there are other surveys out there but cant find them this moment.) [2] is a rough outline of natural proofs paper. there is also a lot of connection of randomization (via pseudorandom generators) across the semifamous "5 algorithmic worlds" introduced also by Impagliazzo.[3] basically various complex algorithms have been successfully derandomized in significant advances, but others resist efforts. one famous case study would be the AKS primality algorithm which for decades was a probabilistic test that was cleverly derandomized by AKS & proven to run in P time. [1] Can every randomized algorithm be derandomized? by Impagliazzo 2006 [2] Natural proofs explained by chris calabro [3] 2009 workshop on impagliazzos 5 worlds 

this is clearly a very emerging area so surveys and established literature would be difficult to come by. also complexity theory may be a little more abstract for this. however a compelling/natural area on the rise/intersection between CS/econ: try recent research into auctions which is especially significant given google Adsense advertising largely funding the rise of the company over the last decade and also their singular auction-based IPO. also note the large-scale economy price fluctuations and buyer/seller dynamics can be modelled somewhat as an auction-like system. another somewhat similar area where some very advanced/substantial CS is applied is high-speed trading, a complex/advancing science but unfortunately it is not openly published research due to its heavy secrecy. [1] Auctions and bidding: A guide for computer scientists by Parsons [2] Computer science tackles 30-year-old economics problem - MIT researchers generalize Nobel winner’s work on single-item auctions to auctions involving multiple items. [3] Menu size complexity of auctions Sergiu Hart, Noam Nisan 

the ref is: [2] S. Arora, C. Lund, R. Motwani, M. Sudan, and M. Szegedy. Proof veriﬁcation and the hardness of approximation problems. Journal of the ACM, 45(3):501–555, 1998. 

the Game of Life cellular automaton, which has very simple update rules and was an early scientific/mathematical/computational example that exhibits/demonstrates emergence, is Turing complete, with the proof initially credited to Conway but it seems to be unpublished. Paul Rendell has constructed versions of a TM running inside of Life. 

a billion node graphs have probably not been visualized much and are right on the edge of feasibility and an active area of research. the approach would generally have to depend on the unique data characteristics to reveal the features that are relevant/key for that dataset. assuming you mean in 3d. there are at least two roughly independent hard parts of your request