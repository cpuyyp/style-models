These subsets of grids, and your graph-theoretic interpretation of them, are studied in my paper The complexity of bendless three-dimensional orthogonal graph drawing. D. Eppstein. J. Graph Algorithms and Applications 17 (1): 35–55, 2013. $URL$ I don't think I included the quadratic example suggested in daniello's answer in this paper, but you can find it in one of my blog posts from ten years ago, $URL$ (see the ETA at the bottom). Incidentally, the same construction (points with coordinate sum 0 or 1) in the 3d integer lattice, without the mod $n$ part, produces a lattice embedding of the hexagonal tiling of the plane. Doing the same thing in 4d, similarly, produces a lattice embedding of the 3d diamond lattice. See another of my papers: Isometric diamond subgraphs. D. Eppstein. 16th Int. Symp. Graph Drawing, LNCS 5417, 2009, pp. 384–389. $URL$ 

According to Guraswami et al, FOCS '08, the unique games conjecture would imply that there is no approximation algorithm for the maximum acyclic edge set of a digraph significantly better than the one that randomly permutes the vertices and includes an edge when it goes from an earlier to a later vertex in the permutation (with approximation ratio 1/2). 

Usually I just cite the journal version. But (if the history is important) I would add a note to the same citation about earlier conferences or preprints. I think this style is preferable to making one paper look like two citations, except possibly in cases where the conference and journal papers have other significant differences than completeness (such as changes to the author list or claimed results). It is also unrelated to whether the citation is to my own paper or someone else's. For harvard-style Name (year) citations, it might also make sense to mention the earlier version in-text as Name (year, announced earlier-year), as well as putting the information in the actual reference. [Converted from a comment to an answer at the suggestion of Kaveh] 

I doubt your features simplify the problem at all, but it's very easy to 6-color a planar graph: find and remove a vertex of minimum degree, color the remaining graph recursively, put back the removed vertex, and give it a color that's different from all of its neighbors. If you maintain an array indexed by vertex degree, with a list of the vertices with that degree in each array cell, and move the vertices to different lists when a removal causes their degrees to change, then you can find the minimum degree vertex by scanning the array from low to high degrees, and the overall algorithm will be linear time. This also has the advantage that it automatically and quickly takes care of the completely surrounded regions: they have degree one, so they're dealt with first. I think the best known time bound for 4-coloring planar graphs is still larger — more specifically, $O(n^2)$ from the work of Robertson, Sanders, and Thomas in the mid-1990s. But there are more complicated methods for 5-coloring planar graphs in linear time; one relevant reference is the paper by Hagerup, Chrobak, and Diks in ICALP 1987, and another is by Frederickson in IPL 1984. 

Use Prim–Dijkstra–Jarník instead and then sort the edges to get the insertion sequence that Kruskal would give, or Use the quadtree closest-pair data structure described in the paper, viewing Kruskal as a standard agglomerative clustering procedure where we merge the closest two clusters into a supercluster at each step, with "closest" defined as the length of the shortest edge connecting two clusters. 

Expanding vzn's comment into an answer: The standard reduction from CNF-SAT to vertex cover is pretty easy: make a vertex for each term (variable or its negation), connect each variable to its negation by an edge, make a clique for each clause, and connect each vertex in the clique to the vertex for one of the terms in the clause. If you start with a satisfiability problem with a known satisfying assignment, this will give you a vertex cover problem with a known optimal solution (choose the term vertices given by the assignment, and in each clause clique choose all but one vertex, so that the clause vertex that is not chosen is adjacent to a term vertex that is chosen). So now you need to find satisfiability problems that have a known satisfying assignment but where the solution is hard to find. There are many known ways of generating hard satisfiability problems (e.g. generate random k-SAT instances close to the satisfiability threshold) but the extra requirement that you know the satisfying assignment restricts the possibilities. One thing you can do here is go through another level of reduction, from a cryptographically hard problem such as factorization. I.e. choose two large primes p and q, set up a Boolean circuit for multiplying p and q as binary numbers, and translate it into a CNF formula in which there is a variable for each input (p and q) and for each intermediate value on a wire in the circuit, a clause for each output forcing it to have the right value, and a clause for each gate forcing the inputs and outputs of the gate to be consistent with each other. Then translate this CNF formula into vertex cover. For a simpler strategy, choose the satisfying assignment to a 3CNF formula first, and then generate clauses at random, keeping only the clauses that are consistent with the assignment, and then convert to vertex cover. If the clauses have uniform probability this will be vulnerable to a degree-based heuristic (the term vertices that match the chosen assignment will have lower degree than the term vertices that do not) but this shortcoming can be avoided by adjusting the probabilities of the clauses according to how many of the clause's terms agree with the chosen assignment. Probably this is vulnerable to some kind of polynomial time attack but it might not be one that's natural for vertex cover, so it might make a good set of test instances despite not having much guarantee of hardness. 

The relevant references appear to be: Ueno, Shuichi; Kajitani, Yoji; Gotoh, Shin'ya. On the nonseparating independent set problem and feedback set problem for graphs with no vertex degree exceeding three. Proceedings of the First Japan Conference on Graph Theory and Applications (Hakone, 1986). Discrete Math. 72 (1988), no. 1-3, 355–360. Li, Deming; Liu, Yanpei. A polynomial algorithm for finding the minimum feedback vertex set of a 3-regular simple graph. Acta Math. Sci. 19 (1999), no. 4, 375–381. (Warning: I have not read either one but they both claim to solve the problem in polynomial time. I don't think the difference between 3-regular and max degree three is important for this problem.) 

Another parameterized paper has just been accepted to SWAT 2012, this time parameterized by longest induced path length: 

Classical physical problems often involve real-number positions or parameter values rather than values from a discrete set (such as the integers) which would be more typical of NP-complete problems. Because of this these problems can often be NP-hard but not (or not obviously) NP-complete. For instance, we do not know whether the Euclidean TSP (for integer points in the plane, with Euclidean distances) is NP-complete, because it hinges on an unsolved problem, the complexity of comparing sums of square roots. Some other geometric problems, such as the recognition of unit distance graphs (of some relevance as an abstraction of protein folding) are complete for the existential theory of the reals, which as far as we know is a different complexity class than NP. 

So, start from $v$, and follow the Hamiltonian cycle within its own component. Then, when the cycle would return to $v$, instead follow any edge to the next component in the total ordering of the components (there's an edge to that component because there's an edge to every vertex and because the edges connecting the current component to the next component are all oriented in the direction you want to go). Then continue the same way in each successive component. 

If you're looking for data structures at a graduate level, my suggestion would be Erik Demaine's online course materials for his class "Advanced Data Structures" (video lectures and notes) available through MIT Open Courseware at $URL$ Unfortunately I don't think there is really a good textbook on this material at this level; for this reason, in my own graduate data structures course, I use a collection of Wikipedia readings instead. 

Single-linkage clustering gives the same connections in the same order that you would find using Kruskal's algorithm for the minimum spanning tree, and the clustering can be found by finding a minimum spanning tree and then running Kruskal's algorithm on the resulting $(n-1)$-edge graph. Therefore, the time is bounded by the MST construction + the time to sort the edges of the MST. The two-dimensional $L^\infty$ MST can be constructed in $O(n\log n)$ time using rectilinear Voronoi diagrams, and an $O(n\log n)$ algorithm for the three-dimensional version is given by Krznaric, Drago; Levcopoulos, Christos; Nilsson, Bengt J. (1999), Minimum spanning trees in $d$ dimensions, Nordic J. Comput. 6 (4): 446–461. more generally an algorithm that is within a polylog factor of linear for any fixed dimension is given by Gabow, Harold N.; Bentley, Jon Louis; Tarjan, Robert E. (1984), Scaling and related techniques for geometry problems, Proc. 16th ACM STOC, pp. 135–143, doi:10.1145/800057.808675 

Along the same lines as ratchet freak's answer, if you fill in the non-starred cells in the following matrix, a 3x3 box at a time, always choosing the next box to fill in to be one that shares rows or columns with a box you've already filled in, you get a pattern like the following for the number of choices per step (filling in the top middle box first, the top right box next, etc). In each 3x3 box after the first, once you've filled in one row or column of the box, three of the remaining six digits are localized to a single row. Choose their locations first, and then fill in the remaining three cells. (So the actual order of which cells to fill in might vary depending on what you already know, but the number of choices is never more than what I've shown.) After you've filled in these cells the stars are all determined. 

Nomenclature aside (a line graph is something different than what you describe), you appear to be describing the problem of ''maintaining order in a list''. You have a list of items $v_i$ (your graph), you can remove an item from one point in the list and re-insert it elsewhere, and you want to check whether one item appears earlier than another in the list. This problem has a constant-time solution; see Dietz and Sleator, "Two algorithms for maintaining order in a list", STOC 1987, $URL$ and $URL$ 

I believe these graphs can be colored in polynomial time. Moron has already provided a reference, but here's an explicit algorithm. Suppose that $G-uv$ is an interval graph, for edge $uv$, and form an interval representation for it. We can assume without loss of generality that no two intervals have the same endpoint. We can also assume without loss of generality that $u$ and $v$ are the two extreme intervals; for, if some other interval were extreme, we could remove it, optimally color the resulting smaller graph (also of the form interval+one edge), and then optimally extend the coloring to the removed vertex (because its neighborhood is a clique). So the remaining question is: does $G-uv$ have an optimal coloring in which $u$ and $v$ have different colors, or does edge $uv$ require us to use one more color? But this is easily solved by a dynamic program on the subintervals of the interval representation. In more detail, for subinterval $i$ let $C[i]$ denote the set of intervals (vertices of G) that cover that subinterval, let $D[i]$ be a Boolean value, true if there exists a coloring of the subinterval (in an optimal coloring of $G-uv$) that does not use the same color as $u$, and let $E[i]$ be the set of vertices that can be colored with the same color as $u$ (again, in an optimal coloring). As a base case, $C[0]=E[0]=\{u\}$ and $D[0]$ is false. When going from subinterval $i$ to subinterval $i+1$, across the right endpoint of an interval $w$, we set $D$ to be the disjunction of its old value and the predicate $w\in E[i]$, and we then remove $w$ from $C[i]$ and $E[i]$. When going across the left endpoint of an interval $w$, we add $w$ to $C[i]$, we add it to $E[i]$ if $D$ is true, and we change $D$ from true to false if the new size of $C[i]$ equals the number of colors in an optimal coloring of $G-uv$. Then, the optimal number of colors of $G$ is the same as for $G-uv$ iff either D is true for the final subinterval, or E[i] has more than one member in the final subinterval. Otherwise, the optimal number of colors for $G$ is one plus the optimal number of colors for $G-uv$.