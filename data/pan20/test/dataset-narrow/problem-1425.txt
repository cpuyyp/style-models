I would say that the singleton design itself isn't useful at all. Global variables can definetly be useful but I'd rather see them hidden behind a well-written interface so that you aren't aware of their existence. With singletons you are definetly aware of their existence. I often use global variables for things that need access all through out an engine. My performance tool is one good example which I use all over the engine to call. The calls are simple; ProbeRegister(), ProbeHit() and ProbeScoped(). Their real access is a little bit more tricky and uses global variables for some of their things. 

I have a home-made profiling system that consists of profile-probes that I've injected on a lot of none-inner-loop places in my code. The probes are initially disabled and I just enable the ones that I want to check up on. The system simply throws out the information to a .txt file (or a network stream) that I then use another language to parse the output from and present the data in a more user-friendly way. The probes are globally initialized upon creation and only when recording them creates any data. The benefits of this is: * While enabled (even in release builds), the system is light on cpu cycles and you'll most likely not notice any performance hit while all probes are disabled. * While disabled (final build), the system is reduced to 0 cost (like most home-brewn profile-systems). * It can measure time, hits, record callstacks, print variables, so it's flexible and can be used for most debugging that you'll need. * It's dynamic, you can get exactly the information that you want from it. On the negative side: It took nearly 2 days to implement so it's fairly complex. It'll likely make up for that time though. Examples for usage: * Timescoping * Memory allocations (sizes, names, etc). * Resource tracking * Debugging (conditional prints). 

forgive me if i understood your question incorrectly, i have given this some thought in the past and decided that i would create an Enum for each action, and map each action to an enum for the controller method and an enum for the button /key press this would in theory allow you to use both controller and keyboard (and mouse for that matter at the same time) all you need to do is code the listening method to return the correct enum set when asking for the mapping of an action finally when in you update loop that key is pressed you need to fire that event and have any component that is listening for it respond accordingly. personally i would just create a wrapper class to do this for you and have the components talk to the wrapper (therefore maintaining separation of concerns a bit more) 

draw each separately and place on top of each other with the tile i would try to draw in order(topleft to bottom right), or define the the specific layer it should be drawn to (you can probably compute this from world coordinates (or tile index) i would imagine the solution may vary from engine to engine but this would be how i approached it from an XNA / MonoGame pov 

Ideally, the water would not be uniformly oily, but instead the oil could be generated from some source (such as a polluting drain from a chemical plant) and then diffuse throughout the water body. My thought for this part would be to keep an "oil map" as a 2D texture that determines the density of oil at each point on the water surface. It would diffuse and move naturally with the water vel;ocity at that point (I have a wave-particle simulation for dynamic waves, and am already doing something similar for foam on the water surface). However, I'm not sure how physically correct that would be, since oil might not move at the same velocity as the water. And I have no idea how to make all those trippy colors :-). Thoughts? 

The problem was one of numerical stability. Approx 30 hours of work on this over the course of 2 months, only to figure out I was doing it right from the very start. When I ortho-normalized the rotation matrices before plugging them into the retarget code, the simple solution of multiplying source * inverse(target) worked perfectly. Of course, there's a lot more to retargeting than that (in particular, taking into account the different shapes of the skeleton, ie shoulder width, etc). Here's the code I'm using for the simple, naieve approach, if anyone is curious: 

there are a number of Camera Tutorials around that will show you how to go about creating a Matrix that will automatically move your camera to a position that you determine all you then need to do is pass it to the Spritebatch and everything will work as expected what you need to be careful with is then converting a onscreen event to a world position $URL$ code from article 

store the location of the ball last frame and draw that, or if that is too close store the location 5 frames ago alternatively if you know the direction of the ball use 

where _time is the time since last frame. although down side of this is that it will not map actual path accurately just be sure the ball is not so close as to confuse it with the current ball 

taking a different approach i would look to do something similar to $URL$ essentially find what is below the line and generate a color 

note this is untested and you may need to alter the order in which colorsNew is filled, but this should basically do what you require 

So I guess that your initial attempt is to iterate through all meshes in your scene, for each mesh, check all triangles if they intersect, right? The brute-force way. I'm not sure if there's a lightweight library for you to solve your problem, but the problem is quite a large discussing area. I would suggest using a bounding-volume structure, such as a KD-Tree used in 3 dimensions. Christer Ericsson suggests an implementation in his book "Realtime Collision Detection" which is cache-friendly and memory efficient. I've implemented his suggestion in a project and indeed it did turn out very well. The task of creating a KD-tree together with splitting your meshes into well-balanced tree's is covered in depth by Ingo Wald ($URL$ I suggest you read up on there. The Surface Area Heurestic (SAH) is considered (one of?) the best algorithms for KD-splitting, Ingo Wald covers it in one of his publications ($URL$ There are a variety of freeware KD-tree's out there, I haven't really looked into kdtree at google-code ($URL$ but it looks pretty decent. There's some interesting tutorials ($URL$ that you can read. Good luck! 

Personally i have created a secondary GUI Layer and have a single class (c#) that handles all draw calls to this layer information is passed in text format along with the sending object and the class organises the data before drawing it to screen here is an exmple of the output $URL$ 

the code doesn't do anything with it i can also wrap the draw method like this also whilst it maynot be the cleanest solution (it leaves a empty component in release mode) it does allow me to ignore any if debug anywhere else in the project. 

it depends on what the output of distance(v1,v2) is if it is a decimal (float or double) over a vector it is likely that distancesquared would be a lot quicker 

as a quick response to a very open question you need to decide why you want to learn these things if it is to purely make games in your spare time why not have a look at unity3d if it is to become a programmer / gamedeveloper you should first learn the very basics of c++ $URL$ or any other language you may choose. after that you need to start thinking about which platforms you want to target and types of games you would like to make. then i would start to consider your options in line with DirectX or openGL but always keep the options open to things like XNA, monogame or other libraries there are thousands of tutorials out there microsoft has plenty of DirectX tutorials, and reimers.net has some also 

The problem is that the projected position is "jumpy". As I make small adjustments to the mouse position, the projected point moves in strange ways. For example, if I move the mouse one pixel up, it will sometimes move the projected position down, but when I move it a second pixel, the project position will jump back to the mouse's location. The projected location is always close to where it should be, but it does not smoothly follow a moving mouse. The problem intensifies as I zoom the camera out. I'm not sure what's causing the problem, but I'm thinking it might be numerical instability? EDIT 1: Video showing the problem EDIT 2: A little snooping around in .NET Reflector on SlimDX.dll: 

I'm trying to unproject the mouse position to get the position on the X-Z plane of a ray cast from the mouse. The camera is fully controllable by the user. Right now, the algorithm I'm using is... 

The red dot is the unit (who's facing upwards). My goal is to calculate the yellow tiles. The green blocks are walls (walls are between tiles, and it's easy to check if you can pass between two tiles). The blue line represents something like the "raycasting" method I was talking about, but I'd rather not have to do this. EDIT: Units can only be facing north/south/east/west (0, 90, 180, or 270 degrees) and FoV is always 90 degrees. Should simplify some calculations. I'm thinking there's some sort of recursive-ish/stack-based/queue-based algorithm, but I can't quite figure it out. Thanks! 

If the class is longer than roughly one page of your editor, refactor it. I don't think the order of methods or members matter much, as long as they're grouped somewhat logical together. 

I would say: Use neither, as long as you don't explicitly need instant-time feedback from the damage. The damage-taking entity/component/whatever should push the events to either a local event-queue or a system on an equal level that holds damage-events. There should then be an overlaying system with access to both entities that requests the events from entity a and passes it to entity b. By not creating a general event-system that anything can use from anywhere to pass an event to anything at any time, you create explicit data-flow which always makes code easier to debug, easier to measure performance, easier to understand and read and often leads to a more well-designed system in general. 

I would say that that the "Hot position" when it comes to programmers is probably Lead Architect, Lead Engine, or any other name to the same job. Essentially the guy who gets to decide what to implement and how. It's often a person with very good knowledge regarding programming, someone who probably has one of the best overviews of the code in the company. I don't think that it's something that you often get recruited to externally, but instead most likely internally. It requires a lot of experience and often have a tendency to be the best "general" programmers that make it there. 

i think mortal online released a map showing locations of player deaths some time back, however why not think of it another way, give a few companies a call and tell them what you are doing and if they are willing to help, tell them anything you learn you will share with them, i'm sure some will be more than willing to pass some free work your way 

I would consider looking into a procedural generation solution for these. this would include the 'stats',and could possibly include the image. when loading up the cards you are not loading an image but loading up a 'seed' for the card which will allow you generate any information required on game load. this would save significant amounts of hard drive space how the seed looks and works would depend heavily on the implementation of the procedural generation all the caching and threading answers would apply to this solution also 

use Texture2D.getData() to extract the colors array then use this array to create a new Texture and add a pixel on each time increment you should be able to modify the below to your need 

Given a fixed rotation and a target "center" point, how to I find the position the camera should be in so that that point is the center? LookAt changes the rotation keeping the position constant. Basically, I'm trying to do the reverse, but the math escapes me :-). Thanks! Camera is currently psuedo-isometric (orthographic with rotation from Euler angles [X:35.264389683ish°, Y:45°, Z:0°]). Might want to change these a bit or allow rotation though, so ideally a solution would work for any rotation. Can easily get the projection matrix. EDIT: thinking about it, there would be infinite such positions that satisfy this constraint. I would want to fix the Y component of the position (camera height) and find only an X/Z. Thanks to Mokosha's answer below, here's the final code I'm using: 

The problem turned out to be one of numerical stability. I was able to solve the problem by ortho-normalizing the input rotation matrix before doing the operation. 

I would expect a and b to be identical (or inverses of each other). However, it looks like q1 = (x, y, -z, -w) while q2 = (-x, -y, w, z). In other words, the Z and W components have been switched for some reason. Note: decomposes the transform matrix and returns just the rotation part of it (I've tried normalizing the result; it does nothing). The matrix is a complete transform matrix and contains a translation (and possibly a scale) as well as a rotation. I'm using D3DXMatrixDecompose to do the actual decomposition.