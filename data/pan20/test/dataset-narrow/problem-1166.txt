Object in the sense of data + operations: That is pretty standard in mathematics. Take any group theory text book. It will have somewhere a definition such as $h_g(x) = g x g^{-1}$. (It is a conjugation operator.) The $h_g$ is an "object" in this terminology. It has some data ($g$) and an operation $x \mapsto g x g^{-1}$. Or you can make it more object-y by taking the pair $\langle g, x \mapsto gxg^{-1}\rangle$ or the triple $\langle g, x \mapsto gxg^{-1}, x \mapsto g^{-1}xg\rangle$. You can construct these kind of "objects" in any functional programming language that has lambda abstraction and some way to form tuples. Abadi and Cardelli's "Theory of Objects" deals with objects of this kind extensively. Objects with state (or objects that change): Does mathematics have such things? I don't think so. I haven't seen a mathematician talk about anything that changes, not in his/her professional life. Newton used to write $x$ for the position of a particle, which is supposedly changing, and $\dot{x}$ for its rate of change. Mathematicians eventually figured out that what Newton was talking about was a function $x(t)$ from real numbers into a vector space, and $\dot{x}$ was another such function which was the first derivative of $x(t)$ with respect to $t$. From this, many deep-thinking mathematicians have concluded that change doesn't really exist and all you have are functions of time. But what was changing in Newtonian mechanics wasn't the position, but the particle. The position is its instantaneous state. No mathematician or physicist would pretend that a particle is a mathematical idea. It is a physical thing. So it is with objects. They are "physical" things, and the states are their mathematical attributes. For a nice discussion of this aspect, see the Chapter 3 of Abelson and Sussman's Structure and Interpretation of Computer Programs. This is a text-book at MIT and they teach it to all scientists and engineers, who I think understand "physical" things perfectly fine. The fact that particles aren't mathematical doesn't mean that we can't deal with them mathematically. If you ask a mathematician to model a two-particle system, he will immediately make up two functions and call them $x_1(t)$ and $x_2(t)$. So, the two particles reduces to two meaningless indices (1 and 2). This is the mathematician's way of saying we don't know what those particles are and we don't care. All we need to know is that their positions evolve independently (or separately). So, we will model them by two separate functions. Similarly the standard mathematical way to model object-oriented programs is to treat each object as an index into the state space. The only difference is that since objects come and go, and the structure of the system is dynamic, we need to extend it to a "possible world" model where each world is basically a collection of indices. Allocation and deallocation of objects would involve moving from one world to another. There is a problem though. Unlike in mechanics, we want the state of our objects to be encapsulated. But the mathematical descriptions of objects put states all over the place, completely destroying encapsulation. There is a mathematical trick called "relational parametricity" which can be used to cut things back to size. I won't go into it now, except to emphasize that it is a mathematical trick, not a very conceptual explanation of encapsulation. A second way of modelling objects mathematically, with encapsulation, is to finesse the states and describe the object behaviour in terms of observable events. For a good discussion of both of these models, I can refer you to my paper titled Objects and classes in Algol-like Languages. 

I am not sure if the Haskell report defines the semantics rigorously enough to settle the question about what $\lambda x.\, \bot$ should mean. However, it is common experience in Haskell as well as all other lazy functional languages, that, if you ask them to evaluate a term that represents $\lambda x.\, \bot$, the evaluation terminates. The "As a consequence..." remark in the Haskell report is assuming that the reader knows this. Samson Abramsky considered this issue a long time ago and wrote a paper called "The Lazy Lambda Calculus". So, if you want formal definitions, this is where you might look. 

If you are interested in functional programs rather than imperative programs, then a good starting point is 

Different people in Computer Science interpret the term "object" differently. One is that an object consists of some data and operations packaged together. The other is that an object is all that but also has "state," i.e., it is some form of a changeable entity. There are deep philosophical issues to do with what "change" means (and what "entity" means, as it is constantly changing), and whether mathematical descriptions actually capture changeable entities. 

(Gosh, Neel, that was a tough question.) The "folk model" of linear logic is definitely the coherent spaces model, discussed in Girard's Linear Logic paper (and also in "Proofs and Types"). This is not degenerate in the sense you describe. Whether this semantics throws any light on how a linear functional language can be implemented, I am not sure. When you are talking about allocation, reading and linear update, you are indeed talking about the implementation. So, perhaps, your question might be formulated as, "how do I prove correct the implementation of a linear functional language that uses state-update?" I don't know the answer to that, but I think it must exist in the papers that propose linear update implementations. 

This additional response is to amplify the point that denotational semantic models are designed to "explain" computational phenomena. I will give a series of examples from the semantics of imperative programming languages (also called "Algol-like" languages). First there was the semantic model formulated by Scott and Strachey. (Cf. Gordon: Denotational description of programming languages - my all-time favourite or Winskel's book.) This model posits that there is a global state, made up of the state of all the locations allocated by a program. Every command is interpreted as some sort of a function from global states to global states. Reynolds said that it didn't model the stack discipline of local variables. When a local scope is entered, its variables are allocated, and they are deallocated when the scope is exited. Basically, this is the question, "in what sense are local variables local?" How does the semantics capture the locality? To explain this, he invented a functor-category model. (Cf. Reynolds: The Essence of Algol and Tennent: Semantics of programming languages). Tennent wanted to model the reasoning principles formulated in Reynolds's Specification Logic (an extension of Hoare Logic for higher-order procedures). The Logic has ideas like expression-like (read-only) computations, non-interference between command-like and expression-like computations, and some data abstraction reasoning principles. He refined Reynolds's functor-category model to find a new one. This called the "SASL" model, also covered in Tennent's book. Meyer and Sieber, and also O'Hearn and Tennent, noted that none of these models still captured the locality of local variables fully. When two implementations of an abstract data type or a class differ in their local variables but manipulate them in ways that have the same behaviour when viewed from outside, they are observationally equivalent. The denotational semantics should equate them. To model this, O'Hearn and Tennent added relational parametricity to a variant of the Reynolds's functor-category model. When I looked at the problem at the same time, I disbelieved in the functor-category approach. I also thought that it was overly technical and believed there must be a simpler model. This led me to invent the "Global state considered unnecessary" model, which is rather like a CSP traces model, but for a higher-order language. As an added bonus, this model also captured the irreversibility of state change, which was not present in the earlier models. My model only worked for a well-behaved sublanguage of Algol, called Syntactic Control of Interference. Abramsky and McCusker extended my model using games semantics ideas so that it can work for full Algol. So, their model explains the same phenomena as mine does, but for the bigger language. In each case, we are able to demonstrate that the new models capture observational equivalences (or other forms of logical formulae) exhibiting the computational phenomena mentioned, which were not validated by the earlier models. So, there is a very precise sense in which these models are "explaining" computational phenomena. [All the work I mentioned here can be found in the "Algol-like Languages" volumes: link and link]