Is it possible to create a Direct2D PathGeometry object from a XAML string (or from any other vector format) or do I have to create such a parser myself? 

To render just the edges of an arbitrary polygon you could use a Solid Wireframe technique. It uses barycentric coordinates to determine which edges to draw. For example you might have a triangle whose barycentric coordinates are (for each vertex) . Put it simply, when these values are interpolated the further any of the values are close to zero, then the further you are to an edge. You can use this to shade the edges differently than the inside of a the polygon. I have used this technique to draw the sphere and hexagon tiles you see in this video. As the others have suggested, you can add a glow/bloom effect to improve the overall effect. 

I am implementing a mouse rotation which works by accumulating the X-Y delta between frames to yaw and pitch rotation angles. The problem is that I wish rotations to be independent of each other. But as you can see from the picture: 

However it seems that over time the sphere tends to become distorted and then shrink back to its original size. Is this due to the simplicity of the integration or am I doing some simple mistake? 

That error indicates that XNA expect your custom vertex type to implement as shown here. Otherwise you need to use the overload that accepts an explicit object. 

I'm going to implement network features for the game I'm currently working on, now I'm wondering if I need to implement IPv6 support or just having support for IPv4 is enough? 

I'm wondering if opengl can automatically manage offscreen rendering. I mean if it can detect and ignore sprites and textures if they are rendered out of screen. if it makes any difference i'm targeting opengl-es 2. 

the solution you sied doesn't accualy make CPU and GPU to work parrarel, it just changes the order they are waiting for each other, since as the other answer implys draw always put it's results into a backbuffer and using swapbuffers you only change what is monitor shoing with the latest thing drawn, to take full potential of both CPU and GPU you have to call draw and update in two diffrent threads and use another second buffer for what CPU is doing (so that when CPu is generating update results in buffer 2 GPU read from Buffer 1 and when CPU is working with Buffer 1 GPu use Buffer 2 just like swap buffers GPU uses to prevent changes in frame already drawn) 

I'm not sure if this is a valid design pattern or not but at least classes doesn't have bidirectional pointers, and player class can always guaranty its members, since it's move that calls other methods. --EDIT2-- This is the best way I could describe my architecture. It's a complete code, with all the thing available in every game. I'm not sure if this is like your previous style or not or if you can convert your code (or even if you are willing to). if you still think there is anything unclear or want to discuss about this code, I think I'll be available in chatroom in 12 hours meaning something around 1:00 GMT. 

Same thing for index data, but with GL_ELEMENT_ARRAY_BUFFER as target instead. You can change GL_STATIC_DRAW to something else depending on your usage patterns. 

You might want to rethink motion blur and only do it for one frame, not blending between several. This will help you avoid a lot of edge cases where your frame rate is stuttering and you have to decide on which frames to blend and how much. A common way to do this is using motion vectors, where you render your scene again, with extra data for each mesh, and render screen space velocity into a separate buffer. This buffer can then be used as a blur direction control. to compose the final blurred image. You can also build depth of field information at the same time using this technique. 

The general answer is to do a frame capture and profile. Use something like NV PerfHUD or other GPU performance counters to see what the GPU is doing, and which draw calls takes time. You can then get information about what the bottle neck that draw call had. Your case seems to be something like two programs interacting and context switching the GPU? 

OpenGL is used quite a lot for 2D games. We used it in Teeworlds for example. Using it as a pure 2D language is ok, it might give you some quirks when setting up camera and especially if you want stuff pixel perfect. But you will learn a lot by doing it. You can use OpenGL with SDL, it's very common. Most people doing it that way only uses GL though, and skips most (all?) of SDL:s drawing functions. 

To conclude his answer you might use any of those three methods but you need to be careful not to over use either of them since as I said all those designs are really dangerous and might easily result in a unmaintainable code. 

How did you get the idea that you could use CCSprite::create like that? the correct syntax would be: 

i started to place a comment bt it went to long so changed it to an answer : first of all you have specify your target platform, and it would also help if you tell which genre are you going to create a game. the brad answer is to download and install dx SDK if you are going to develop for microsoft group or opengl sdk if you are going to develop for others. there are many sample codes with enough documentation inside each sdk. or you can just pick a game engine again based on the genre and platform you are going to create your game and start reading that engine's specific manual. studying a engine help you create your games easier but will take you a lot more time until you reach the point that you can start your games from the scrach( and blieve me starting to develop a gameengine is almost always a bad idea). for stat I suggest essenthel engine. it comes out with a lot of samples and an active community and it's very easy to use almost the easiest engine i've ever seen in c++ and it's also free unless you want to publish a game with it. but it needs a lot of c++ knowledge to begin with and one might consider it as a moderate engine compared to UDK or similar gigantic engines. --edit-- esenthel engine has only target platform of pc and mac and if you are a license developer you can also create games for ipad/iphone. for an opensource game development i recommend taking a look on ogre3D, it's an opensource engine and even there is chapter in "deitel & deitel: c++ how to program" about it. but as far as I know (I didn't try that engine myself) it's almost somevery basic framework which force you to add many conecpts of your game yourself. And I think givving a bigger challange you can learn a lot more if you really get into it. 

We used Computer Graphics with OpenGL (Hearn & Baker) when I was in university and I liked it a lot. Despite its name, it gives the fundamentals of 2D and 3D graphics and rendering. OpenGL is used as example when doing 3D graphics, but only after the fundamental maths and algorithms have been presented. $URL$ After that, Real Time Rendering as already suggested. 

I usually keep my own format internally, and a standardised format externally. The artist only sees the standard format and my engine can only load the optimized internal format. This way you won't have to have model loading code in engine, it can all be done in some nice high level language as a compile step. I usually use a existing build system that rebuilds an art folder on demand, will only rebuild changed content. Pros: 

Don't roll you own engine. Roll you own game. If you happen to write an engine at the same time then good for you, if not you can always refactor whatever parts you might want to reuse to make it more "engine" like. People often over estimate what it takes to write the "engine" part of a game. If you only do what you need it won't take that long. The hard part is to not get stuck writing infrastructure and to only write what you absolutely must to solver your problem. I would use an existing engine when: 

AFAIK there are two ways to implement that, the first one which is easier is to create an Object, then using CCAnimate and CCSequence classes, first animate an image and then convert it into an image. the harder way which will result in cleaner code (I suggest this one) is to create a class which inherits normal CCMenuItems class. and change it's constructor to start an Animation instead of immediately being clickable. 

Parallax scrolling is just using a set of layers moving with different speed. each layer can be a tilemap, just a sprite, or anything else. normally the most front layer is a tilemap and you only check collisions and other gameplay features with that layer. just keep in mind parallax scrolling is going to simulate 3d projection using only 2d objects, so objects back in the scene should move with slower speed than those in the front. to ease your work,, you can keep the character(player) in some fixed position. then give negate of player velocity to your parallax node. I suggest for a parallax node you only change setPosition function, in that function instead of moving parallax node itself, you have to move all it's children, respecting their depth value. for example you can use some code like this one: 

also you can completely change how you look at the problem and add a focused widget to all your widgets. This way you'll have a little bit advantage of remembering which widgets had focus when user was working with another widget (maybe doing something in another window). but keeping track of is focused get's a little bit harder. 

OpenGL know nothing of fonts, so you have two choices. Either use bitmap fonts (a font written into a texture) or use Canvas/HTML to display your text. Most regular OpenGL games uses bitmap fonts. 

Using a part of the UV space is the "correct" way. It's used for almost every full screen operation (except clear and some resolve ops). Avoid blitting and tex copy as much as you can. Using UV and geometry gives you a lot of flexibility, you can rotate/zoom images and batch together sprites that share the same atlas. Just be careful about pixel center and filtering so that sprites don't bleed into each other. 

You seems to render without depth test on. This might make triangles further away render on top of closer triangles since they might be rendered afterwards. The solution is to turn on depth testing in your render setup and set the depth compare function to Less or LessEqual. Remember to turn on depth write too if you happen to have that turned off. 

Box2D was written as a tutorial on how to write 2D physics engines. The site contains links to a lot of presentations on how the algorithms work and how to make it efficient. You might also want to look into this presentation done by the Pixeljunk Shooter team, describing how they did 2D fluids. If you are interesed in 3D, read Realtime Collision Detection. For more cutting edge offline physics this might be a good presentation. It describes how a new solver was developed for Maya, and I remember our physics programmer going nuts over it some years ago.