And this process continues until the Sequence Number maxes out and resets back to to zero. It is worth noting, that the Sequence Number is not an infinite field and does have an innate maximum. In the case of IPsec, the field is 32 bits, and therefore the Sequence Number maxes out at approximately 4.2 billion. When the maximum is reached, the keys which were securing the packets must be rotated to avoid a looped sequence number vulnerability. The solution to your Problem What is happening in your case specifically is the window is moving forward to fast, and legitimate packets that should be accepted are being dropped because they arrive at the other end just as the Anti-Replay window moved out of range. The solution: Increase the Anti-Replay window. But the tricky part is what do you increase it to? A good rule of thumb is for your Anti-Replay window to be 0.5x to 1x your average Packets Per Second. I suggest starting conservative (0.5x) and increasing slowly until your performance errors falls within an acceptable level. Do not be over-aggressive with increasing the Anti-Replay window, because that leaves you open to inadvertently accepting a replayed packet. Increase it slowly until you are happy with the results. On an ASA, the command is: 

To tie it back in to your question. There isn't a way for a remote server to learn whether two clients might be on the same network. BUT, there is absolutely a way for the two clients to discover for themselves whether they are on the same network, and then report their 'finding of each other' back to the remote server. As Ron said, the Remote server can't assume the two clients are on the same LAN if they share an IP address. Neither should the two clients assume they are on the same LAN just because they share the same Gateway (or even Gateway MAC address, HSRP mac address collisions are not as rare as you think), or each have an address in the same IP Network. Their surefire way of detecting whether they are on the same network is via some sort of discovery mechanism. 

Or, in plain english: speed of light in meters/second times 30 milliseconds (60ms RTT means a 30ms one way trip) gives you about 9000km. The real world is not generally ideal, so I suspect the real distance you need to be from their DCs is going to be quite a bit lower (speed of light in fiber is 1.5 times the speed of light in a vacuum, so on a pure fiber network with no switching, max distance is already something like 6000km, not 9000km). In other words: the great performance is totally dependent on the quality of content delivered, and on the distance between you and an Nvidia DC. What exactly is transferred to/from their servers is also an unknown to me, and it may be mouse/keyboard is processed locally, and the resulting coordinates/events are transferred up (this is a total guess). So, on the face of it, the answer is that they have pretty high network requirements, which allows them to move a fair bit of data round when they need to. Refs: 

Figured it might be better to work my comment into an answer: Nvidia requires a fair amount of available bandwidth to be available, and also has a requirement for users to be within a 60ms RTT of one of their (6) datacenters. Their maximum bandwidth requirement is 50Mb/s (6.25MB/s) for 1080p quality. This is substantially more than Netflix requires for an equivalent quality stream (1080p is an HD feed, Netflix wants 10 times less (5Mb/s) for it). If we assumed the entire network to be one continuous strand of fiber AND that the light was travelling in a perfect vacuum (neither of these assumptions is actually realistic), then you would need to be within a 9000 kilometer radius of one of their DCs: 

Although nmap can do some things to 'get around' stateful firewalls, its basic use is in identifying running services. Yes, I know it is called nmap for a reason, but I do not believe its primary use case is mapping firewall-protected remote networks (rather, you would use it to see what a given range might be exposing - shodan exists in part because what people think is exposed and what is exposed are often different). If you have a host within the same broadcast domain, then you can enumerate all hosts whether or not they have a firewall, by generating some kind of ARP ping. One way of doing that would be to try and send a single ICMP echo request to each host, and then check your ARP table for live entries (e.g. using ). If you are not within the same broadcast domain, then it is another matter. You could mess around with GRE and IPIP, I guess (there is a slim chance that could do something for you), but in general, stateful firewalls will do their job fairly effectively, and obfuscate much of the network they are trying to protect. That said, it never hurts to look at the TTLs of returning packets, in order to try and get a sense of the network's depth. 

You're arguing that it's better to flood, limiting the total throughput the switch to effectively the bandwidth of its slowest link, to avoid a few nanoseconds consulting a MAC address table? I'd argue that you're looking at it wrong - switching provides much better performance than flooding, at an extremely minimal cost of a lookup table, which is done in hardware for speed in most cases. The performance trade-off is most definitely in favor of switching over flooding. 

After upgrading our ASAs from 9.1(1) to newer versions, users were no longer able to connect using native IPsec VPN client software when inside of an office network. From outside networks it still worked just fine. The office networks have established VPN tunnels covering the IP range that the user's system falls under, but the workflow is to VPN in to gain access to restricted resources. We verified that disconnecting the LAN to LAN IPsec tunnel to the office allowed the client to connect in successfully. When debugging the connection attempt's IKE and IPsec, a log entry shows why this is failing: 

That log entry led to several reports of this issue (1, 2) with information clarifying that this behavior was introduced as a security fix in CSCuc75090, but no real functional workarounds - just recommendations to use the established tunnel or NAT the users to a different address than the tunnel peering is happening over. Is there an effective workaround to allow for client VPN from these locations again? 

Does having configured on an interface prevent unicast flooding for a MAC address the switch hasn't learned? The information that I'm seeing conflicts -- the wikipedia page on unicast flooding cites protected mode as a mechanism to block flooding, while Cisco's documentation says that doesn't matter, and that would still be needed to prevent flooding. However, I recently ran into an issue where on a 2950G running some relatively ancient 12.1(22) code, unicast flooding seemed to be completely broken for a protected port -- the aging time on the switch was 5 minutes, while the router's ARP timeout was 30 minutes, and the one TCP connection utilizing this interface had a tendency to sit dormant for 10 minutes at a time - and be non-functional when waking up after 10 minutes in this case. Captures run on the host showed no unicast flooding when it was expected, and increasing the MAC aging timer on the switch to match ARP completely resolved the problem. Is this behavior undefined or inconsistent in older IOS versions, or is this just a bug in this old code?