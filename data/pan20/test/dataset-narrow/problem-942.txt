You can try a junction by copying the files to the new drive, then renaming the old installer folder temporarily, creating a junction from the default folder to the new. Then test things for a bit before deleting the renamed installer folder. Maybe install a bigger more complex program like visual studio, or adobe Photoshop, then uninstall it just to make sure all is well. But be forewarned, if anything goes wrong, you might not be able to install or re-install programs. Been there, done that. :) 

Share is on Windows 7 Ultimate and Client with permission errors is Debian Wheezy. Now I am out of searching terms and ideas. I thought this would be simple; now I have wasted hours. Anyone got any ideas? Its probably something simple right? Edit: Forgot the dummy check of trying to access the share from a windows computer. It did not work leading me to investigate more windows settings which led me to the solution posted below. 

You cannot delete the root of a folder from someone else's account, that is you cannot delete a "share" from their computer and account via yours. Hence even unsharing means they still have the files, you simply are not sync'd any more But you can delete all the files IN a shared folder and those changes would propagate to all the other members of the share. This means you can help your wife by deleting the files which would free up the space. But the folder itself would have to be removed from your wife's computer. So to do what you want, you simply create a folder, in a folder, in the Dropbox folder. Currently. you have "Collaborative Folder" that is a folder and a share you want to delete. Instead, you create a folder say "Joint" that is also the share "Joint", then in that you create "Collaborative Folder". Now you can delete the "Collaborative Folder" folder leaving an empty "Joint" Folder. Another option is to use the same account. My wife and I use a single account so what I do, deleting shares for example, she sees because we use the same account. 

8 bits of data gives you 256 different storage combinations because 256 is 2^8 which means 8 bits of data, with each bit having 2 possible values, will give you 256 possible combinations that the 8 bits as whole can be in. This means you can distinguish between 256 different levels of grey in each pixel if you use 8 bits of data per pixel. 24 bits of data per pixel means you can give 2^24 different values of color or 16.7 million colors. This usually equates to 8 bits of value per Red, Green, and Blue colors giving you 16.7 million possible color combinations. In retrospect you could also have 256 values of color (instead of grey) as well; For this they had 3 bits (8 color levels) for red, 3 bits for green, and 2 bits (4 color levels) for blue for a total of 8 bits as well but in color instead of grey. To calculate the size you would multiply the the number of total pixels to get the total number of bits needed to store the images. This is (5*1,600*1,200*24)=230,400,000 bits. Divide by 8 to get bytes; 230,400,000/8 = 28,800,000. Divide by 1,024,000 to get megabyte; 28,800,000/1,024,000 = 28.13 MB. This is the total number of MB your would need to store the raw data for the images you decribe. If you add in file headers and exif data, you usually will see a larger file than just the image alone and of course, compression would alter the value as well. Maybe this was a bit overkill. 

First, realize their is a segregation between hardware and software. They do not dynamically match each other because they are radically different things. 

Is there a single value in each row, for 4096 rows? And you want the RMS for every 20 rows?What is the formula? Just for an example, if your values were in col A starting at row 1 and you wanted the mean (which I think is different than the RMS) you could merge the cells B1-B20 into one cell, then write the formula: 

To your question specifically, you just have to figure out a couple things about your raid controller. 

You definitely need to use a RAID card or integrated RAID on a motherboard. It can be integrated RAID into your motherboard, a "fake" RAID card or dedicated hardware RAID card. You cannot use pure software raid with the setup you described. So first you simply setup your RAID arrays per your RAID documentation; this will be done before your OS boots. Then, on each OS, install the appropriate RAID driver, if needed, to read the array. That is it. Each OS will see the array and be able to mount it as a drive. 

If your ISP allows port 80 traffic, and your web server is serving the site correctly, then it should work. The trick is this: Use a proxy site such as this to try to access your site if you are trying to access your site from behind the same router as your webserver. Or use a cell phone or someother mobile device connected to another network. Point is you cannot access your site from the same network as your webserver using the internet address without further configuration; but that further configuration usually circumvents the packets from ever leaving your network which would defeat the purpose of trying to use the web address to see if it works from anywhere on the internet. 

In windows XP, (I think Vista, 7 and 8 too), a hyper-threaded single core CPU running a single thread at 100% utilization would show 50% CPU utilization in windows task manager. To extrapolate, this would say that your computer using a dual core with HT would show 25% when a single core is being utilized 100% by a single thread; that is if your game is single threaded, it would be use 100% of a core, which is 50% of the CPU, but only show 25% utilization. If you disable HT, the single threaded game will still utilize a core 100%, which is still 50% of the CPU, but it will actually show 50% utilization. Many articles have shown that having HT enabled on average increases performance even though there are circumstance that HT shows decreased performance. That being said, the biggest advantage of turning off HT would be so it feels better because it will look like you are using your CPU more. Psychology would say via the placebo effect that this might actually make it seem like there is a performance benefit because you feel like 2x as much of the CPU is being used. While many might disagree, how you perceive things can have more of an impact than how things actually are. If this is true with you, then turn HT off! The performance decrease would be minimal. But if you want to stick with the facts, then disabling HT would decrease performance on average regardless of what the CPU meter says, there in you should leave it enabled. As for whether you can enable and disable HT on that computer; it looks as though in the user manual for your laptop there is nothing about having options in the BIOS that you can modify. You might try a BIOS update to see if that allows you to toggle the option. Other than that, if you cannot modify the setting, you are pretty much out of luck. 

Set the cell to whiteout using conditional formatting by setting condition to "Formula Is", the formula to "=ISERROR(cell(s))" [cells are the cell or range of cells you want to check for an error value], and setting the format to a white text color. This work on any error, including the one in question. You could also use "=ISNA(cell(s))" to only white out on the #N/A error and not on the other errors. Conditional formatting copies with the cell so create the first cell, set the conditional formatting, then copy it around as needed. 

I would say you should not be worried with the rail distribution on a power supply with only two rails @ 450 watts from a reputable manufacturer like Antec for your CPU and GPU. Video cards and Motherboards use specific connectors that take away your ability to choose what rail the GPU is on and what rail the CPU is on so you have to trust that Antec put them on separate rails or balanced things correctly. Even an un-reputable brand would do this, but maybe there is anomaly out there. To check for your self, you might be able to take a multimeter to the connectors while the PS is off, disconnected from the motherboard and all other components, and disconnected from the wall. Check the resistance across pins or wires that you know are on a common rail (for example probe between 12V lines on the same connector that have individual leads going to the PS housing) then check the resistance between 12V lines across different connectors; resistance that are approximately the same will be on the same rail and resistances that are different will be on different rails; resistances on separate rails might even have infinite resistance (or "1" on a multimeter) (NOT RECOMMENDED IF YOU DO NOT KNOW WHAT YOU ARE DOING.) If you want to check by sight, you could crack open the PS case and trace the wires. They should end up on common soldered paths on the boards inside the PS if they are on the same rail, and connectors on separate rails should have leads that have to go through some components in the PS before they combine. But realize the PS has large capacitors that could shock you and possibly kill you (unlikely, but possible!) if you short the capacitors with your body before they are discharged. 

I've have seen programs like virus scanners and file backup programs that slow things down tremendously without major CPU usage; especially on restart. If it happened 2 months ago, what software changed 2 months ago? Try to identify the program and either eliminate it, optimize its settings, or get rid of it and find an alternative. Or, try to roll back to a system restore from 2 months ago to before when it was faster, then incrementally move forward with programs and MS updates. 

You metadata has been changed. When you compare the metadata using this online metadata viewer, of the collet files, you find that the larger file has more metadata (aprox 4.2k) which accounts for the bulk of the file size difference. The bigger file has added padding, and the thumbnail size is different, along with there simply being more exif data available to view. Point is that something has modified your exif data, probably a legit program either doings things someone told it to, like save, or someone didn't know they were telling it to (rotating in microsoft picture viewer saves even though you simply wanted to rotate. I'm sure other programs have similar pitfalls) There is still an additional 2K +/- of metadata unaccounted for, but I would bet with some research you could figure out what it is. Identifying what program did what would be difficult in hindsight, but in answer to your question, I would say it is safe to overwrite the larger files with the smaller ones unless you think you will need the extra metadata in the future. Although with the simple addition of padding found, I would bet that the extra space might come back if whatever happened before, happens again. There is metadata with so many multimedia files that I would assume this is the case with all the file types you listed. 

At the sizes you are talking, RAID 5 would probably be fine. RAID 10 has the advantage of no parity which carries several benefits, namely performance and increased rebuild success rate, at the cost of one additional drive; but drives are cheap nowadays. I use non-parity raid (RAID1, or RAID 10) where uptime, performance, and durability are needed, and use parity RAID where increased efficiency is needed. And technically I have software RAID10's as Linux MDADM RAID10's on 2 drives, not 4. Point is "the rabbit hole" can go deep. RAID 10's lack of being "interesting" is what makes it great. It is simple, cheap and fast. All things you want if your data matters and gets used. You do not want complex, slower, and more expensive. While RAID 5 is "cheaper", it is more complex and slower for writes and rebuilds, and reads not much faster than RAID10. If you have the physical room, RAID 10 would cost about $30-$60 for the drive (consumer) and $5-$10/yr for the power (24/7 power on time). Most people find this worth the added benefit.