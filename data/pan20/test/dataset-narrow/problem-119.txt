The data sheet "Cisco SFP Modules for Gigabit Ethernet Applications Data Sheet" says "the minimum cable distance for all SFPs listed (multimode and single-mode fiber) is 6.5 feet (2 m)." However even though the transmit maximum power is equal to the receive maximum power, for very short distances (5m) I get receive overload warnings which may be due to reflections (see my question "1000BASE-LX/LH Receive power level greater than transmit power level" ) The datasheet text quoted in the other answer is for the "1000BASE-ZX SFP for Long-Reach Single-Mode Fibers" which have a higher transmit than receive power The 1000BASE-LX/LH can use SM or MM, however mixed SM and MM cable in the fixed plant causes me a lot of headaches and I would recommended SM with attenuators if needed. 

is "possible" as it appears you are adding the office network to the data-center firewall - So then the datacentre firewall would send all traffic out that port This is the "not a good idea to span subnets between sites" statement that Ron mentioned. However even with a new gateway located on a device in the office and connected to the new AT&T connection there is an issue of how the data-centre routing decides on which of the two links should be used to send traffic to the office network. You may need to "move" each office device one at a time. For each move you would modifying routing at both ends of the link. This depends on the capabilities of your routers. I think this is what you described 

If I ping 172.17.5.10 from Router2A the firewall does see the packets Router 3 is a 3750 , Router 2 are 3850s There is no device with an IP in the range 172.17.5.0/25 - I am using this to demonstrate the problem to myself So I'm close to saying this is a bug - I'm waiting for a reboot but my questions at the moment are 

I have three routers - (a HSRP pair RTR2A and RTR2B and a router RTR3 and a firewall - the firewall is setup to capture packets on its interface connected to RTR2A as I am having problems with routing RTR3 is being used to send packets to the IP addresses 172.17.4.10 and 172.17.5.10 - The routing tables for the two networks containing these addresses look the same to me 

Does the order of the output of sho Ip route indicate some difference in how the routes are operating? Can anyone see a difference in the routing tables? If not then is there some other mechanism that a router uses to route packets other than the routing tables? - in relation to this there is no ip source-route on the routers 

An "alternative" would appear to me to be (in line with answering "or if you can think of an even better solution") - Treat the switches and the network as untrusted and force the clients to use VPN to connect. This is my company's standard response to small offices (4 workstations seems small to me) due to the difficulty of controlling the physical switches on site .For the offices we use like this the printers can only be used when not on VPN or using direct USB. I'm not sure this is applicable for you - I either got confused about the switches you propose or you seem to have a requirement for a lot of ports for just four computers. 

Nope. There is no multi-speed option in 1/10G optics for Juniper (or Cisco or most others). That said, you can likely just put another 1GE SFP optic into the SFP+ slot currently occupied by the 10G SFP+ on the switch side and it ought to work. 

At least in the context of network devices clock synchronization tends to refer to synchronous circuits where a constant time signal has to be maintained so that two devices can know the precise rate at which data is being transmitted and received. If the respective clocks of two devices are skewed then the integrity of the circuit will suffer. As such it's fairly typical for one device to derive its clock from a neighbor which, in turn, either works from an internal oscillator or an external source. Time synchronization is generally referring to maintaining accurate time/data values on a number of devices. An example of this would be through the use of the Network Time Protocol (NTP) which allows for synchronization of time/date to global standards with at least a fair degree of precision. Keeping accurate time is incredibly important for logging/forensic purposes but also crucial for certain cryptographic and security processes (among other things). So - you can think of clock synchronization as being akin to making sure the second hand on two clocks are ticking at the same rate while time synchronization is making sure that the absolute second, minute and hour hands of the two clocks keep reading the same. As such it's possible for two devices to have clock synchronization but be set to different times and, within some definition, two unsynchronized devices to have very closely synced time/dates (or calendars as they're sometimes known). As an aside - it's possible to get high-resolution timing devices that can both act as an accurate source of time/date information as well as providing high-resolution reference clocking but these functions can also potentially be had independently. 

Yes - such features exist in a couple of protocols, and I'll give a couple of examples. They're not in wide-use, though, because in actual usage they're virtually always a terrible idea. First off - there isn't really a notion of a router individually being busy, but rather links between particular sets of routers being busy. The idea has generally been to respond to a busy link by causing some number of upstream links to choose paths that are, ostensibly both less utilized and (normally) less preferred. Keep in mind that I used the term preferred rather than direct, as the means of choosing links may include any number of potential factors. So - let's look at a couple of easy examples: Cisco's EIGRP and MPLS auto-bandwidth In the case of EIGRP, as you may know the DUAL algorithm actually makes final metric determination (and thus routing decisions) based on several values known as K1-K5. These are actually various multipliers of values that the protocol is carrying. The values themselves are (minimum path) bandwidth, (additive) link delay, (minimum) link reliability and (maximum) link utilization. This is all explained in good detail here. Again, though, these K values are integer multipliers of these values, not the values themselves. What's more, by default three of these five values are actually left at zero while the other two are left at 1. The net effect here is that link reliability and link utilization are ignored, while link bandwidth and delay are actually used. Why these attributes? Because they are statically defined on links. In early deployments utilizing all of these values it was quickly discovered that the variability of these values could cause rippling instability in larger networks. What's worse, utilization in particular created an oscillation condition, where traffic would tend to be steered away from a busy link only to cause another set of links to become busy which would, in turn, redirect back to the original link. The issue here is that the network is potentially never in a completely settled/predictable state. This basically means that a busy link can actually commonly lead to network instability - which means that slowness for one set of users just resulted in unpredictable performance for potentially a great many users. Similarly, link quality determination tended to magnify a circuit taking a few CRC errors into a network-wide convergence event. At a minimum this churned CPU, but worst-case it could (and did) yield outages unto itself. In the MPLS case the implementation is quite different but many of the issues are the same. In this case RSVP-TE is used to set up TE tunnels / LSP's (label switched paths) - which, for the unfamiliar, are specially signaled paths across an MPLS network. These paths are unidirectional and in nature built between an ingress and egress router based on a number of factors learned about the intervening network via both traditional metric information and extended TE-specific data carried a link-state routing protocol (IS-IS or OSPF). These factors can include bandwidth, link affinity/coloring attributes, explicit paths (i.e. which intervening nodes should be waypoints) as well as traditional unidimensional IGP metrics (i.e. standard link-cost). RSVP actually provides the mechanism by which these TE LSP's are signaled through the network. Based on the criteria the ingress router requests the routers on the way to the ingress will either signal back their acceptance of the path or provide admission control to reject a proposed path. As mentioned there a bunch of criteria that can be used but if we focus on RSVP bandwidth we can see your use-case in action. As an aside, RSVP bandwidth is a static attribute set on a per-link basis. If a given LSP is configured to ask for a bandwidth reservation then this value is used for admission control by the intermediate routers. If a given requested link has bandwidth then it is allowed and the total reservable bandwidth on that link is decremented by the reservation amount. If the remaining reservable amount is insufficient then the request is denied and a different path is attempted. As an example - consider a diamond/square topology of four routers: A, B, C and D. A connects to B and C and D connects to B and C. The path A -> B -> D is all 10G, while the path A -> C -> D is all 1G. Put another way, under normal circumstances a standard IGP will steer all traffic via the A->B link, leaving the A->C link in play as a backup. In this case, though, there are already LSP's running via A->B that have reserved 9.5G out of 10G. When A tries to set up a new LSP to D it will find that it can't signal a new 750M LSP via the preferred path so will, instead, signal via the lower-speed path via C. So... A couple of side notes are in order: First, the bandwidth requested on a given LSP is generally a static value. Second, there's nothing (by default) either restricting a given LSP from transmitting more than its reservation or, conversely, making unused bandwidth available to other paths. Indeed, the bandwidth value itself on the interface is just an integer. It's convenient to consider it in terms of kilobits, but it's not absolutely necessary. It's also the case that while the simple case is that bandwidth on the link is allocated on a first-come/first-serve basis it's possible to both allow overbooking for certain types of traffic (i.e. allow, say, 8 gigabits of reservations for certain LSP's on a 1 gigabit link) and also to give relative priority to different LSP's (...so one LSP can bump another, possibly even knocking it offline if no other path is available). So - with all this in mind (...and there's LOTS more to be written about TE) the idea with auto-bandwidth is that the ingress router starts off with an initial reservation but actually measures the amount of bandwidth entering the tunnel. As the ingress sees the actual usage it will actually periodically resignal the path. If the actual utilization is less than the initial reservation then the intervening nodes know that more bandwidth is now available on the links our LSP traverses. If the actual utilization is greater then the reservations are either updated or, if insufficient bandwidth is available, alternate links are selected. This all sounds nice in principal but, again, this doesn't map very well to the real world. One of the initial issues is that there's no guarantee of optimally efficient bandwidth distribution and, in fact, it's common for vendor implementations to actually have options to look amongst otherwise equivalent candidate paths and choose the least utilized, the otherwise most utilized or just random choice. There are actually formal proofs for the fact that these methods end up being essentially equivalent and statistically likely to be suboptimal. Much like the EIGRP case mentioned above, the problem is that as the network tries to move traffic around that the load condition on intervening links will tend to lead to ongoing instability and oscillation. The periodicity of this oscillation can be adjusted (re-signaling timing can be adjusted to, say, once an hour or once a day) but this hasn't really yielded a substantially better experience in most networks and has led to less determinism and greater instability in plenty of cases. It's been argued that using a central controller that can more intelligently respond to load conditions by forcing the re-signaling of LSP's can work really well. This tends to follow a much more specific and bounded set of use-cases (...say, redirecting spiking backup traffic via links through an underutilized user site), rather than allowing a generalized algorithm to just go nuts across your entire network. This is probably one of the better use-cases for so-called SDN, even though it predates our present use of the term by 10-15 years. There's a good presentation on MPLS-TE and auto-bandwidth here but, as mentioned, the overall topic of TE can get pretty deep and will also vary based on vendor implementation (..and even within vendors based on hardware platform capabilities, etc). The point, though, is that while it sounds like a good idea to be dynamically re-signaling networks based on observed traffic loads that in practice the network will rarely benefit and will often be destabilized by such approaches. Engineer based on observed loading. Make careful changes based on observed data. A slight improvement in performance is useless when it brings a substantial decrease in stability. 

Is there a way of setting up a Cisco swtich (Cisco Catalyst 3850 12 Port GE SFP IP Base - its not arrived so I don't know the IOS) to allow SSH without specifying a USERNAME The customer currently has many switches all setup allowing TELNET using 

Personally I prefer to not change anything until I know what is meant to work You seem to have two subnets in the same system - I dont know why (as in what is the functional requirement for two subnets ) There is no restriction to enforce that devices on the same switched network are in the same subnet - they cannot talk to each other , they still need a router and yet they share a layer 2 collision domain - but it still works - just maybe not the way you want. 255.255.240.0 means there are more possible devices in the collision domain at the IP level so there is a possible performance hit if you get to that many devices actually being present in the subnet - it makes no difference if there are not Being locked at 255.255.240.0 is not an issue but having read all this - I think you are adding a new device and NOT specifying your correct sub-net mask of 255.255.240.0 and thus the new device cannot reach the devices it needs to and so it freezes with network timeouts (This is understandable )or applications crash because of network connectivity issues- (not so understandable - but it could happen) 255.255.240.0 is correct - so typing in a incorrect mask is wrong - if you cant change the router - then accept that's what the mask is and make sure you use that mask - Changing the mask after first implementation means changing the mask on all devices at the same time. (sort of if you know what your doing and understand the sub-nets you can sometimes work around this ) I'd relax - leave the subnet mask the way it is - fix all devices to use the correct subnet mask - and see what is and is not working - document (ie find out) what is meant to talk to what and then decide what to do 

So this seems to me to mean that you can connect them with any length cable as the Transmitter maximum is the same as the receiver maximum (-3 dBm) Yet if I connect them to each with a five meter patch lead to each other (in the same switch) - or if I connect one to itself I get a high RX power warning 

And more importantly is this a problem ? I can see that the 1000BASE-ZX has a much higher transmit power than a receive power - so this would need an attenuation cable 

and I want to covert them to SSH. So I'll need to change their current method of logon. I've always used aaa new-model and so on and so whilst I don't believe its possible to use SSH without a user I want to know that this is true before I tell my customer. I've seen some articles about using certificates but nothing specifically about this. 

It's hard to know. The issue is that the anycast route needs to be provisioned in such a way as to not get lost behind a summary route or otherwise held up such that a retraction is actually seen. The other issue is how the carrier has linked the health of the service to the route advertisement. So - for example - if the /24 where the DNS server lives continues to be advertised whether the server is live or not (hopefully this isn't the case) then all manner of failures can occur without even an attempt at restoration. IMO the ideal design should be advertising the route conditional on the proper return of a synthetic transaction and that said route should be a valid/non-summarized /24 (i.e. fully accepted by all carriers) but there's no guarantee that this would be the case. 

Your issue isn't BGP. If you can get IP connectivity, you can get BGP running. Instead, your issue is that IP unnumbered is for use on point-to-point interfaces, not shared segments. If you wanted to set aside specific VLAN tags for the transit links between R[1-3] and R[4-5] you could use unnumbered, and would generally base it on a loopback (not necessary, but probably the most typical). Put another way - VLAN A would include [R1,R4], VLAN B would be [R1,R5], VLAN C would be [R2,R4], VLAN D [R2,R5], etc. That said, if you set aside different VLAN's for each link then you wouldn't have to worry about any kind of conversation between R4 and R5. If you want to run on a shared segment then you'll need some kind of addressing to disambiguate what traffic is bound to where. If you want to keep clients from talking to one another on this shared segment then you'll need some mechanism at L2 - likely PVLAN, but I suppose there are other (likely more labor-intensive) ways to accomplish this. For what it's worth the problem you're describing is pretty common in a lot of IX's: tons of routers from different organizations on a shared IP segment that should only be allowed to talk to one another according to a very specific (if frequently changing) set of rules. Based on your design and the requirement to keep R4 and R5 independent I would look in this direction if I were you. 

You need to look at your existing configuration ( from an enabled prompt) and find the existing NAT configuration ( or with the dots being the remainder of the command). Enter configuration mode ("conf t") Type "no" before the line to be removed. So - for example - if it presently has something like "ip nat inside source ..." you would type "no ip nat inside source..." At this point you should be able to enter the new translation command. 

The 4948 is a very capable platform and can definitely route IP multicast between subnets. Take a look at this configuration guide to get yourself started. It's fairly comprehensive and you'll want to focus on the section about PIM with a static RP ("Configuring a Single Static RP"). You'll generally be doing the following: