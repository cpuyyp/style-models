This will mount the CD disc, make it the only package repository and install a kernel that has support for more than just a handful of vmware/xen/etc virtual devices. After you get it working, restore /etc/apt/sources.list file from the backup and update aptitude again. 

How would one see conveniently which users exactly have which permissions on a folder when a folder's Security tab has many usergroups? I'm specifically looking for some technique or a GUI/CLI tool which lists individual users and their permissions for the folder. I googled and checked out DumpSec and Hyena but they didn't seem to have an option to dump individual users. 

I have googled high and low but there doesn't seem to be any example doing raid10 with megaraid (only the syntax). Can anyone explain what is wrong? 

We have an installerless program which we want to set up for Windows 2003 terminal server users so that they can just double click it's file extension and that program will open that file by default. Is there any tool or a clear step-by-step guide for doing this? 

I need to configure Postfix to send for a specific domain. I have tried to google for returning custom error codes for a domain with no luck so far. 

Can someone explain why these stick don't work in PowerEdge 860? I.e. bring out the reason what exactly makes them incompatible with this server? Is it because these sticks are not unbuffered as Kingston told they should be? Or are they? How to tell? 

A customer has a rack with some 1U servers and Dell™ PowerConnect™ 2716 switch at ISP's server room. One port is uplink to the ISP. Some servers run ESX5 while one 1U server is a plain Windows 2008 R2 box with 2 nics. The switch allows me to use web based interface but there are no mrtg style graphs available to monitor bandwidth (ab)usage. There have been 2 occasions where the whole 100Mbps that we have given by the ISP, is fully under load and we have only our gut feeling to determine if the slowness is caused by the server or the network. So far we have been solving problems with this gut feeling but before we rush to the shop buying expensive Cisco gear, I'd like to know if I could take advantage of the switch's port mirror feature and mirror the uplink port to a port in switch from which I could pull a cable to the secondary nic on the physical plain Windows box and do some network traffic analysis on that plain box (by using promiscuous mode and some software to make statistics). What would be the software that I could use on the box in order to easily see: 1) How big the total network load is on the uplink port. 2) How it is distributed among IPs/MACs 

When I create a new Outlook profile and re-add POP account, Outlook starts to redownload old messages from POP server if Outlook had previously configured with "Leave messages on server" setting. This occurs even when the very same PST file is used as message store. I would like to know, where does Outlook keep the information associated with "Leave messages on the server" setting. And if there is a way to "cheat" Outlook into thinking that it has already downloaded these mails (when I use the same PST from it's older install instance). 

I have a 2.7 TB virtual disk (LSI MegaRAID controller with ten 600GB SAS drives configured in RAID10) under Linux. I am sharing this disk to a remote ESX host via ISCSI. Unfortunately ESX will only make a 740GB VMFS partition if you present it LUN greater than 2TB. I could make a 6 disk RAID10 (which would be smaller than 2TB) but I really don't want to lose spindles (IOPS). Is there a way to split this big RAID10 virtual disk up (for ESX) in Linux? 

Every chunk of data has fair checksum on ZFS. So ZFS know which drive holds correct data in redundant setup when failure. Running will repair data or spread data to all running drives for RADZ. ZFS employs Reed-Solomon's error correction which is best for bursts of errors. Missing drive is such burst of errors, which R-S can correct. 

Try to precompile Ruby files to Java classes for WAR file. It is done during WAR deployment nevertheless, so for why it take a lot of time... especially on SPARC machines. Offload compilation files from server to your development machine. 

It will inherit netmask from global zone interface. Of course you can setup more interfaces, or put zone only on 'internal' interface (no public IP) and the let provide . 

The most likely you forgot to enable forwarding. Add to , then or restart. Also try to add following to OpenVPN config: 

For this case is better choice. It is Solais derivate, that runs completely from USB stick and local disks zpool just store your data, nothing from OS. Upgrades are way you just copy new image to USB stick. is primary a hypervisor, but all other features are there too + relatively fresh prebuilt packages repo available. >SmartOS< Btw when you want full featured storage appliance and no problem for you to install appliance SW on disks, then is definitely your choice. Comparable with FreeNAS... but much more features. You can even make fiber channel storage device from your old PC... just click out on web GUI. >NexentaStor< 

option - when you want to stay with FreeBSD, check FreeNAS to automate complexity you are afraid of. option - NexentaStor, it is Solaris based storage appliance SW with great management web gui. Up to 18TB setup is for free. Again there you can easily manage complex vs. a lot of datasets configuration. 

Zone virtual interface has some features limited... some states can't be setup, packet filter doesn't work in zone too. If I remember right, zone interface can't send ethernet broadcasts, so then no DHCP. Btw why you doing that bloat about setting up zone interface? What about this? 

Use , but also add per every network you want to route through VPN. Btw note that DNS setting on other interfaces will stop work, when that interface will not have route to its DNS servers. This is what happens when drops default gateway from your (W)LAN interface and adds host route to VPN server IP through original GW. Depends on your setup, may be there is no working setup and you'll have to change DNS naming to include some subdomain for internal networks. 

Note that adding interface to bridge, sets promisc flag appropriately. Bridge interface need not to be in promisc mode. I got the same setup running, but on OpenSUSE, TAP interfaces are created during startup and OpenVPN just opens them - no start/stop script in OpenVPN. 

Note that means command has to start in user login shell loading user environment too. In case that login shell is something like for security reasons, there should be a problem. Try to change to and potentially do fine settings in for that command. 

I'm running small Ubuntu devel virtual on VMware Fusion. 4GB disk and 512MB RAM is enough for development. Network of VM is in NAT mode, so I can access it even when not on Internet. I also configured AFPd so I can edit files directly mounting share. As far as I'm doing Django only that way setup is as following... Django app running under some user account I created, that user homedir is also a root (loaded on login), I use that user to login to AFP. When new project I just clone template machine and create new user account + . Installing to VMware Ubuntu chooses kernel that holds main virtualisation abilities... thus XEN, KVM, VMware. Deploymnet should then be DevOps way... just copying VM files to cloud and starting it online (maybe conversion of disk file or its growing to production size). 

Two way Intel E5504 @ 2GHz, 24GB RAM, 12x32GB Intel X25-E SSDs in RAID10. Intel Core2 6400 @ 2.12GHz, 3GB RAM, simple 80GB SATA drive. 

So it is not exactly broken. Com port is correct because otherwise it would not respond at all. There is a configuration utility with the pole but it is either the wrong version (it says it's for VFD660_460 but the documentation at $URL$ says that VFD860 uses software which installs itself to Start menu > Programs > VFD-660_460) or there is some other problem because whatever choice I make there, after clicking Accept I always get Device Time Out error (even though I see another garbage character appearing onto the display the second I click Accept). How to fix that? 

I have a Strongswan IKEv2 server and I can connect to it from Windows 10 using built in VPN client but I cannot ping the subnet behind the vpn server. It only works when I manually add a route to the subnet with route add 192.168.12.0 mask 255.255.255.0 10.100.0.1. Basically the same issue that strongSwan server with Windows 7 clients doesn't route traffic. Is it possible to automate it from the server side (i.e. I don't have to create a bat file on every client desktop to add the route)? 

I have OpenFiler storage server. Without installing Windows and MSM, I want to create raid10 array from disks 2 to 21. I have already successfully installed MegaCli to OpenFiler but I'm stuck in figuring out the correct command line for creating a raid 10 array. The documentations says that the syntax for creating a raid 10 is: 

When I put a crossover cable between physical box and a laptop and witnessed excellent speed and then put a switch between and the speed was still great and then changed the IP addresses from 192.168.0.x to real IP addressses that I had for the physical box and the VM, it occurred to me that while the ESX and physical box are just over the switch for each other, their different IP subnets dictate that all traffic shared between them has to go through the ISP router which is also connected to the same switch. So, due to different subnets, the traffic went through my ISP's box which shaped it down to 100Mbps! 

We recently migrated from Exchange 2003 to 2010. Half of our Outlook users are using Outlook from terminal server which is in the same domain as Exchange. The other half of Outlooks are installed on laptops which are not on domain. They usually use OpenVPN to connect to Exchange (and also to other services) but occasionally, when they are located somewhere where there are most outgoing ports blocked (hotels mostly), they use OutlookAnywhere. We have 2 certificates: one for 'ourexchangeserver', self-signed, and other for '*.ourexternaldomain.tld', signed by StartCom. By opening EMC > Server Configuration > Exchange Certificates, we can assign IMAP, POP, SMTP and IIS services to a given certificate. The problem is that RPC also seems to use this same certificate. So when we assign the wildcard certificate to IIS, we can access OWA externally without any security alerts but Outlooks display a security alert that host name is invalid (does not match the issued to field on the presented certificate). When we assign the self-signed certificate to IIS, it's the other way around: Outlooks don't complain but browser displays the same security alert when visiting OWA. My certificate provider (StartCom) does not allow me to generate a certificate issued to a host with missing or nonexistent domain part. Would it be possible to configure Exchange 2010 with these 2 certificates so that OWA would present the public certificate and RPC traffic would be covered with the self signed certificate? 

This may be a somewhat simplified question, but I've read online quite a bit and have found very little on the comparison. We are a smaller shop, approximately 200 users. Currently our Exchange mailbox quotas are set at 400MB. For as long as I can remember we've had users archive email as they fill up their mailbox, so we have more .psts floating around than we would like. I've looked into the archiving feature of Exchange, and it looks nice, but I'm having a hard time determining why I would go that route (for the cost, would be about 12K for licensing) versus just having more hard drive space on the server and increasing everyone's mailbox limit to 10GB (for example). I would imagine having their primary mail on one server and archive on another would be ideal for balancing the load/stress on the system, but with our small shop we only have the one server/database and had planned on putting the archive database on the same server anyway. We plan to deploy DAG with a DR site in the near future as well. So, other than being able to give our legal department more capabilities with the discovery process, is there any benefits I'm not seeing here? Also, we are currently on Office 2007, from what I read a lot of features aren't usable unless you are running 2010, so that would be something else to take into consideration I suppose. But anyway, I would appreciate some thoughts on this from those who have used both ways and are more "in the know" than I am with regards to Exchange/archiving. :) Thanks for your input! 

We currently have a pretty simple setup. We have a 2008 Windows Server using DHCP for our clients. We have a remote site that has 10 people. The remote site currently get their IPs from the router, but we'd like for them to get their IP from our local DHCP server here. From what i've read this seems fairly straightforward. On the remote router turn on Ip-helper x.x.x.x to point to the DHCP server back here. I guess my concern is, how will the transition go? If i enable that right now, will the users who currently have an IP lease from the router drop and acquire a new one, or will it just allow those leases to expire, then once they do, it will then look at the new IP range from the local DHCP server here? Just curious if this is anything i need to worry about or is it really as simple as it seems, just set it and run. I've configured RRAS on my side as well per several online articles discussing how to set this up. Thanks for any insight you can give! 

Actually, I just figured out what it was. I was passing in -assecurestring but it wasn't actually returning the password I entered. Apparently I was barking up the wrong tree. :) Thanks for your time! 

Others have said online that it works for them, but so far it hasn't for me. It doesn't give an error, it accepts the command just fine, but when I look in ADUC, the groups are still there for the user. Any suggestions as to what I may be doing wrong? Executing from Windows 7 with domain admin rights, Exchange cmdlets and Quest snapin loaded. Thanks! 

I recently installed a second Exchange Server (standard, 2010) to our organization as part of a Disaster Recovery solution. The two servers will soon be part of a DAG. Before placing the server at our remote location I was curious as to the amount of data that is transferred back and forth between the two servers. Is there a way to monitor or get a daily report of how much data is transferred per second and/or per day between the two? I would like to have an average metric so as to know if our current connection will be saturated or not. Thanks for any help you can offer.