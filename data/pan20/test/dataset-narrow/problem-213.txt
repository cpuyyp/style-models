@@ROWCOUNT is a system function that returns the count of the last query run. If you want to preserve that value for later use, you will need to store it somewhere else, even if it is only a variable. Such as: 

As @JNK mentioned, you can use a view. There are some steps to take, of course. The view should map only to columns in a single table. I assume that you do not want to deploy completely updated code that uses the new name. So, you can create a view with a different (but similar) name and any new code could use the view, and the new name. Existing code would still be going directly to the table. This would get you moving, but one day you will probably want everthing to use the new column name. Eventually, you will have to deploy new code. Which would still mean a number of name changes if you don't want to have the view layer over the table. 

The changes the datatype (if possible) from to . Just make sure to to the proper data type and all should be well. 

A SQL Server BACKUP only backs up extents that are being used to hold data. The unused extents are left behind by the backup. When a page is used for data it will be formatted for use as needed, so that page would be free of old data. Therefore, all you should need to do is backup the database and restore it elsewhere. The restored files will be of the same size as the original database, but the unused extents will be created using the capabilities of the target server. This may be initialized fully or instantly initialized using the blocks of disk on the target server. However, because extents are the level at which backups happen the unused pages in the extent could still have potential to expose some data when restored on another server. Not as much as could be exposed on the source server, since the unused extents are not restored. 

You rightly cannot get rid of the built-in administrator login, of course. So you just need to decide whether the minor side-effects are a problem for you. I never use "SA" for my work, but use my own special domain account with sysadmin permissions. 

The integer will provide a small key for use in joins, referential integrity, and so forth. This makes all the joined tables smaller than if you used the longer as the technical . By the way, the longest index in SQL Server is 900 bytes. You mentioned 60 characters in a column defined a . I assumed that was just over definition and it would be smaller. I suggest trimming that down to a more reasonable and usable length that SQL Server can absorb. So, as long as you can see that and are separate concepts, you can make the appropriate decision for each use case. 

Yes, you can restore the logs by changing the settings for the Restore Job to be set to STANDBY, instead of NORECOVERY. This would provide a degree of Read Only access until the next restore is run. If you are using the log shipping functions that come with SQL Server you use the settings shown by Ali Razeghi for using . If you have rolled your own log shipping process (which many people have done) then you are already controlling the restore process yourself. EDIT: Since you restore the secondary one time a day, the READ ONLY window will be most of a day. So that eases the scheduling issue. Since the procedure sp_change_log_shipping_secondary_database is not working, either (1) you ran this on the primary instead of the secondary server, or (2) your organization made their own custom log shipping process. EDIT: If you are in the (2) state, then please include the details of the secondary server's Log Shipping Restore Job. However, a database in NORECOVERY can be updated to STANDBY like this: 

Yes, the 2005 to 2008 problem is fixed. Now you can disable the SA account, you can rename it to SomethingElse, you can give it Chinese password, or you can mix and match. See: $URL$ Notice that since the SID of SA (whatever you rename it) still remains, the new name can be discovered by: 

Learn to use the functions such as to move through time. Also, gives you options in how you format dates to match the current purpose. (Which could include formatting for other languages.) Then, if needed, the predefined formats can be further manipulate as needed. Though formatting for printing is best done in the presentation layer. 

Some notes from the MSDN Table Hints topic show limitations on how the ROWLOCK hint may work or not work. Remember, this is a HINT not a REQUIREMENT. For examples of issues that may not match your expectation: 

You are correct that updating an non-indexed column will not cause changes to the indexes. In a simple case, there would also be no overall impact on the table. If a query can use the Index to look up data, it may speed up the lookup, but the exact behavior (depending on your SQL brand) may differ from other brands of SQL. (I use Microsoft SQL Server primarily.) Of course, updating a column with a significantly greater volume of data could cause some moving of rows to different pages, et cetera. 

Therefore, the execution of the stored procedures must be scheduled by using cmd files and Windows Scheduled Tasks. Follow these steps. 

Review the options that you would like to use from that page. As Shanky described in his comments, shrinking files is a really bad choice. Using the or the options of will give you better results. However, the should not need to be run frequently. Analyze the degree of fragmentation in order to choose the frequency and the window of time you will use. An with either or will order the data into the update pages while reserving the space indicated by the . This means that if many of the data pages are fragmented, perhaps due to many deletions, the data will be moved around so as to put data in the order. While the data is being moved into logical order, it will empty pages and extents which will result in recovering space in the database. EDIT: $URL$ (for 2014) explicitly makes the following comments: "Rebuilding an index drops and re-creates the index. This removes fragmentation, reclaims disk space by compacting the pages based on the specified or existing fill factor setting, and reorders the index rows in contiguous pages. When ALL is specified, all indexes on the table are dropped and rebuilt in a single transaction." "Reorganizing an index uses minimal system resources. It defragments the leaf level of clustered and nonclustered indexes on tables and views by physically reordering the leaf-level pages to match the logical, left to right, order of the leaf nodes. Reorganizing also compacts the index pages. Compaction is based on the existing fill factor value." 

I am curious about what you will accomplish by getting the plain text. You already have the documents in the FileTable and you can open the files when needed using the appropriate tools. For example: If you are looking at a PDF, a Word document, an Excel spreadsheet, and so forth you probably have the tools to look at the data. Most tools will even allow you to save the 'plain text' manually. But I suppose it depends on how you define "plain text". Save of Word document to a non-Unicode .TXT file? Or something more complex? Of course, I realize that you would likely want a more automated approach, which I comment on further down. One thing to know is that not all files will necessarily copy to "plain text". (At least I had trouble with plain text from Chinese.) Regarding the Full Text Indexes: Although the SQL Server Full Text Index is aware of the relative positions of 'words' in the index so that it can search for phrases, it has no interface to reveal the serial sequence of words in the text. Thus, there is no way (currently) to build plain text from the Full Text Index. Even if those details were available, the Full Text Index still does not have everything needed to fully represent a document. 

This query runs just fine, but does not include entire days unless your time is set to midnight. This is because returns date and time,so it will only return rows >= to the exact moment 7 days ago that matches the time of your query. If you are trying for whole days, perhaps: 

This is all about how NTLM and Kerberos work. There is a blog from a few years ago that offers some details on Linked Servers and NTLM or Kerberos authentication: $URL$ One edited quote is: "In a single-hop setting, windows NTLM authentication, which is available if all machines are windows, is sufficient for delegation; while in a double-hop setting, Kerberos authentication is necessary for the userâ€™s credential to cross machine boundaries from the client to the linked server." Now, suppose that you do indeed have Kerberos configured properly and still are mystified by the behavior. In that case you might need to check into whether there is a duplicate SPN. If so that will need to be corrected. The following blog discusses duplicate SPNs and other Kerberos issues: $URL$ Note: Some people just fall back to using Named Pipes instead of TCP/IP, but this is not a recommended solution any more. Bottom line: Resolve the authentication delegation problem and everything should work. 

This would allow you to incrementally batch the insert of rows into the intersection table a bit at a time, thus keeping the update transactions quite small. Perhaps insert one day at a time, 10,000 rows at a time, or some other batching method. Each batch should be a transaction that begins before the insert/update and commits when finished. That means that the updating of the batches of your choice would be many small transactions instead of one big one. That would limit the resources needed and, in many cases, would run faster that one big update. Perhaps having a included would help to filter the results more effectively. NULL keys are probably needed for the periods that are incomplete. What indexes do you currently have? SQL performance issues often depend on having the indexes properly defined. The columns in the intersection table likewise need to have indexes, as do the and tables. 

I added a second answer because you asked another question entirely. What you can do is limited by all the physical factors that prevent an activity from happening instantaneously. Your customers need to understand that instantaneous does not exist, and that you latency is 1 to 10 seconds, or some such number. Then you endeavor to treat that as real limitation. The universe has rules, you know. If you want to have things seem synchronous (even though they are not) you will need to enforce a delay someway. [Kludge Alert!] 

Adding SSIS to your server should not cause the running SQL Server to be affected, stopped, restarted, etc. I have never seen this happen with adding SSIS to a server. However, if you want to make absolutely sure, you could test by installing SQL Server on a test server. Then come back and install SSIS and see what happens. 

To fully understand your comments on Date and Hour, it would be good to see your data definition and some representative data. 

Database Indexes are a major benefit to performance of queries. I work almost exclusively with Microsoft SQL Server, but the principles apply on pretty much all flavors of SQL servers. Because the indexes are smaller than the overall table and have the needed value to be searched in a sorted order, creating indexes (to a reasonable degree) is the quickest way to speed up queries. You can overdo it, of course, since too many indexes can drag down performance. 

As you can see from the definition you provided for [dbo].[ConfigData], both and are defined as data types. The error message you are receiving is: 

Whether you use one table or two, you should be able to insert all the data needed for in a single transaction. More importantly, you should not store the password, but instead store a password hash. Here is one post on using a password hash such as SQL Server itself uses. This is using SHA_512 hashing with a 32-bit salt. $URL$ This way you never store the actual password. At the time of the creation of the password, you need to share the password with your new user. And ideally force him to change the password at first use. Each time a new password is created, you must, of course, update the hash to match the current password. Which means that you must manage all password changes, not just the initial password. EDIT Re: "how can I am able to enter employee details in employee table and generate user id / password for user and store in from separate table in one action." You must do the work in a transaction. Here is a sketchy outline using 3 stored procedures. Of course, you need to write the actual code: