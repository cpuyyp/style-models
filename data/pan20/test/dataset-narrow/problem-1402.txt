I'm trying to implement depth-only SSAO and for that, I render a depth map into a texture and pass it to my SSAO shader which then uses it. The problem is that when I try to output the depth map values from SSAO fragment shader (for testing purpose), I get something really weird. Here is the result : 

But in practice, your surface isn't going to be a smooth line (like shown above), but it's going to be jagged like so : 

The fragment shader didn't change when I implemented instancing, so I don't think it's relevant to put it here. Also, here is how I render the scene : 

My guess is that I may be projecting the depth texture in a wrong way. Thanks in advance for any help. 

The rectangles are actually colliding properly but you are drawing them at a location other than where you they actually are. If you change the origin parameter in your draw call to be Vector2.Zero your collision code should work as expected. By specifying a non-zero origin you are drawing your rectangles at an offset location from the position where you are performing your collision detection. 

8 kilobytes per second is the number I have seen tossed around on the AppHub forums. There is a short description of how headers and voice affect this number on Shawn Hargreaves blog. 

Vector2 uses floating point numbers, so when you calculate the difference between where you want to go and where you are (goTo - player.Position) it will almost never be exactly zero. This leads to some jitter, which is likely worse at some locations. If you can't switch to integer-based positions (i.e. Point) you will end up having to cap the movement as you have found out. One way of doing this is to compare length of the direction vector before you normalize it and if it is under a set value simply go to the target position. If your margin of error before snapping is small enough you will not notice the snapping at all. 

Don't know much about internals of MonoGame, but texture are definitely not stored in a ConstantBuffer. The texture is not a constant buffer, it is a texture which has its own slot and is bounded completely separetly from the ConstantBuffer. To get the slot of the texture, this is done through the ShaderReflection object and method reflect.GetResourceBindingDescription(i);. 

Use Device.UpdateSubresource (requires texture to be declared with Usage.Default) or Map/UnMap (requires texture to be declared Usage.Dynamic).In the case of the swapchain, I guess that only UpdateSubresource will work. Keep in mind that you are refering to the low level Direct3D11 API in SharpDX, so there can't be any high level methods like "SetData". If you want to have XNA equivalent API, you have to use the Toolkit which is available from the 2.5 dev package. If you want to stick with plain Direct3D11, you will have to dig into all the details about how Direct3D11 is working. 

In red, you can see what the surface actually looks like when you sample from it. Here, a problem arises : you'll have rays that are, in theory, above the surface but in practice will be under the surface and then get occluded. Of course, the problem gets worse when the resolution of the depth buffer is low. Potential solution A solution to this problem would be to limit the area of where to account for rays under or above the surface. Here's a picture of what I'm talking about : 

The depth buffer seems OK, so I guess it comes from a transformation done in the SSAO shader. Here are the shaders (I'm using the bgfx library, but the shader language is very similar to GLSL): Here is the way I output the depth from my SSAO for testing : 

It sounds like for each bone you are currently defining the texture to be rendered - you might as well allow for more flexibility and include a texture origin offset in your bone structure as well (relative to either of the joints you choose). That way you can be sure the rendered texture will be consistently placed. 

Moving the joystick in a complete circle gives you the upper bounds of the joystick range, but the at rest (i.e. no input) position of the joystick can't be accurately determined from those values. You could assume that that rest position is the exact center of the available range but that is only true in ideal circumstances. Over time controllers wear in non-uniform ways. You want the actual rest position for the device, which can only be accurately determined by asking for it during calibration. 

(Yes, every pictures are done with MS Paint...) The areas in gray are the surfaces that you're not going to discard in your computation of the effect. To do that I would compute the dot product of the ray and the surface normal and discard the ray if it is under a certain threshold set beforehand. Also, try playing with this value until you get a decent result. In doing so, you'll not get falsely occluded rays and you'll avoid your heavily occluded areas. Hope this helps anyone ;) 

A little late I guess but anyway it can be helpful, so here's my thought. The problem I think your problem might be caused by the fact that you project a ray from your hemisphere (or sphere) to sample depth, like this in theory : 

When playing and you hit the P key your if(CurrentGameState == GameStates.Playing) block is executed, changing the state to paused. Then the if(CurrentGameState == GameStates.Paused) block that follows also runs (because you just changed the state to paused above and the P key state hasn't changed), changing the game state back to playing. This is why you never experience the paused state. At the very least, I'd make the code for each state exclusive within the update method, either by using a switch statement or the following: 

You also aren't allowed to distribute the full XNA studio installer in your install package, so if you are creating a tool to be distributed with your game the content pipeline isn't a great fit. It's likely not reasonable to expect end-users to install a developer tool to be able to use your custom tool. 

The effect is automatically managing to update the constant buffer, upload it if it changes since last apply...etc. Though you can still update the constant buffer directly as you did. 

The main reason Direct3D10 Map methods were moved to Direct3D11 DeviceContext is to support multithreading. They were previously attached to each resource (thus implicitly, a single device), but with Direct3D11, It is now possible to update the same resource from different deffered context. Concerning your issue with MapSubresource, you need to check this documentation on Resource Usage. You will see that it is not possible to use Map method with Usage.Default, as it is only working with dynamic texture. Usage.Default is suitable if you are only using UpdateSubresource. The correct way to use Map is to declare the texture with Usage.Dynamic and Map with WriteDiscard. It is not possible to keep the content of the dynamic texture (update partially) as a race condition between the GPU and CPU would arise. 

I don't really know where the problem could be. I can give more code if needed. Thanks in advance for any help. 

The shadows are still rendered fine, but the grass lighting is completely off, alternating between dark and bright grass. The small "scene" above the grass is also very dark (I use the same shader as the one for the grass, for convenience purposes). Even the debug text in the upper left corner isn't being rendered anymore... I use the same shader for both scenes, except I use a uniform to let the shader know when I use instancing and when I'm not. Here is the lighting shader: 

I've been rendering a scene (some objects over a large field of grass) to test shadow mapping which is working fine. But when I use instancing to "gain" performance, I not only get a decrease in performance (by losing 2-4 ms per frame !), but my lighting also gets messed up. Comparaison : Scene without instancing : 

There is no built-in Kinect support in XNA currently, so any Kinect development on the Xbox 360 is out of the question. If it is one day introduced, it may well be similar to the available Windows SDK, but there has been nothing announced. As for licenses and fees, you can develop for the Xbox 360 if you have a $99 AppHub account, available from $URL$ 

Obviously you can improve the performance of this example and could remove touch Ids from the list of those tracked when the TouchLocation state is released, but the basic idea of tracking which touches you have handled and ignoring them on subsequent updates is the same. You could also limit firing a bullet to the initial touch location by simply checking that the touch state is TouchLocationState.Pressed, which should only be true for the first frame in which the touch is active. I haven't used that method myself. 

Minor issue: don't perform any GPU interaction in the update method but only in Draw (in fixed time step, this method can be called several times per frame). The correct way to implement the micro-synthetic test is to do it like this: 

As catflier mentionned, moving from a "high level" framework like XNA to a low level Direct3D11 API would require quite some work in order to achieve the same results. But there are now some options that you could also consider: 

If you are creating a Texture2D with an initial DataRectangle, the Pitch must be set to the number of bytes per row and is theoretically equal to TextureWidth * SharpDX.DXGI.FormatHelper.SizeOfInBytes(Format.XXX), unless you are laying out your data differently in memory. If your are using DeviceContext.MapSubresource, you can't determine in advance what would be the stride and you need to use the Pitch returned by the DataBox.RowPitch. The stride could be hardware dependent, depending on the layout on the GPU memory.