So, I compile it, put it in my project, I run it and... it works! What the hell?? This is weird because I've downloaded the binaries, they didn't work, I've compiled the binaries myself. didn't work either, but now I make a small change to the code and it works? >_>. So, now I remove the two lines, compile it again and it works again. Someone care to elaborate what is going on? Probably some weird caching problem! 

It does work if I load a sprite, so it's not a pathing problem. I've checked the samples, they do work, but I think they also use a different version of the XNA framework because in my version the "Content" class starts with a capital letter. I'm at a loss, so I ask here. Edit: Something super weird is going on. I've just added the following two lines to a method inside , just to check if code would even get there: 

I've tried other settings but they don't help Edit: I think I have to somehow set the BlendState of the graphic card in some way so that the textures behind other textures get rendered. 

I get this error on the _testFont line: File contains but trying to load as . So I've searched around and by the looks of it it has something to do with the content importer & the content processor. For the content importer I have no new choices, so I leave it as it is, for content processor and I select And then I try to run it. 

I've been trying to get this to work for the last 2 hours and I'm not getting what I'm doing wrong... I've added to my references in my content and I've added & in my main project. I've put t & in the root of my content directory. 

I'm trying to draw a partly transparent texture a plane, but the problem is that it's incorrectly displaying what is behind that texture. Pseudo code: 

I'm loading a simple texture and rotating it in XNA, and this works. But when I run it in full screen 1920x1080 mode I see spikes while my texture is rotating. If I run it windowed with 1920x1080 resolution, I don't get the spikes. The size of the texture does not seem to matter, I tried 512 texture size and 2048 texture size, same thing happens. Spikes in full screen, no spikes in windowed, resolution does not seem to matter, Debug or Release does not seem to do anything either. Anyone got ideas of what could be the problem? Edit: I think this problem has something to do with the vertical retrace. Set this property: you'll lose vsync but it will not stutter. 

Since you're using XNA you can check out the Platformer Code Sample on App Hub. I believe the relevant code is in the method in the class. This is a working example of what I outlined above. Metanet also has two really great tutorials on 2D collisions. 

Using a plain ole sprite sheet and animating frame-by-frame works just fine. The same goes for doing skeletal animation. It's really going to come down to your specific needs, for instance: 

That is setting the size of the screen Flixel will draw onto. If you want a zoom level of 2 you should have . You should check out the source for Mode to see how to create a world larger than the screen. What happens in Mode is that the world size is set to 640x640 and the player, blocks and enemies are added in that world space. The create() and generateLevel() methods are where most of this happens. 

I've used A Bitwise Method For Applying Tilemaps and found it to be a very elegant solution. The article provides a concrete example and discusses how to extend the algorithm to handle multiple terrain types. 

Using the latest SFML from github (2.1 should also work but I didn't test with it) you can listen for the and events as described in the SFML Events Tutorial. I've tested the events and they are both fired on Mac and Windows. A sample program to test this would look like: 

These are just a few questions to ask yourself and your team. You can probably come up with plenty more. Whatever you do you definitely want to be exporting bitmaps for use in your game. If you're interested in skeletal animation you should check out Spriter. Looks like there is at least one Cocos2d implementation of the Spriter format on Github. 

I'd like to go with option #3 and could devise my own solution easy enough but don't want to reinvent the wheel unnecessarily. Is there some standard naming convention used for a gamepad API that supports both 360 and PS3 (and possibly other, similar) gamepads? Is this even really an issue -- should I just create an API, document it and call it good? 

Just support different aspect ratios and don't worry about it. Pick a specific aspect ratio (say 16:9) and do a best fit on all other aspects (i.e., letterbox or pillarbox) 

In your collision processing you need to get a list of all rectangles that your player is definitely colliding with. As you loop through this list you need to test the intersection of the player and each rectangle. This intersection will give you and values. Compare and . Whichever value is smaller is the axis you want to resolve along. That is, if , adjust your player's position along the x axis. If , adjust the player along the y axis. Loop until done. 

Ive been reteaching myself opengl so I can make a game on android. However Ive been struggling with how to build objects and scenes in opengl using c/c++ and passing them through the jni to the virtual machine where android can use them. Can some one point me towards some tutorials that actually show the use of natively built objects being created and passed through to the jni. Im fine using c++ or java I just dont have much experience using the jni. Ive built some sample projects where I pass primitives like floats and perform operations on them on the native side and then passed them back but I cant figure out how to create a scene in opengl in c++ and then pass it to java. Ive been looking at writing everything using java but Im not sure if the java bindings make for some performance loss. Any help would be much appreciated 

I have a kind of broad question to ask but I have to start some where so.....What is the best way to handle onscreen clicks for moving objects being drawn on a canvas in a view. Im registering the screen clicks just fine and Im able to get the x and y but when it comes to matching it to an object on screen Im at a loss. I have a really hacky way of traversing through an array of existing objects and checking their onscreen coordinates against the coordinates of each item in the array but its no where near reliable and doesnt work most of the time. when it does work the click ends up not matching the item I clicked on. At the moment this all takes place in a custom view and is being drawn on a canvas but in the future Im going to implement it all in opengl when I have the time.....or the money to pay some one else :0) Any opinions, links to tutorials, or suggestions would be much appreciated thanks. 

Well it looks like for the time being I will go with Java to use the opengl. I have noticed a definite increase in performance so I cant say how much more I would see rewriting my code all in c++ although I just got a new book on the developing apps all in the ndk and I might take it up some time soon. If anyones interested the book is called Android NDK Beginner's Guide and so far its helped me quite a bit. 

In a small game Im working on I was able to implement ray picking with an opensource 3d engine called min3d but I cant figure how to keep track of what object is onscreen. I will some times have upwards of 120 objects to render within my scene and the raypicking is off occasionally. What id like to do is keep track of how many screen objects are within the camera and being rendered onscreen and set a boolean value based on that to add or remove objects from my arraylist I iterate through when the screen touch is registered and the ray picking method goes off. So how can I check for which objects are onscreen and offscreen in opengl es on android. 

In my case I maintain the state of the keyboard by listening for the and events in the client. When one of these events is fired the client sends a message to the server and then updates its own state. This allows the client to employ client-side prediction (see this article for more details) and gives the server the minimal amount of information it needs to execute the move. When the server receives one of these events it updates its own internal state and then rebroadcasts the event to all other clients so they can handle it as well. To keep everything in sync the server will periodically (every 10 ticks of the engine in my case) send a "sync state" message to all of the clients giving them the exact positions of all players. You never want to sync the state of a client to the server as that opens up all sorts of cheating opportunities. EDIT To be clear, state syncing should only ever go from the server to the client, never the other way around. END EDIT I found Maple.js to be quite useful as a reference for a concrete implementation in Javascript. 

CreateJS is a Javascript library for working with Canvas and other HTML5 web stuff like audio. It's not a game engine but it can definitely be used to make games. 

Texture Packer won't convert it's exported data from one format to another. To export in different formats you need to have the Texture Packer (tps) file used to create your JSON atlas. If you have the tps file, just select the exporter you need from the "Data Format" drop down list in the left-hand pane. The TP home page has a graphic that explains the process succinctly. If you don't have the tps file you have two options: 

Your signature for is incorrect. It should be . Flash can be forgiving about this sort of thing resulting in some infuriatingly subtle errors. 

Write a script to parse the JSON format you have into the Cocos 2D format you need. Recreate the tps file so you can easily export whatever format you may need in the future. This assumes you have the source sprites that are packed into your atlas. 

Are there any particular technical contraints that make one option more attractive than the other? Frame-by-frame animations will tend to use more memory than skeletal ones. Skeletal animations will require more complex code to implement. Are there any design constraints that make one option more attractive than the other? Do you want your character to bounce around like a rag doll when he dies? Do you need to be able to change the animation at runtime? These things will be easier to do with skeletal animation. What tools does your artist prefer? What workflow does your programmer like?