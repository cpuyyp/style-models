If you don't care at all about memory performance, you could store your sprites uncompressed such that pixels with color 0 are pure red, 1 are pure green, 2 are pure blue, and 3 are pure alpha. When about to render a sprite, set a matrix pixel shader constant made of four vectors that correspond to colors 0, 1, 2, 3. In the pixel shader, execute the following code to recolor the sprite texel: 

and the same applies to colors 1, 2, and 3. If you do care about memory performance, then by all means store your NES palette as a 256x1 RGB uncompressed texture, set texture filtering to nearest-neighbor, store your sprites as uncompressed 8 bit single-channel textures, and do shader code something like this: 

Games were once written in machine language, because they had exotic hardware for which there was no compiler. The hardware also lacked features that C programmers take for granted, such as efficient 16-bit integer math. Once games settled on familiar hardware, C compilers became available and in a short time all games were written in C. C++ seemed like a good idea at one time, and most games are C++ today, but engineers are now mumbling about a return to C, and that might actually happen. I would love to work on a game in C, and so would many coworkers. There's no feature new to C++ that I think improves games. It would seem now that computers are 1000x faster than a few years ago, a high level language would reduce development time ($) making C obsolete. This has not happened because game buyers know that the hardware is 1000x better, and want to trade their dollars for a game that looks and sounds 1000x better. This removes the slack from the system that a high level language would consume. Performance requirements in games are brutal. A new frame of graphics must be rendered in under 33ms (or 16ms!) without fail. Everything the hardware does must be accounted for, so that this budget can be met. Any language that goes off and does something with the hardware that the programmer doesn't understand or expect is going to make it very hard to meet this budget. This is an automatic minus against anything high-level. Game programmers not only work in a low-level language, but they shun high-level data structures and algorithms too. Games typically don't have linked lists and seldom have trees. There is a movement towards avoiding pointers whenever possible*. Any algorithm with more than O(N) time or O(1) space tends not to find wide use. *If a pointer doesn't cause a cache miss, then why spend 32 bits to store it? If a pointer does cause a cache miss, best get rid of that cache miss. 

I'll try to explain how things work without using much jargon. If simplicity rather than interactive speed is your concern, a 3D surface in the computer would be just a huge cloud of points in space, dense enough so we can just render each point individually, without gaps between them. You want to store a model only once in memory, but you need to display it at various sizes and from various angles, so when you render a 3D model, you need to "transform" all the points as you read them from memory. For example, to render the model 50% as big, you need to scale the positions of the points by half: 

In console games we often use Bicubic Interpolation to solve this problem. First, sample an object's position at regular intervals of time t. For a projectile, add gravitational acceleration [0,dy/dt/dt] to its velocity [dx/dt,dy/dt] at each interval. Record all the [x,y] coordinates so generated in an array. Later, to reconstruct the object's position [x,y] for a given t, read the four samples closest to that t from the buffer you recorded: [t-1,t,t+1,t+2]. Blend the four samples according to the coefficients in the linked wikipedia article to get smooth motion in space. This is not as physically accurate as performing physics calculations on-the-fly but it permits artistic license and economy of scale to assist your simulation. 

If you update thirty times per second, a human will not be able to press keys faster than you can sample the keyboard state. If you update more slowly than a human can type, then you may need one thread for rendering graphics, and another thread for reading and responding to the keyboard / mouse. But, if you update more slowly than a human can type, then you can't provide visual feedback for each key press either. This doesn't matter if the idea is to display aggregate feedback, such as average time between key presses. 

That is one of the simpler ways to make ambient look better, and was used often in PS2 and XBOX1 games. Contemporary games go further by using an "ambient cubemap" or "ambient spherical harmonic coefficients." 

N_a is the result of the normal map fetch, which is usually not unit length because it is a linear blend of almost-unit vectors. The normal map typically encodes normals in tangent space, which is to say that a normal in the map with the value [0,0,1] points directly away from the surface along the surface normal. You are right that N_a is "the normal ... before transformation into world space" in the typical case. Take care that the "H" in "dot( N_a, H )" is in the same space as N_a. 

Your problem is that your ambient light is a constant color. In reality ambient light tends to be bright from the top and dark from the bottom, because light typically comes from above. There is much you can do to fix this. At the very least, you should have a "top ambient color", "bottom ambient color", and "top ambient direction" vertex shader constants. In your vertex shader, take the dot product of the "top ambient direction" and the vertex normal, and use the result to lerp between the "top ambient color" and "bottom ambient color:" 

I use integer vectors when my concern is in "which bucket" something occupies or "from which bucket onward" something occupies, and float vectors when my concern is "where in space" something "is." Integers are much better than floats at bucketing things, and floats are much better at saying "where" something "is" in space. 

It sounds to me like you want rectangular textures with air on top and dirt on the bottom. You can map rectangular textures to the circles by making the U texture coordinate represent angle around the circle, and V texture coordinate represent distance from the center of the circle. For larger planets, U can wrap around the planet several times. To convert from regular 2D coordinates XY to the above UV coordinates, you can do math like so: 

This is almost the simplest "pixel shader" one can conceive: in goes a blend of the colors of three triangle vertices, and out goes the same color. The inputs come from the outputs of the "vertex shader" and the outputs are written to the screen in memory. So - the "vertex shader" is a program that runs inside the GPU chip. Its input is a "vertex buffer" in GPU memory, and its output is fed directly into a "pixel shader." A "pixel shader" is also a program that runs inside the GPU chip. Its inputs are a blend of three vertices from the vertex shader, and its output is a pixel on the screen. 

I recommend using the same idea that they use in movies - chroma key. Reserve one color that you don't otherwise use in your textures (e.g. green, blue, magenta). Let's call it the "reserved color." In the engine, make a matrix that rotates the "reserved color" onto the "player color" you wish to render at the moment. Set this matrix as a pixel shader constant. In the pixel shader, compute the chroma of the pixel color and find its angle to the "reserved color's" chroma. Lerp the pixel color to the pixel color transformed by the matrix, according to how close the pixel's chroma is to the reserved color's chroma. Why do this instead of using an alpha channel? Because when textures are DXT compressed, adding an alpha channel makes your texture 2x bigger. A matrix multiply and a little bit of trig in the pixel shader is a lot cheaper than reading 2x as much memory - and will become even cheaper as the years roll on. 

you often care only about, for example, the positions of all the objects. like for example you want to collide the objects with each other, in which case you don't care what their color is. so you want all the positions to be contiguous in memory and you want the colors to be somewhere else far away, to avoid polluting the cache. but std::vector requires you to store everything for each object in a contiguous chunk of memory (e.g. position then color.) so if you do work that reads only the positions, you need to read all the colors into the cache too, even if you don't use them. this is wasteful.