One fairly common approach you can use that should give the results you're after: rather than rolling a die every time, instead pick a card : suppose you have a 1/10 chance of 'critical failure', a 4/10 chance of failure, a 4/10 chance of success, and a 1/10 chance of 'critical success'. Then rather than rolling a (metaphorical) d10 and handling the result, instead shuffle a stack of ten (virtual) result cards and deal them out, one by one, whenever you need to generate such a result. When you run out of your deck, just reshuffle and start dealing again. This can still generate back-to-back critical failures, but it guarantees that there will be success (and critical successes) within some reasonable span. If you want things to be not so obvious (and don't mind introducing a small chance of successive extreme results), you can always 'double up' your deck; build a stack of twenty cards which contains two copies of each result and shuffle that instead. (Note that in the limit of putting infinitely many copies of the deck together and shuffling them, this becomes exactly the roll-a-die approach. 

I think your behaviorally-based approach is right on the money - and I'm not sure that overshooting your target is the problem that you're making it out to be. What you're describing is essentially a 1d steering behavior, and overshoot is an inevitable element of that behavior. Think of it this way: suppose you started at x=0 and you're after a current target of target_x=1000, with your cur_x=800 when a new target is chosen 'behind you' at target_x=700. You presumably wouldn't want your 'chase' to stop on a dime and flip velocity instantaneously, because that would be an implausible acceleration and a discontinuous velocity — basically, a 'kink' in your curve. Instead, you'd keep incrementing cur_x a little until you were able to change your velocity to the point of starting to decrement it towards target_x. The same behavior should be true if target_x=750, or if target_x=799 — and it stands to reason by 'continuity of behavior' that it should still be true if target_x is just ahead of you, say target_x=850. As far as the specifics on either end of the curve, I think the best way to handle 'ease out' from a stopped position would be your suggested approach of putting a limit on acceleration; for symmetry purposes, then, you'd probably want your ease-in to be symmetric, with just enough lookahead to know when it should start decelerating in order to hit the target position 'on the nose'. Alternately, if you don't care about precisely hitting your target when it ultimately 'holds still', you could use an exponentially damped approach where you have a target velocity v given by v=dx/dt = C*|x_target-x| (with C the constant controlling the damping behavior) and you clamp your acceleration attempting to reach that target velocity; this will give asymmetric ease-in and ease-out (since ease-out from a stop will be quadratic, but ease-in to a stop will be exponential) but makes the updates slightly easier since there's no real lookahead involved. 

You're probably better off not representing your orientations as angles in the first place, for a couple of good reasons: for one, because there's an inevitable discontinuity of representation somewhere; but even more importantly, because it leads to a host of unnecessary trig calls — the call here is one example of that, but there are no doubt a host of and calls down in the rendering engine somewhere. Instead, I'd recommend representing orientations (and in particular, the enemy's facing) as a (normalized) vector of the direction they're pointing in; this lets you determine which side of your enemy's facing the player is on by doing a simple dot-product test between the vector from enemy to player and the normal to the enemy's facing, and since the normal to a 2d vector (x,y) is just the vector (y, -x), this leads to the following code that replaces all of the awkward code above with two multiplies and a compare: 

As was noted in comments, what "Gameplay Programmer" means varies wildly from company to company. In my own experience, the most useful way I've found of thinking about gameplay programming is this aphorism: 

Now things get a little bit trickier. First of all, understand that the circumference of a circle — that is, the 'arc length' of an arc with an angular measure of 2π — is 2πr. In general, the arc length of an arc with an angular measure of θ along a circle of radius r is just θr. If we were to use the d in your diagram as the arc length, and since we know the radius, we can find the change in theta to get us to the new position by just dividing out: 

Another approach that ought to work is based on turning a 1d 'noise' function (Brownian motion or something like) into a closed path. Imagine that you wanted a perfectly circular pool; then a simple way of imagining that would be to express it in polar coordinates (r,θ) : r=C for some constant C. If you wanted to put a little wobble into the boundary, you could introduce a bit of a sine wave to it: something like r=C0+C1*sin(θ), tracked for 0 <= θ <= 2*π, where C1 is much less than C0 (you don't want to have too much wobble, after all!). But that's only a bit of low-frequency noise, and you want a little more wobble — and you want your wobbles to be out of phase with each other — so add more terms representing higher frequencies: 

Part of the problem is that your notion of 'velocity' isn't physical. Your updating of position is fine: 

The keys here are that the fact you're swapping two spots means that you never unbalance the colors, and likewise the test that you do before finalizing your swap ensures that you never create regions that are too large. If you have some means of displaying your grid, you could even visualize this process to watch how it 'builds' its regions through the repeated swaps. If you can't start with an equidistributed regular coloring, incidentally, then you should still be able to do something similar to equidistribute the coloring: while your coloring isn't equidistributed, pick an element at random; then, if it's one of the over-represented colors, provisionally set its color to one of the under-represented colors and then check to make sure that doesn't create too large a region of the new color. 

Another approach would be to start with a distribution that's 'fair' but regular, and then use an appraoch similar to Simulated Annealing to break up the regularity without losing the fairness: 

Note that this won't give a precisely uniform angular spread, because the surface of a sphere isn't flat - points near the center of the cone will be generated slightly less often than they 'should' be, compared to points at the fringes. But for small angles theta this gives a pretty good approximation, and it should certainly be good enough for most random-animation purposes. 

Of course, that last step is where all the details lie. It's not too hard to do segment-Bezier intersection and you can find most of the details with a bit of hunting around the web, but there are a lot of complications, and little tricks that you can do to speed things up and do as few tests as possible: 

One useful thing to understand about minimax for a game like Checkers is that it's traditionally viewed (to first approximation) as symmetric - this means that both players can share the same evaluation function, but simply with the signs flipped, or put another way that it's a zero-sum game: if you evaluate the position as being 4/10ths of a checker in your favor, you know that your opponent's evaluation will be -4/10ths of a checker. This means that you can use the same loop structure for both sides and simply multiply by a 'sign flip', rather than having to have different control structures for min and max (or switching within the loop). In simplest form, the minimax can be done as a classic recursive function, with a termination once you've reached your maximum depth: 

Notice how if you took the asin out of this formula, and cancelled the 2s, this would be the same as the last formula; this is the same as saying that sin(x) is approximately x for small values of x, which is a useful approximation to know. Now we can find the new angle by just adding or subtracting: 

For the case where d needs to be a linear distance, things are a little more complicated, but fortunately not much. There, d is one side of an isoceles triangle whose other two sides are the radius of the circle (from cX/cY to oX/oY and aX/aY respectively), and bisecting this isoceles triangle gives us two right triangles, each of which has d/2 as one side and radius as the hypotenuse; this means that the sine of half our angle is (d/2)/radius, and so the full angle is just twice this: 

And once we have this relative vector, then we can know the radius of the circle we're working on by finding the length of it: 

If you're trying to make a good AI for your checkers program, then the first place to look is what's known as Alpha-Beta game tree search. The short version is that any AI that only takes into account static features of the current position is bound to run into trouble, especially in the early-to-mid game, because it simply can't understand what's presently happening in the game and what the threats are. Instead, what you want to do is to write an algorithm that searches all possible moves-and-replies for some number of moves ahead (5 to 10 would be typical), evaluates the position at the end of each branch of this move-and-reply tree (in terms of 'how many pieces ahead or behind am I?), and then makes the move that gives it the best chance - in other words, the move that maximizes its possible value, where the possible value is calculated as the minimum possible value across all of your opponent's replies (assuming, in other words, that they'll make the move that's best for them), etc. - this is why this algorithm is often called the Minimax algorithm. What you'll find is that many of the elements you're talking about - moving pieces to the side, moving pieces out of danger, etc. - will become elements of the positional evaluation function of the game tree search. Essentially, instead of asking the simple question 'how many pieces ahead is one side or the other?', you'll say 'what is the value of this position?' and then give point values to various features of the board (e.g., whether a piece is on the side, whether it's vulnerable, etc.) in terms of partial pieces - for instance, you might decide that the difference between an edge and a center piece is worth possibly .1 piece, so in a position where you're a man behind but have an extra edge piece the overall value to you will be -0.9. One critical advanced notion for checkers AI specifically is the concept of Quiescence search: imagine that you go down six moves into your tree, and at the tail end your opponent has just made a capture where your (forced) reply is an immediate recapture. Unfortunately, the positional evaluation function can't see the recapture, so it evaluates the position as being a piece up for your opponent even though you're about to regain parity. Quiescence search is an attempt to solve this problem by forcing the evaluator to go down into a branch until all possible forced captures have been made, and only then evaluate the position. This may all sound fairly complicated, but I think you'll find it's more straightforward than it looks - once you write your evaluator function, the tree search is relatively easy; there are a lot of smart concepts (things like transposition tables) that you can apply to it, but it should be easy to get something working and then continue to improve it. For more details, I suggest searching on pretty much any of the key terms (alpha-beta search, minimax, quiescence search, game tree, etc); there's plenty of good information on all of these concepts out on the web. 

Then where A and B overlap on-screen (near the XY point (0,0)), B will be on top (have the higher Z value): its Z value will be approximately 0.66 whereas A's will be approximately 0.33. Similarly, where A and C overlap (near the XY point (1, 1)), A will be on top; and where B and C overlap (near the XY point (1, -1)), C will be on top. There's no way of ordering these three triangles such that drawing them to screen in the specified order will give the correct result. As Nathan Reed suggests, the fact that you're in an isometric view means that you would probably be able to avoid this particular issue; the question is whether it's worth avoiding or not, and that's more contingent on your environment and the particular functionality you have available. Most platforms you could be developing on have at least some form of 3d rendering readily available, though, and my first inclination would be to just piggyback on top of that for your purposes. 

For concreteness, let's say that your screen spans from sx_0 to sx_1 and sy_0 to sy_1 (so the four corners of the screen are (sx_0, sy_0), (sx_1, sy_0), (sx_1, sy_1) and (sx_0, sy_1) ) and likewise that the inner box runs from ix_0 to ix_1 and iy_0 to iy_1; finally, say the user has touched at (tx,ty). The simplest way to order the tests is to first test the touch point against the inner square; knowing that it's not inside simplifies the other ones. This test is straightforward: if 

Now with this in hand, the acceleration for the two bodies is easy; body 1's accel just points towards body two, scaled by body 2's mass, while body 2's accel points towards body 1, scaled by that body's mass: 

Note that this code presumes a half-on, half-off blink cycle (that's what the in the test represents), but could easily be tweaked for something like two-thirds on, one-third off just by tweaking the appropriate constant. This also doesn't do anything to 'synchronize' blinking between the fast and slow states, but that's relatively straightforward to polish. This should be straightforward to plug in, and it will have the IMHO substantial advantage that players will be able to see the switch from 'slow' to 'fast' blinking and know exactly how long they have left. I would start with parameter values like 5s for and 0.5s for , and 2s / 0.25s for and , but that's definitely dependent on your particular game. 

To be frank: RK4 almost certainly isn't your biggest need right now. What's more, unless you're after very accurate game physics, I recommend against using Runge-Kutta entirely - it's simply more complication, and for most platformers standard Euler integration should be more than enough. In fact, most platformers don't really need that sort of physics at all - if you're looking to try and control character position, I would suggest 'faking it' by giving the character a constant velocity while the keys are down, with simple acceleration to speed (increase the velocity by a constant amount each tick until maximum speed is reached) and the inverse (deceleration to 0) when the key is released. What's the core problem that you're trying to solve? 

As was approximately pointed out in comments, the simplest way to do what you're after is to test the center of the square, rather than all of the corners. This isn't exactly equivalent to a majority of the square's area being within your circle, but the latter is a Hard Problem, and it should be close enough for your needs. But note that this doesn't take any floating-point arithmetic, either — testing whether (x+1/2, y+1/2) is within some distance r of your center (which I'll take as the origin) is just checking whether (x+1/2)2+(y+1/2)2 < r2, and by multiplying by 4, this is exactly the same as testing whether (2x+1)2+(2y+1)2 < 4r2. This is useful for testing individual grid cells for inclusion. For anything beyond this, though — and in particular, for generating all the points at once — I heartily second David Kiger's recommendation of "Bresenham-style" algorithms like the midpoint algorithm. They're also all-integer algorithms and can find you the endpoints for each row of your circle with only a small amount of arithmetic.