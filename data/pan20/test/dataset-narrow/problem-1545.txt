Is it possible for any directed acyclical graph (DAG) to reverse all edges and still have a DAG? Assume a DAG $G$ and data is given. Now we construct the inverse DAG $G_\text{inv}$. For both DAGs, we fit the data to the corresponding Bayes networks. Now we have a set of data for which we want to use the Bayes network to predict the missing attributes. Could there be different results for both DAGs? (Bonus if you come up with an example) Similar to 2, but simpler: Assume a DAG $G$ and data is given. You may create a new graph $G'$ by inverting any set of edges, as long as $G'$ remains acyclical. Are the Bayes networks equivalent when it comes to their predictions? Do we get something if we have edges which do represent causality? 

From your labeled data: create a training, validation and test set. Don't touch the test set until the very end. Try something simple, e.g. a multilayer Perceptron (MLP) with 350 input nodes and 1 output node (giving the probability of "true"). Try more stuff (e.g. $URL$ Try to combine classifiers in ensembles (see examples). A (naive) bayes classifier might be worth being investigated. 

I've understood that SVMs are binary, linear classifiers (without the kernel trick). They have training data $(x_i, y_i)$ where $x_i$ is a vector and $y_i \in \{-1, 1\}$ is the class. As they are binary, linear classifiers the task is to find a hyperplane which separates the data points with the label $-1$ from the data points with the label $+1$. Assume for now, that the data points are linearly separable and we don't need slack variables. Now I've read that the training problem is now the following optimization problem: 

"How do you handle being given a dataset, but no clear objective?" This will be common. Apart from the advice above, understand that it is essential to understand the goals of the business you are in, and of your immediate client. Frequently you will need to understand the specific problem that made them turn to data better than they do. It is very highly common to be presented with data and an unclear objective from your internal or external client - it will be usually your task to supply a goal that can be achieved with the data and will solve the client's actual business problem. An amount of lateral thinking will be required to make the data outcome and business solution match. I would summarise the above as 'defining the objective is too important (and possibly too difficult!) to be left to the client (alone)'. In the machine learning context, CRISP-DM is a methodology which tries to solve this problem by iterating through a loop so that additional data understanding can be used in discussion with the client to better understand the original problem. So, for example, they may state a ill-defined goal, a second discussion after you've done some EDA will sharped it a little. When you later produce a model that works well, but isn't on quite the right target, you'll get closer to the real business goal again. In other words, don't be too disturbed by the fuzziness of the task. Expect to encounter a vaccuum, and fill it to your advantage. It's a slight sideways shift, but the six sigma methodology attempts to solve this problem in a different context with the DMAIC system (the 'D' standing for 'Define', in terms of the 'voice of the customer'), so it is probable that some tips can be gleaned in resources for the six sigma context (e.g. exercises you can do with a client that help them express what you want more clearly) 

Gradient checking (e.g. this explanation, but there are many more - pretty sure also in the course) XOR problem with a 2:2:1 network with only sigmoid activations. Plot the error surface. Compare the decision surface with that of this interactive demo. 

The classes of ImagNet have a hierarchy. Did anybody try to build a hierarchy of classifiers to use this fact? Searching for "multistage classification" leads to different results. 

So the answer is that you can't simply categorize such a general technique as probabilistic graphical models in a single one of those categories. See also: $URL$ 

Have a look at the derivative of the sigmoid function. It is biggest at 0. This means the gradient there can be big. This helps by learning, because the basic learning rule is $$w \gets w_i + \Delta w_i\;\;\; \text{ with } \Delta w_i = - \eta \frac{\partial E}{\partial w_i}$$ So you can get bigger adjustments if you normalize it to have mean of 0. The part about the variance ... hm. That's harder to explain. I'm not entirely sure about it. One thought is that you want the data to be in a very restricted, similar domain (independent of the application) so that you can treat results independently from your application. Also, it might help with mini-batches not varying too much. 

I guess the pattern is right, but the values are just not quite right. Also, I'm not totally sure if only one hidden layer with 3 neurons (or more) might also work. I always include biases. The solution 

I have noticed that when you make a small decision tree model, and then extend the model by creating an ensemble of trees around the same tree settings, the variable importance is diluted in the sense that the least important and most important variables become a lot more closer together. In some cases, there may be almost do distinction in importance. Are there methods available to either mitigate this effect or to measure it, with a view to defining any tradeoff between understanding variable importance and overall accuracy? 

Yes - this is an active area of study, especially famously with respect to disputed plays of Shakespeare. Features commonly extracted include frequency of key words, novel vocabularly, word length, and these are well adapted to being used as data mining features. For example, here is a thesis that data mined Shakespeare's extant plays to test whether they could have been the work of a number of authors often touted as being the "true Shakespeare" -> $URL$ 

One of the researchers, Marco Ribeiro, who developed this method of explaining how black box models make their decisions has developed a Python implementation of the algorithm available through Github, but has anyone developed a R package? If so, can you report on using it? 

There are many instances of quotes and texts where the true author may be disputed. Are there data science or machine learning techniques which may be useful to establish the authorship? 

Look at the CUDA compute capability. They are a mixture of hardware and software features a GPU has (see guide). I benchmarked the GTX 1070, Titan Black, GTX 970, GTX 980, GTX 980Ti. The numbers can be found in my masters thesis (Table 5.3 and Table 5.16), but the gist is: 

Question 2: Tagging texts This can be treated the same way like question 1. Question 3: Finding locations Download a database of countries / cities (e.g. maxmind) and just search for a match. 

Let's make an example: I want to build a neural network which should predict if a person is obese. It gets the following features: 

You can apply a technique I described in my masters thesis (page 48ff) and called Confusion Matrix Ordering (CMO): 

Reading the Zeiler&Fergus paper (my summary), I wonder how exactly they trained the deconv net. What was their data? I think for one CNN which they want to analyze, they train exactly one deconv net (in contrast to training one deconv net per layer). The featuers (inputs) of the deconv net are the activations of the layer they want to analyze. The output they train them on are the activations that actually was the input of the layer they want to analyze. So although they have one deconv-net in total, they train it layer-wise. So for each training run, the weights of only one deconv layer are adjusted. However, I wonder why the images look that unrealistic: 

The notion of ensembles of models leading to better outcomes is widespread in the Data Science and Machine Learning communities. For example, the widely read text 'The Elements of Statistical Learning' by Hastie, Tibshirani and Friedman, devotes space to the general notion of model averaging (section 8.7-8.8) with further discussion of boosting in relation to trees (e.g. chapter 10). Hence, it is common to see examples of ensembled models in the wild, using any conceivable algorithm as the base, even to the point of effectively seeing ensembles of ensembles. Specifically with respect to Support Vector Machines, there are at least a few attempts at improving SVM performance by using ensembles. A recent example is EnsemblesSVM (Claesen,De Smet, Suykens, De Moor - see homes.esat.kuleuven.be/~claesenm/ensemblesvm/). The authors promise that this algorithm will lead to better training times by ensembling lightly trained SVMs, and distribute a free implementation via the website above. 

To be more specific, loss reserving models in actuarial science, such as the chain ladder method, can be expressed as GLMs. I have developed a predictive model using neural nets which takes into account some aspects of the insured (it is an individual risk model). Can the output of this model be safely used as an input to the insurance company's existing loss reserve model? 

Tom White's 'Hadoop: the Definitive Guide' has become a popular guide to the entire Hadoop ecosystem and earned a reputation as providing both a broad survey, as well as covering individual aspects of Hadoop in decent depth. Has anyone thus far attempted to provide the Spark equivalent? 

Machine Learning is a really big field. Depending on what exactly you want to do, there might be huge differences. Having said that, the following skills are helpful: 

Start with a minimal network with input and output units only Learn those weights with standard algorithms (e.g. gradient descent - they seem to use another training objective which I don't quite understand, so it is gradient ascent in the paper) When the network doesn't improve, add a single new hidden unit. This unit gets input from all input nodes and all hidden nodes which were added before. Its output goes to all output nodes only. Repeat step 3 

However, please keep in mind that the problem might not be your implementation, but rather the network architecture / hyperparameters such as the number of epochs you're training or the training data. Also, very important: I doubt that you will get good results for $y = x^2$, except if $x$ is restricted to $[-1,1]$ or something similar simple. Please keep the domain of your output layer in mind. 

If you have a classification problem, you should you LDA instead of PCA. PCA ignores classes, whereas LDA is class-aware. For example, if your data is 2D and you use PCA in the following example, you get: 

Is it gray because MSE is the training objective? Why aren't the first layer filter outputs gray then, too? 

Ripley's nnet package, for example, allows you to model count data using a multi nomial setting but is there a package which preserves the complete information relating to a count? For example, whereas an ordinal multinomial model preserves the ordering of the integers that make up the count, a fully developed model of count data as a GLM such as Poisson or Negative Binomial Regression includes how large the integer counts are in relation to each other. Another phrasing might be, 'What kind of models come closest to combining the advantages of neural networks, in terms of, as an example, easily modelling non-linearity in the predictors, and count data GLMs, which are good at taking into account that the data is in fact a count?' 

Cook's distance and the alternative method DFFITS are not strictly speaking methods to detect 'outliers' in the sense of purely anomalous values, rather they detect 'influential' points, where leaving the value in or out of the analysis noticeably changes the result. Hence, Cook's distance measures how much the beta values change when a specific observation is omitted, which is a different idea to detecting an outlier as such, although they will naturally often be the same points. From the description of your problem, it is possible that detecting influential points is what you are actually trying to do. To directly answer your question on the Cook's distance threshold, the F-statistic with p and n-p (where p is number of regressors, and n is observations) degrees of freedom is often used. Outliers per se in regression are more often identified via residual analysis e.g. if the data point's corresponding residual is large in the context of the data set. This is often taken to be when the value lies more than three standard deviations away from the mean of the residuals (though note that in a sufficiently large data set, a well fitted model will still have some observations at this level) 

I know that there are various pre-trained models available for ImageNet (e.g. VGG 16, Inception v3, Resnet 50, Xception). Is there something similar for the tiny datasets (CIFAR-10, CIFAR-100, SVHN)? 

Of course, one can (should?) let the agent learn all the time as products change and probably search terms / language changes. But when do I know that the agent learned something weird / that I should stop it? I can imagine the following: 

Please note if you know a citable source which gives a good definition. Conditional Random Fields According to Wikipedia: 

Today, in a lecture it was claimed that the direction of edges in a Bayes network doesn't really matter. They don't have to represent causality. It is obvious that you cannot switch any single edge in a Bayes network. For example, let $G = (V, E)$ with $V = \{v_1, v_2, v_3\}$ and $E=\{(v_1, v_2), (v_1, v_3), (v_2, v_3)\}$. If you would switch $(v_1, v_3)$ to $(v_3, v_1)$, then $G$ would no longer be acyclical and hence not a Bayes network. This seems to be mainly a practical problem how to estimate the probabilities then. This case seems to be much more difficult to answer, so I will skip it. This made me ask the following questions for which I hope to get answers here: 

I would like to point out The Mythos of Model Interpretability. It formulates some ideas about interpretability in a concise way. Your question 

It looks analagous to drug testing, where reporting of side effects during drug trials is obviously very important - i.e. the increase in Y seems analagous to a side effect. And some famous drugs have begun their lives as research into a side effect. Viagra is probably the most famous case, being a spinoff from a drug developed as angina medication. So in your write-up on your experiment you should definitely report the apparent effect on Y. However, if the effect on Y is commercially important, then you still need to go back and do an experiment around a hypothesis that references the increase in Y to validate the existence of the effect properly. 

Articles which use the terms 'stacking' and 'Super Learner' often seem to use the terms interchangeably. Is the Super Learner algorithm a specific form of the more generic stacking concept, or is Super Learner essentially the same thing, and at some stage one of these terms is likely to become redundant? 

The thing you need to understand as completely as possible is how they expect a data analysis to enable them to achieve their objective. They are a business, so their overall objective is likely related to maximising profit. However, there will be a more immediate objective underneath that heading. To maximise profit you can either reduce costs or increase sales. In turn, to increase sales you can increase the number of customers or increase the amount of sales to each customer etc. The question then turns on how you can use data science to perform one those objectives. For example, questions that can almost be answered with data science could be 'how do I better identify potential customers?' or 'how do increase existing custmers' spend?' These are still very high level questions, but they are the sort of questions that you need to have in mind as you start to do your descriptive stats etc. Bear in mind that this is an iterative process and it is completely normal to start off in a fuzzy sort of area. At this stage it is almost the case that having a question in mind is a McGuffin - it will kick things off, but it may not be the question you end up answering. The CRISP-DM process is a process that has been built for data mining that discusses how to iteratively use results from analyses and models to increase your understanding of the customer's situation, and hence drive the development of a better business objective for use in a data science project.