The set of lectures by Ryan O'Donnell on Analysis of Boolean Functions, taught in 2012 at CMU, is really nice: $URL$ The page includes the video recording of each lecture. 

On sublinear algorithms: see Sublinear.info. This is a (maintained) compilation of open problems, gathered from workshops and conferences on sublinear time algorithms (streaming, property testing, etc.) On learning theory: see the open problems from COLT: 2013, 2014, 2015, 2016. COLT (Conference On Learning Theory) hosts a session dedicated to open problems, with a call for participation sent out every year: 

This is mentioned in e.g. this paper (Section 1.1.2), which does a pretty good job (in my opinion) of summarizing the landscape. 

On the other hand, Baleshzar et al. [3] showed that non-adaptive testing of unateness had query complexity $\tilde{O}(n)$, hence the separation. 

In the referee (SMP: Simultaneous Message Passing) model introduced by Yao (see e.g. [1]), Alice and Bob have respectively inputs $x\in X$ and $y\in Y$, and wish to communicate with a third-party, the Referee, to compute $f(x,y)$ where $f\colon X\times Y\to\{0,1\}$ is a function known to the three parties. The restriction, however, is that the communication is one-way: Alice and Bob can only send a message to the referee, who then must output the answer ($A\leadsto R$ and $B\leadsto R$). (This differs from the one-way CC setting as the referee does not hold any input.) While the deterministic communication complexity in this model seems well-understood, and lower bounds (tight for $\sf EQ_n$) for the private-coin setting are known [1], I could not find examples of cases (preferably for promise problems, i.e. with a gap between $\sf yes$ and $\sf no$-instances) for which there was a strong separation between one-way public-coin communication complexity and SMP public-coin communication complexity. 

Now, this is trying to address the question "after coming up with a (set of) hypotheses, how to test whether they are good. (Hence the testing and tolerant testing focus.) You may also want to start from the start, and ask how to learn the distribution itself, or the relevant parameter (i.e., learning instead of testing). Not surprisingly, this becomes distribution learning (or density estimation), with all its variants (proper learning, agnostic learning, etc.). I am a bit more out of my depth there, but if that's what you are after you may want to have a look at 

This seems to be asking the same as in this question of mine (which only has a partial answer, fitting for a partial function). Quoting from the question: 

The work of Berman, Raskhodnikova, and Yaroslavtsev [1] introduces testing of functions $f\colon [n]^d\to \mathbb{R}$ with regard to $L_p$ distances, for $p\geq 1$. It is meant to capture situations where the magnitude of the noise is what matters (rather than the more brittle Hamming distance). (Some results pertaining to $L_p$ distances can also be found in [2]). See e.g Chapter 12 (Section 12.4) of Goldreich's Introduction to Property Testing for a discussion of testing with regard to edit and $L_p$ distances. (Note that $L_1$ testing is not the same as distribution testing (typically with regard to $L_1$/total variation) as (i) the object testing is not the same (functions whether probability distributions), (ii) the type of access is different (query- vs. sample-based, typically), and (iii) the $L_1$ distance as defined in [1] is normalized (by $n$) for scaling issues, and is not in distribution testing (as the mass is always $1$ by definition). 

To apply the Majority is Stablest theorem, you need to apply it to a non-negative parameter $\rho'\in[0,1)$ (read the statement of the theorem). Since in Proposition 7.3 the parameter $\rho\in(-1,0]$ is non-positive, this means you here apply it to $\rho' \stackrel{\rm def}{=} -\rho\in[0,1)$, giving $$\mathbb{S}_{-\rho}(g) \leq 1-\frac{2}{\pi}\arccos(-\rho)+\epsilon = -1+\frac{2}{\pi}\arccos(\rho)+\epsilon$$ using that $\arccos x+\arccos(-x) = \pi$ for all $x$ (This may very well be the part you are missing. $\arccos$ is not an odd function). Then $$\mathbb{S}_{\rho}(f) \geq -\mathbb{S}_{-\rho}(g) \geq -\left(-1+\frac{2}{\pi}\arccos(\rho)+\epsilon\right) = 1-\frac{2}{\pi}\arccos(\rho)-\epsilon$$ as stated. 

(All imprecisions above definitely mine, I cannot claim I fully understand the theorem.) This does strike me as a very useful tool, similar in spirit to some type of dimension reduction: 

where $d(f,\mathcal{P}) \stackrel{\rm def}{=} \inf_{g\in \mathcal{P}} d_H(f,g)$ is the minimum (Hamming) distance between $f$ and a function satisfying the property. Tolerant testing (as introduced by Parnas, Ron, and Rubinfeld) relaxes the first (completeness) guarantee from $d(f,\mathcal{P}) = 0$ to $d(f,\mathcal{P})\leq \varepsilon'$, where $0\leq \epsilon' < \varepsilon$ is another input to the algorithm. In particular, tolerant testing is at least as hard as testing, by choosing $\varepsilon' = 0$. However, I am aware of only very few separations between testing and tolerant testing which show the latter to be actually harder, for "natural" properties of functions $\mathcal{P}$. (Of course, here the word "natural" is fuzzily defined; I guess we recognize what it means when we see it.) An example (for contrived properties) was given by Fischer and Fortnow [1], where they provide a property with $O_{\varepsilon,\varepsilon'}(1)$-query testers, while every tolerant tester requires $n^{\Omega(1)}$ queries. This is the extent of my knowledge regarding published or available results. 

You might find this short note helpful ($\LaTeX$ code available [1] if the binary link breaks). I am reproducing the relevant part below: 

Note: I am considering here property testing in the query model, with regard to Hamming distance. (So, for instance, of Boolean functions—I'm phrasing it that way below.) I am in particular not interested in separations in distribution testing. The property testing model (for Boolean functions) asks for algorithms that, for a fixed property $\mathcal{P}\subseteq 2^{2^n}$, are provided with a proximity parameter $\varepsilon \in (0,1)$ and query access to an arbitrary function $f\colon \{0,1\}^n \to \{0,1\}$, return either $\textsf{accept}$ or $\textsf{reject}$, such that: 

My question is: has this theorem, or some version of it, been applied or explored in the context of computational learning? If so, where can I find references of it? If not, is there a reason why—e.g., "it does not apply in the usual settings we consider because [...]"? 

Note: a lower bound of $\Omega(\frac{n}{\varepsilon^2})$ (also folklore) is easy to derive from Assouad's lemma, by considering the family of distributions over $[n]$ where each pair of consecutive elements $(2i,2i+1)$ has either probabilities $(\frac{1+c\varepsilon}{n},\frac{1-c\varepsilon}{n})$ or $(\frac{1-c\varepsilon}{n},\frac{1+c\varepsilon}{n})$ for some suitable constant $c>0$. (Intuitively and a bit misleadingly: any learning algorithm has to "figure out" at least $\Omega(n)$ of these independent choices, but each of them requires $\Omega(1/\varepsilon^2)$ samples.) 

For instance, defining the property to be the singleton $\{p\}$ (where $p$ is a known, fixed distribution of interest) you get the identity testing problem. People have considered many variants, including varying the metric ($\ell_2$, Hellinger, Earthmover, $f$-divergences). It dates back to last year, but here is a list of references (from the second survey below). There has been a lot of work in this area: I would suggest the following pointers and surveys: 

The end of the proof of Theorem 7.2 explicitly states "Using the fundamental theorem of statistical learning, this implies that the VC dimension of $\mathcal{H}_n$ must be finite, and therefore $\mathcal{H}_n$ is agnostic PAC learnable." Now, this is confusing, since looking at this "fundamental theorem of statistical learning" (Theorem 6.7 in this book), it looks like we want to use the implication $(4) \Rightarrow (6)$, namely PAC learnability implies finite VC dimension. But, as you point out, instead of PAC learnability we only have the seemingly weaker guarantee you wrote: 

This is a question that I've been pondering, on and off, for a while, and unsuccessfully. I'd be very interested in any insight regarding this conjecture. (Or rather, these conjectures.) Recall that, given a Boolean function $f\colon \{-1,1\}^n \to \{-1,1\}$, the Kahn—Kalai—Linial theorem states that $$\max_{i\in[n]} \operatorname{Inf}_i f \geq \operatorname{Var}[f]\cdot \Omega\!\left(\frac{\log n}{n}\right) \tag{1} $$ from which we get that, for any monotone Boolean function $f\colon \{-1,1\}^n \to \{-1,1\}$, $$\max_{i\in[n]} \widehat{f}(i) \geq \operatorname{Var}[f]\cdot \Omega\!\left(\frac{\log n}{n}\right) = (1-\widehat{f}(0)^2)\cdot \Omega\!\left(\frac{\log n}{n}\right) \tag{2} $$ (writing $\widehat{f}(i)$ for $\widehat{f}(\{i\})$, $i\in\{0,\dots,n\}$). Moreover, (2) is tight, as shown by considering the $\textsf{Tribes}_n$ function. In particular, this implies that $$ W^{(0)}[f]+W^{(1)}[f] = \sum_{i=0}^n \widehat{f}(i)^2 = \Omega\!\left(\frac{\log^2 n}{n^2}\right) \tag{3} $$ for any monotone Boolean function $f\colon \{-1,1\}^n \to \{-1,1\}$, where $W^{(k)}[f] \stackrel{\rm def}{=} \sum_{S: \lvert S\rvert =k} \widehat{f}(S)^2$. Now, consider two monotone Boolean functions $f,g\colon \{-1,1\}^n \to \{-1,1\}$, and let $h\stackrel{\rm def}{=}fg$ be their parity. It is easy to see that we could have $W^{(0)}[h]+W^{(1)}[h]=0$, e.g. by considering $f,g$ to be two different dictator functions (but in that very specific case, $W^{(2)}[h]=1$). But must there be some non-negligible Fourier mass on the first 3 Fourier levels, then? 

The recent preprint of A. Levi and E. Waingarten [1] establishes such a separation* for two "(arguably) natural" properties of functions: unateness and junta-ness. *(for junta-ness, such a separation is shown only for non-adaptive testers.) 

After the OP's edit (see comments below), this answer is outdated and does not address the question. Leaving it for the said comments.