Running Debian Lenny distros : I'm still wondering how to iso a complete distro setup "easily", but for the time being, I'd like to able to run easily and quickly a reinstall, so I added such a line in my rsync backup shells : 

On Linux Debian (and I guess ubuntu too), ignoring best practices using ssh and sftp, you can set ftp with chrooted virtual user(s) using pureftpd, which is the best ftp server I experienced till now. 

You will have to adapt some data in the shell, given as an hint. Same applies to your data (/home and so on), I mean using rsync your backup tarballs (rsync is using ssh). Even these rsync can be managed in a cronjob sothat the backup are done regularly. Hope it helps. 

A2: This depends on what you want. If there are only two or three of you working together - then there really isn't much reason why sharing an account would be a problem. On a side note, depending on who you are working with and your trust level with these folks, you really want the ssh/sftp account that you are all sharing to NOT be a root/administrative user. 

This produces c:\temp\email-addresses.txt, which, although it contains a little extra garbage characters, it can easily be parsed out with a search & replace in Notepad++. 

What is the sensible way to get around this? Can I change the default directory on the command prompt processor, when it's first loaded? Or is there a way of changing my batch command code to use the local paths correctly? Maybe this isn't the problem at all and it's something else? Any help greatly appreciated. My command line code: 

Our .co.uk domain isn't used anymore but we still own it. I managed to delete the rule pretty quickly from the config file, as luckily it's in development stages and nobody would have landed on it anyway, and I also deleted the rule from IIS too. However, my browser still gets redirected to the wrong domain but other browsers don't. So I assume everything is OK apart from my browser has cached the rule somehow and somewhere. Have I done any permanent damage to how my site will run in the future and do I need to do anything else to remove this incorrect rule? 

But no "incrond" pid is running there. Question Shall I absolutely use /etc/init.d/skeleton as a starting point or is it still possible to symlink to the existing "incrond" daemon, and how then ? Note: I don't have "service name start" available on this Lenny distro. 

Is there a better way using dpkg or another tool in order to be able to generate an automated reinstallation file from an existing system in case of failure ? 

Here is an example where you 'll see the steps for that process (looks like you're missing the apxs2 and the apache LoadModule directive in our question) : 

To solve this you need to extend the session's idle time. You can do this by going to: Start > Control Panel > Administrative Tools > Terminal Services Configuration : Right Click Connection > Sessions Tab And then altering the idle timer settings to suit your needs. I changed mine to have an idle of 1 day before disconnecting and logging out. 

We tried copying imagick.so and memcache.so from the old extension directory to 5.6.7's extension directory, but without any luck. How do we install these extensions to our latest version, PHP 5.6.7? Or is there a way to resolve this without reinstalling anything? Edit: To install PHP 5.6.7, I used the steps given in this gist: 

but here I see no point how bash would link globals with /etc/network/interfaces. So I tried also like : 

I installed pureftpd on a NAS with a Nux busyBox but not on a Debian's like machine. Pls find anyway the best doc I found (sorry, some are in french) : $URL$ $URL$ $URL$ $URL$ I also wrote an installation shell here, that might help also on other Nux OS. I also wrote a hook shell sothat the received files are unitary controlled before saving them locally. It's not a shared script but I can share or send it if sbdy needs it. 

Working overly tired caused me to use the wrong web.config file in my application, therefore applying a permanent redirect on the wrong URL!! I was meant to convert: 

I have a growing stock photo website. It's currently hosted on a pretty basic dedicated server from WebFusion and I now need to expand, both storage and performance, and to lose their rubbish support team. We have 500k photos online now and reckon we could make the million or two mark quite soon. I'm now stuck on what options there are for expanding, whether to just upgrade the server we have to hold more files, use a third-party storage service, like Amazon, buy our own server or something else. Any suggestions would be amazing, thanks. 

I commented on your question with questions of my own. I might be able to help if you can elaborate a bit. Either way, you'll have to forward VPN ports on your wireless router to your DC so your DC can handle the VPN traffic. 

Our Exchange server is running on the . We're dealing with the mail store size issue, where if the mail store goes over the limit, it gets dismounted. While we are working with the powers-that-be on a policy that will prevent this happening in the future, I would like to see if it is possible to re-mount the mail store via the Windows CLI. I'm already monitoring the Event Logs and alerting on mail store warnings and dismounts - I'm just tired of getting up at 5am to manually re-mount the store while the political wars ensue. My alerting tools have the ability to execute a batch script when an alert is generated. I would greatly prefer a native CLI option. I'm not too keen on running some random vbscript found on the Internet and I don't really care to spend my time debugging someone else's code. PowerShell might be an option, if it can be triggered from the CLI. 

We have two versions of PHP on our Linux CentOS6 machine, 5.3.3 and 5.6.7, and wanted to install PHP extensions, memcache and imagick, to 5.6.7. Logged in as root, using yum, we installed both of these, but realised they were only usable in 5.3.3 and not in the latest version. This are the commands we used: 

As the title reads, I'm about to download and install URL Rewrite Go Live extension on my Windows Server 2008 R2 dedicated server, and I need to find out which version of URL Rewrite I should be downloading, x64 or x86. The information that came with the server when I started to rent it said it was 64-bit but when I look at my C: directory I have two Program Files directories, one titled "Program Files" and the other "Program Files (86)" - so this has confused me somewhat. Can anybody suggest how to find this out? 

Trying to apply these rationals on an ubuntu VM box to automate wifi connections but processing just into an infinite loop as I guess I'm not using glob as it should but can't find why/where the fault(s) : I tried to run this using : 

I'm using a QNAP box (mounted RAID5) which is a good solution for us, but take care about the OS and microP. Native OS is a simple BusyBox but there are existing Qnap variants, accepting Debian, which is .. significantly more user friendly and flexible. 

I am trying to build an automated background backup program to backup my entire website and its heavy photo folders, using Amazon's cloud storage service, S3. I am using S3Sync from S3Tools and have successfully tested a dummy backup using only the command line window. When I save the working command line to a batch file (.BAT) and have a Windows schedule call it, it does not work. I can only think this has something to do with the local paths set in the command line. If I go on to my server and open the command prompt from my 'Start' button, the command prompt has a default of: