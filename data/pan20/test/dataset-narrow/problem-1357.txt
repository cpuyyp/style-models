You can control the shapes of the islands using the persistence value of the noise, the value of , and the threshold value you choose. You will need to modify it somehow to make sure you only get one island. You will have to play around a bit; one idea is to start in the middle, and do a spiral search until you find a filled pixel, and then make a new array, and fill it with pixels that are filled in the bool array only if they are connected to the first pixel (the one you found in the spiral search). (*Including me in the article :( ) 

Generate one random point. For each point in the array with at least one empty neighbor that you have not already processed, fill each empty neighbor with some probability. Repeat step 2 until desired. 

You can control the shapes and sizes of the islands with the value p that you choose. You need not keep p constant, it may work well to decrease it as you go on. You may also make it depend on the number of neighbors (for instance, make it proportional to the number of neighbors of the pixel you are processing). You can (probably) make the algorithm more efficient by maintaining a list of border pixels, and another list of processed pixels. It becomes then something like this: 

I think the following should do the trick. (Edit: as pointed out in the comments, this gives the unsigned rotation). 

(Other possibilities are also possible if this is too slow.) Method 2 Generate cloudy noise (or Perlin noise, as some people* mistakenly calls it) in an array of the same size, and then use a threshold function to make the island. Check this out for generating the noise: $URL$ $URL$ To generate islands, you can use this algorithm 

Either the matrix is transposed (i.e. rows and columns swapped) in , or the equation in uses the row vector instead of the column vector. The two values just happen to be close by accident. Here is a Matlab trace showing whats going on. The quote is used to indicate matrix transposition. (The multiplication below is swapped around, of course you could also do and ). BTW, using tools like Matlab (or Octave) are great for quickly prototyping these types of algorithms and finding bugs like these fast. 

You can try TuDee: $URL$ I have used it successfully for 3D tile-games. It exports XML, so it is easy to read into whatever game engine you are using. It supports multiple maps (useful for different levels), as well as layers, entities, custom variables, and many other features. Here is some more info: $URL$ 

There are several things you can try for generating random shapes that are meant to represent islands. You could modify your algorithm to make sure the resulting shape is convex. Although it's not required for the islands to be convex, I have a feeling that using it vanilla will lead to shapes that look odd as islands. But more organic shapes are possible. Here are two suggestions: Method 1 

This was simply an error with her and my Unity versions being different. By updating my version of Unity, that solved the issue. Apparently files need to come from the same Unity version to be compatible! 

My team is currently building a 2D game in Unity and we've run into some workflow/script organization blockades for many of our game's characters. For example, we're not sure what the standard method of encapsulating/organizing a character's movement, animation, and more complex AI code is so that things don't become a behemoth mess. Originally, we had all a character's code in one file -- movement, animation, and AI decision-making code. Needless to say, this became messy really quickly and horrendous to debug. Then, we redesigned it so that there were three scripts on the character: a movementHandler, animationHandler, and AIHandler. These scripts would communicate to each other, but encapsulate their own functions. This worked better than before, but also grew to a point where it was a bit messy organizationally and debugging is becoming a nightmare again. We're interested in knowing how people typically organize their scripts. Is there a way people know to organize these code sections so that they're more scalable and don't become headaches to manage once the project grows and grows? 

So, if the direction is RIGHT (aka 1) it flies right. If it's LEFT (aka -1) it flies left. However, the orb direction stays at 0, and is never set. This indicates to me that the initial code above in the block is incorrect. Am I accessing the GameObject incorrectly? I feel like it's just a slight coding error with objects but for the life of me I can't find it. 

So I create the new orb projectile, instantiate it, and then attempt to set the direction. In the orb script: 

I currently am creating a script that allows the player character to attack by shooting orbs at foes. I have the current code to do that (not final code, for testing purposes): 

She's exporting everything as a .unitypackage and I'm importing the .unitypackage, but it doesn't work for some reason. In addition, she was able to create a new project on her computer and import the package fine. Any ideas why mine is funking up? 

After some more testing, it appears the problem was the Start() method. Apparently, for whatever reason, the code was being executed as follows: orbControl instantiated -> SetDirection() -> Start() Thus, because of this, direction remained 0. So, I changed Start() to Awake(), and all's well. It appears to me after more research that this is the main difference between Start() and Awake(), and that generally one should look to use Awake() for initialization. 

Our artist created some .anim files using the built-in Unity Mecanim system (where you use keyframes and drag various body parts to construct the animation). However, now we're trying to export them from her Unity program into mine so that I can incorporate them into the scene. The problem is that they're simply appearing as blank files. Here, the files are importing and everything looks fine aside from the controller: 

Each time I create a new project UE4 adds a generic bundle identifier to the iOS platform settings, that I always have to change to in order to be able to run the newly created project. So, I wonder how can I make UE4 to correctly auto detect this field from the picked provisioning profile. I was thinking something like putting (including the square brackets) but the editor crashes when I put that in the bundle identifier field. 

Where A is the duration of the clank from where the movement starts slowing down until the end of the ease transition, and B is how deep is the valley measured on a line perpendicular to that intersects the line at . 

dot product is negative when the angle between the two vectors is greater than 90ยบ, for the code to work properly you would need to take the absolute value of the dot product. 

How can I change the dimensions of the capsule for one bone in the physics assets tool? The problem is that bones not connected by joints have overlapping collision volumes in the mannequin that comes with the starter content, which causes those body parts to apear dislocated or out of place when the simulation is running. For instance in this image the pelvis and the middle bone in the spine (Spine 2) are overlapping. 

Since vector algebra is GPU friendly, normalizations and dot products can be used to find the four corners of the original plane as follow: 

You know those mechanisms that moved or rotated, and then just a few millimeters near the end of the trajectory they oppose a bit of resistance and then clank to the final position. I want to simulate that clank with an ease function that can be combined with the standard ease actions. The link is for reference to some examples of ease transition functions, but I just need the pseudocode like this: 

Where A and B are parameters passed to the ease function to indicate where to star the clank and how deep is the valley near the end of the curve, respectively. 

You could calculate the path the car would describe if it turns with the current speed without drifting. Then apply brakes in proportion to the distant d, which is the distance measured from the calculated path to the curve. 

Given the projector point (P), the projected point (B), one arbitrary point on the plane that contains the distorted rectangle (Q), and the normal vector to that plane (n), the point of intersection (A) of the line from P to B, and the plane is given by 

I would like to expose to blueprints the variable CurrentTouchInterface in the class APlayerController, just like the method APlayerController::ActivateTouchInterface. So, I'm guessing I have to change the header file PlayerController.h from this 

How is it called, what is it used for, and what is the most common way to implement it? I know these are three question in one, but since the first and second are just one-liners I decided to make them into one. The following images are two screenshots showing the visual effect; (A) show the zones that are darker and (B) the normal zones