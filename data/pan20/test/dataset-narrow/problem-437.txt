I don't really like the methods which forces the user to call it every time before calling . Besides, the algorithm is very basic... Are there libraries doing this already ? Is there another algorithm, simple to implement (performance is not really an issue, this was working with roughly 1000000 elements) My tests are really poor as well, are there better guidelines to write them ? 

My knowledge in graph theory is very limited. I have to look for elements in an (undirected) graph who are in the same connected component. The idea is simple. First, build the graph. Then, allocate a "color" to a point and spread it to its neighbours recursively. Once there are no neighbours to color any more, pick a point without any color and repeat the same process. This ends when all the points have a color. I wrote the following class : 

Note : I am using OCaml 4.02, but I could upgrade it to 4.03, especially for the Array.map2 methods. 

In order to have a "unified" (I realize how ambitious this actually is) syntax when working on dataframes, I wrote the following functions that is a general purpose dataframe set of tools in R. 

There are times when it makes sense to have some sort of class whose instances are objects that can perform a bubble sort. This is typically when the algorithm might need access to some precomputed data, or maybe to acquire resources that will be reused through several invocations of the algorithm, or hold configuration options, or is keeping track of performance metrics, or other such things. (but this pattern has its own advantages and disadvantages and there are other patterns that can be used to achieve that effect) However, this implementation is very much not one of those times. 

One issue is that your function is four functions in one. The problem is that they are four unrelated functions — yes, they all have the job of displaying results, but: 

Finally, one may dislike the fact that useful functionality is buried in nested functions; we can pull the nested functions out: 

If you feel it's important to write the code so as to start with an empty list and extend it, you could instead use 

I've mainly just made a function sets up the right arrays, and then converted the original implementation into the nested function . Notice I've created a array for storing the results. Also notice the need to make a copy of the potential answer when storing it as a result, since we will continue to modify . I've also modified the list of words so there is more than one result. I assume you want to obtain all answers; it shouldn't be hard to modify this to end the recursion as soon as an answer is discovered... however, a better approach will be described below. Given this change, the arguments to are redundant: it can be changed to the following. (if you're really serious, you should profile this change, to determine whether it actually makes things faster) 

I translated the given C# code to Java, and timed it on my machine using the Unix command. It ran in 0.161 seconds. Your original code ran in 1.023 seconds. Here's the Java translation of the C# code: 

I would prefer not to catch the here. Letting an exception go uncaught will just stop the whole program, which seems to be what you wanted. Some other languages force you to catch or declare every exception, but Python will just bring down the whole program around you. That's not what you want for production code, but that is absolutely what you want for development: anything anomalous will make the program crash and die right away, with a reference to the line number where the crashing and dying occurred. As a bonus, it's quicker and easier to write the code that way, because you don't have to add blocks around everything. If you can do something about the invalid input, then definitely catch the exception and do something. But if all you can do is say "You screwed up, fix it", then why not just let the exception be thrown? This piece of code from could be a lot shorter and cleaner: 

Use the memory management tools the standard gives you In particular, should be of type , not . The memory management you are doing is a standard and common thing... and also well-known to be an extremely common place for programmer errors. Use the right tool for this job, so that it's easier to write code, less likely to have errors, and more obvious to the reader what your implicit intentions are. (and yes, you do have errors — for example, the way you wrote the code requires a destructor to deallocate the memory, and you don't have one!) You have a const correctness error is a const member, but it returns a pointer that would allow the user to modify the contents of the string! If you are going to have this function, you should have two variants 

This advice is likely to be somewhat controversial, but Explicitly flush when output should be available 

and let manage the allocated memory, rather than managing it manually. Similarly, in , you have declared 

While some would advicate relying on the implicit flushes coming from being tied to , my own observations are that: 

Generally speaking, buffering is good for performance, so it's better to write newline characters rather than inserting when you don't actually need flushes to happen. As a bonus, they're less typing and usually easier to read. Of course, I/O performance is basically irrelevant here because the human delay far outweighs any other concern — but it's good to get in the habit of writing what you mean early on. Thus, the above code snippet demonstrates the general pattern: I use newline characters to write newlines, and I do something to flush the stream at the point I want to ensure that all of the output has been written. Using to do the flush isn't an option here, if I want the flush to happen at the right place! 

Or, if you're uncomfortable with the shortcut syntax for anonymous functions (it can get pretty hairy), like this: 

Think of it this way: is there any way to count the number of distinct elements without actually looking at every element? (More accurately, without looking at some substantial portion of the elements?) If not, then \$O(N)\$ is the best you can do, asymptotically. There might be other optimizations you can make to speed things up in wall clock time, but the algorithm is as fast as it can be. I suspect, though, that your code isn't actually running in \$O(N)\$ worst-case time, because I suspect that adding an item to a Java TreeSet is an \$O(\log N)\$ operation, since I think they're implemented with Red-Black Trees. If you process \$n\$ items, and each time you process an item you do something with it that takes \$\log n\$ time, then your algorithm has worst-case complexity \$O(n \log n)\$. A Java hash set, which uses a hash table, should insert in \$O(1)\$ time, so your code would run in \$O(N)\$ worst-case time if you used a (as Simon André Forsberg suggests too) instead of a TreeSet. In general, I think that's the best you can do if you're just looking at an arbitrary array of items. 

In the source code, you can collapse a lot of the output statements to improve readability and so that they take up less vertical space. For example, 

Note the use of and for yielding results. Using generators has a number of advantages including: you get to see results as they're created, you can stop iterating when you're happy with a result, rather than having to wait for the entire recursion to finish, you don't waste memory/time creating a list of all the results. Generators take a little bit of time to get used to, but they're well worth it, and should often be preferred to returning lists of results. Finally, one last neat trick; the general pattern of "make a change ... do stuff... undo the change" can be error prone; it can be easy to forget to undo the change, or an odd code path (e.g. an exception) skips the change. The other answers suggest making copies; however, backtracking algorithms like this can often suffer massive performance penalties from such a change, so it's worth knowing a pattern that mitigates this problem without introducing copies. We can use a context manager to do this automatically, such as below. (this post is not meant to be a tutorial on context managers) 

I feel there are other places this code could be tightened up, but without knowing what it's supposed to do, I don't want to suggest anything that misses the point. 

There's a precept in Python, EAFP, which stands for "Easier to Ask Forgiveness than Permission". What it means is that Python programmers tend not to check things with conditionals, like doing . The style in Python is more to assume everything is good, and let the program throw an exception if it's not good. In this case, if there's no such file, you throw and complain. Sometimes you do want to ask permission, but I think this is a case where it's easier to ask forgiveness. This is something I also see elsewhere in your code. It's good to be safe, but in Python, people tend to really lean more heavily on exceptions than on explicit conditional checks in most cases. The case where you do use a conditional is when there are multiple possibilities, all of which are valid, and you need to figure out which case you're in. But if something is wrong or invalid or unexpected, like the passed file name not being a real file, I recommend exceptions. (By the way, you don't need in your clause. What does is skip over any code that comes after it to go on to the next iteration of the loop. In this case, there is no code after , so it would always go to the next iteration anyway.) In both and , you have some code like 

I wrote the following implementation of the k-nearest neighbor algorithm (for a binary classification task). I am not familiar with OCaml's built in functions, I have the feeling that some of them somehow reinvent the wheel : 

I want to plot (on the complex plane, with ) the power series whose general term is the number of partitions of an integer. The more points I want (and the larger the degree is), the longer the plot takes. I first wrote a naive version, added memoization of the sequence, changed the naive evaluation of the polynomial with the Horner algorithm. All these modifications led to speed ups, and I want to know if there are more optimizations I could do. 

Function naming and are kind of misguiding, I would expect that , but this is not the case as each function treats the diagonal in a different manner. In order to improve readability, I would write a method and a 

Comments I don't really see the point in on top of your methods. You can just type which automatically propose a neat documentation, per example, in the MatrixCreate function : 

Hardcoded values They are usually a bad idea (what happens if, per example, you use this value somewhere else, and decide to change it someday?): 

This is a really cool project, and I don't think the non-functional aspects are as problematic as they might seem. One of the things that makes Clojure so flexible is that it lets you be imperative, or even object-oriented, when it makes sense. I think most of the messiness in this code comes from insufficient generalization, rather than being imperative. If you do want to make it more purely functional, James Hague has written some really interesting essays about game programming in functional languages (he uses Erlang, which is even more purely functional than Clojure); the most famous is Purely Functional Retrogames, where he takes apart the process of implementing Pac-Man in Erlang in a purely functional manner, without passing around a "game state" variable. He also argues in Functional Programming Doesn't Work (and what to do about it) that even in a purely functional language, there are certain situations where an imperative "pressure relief valve" is extremely useful and that we shouldn't contort ourselves trying to avoid those. We Clojure users have it good here, because Clojure has high-quality imperative pressure relief valves like the reference types. I've never written a game in Clojure, but I'll try to offer some suggestions based on general principles and my understanding of Hague's advice, starting at a low level and moving up. In general, I think you could clean up your code quite a bit if you had more small helper functions. For example, I would put the calculation of in into another function: 

This is a simple implementation of a generic binary tree that holds elements of type T. I was wondering if there was something that could be done better (especially in the EnumerateNodes methods). 

Is there a smart way to optimize these bottlenecks ? I feel like there is something redundant in evaluating hashes and storing values in hashtables... 

I am running a simple OCaml program which opens a CSV file with a pseudo dict-reader and hashes "key" + "value" (where key and values are strings). Then some counts are evaluated on the hashes (but it is not really relevant for what follows). After a quick look at the default OCaml profiler (), I noticed that my program was mostly spending time in hashing elements (I don't know what does though). 

I wrote a simple online logistic regression, calibrated using gradient descent to compare the speed of an OCaml implementation vs the same Python script, executed with Pypy. It turned out that the OCaml implementation was slightly faster than the one run with Pypy (by about 10%). Now I would like to optimize my code even further. The assumption about the data is that the values of each rows are sparse (can be considered as factors), they are encoded as integers (collisions are allowed) and stored in a large array. maths.ml