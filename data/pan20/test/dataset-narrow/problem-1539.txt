It seems like you are overthinking this and getting caught up in your own head a little. We can define a restricted set of time series as those which are well behaved (non-asymptotic) and single valued. These time series then form a time series algebra which have additive, multiplicative, commutative, and associative properties. There is an identity element (straight line with value 1) and a zero element (straight line with value 0). We even have a well defined inverse member for all time series not crossing zero. I believe this even forms an Abelian group. Further, previous posters are correct that this group can be perfectly represented by various orthogonal vector spaces such as polynomials and Fourier space. This is true whether we are talking about Lagrange polynomials, Fourier series, or Gauss-Lobatto-Legendre polynomials. The point then becomes... where does this get you? You got caught up in the suggestion to employ Fourier series in that you didn't want to remain in frequency space, but this is entirely unnecessary. You can, for instance, Fourier transform into frequency space, apply a high frequency filter, and then transform back into the time domain. This is incredibly effective in removing noise (although band pass filters tend to work better). Stepping back from the question a little, it seems like you might really be asking: Given typical time series and typical time series operations (smoothing, de-seasoning, de-trending, etc) do the time series and their typical operations constitute a group with a well defined algebra? The answer is, yes. All of these operations just involve finding other time series which can be added, subtracted, multiplied, or divided by the original time series in order to yield a more physically tractable (interpretable) representation. 

While previous answers are correct in describing how categorical variables can be encoded with sets of binary variables ( or ), I'm surprised that no one has pointed out the obvious... Neither or require one-hot encoding for categorical variables. This is one of the very convenient aspects of both and classifiers. They can operate on integer features, floating point features, ordinal features, and categorical features and a heterogenous combination of them. So go ahead and use your categorical variables without encoding them. Decision trees have the added benefit that you can visualize them to see how the variables are oriented in the . I know this question is quite old, but I wanted to add so that future readers are aware of this feature. Thanks! 

The paper that you cited references two other papers that explain the method you are looking for here and here. The second one is behind a pay wall. But... these look like deterministic methods to me, and I suggest you use a machine learning method instead. You basically need to separate events from each other using some sort of clustering algorithm. I suggest you use and adjust the parameters based on whether you want every event to be assigned to an episode or not. Another algorithm that might work well is simple clustering with the addition of an or to determine the optimal number of clusters. 

Strictly speaking, the k-means algorithm does not have a definition for "inside the cluster" and is therefore not a great candidate for anomaly detection. In k-means, every point is assigned to one of k clusters and then a new cluster centroid is calculated. But as previous uses have pointed out, you could construct some sort of ad-hoc system where you process a set of data and then define new data as anomalous when its extends beyond 2 standard deviations of the centroid location. DON'T DO THIS! K-Means will not work well for this ad-hoc method. If k is poorly chosen, then the distribution within a cluster will not be normally distributed. You very, very frequently see natural distributions of points which are split between two clusters. For instance, take a look at the ad-hoc segmentation of points in this location data for a cell phone user's location over a month: 

It sounds like you are grappling with large data set sizes, for which I first suggest switching to . Mini-batch scales better so will be less frustrating. Regarding apriori estimates of the , I suggest using a sample data set to approximate the with appropriate margins of error. But, mini-batch may just preclude your need for apriori . Hope this helps! 

And here is a big picture viewpoint with some heuristics. Additionally there is a very sophisticated treatments called for outlier detection that instead rely on principal component decomposition. There is a corresponding R package, but the theoretical treatment is behind a paywall: P. Filzmoser, R. Maronna, M. Werner. Outlier identification in high dimensions, Computational Statistics and Data Analysis, 52, 1694-1711, 2008 Hope this helps! 

Now, answering your questions: Is it relevant to center / scale euclidean distance on each cluster ? (and then consider outliers as the ones with the highest scaled distance) Yes, you can certainly do this. Combining k-means with outlier detection is certainly possible but is probably not the most elegant or efficient algorithm. It kind of sounds like poor-mans's DBSCAN. Euclidean distance works fine, but just do a second set of normalizations using the centroids and the standard deviation of the cluster. Are there other kind of distance to consider? There are lots of other metrics that are useful for many different reasons. As stated, the k-means convergence proofs hold only for Euclidean distance. For outlier detection Euclidean seems best, but there may be cases where Cosine Similarity metrics could be useful. People may suggest L1 (Manhattan) distance metrics, but I find this is only useful when there is significant linear dependence in your data, which can be remedied with dimensionality reduction. Short answer: Give it a try as Euclidean should work fine, but also take a look at clustering via DBSCAN, which has outlier detection built into it. Hope this helps! 

I'm not really seeing the issue with an infinite loop. It seems like you are looping through your clusters and finding all the clusters that need to be merged, then in a separate loop doing the merging and are getting tripped up when two clusters are flagged in such a way that they both need to be merged into one another. Instead, you can think of this as more of a queue. Then you can loop through one time and merge the small clusters with their neighbors and then destroy them. Imagine you have a class with attributes: , , and nearestNeighbor, and methods and . Then you could do something like: