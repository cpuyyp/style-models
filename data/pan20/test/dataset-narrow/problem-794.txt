This will setup the monitor. Every closed file handle on the filesystem that had a write flag open initiates the event check. 

Alter this value to be something way lower. Perhaps would be a more reasonable number. You also shows some 'orphaned tcp socket' errors. You may also wish to reduce the values for and which will permit you handle more sockets (at the cost of latency). So, to answer your question why are you killing processes with so much free swap - the answer to that is the setting is ridiculously high for the amount of actual memory you have in each zone. Reduce this value from 32MiB to 1MiB. 

Because we consider who is performing the request before allowing it, we can perform more intelligent decisions of who gets to do what. 

You are on the right track, uses this file for this purpose. But you need to read it more than once. Utilization is a is a measure of use over time. You can read it once providing you know the uptime in seconds of the host, then divide by that, but that would give you a utility rate of the host since the machine was booted. If you want a rate over 5 seconds, you would read the file once, sleep for 5 seconds, read it again, obtain the difference of the calculations and divide by 5. 

The parameter refers to traditional UNIX IPC shared memory. You can see the memory allocations of that using the command . The temporary filesystem is a totally different subsystem used as a ram based, swap backed filesystem. is used as the basis to perform posix shared memory in fact, which is a different type of shared memory system to unix IPC. 

That value is calculated by taking the 14th field from /proc//stat which the kernel manages. The value in question -- as far as I understand it -- only ever increases in 'jiffies' (effectively 100ths of a second). Can you cat the value of /proc//stat for that pid ten seconds after one another? 

|The first line is the GFP mask assigned for the allocation. It basically describes what the kernel is allowed/not allowed to do to satify this request. The mask indicates a bunch of standard flags. The last bit, '2' however indicates the memory allocation should come from the zone. If you look closely at the OOM output, you'll see no zone actually exists. 

The two dont necessarily correlate, but to me this strongly looks as if something is leaking memory. The fact that you have pages not being accessed by any applications growing, and swap growing too suggests something is allocating memory, forgetting about it then not freeing it afterwards. Memory could be 'inactive', for example if malloc() is called. This is a libc call that may allocate a chunk of memory, but only a portion of it is actually utilized to do any work (less than the number of pages allocated anyway). Even if you free in malloc it doesnt actually mean you free the memory by asking the operating system to do so, its just mallocs tables might mark is as 'reusable', it might free it after. 

Some of the characters in your command are shell meta-characters. You are effectively starting one task in the background. You need to quote your command. I've re-ordered the command since its a big ugly. 

This works as an event based mechanism. I've not ran it for long periods so wont guarantee its stability. This uses a very recent system call API called fanotify. Probably need a 2.6.37 kernel or greater to run it (so EL5 is out of the question, for example). If you get complaints it wont compile, its probably too old a kernel. It compiles with: 

There is a explicit named rule. There is a explicit non-named rule. Inherit the same context as the parent directory. Apply the . 

Is the post labelling policy. What you discuss in your problem actually relates to the runtime policy. When a entry is created in a directory using SELinux the rules governing what label the file or directory ends up being are not dictated by the regular expressions you quote but other rules as follows (I believe this is the correct order but might have missed something). 

Load is an aggregate value of tasks with processing work left to run. It is a measure of the remainder of processing left to do after each process has been given a fair time slice of CPU. Effectively it puts a number on how well the system is dealing with competition of resources between processes. IOWait can also increase load if processes are causing large IO usage which would point to a memory problem (using far too much of it and aggressively swapping) or an underlying I/O problem. If its just one process that uses up loads of I/O it would be punished usually anyway without too much affecting other processes. I dont think you can just simply kill one process to fix a problem like this as the problem stems from a few processes demands on the CPU. You could kill a process group or a thread pool for one particular process though. 

With KVM/libvirt you can run on the host VM, it exports the UUID generated in libvirt from the XML description. It should be unique to each VM. 

You should be able to test that this is the case by setting up your own VM in KVM setting available to 6GiB, current to 1GiB and running your test using the same kernel to see if this behaviour you see above occurs. If it does, change the 'available' setting to equal the 1GiB current and repeat the test. I'm making a bunch of educated guesses here and reading inbetween the lines somewhat to come up with this answer, but what I'm saying seems to fit the facts outlined already. I suggest testing my hypothesis and letting us all know the outcome. 

This creates a 100mbit class, 50mbit of which is in the default class (but can burst up to 100mbit) whilst the other class permits a realtime requirement so that 1500 byte packets must leave the queue within 50ms, the maximum rate of this class is 10mbit at all times. Finally we added a leaf qdisc onto that class which actually delays packets leaving the queue by 150ms. Traffic into the realtime class is selected on the basis of it having a source port 22 attribute (so all ssh traffic). 

In this example, the rule states that. If the process/user performing the file creation is and the directory the object is being created in is and the object is classified as a , then the new file must be labelled as . This, of course has a number of limitations, a good example of this is the condition when you create .htaccess files in apache (in /var/www/html). In this example the default policy of creating a file type with the same type as its parent directory applies, but in reality the proper type of this file is not the default of . This was a known problem for a number of years and was eventually fixed by allowing policy writers to specify the filename that the transition applies to in policy -- unfortunately this features is not available in EL6. In your specific case -- as you have mentioned there are some workarounds involving restorecond. Other than this you should ideally split your data up with different types by putting them in separate subdirectories where the subdirectory is an adequately labelled type. If this is still not possible, and restorecond is not possible -- the only solution is a post-fix of running restorecon on the file after its creation. Even the 'newer' named filetrans has problems because ultimately it does not support globbing or regex, which severely limits its functionality to specifically well-named files (like .htaccess). As it stands at this moment, there exists no in-kernel mechanism as flexible as and its regexes to properly label files correctly to that degree. 

For the case of performance optimization, limiting CPU resources or usage is never a good idea -- you'll only make performance worse. You only want to restrict CPU resources or CPUs that can be used where you are deliberately attempting to cripple the process. Times where you might want to cripple a process would be: 

We can also check that the rule that is being hit in policy will not get hit in (which it shouldn't). 

This will set the hostid in a manner for which gethostid will return the same value as the donating box as the migrating box. 

The -F defines the filters and the -S defines the syscalls, the more filters the less intensive it is on the kernel to track it. So in this case I filter on the user (apache), the vhosts directory and arch. Arch becomes important b64 being 64 bit b32 for 32 bit. You can set these up long-term by putting the rules in /etc/audit.rules.