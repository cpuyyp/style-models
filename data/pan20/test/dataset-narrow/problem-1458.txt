tl;dr: Value student work and universal communication over content. I'm going to add a second answer to discuss a somewhat broader context. I was a pioneer in hybrid courses: partly online and partly face to face. One model was monthly face to face meetings of several hours with most work done remotely. The model assumed round-the-clock work (students lived in many time zones and had different work schedules) and so the possibility of anytime contact had to be maintained. All work in the course was team work with teams of 4-5 students in a class of about 20. The individual teams also found it difficult to meet face-to-face (FTF) other than during the lunch period of the monthly FTF meet up. During the FTF we (the two co-instructors) were careful to do only those things that required group interaction, so there was no lecturing. Educational games were important to us. You can teach software process through games, it turns out, producing a non-software product instead. Content of the course could be read by students from books and online material, some from the instructors and some otherwise. The core of the course was a large iterative project done by each team. Sometimes the teams worked on the same thing and sometimes they each worked on different aspects of the (software) project. The students were expected to do all of their work between FTF sessions, so communication was all important. The two main tools we used were a wiki, which any student or faculty member could edit, and a mailing list to which everyone was subscribed. The faculty could put up wiki pages (as could students) to point everyone to content, etc. The mailing list guaranteed that any question asked by anyone was seen by all as were all answers. It was a "full information" situation. Private messages to faculty were discouraged for anything other than personal issues such as grading. The individual teams sometimes used Skype for coordination and planning, but could also use the mailing list or wiki for that. While we didn't use it much, a chat-server can also be useful for real-time conversations. This can be advantageous over Skype in certain populations - our students were older so hearing may be an issue. One issue is that not all students may be available for a real-time conversation (here email works better), but if an entire conversation thread can be captured and then posted to either the wiki or to the mailing list the downside is minimized a bit. A chat server is more useful to a small working group as the numbers are smaller so it is more likely everyone can get involved and the conversation thread is less chaotic. The underlying philosophy of the course was that the important things were student work and universal communication. Content was much less important than those two. Content is available everywhere on nearly everything. It isn't content that makes the course. I found the same tools and philosophy useful in other hybrid courses that weren't quite as intense as the one described above. 

Note that one advantage of e-books is that some of them at least are updated with corrected versions and new editions. Some of these are at no cost, I've noticed. That is an advantage you don't get with paper. On the other hand, I still have, and occasionally reference, important books I used as an undergraduate in the 1960s. I also have some of my hand written notes from then and through graduate school. I haven't had to worry about obsolescence of format or device. Some of those books are classics that went out of print and the replacements are not of the same caliber. You should note that the paper text books you get from established publishers in technical fields will probably only be published for a few years. Text book publishers value the new over the old. If that happens to e-books then you become especially dependent on the devices you now own, but which you will likely want to replace in a few years. It isn't especially costly for a publisher to continue to make old e-books available, but they need to take the trouble to do so - as well as the trouble to update formats as they change. 

I'm going to offer an answer that is orthogonal to your question by looking at a deeper question. The "work-flow" you seek may actually be irrelevant to the problem of (a) being effective with your students and (b) being efficient with your own time and effort. Hopefully, the answer here will be valuable to others who don't have quite the same context that you do. I'll focus on the small number of students and the long daily sessions, primarily. The answer will be less valuable for larger groups and/or shorter sessions, but some of it might be adapted. tl;dr: Keep continuously aware of their progress, day to day, with short conferences. Restrict your evaluation to the most important issues as they evolve. With only a few students and long sessions, there is really little reason to have to look at everything in detail, captured by GIT, or otherwise. This is one situation in which printouts sounds like a terrible idea also, though that is often the most efficient method of looking at student production. You can both reduce your work and be more effective if you require some sort of teamwork, such as pairing. If you only have five projects to keep straight it is much easier than ten. You can, in long sessions, set aside say one hour in which each team consults with you for a few minutes on their current work and issues. They show you their current product and you give them advice. But if they are pairing, they will need less advice. One concern you likely have is honesty. Looking at each student's (team's) work for a few minutes each day (or so) lessens the likelihood that you won't notice bad behavior. One thing that will help you keep track of the students and keep them on track as well is to keep a running record of their progress. A Hipster PDA (discussed elsewhere on this site) is one way. A spread sheet is another. Decide before the course starts which low-level results/behaviors/activities are to be encouraged and valued and keep a record of these for each team, each day. A check mark is all that is needed for many things, though occasionally a written note (to them and/or to yourself) might be valuable. It is a continuing and cumulative process, not an all-or nothing evaluation at the end. If students work in teams you can also keep yourself aware of each student's contributions to the team simply by listening to how they interact when you confer with the team. A quick notation on an index card captures your impressions for re-confirmation later. If you need to give advice on code quality you don't need to look at it all at once, but can look at fragments (one class, one method) in a review and get a sense about whether they have it right or not. You won't catch every flaw, but you aren't guaranteed to catch everything in an overall review either. If several teams are going wrong in the same way you can alter your "lectures" to guide them back. If a single team/student is off the rails you can focus your efforts there, instead. None of this requires that you capture everything in a repository or even that you comprehensively review their work. If design is one of your goals, you can focus your daily review on that, warning them the day before that you need to see designs, either on paper or otherwise. Even if you don't want the students to work in pairs/teams, you can still use a different form of teamwork. You can, for example, set up a rotating peer review system in which each student briefly confers with another on each student's work. Each can give advice to the other. I suggest that the advice be written, say on index cards, with both student's names listed as well as the questions/advice/etc. You can quickly review these cards and can give credit to both the one receiving the advice (for responding appropriately) and the one giving it (for being a good colleague). You can use this instead of conferring with the students/groups yourself on some or all days. Students can teach each other and will if you give them the opportunity and encourage good behavior. 

Perhaps the place to start is with a discussion of variables and making the distinction between a "thing" and a "name for the thing." A pretty good place to start that conversation is with the a poem from Through The Looking Glass, the sequel to Lewis Carroll's Alice in Wonderland. 

My clear preference is to start in a high level language and introduce low level concepts (1) as needed, and (2) later in the curriculum. This is in spite of the fact that over my long (45+ year) career, I worked in low level languages early on as that is the historical development. I also struggled each time I had to "up my game" as the path from low level thinking to high level thinking isn't necessarily clear or easy. A stone age human, while fully human and having the same mental capacity as modern humans (which they were), and probably an expert (if male, anyway) in creating stone tools, would have a terrible time trying to understand a socket wrench, though a hammer might be easy enough. However, I don't believe that my students should recapitulate my experience as much of what I learned is now actually obsolete. Flow Charts for example, though some will disagree. But the real reason for starting in a higher level language is that I'm trying to teach students to think not to code. Higher level languages provide higher level concepts (duh), so provide a more amenable environment for teaching thinking. I also want students to be able to build modern software, not the kind of thing I built before 1980. They need practice at that. A lot of practice. Modern software builds big things out of small things. The things inter-operate in complex ways, but if I try to build complex things out of complex parts I wind up with a mess. Build big and complex things out of small and simple things. Both object-oriented programming and functional programming emphasize this. A Scheme function returns a single thing, ideally without side effects. Java classes, if well designed represent simple compositions of still simpler things. Of course it is possible to misuse such languages, writing thousand line Scheme functions or hundred method Java classes. Of course, it is possible to use C as a higher level language, though most programmers don't. A C program could consist of a thousand 4 line programs and be much better than a four thousand line monstrosity that is impossible to understand. Part of the problem is that C was invented at a time at which "subroutines" were rarely used, and only for those things that people thought would be reused. Actually people learned long ago that reuse is a false deity. Don't worship it. Even in the Algol days it was understood that decomposition into parts was for simplifying the understanding of a problem. High level languages are intended to put a premium on this way of thinking. If you teach them to think, they will be able to code. 

As Guy Coder says, Prolog doesn't help a lot with employment. But it goes a bit farther than that. As educators we normally teach students in CS how to build things. Logic Programming languages such as Prolog have other strengths, but building systems isn't their main goal. It therefore doesn't well support the courses that follow in most of the curriculum. Logic Programming can be extremely important in some fields, such as (duh) Logic and also in AI, but not, generally speaking, in building information systems. Actually, Logic Programming isn't the only useful tool that is seldom used as a first language. A CS curriculum isn't likely to treat SQL as a first programming language either, as useful (and powerful) as it is. The main thing about these languages is that they focus on the answers themselves, not the algorithms used to find the answers. They are about the what rather than the how. In CS, we build things and so the focus is mainly on the how, especially at the start. Later on, such descriptive or declarative language can be extremely useful and there are courses that go into how they work internally, but implementing those algorithms isn't something the typical programmer often does. In the future, this may change, but I think we are many years away from having systems so powerful that we can just, in general, describe what we want and have the system figure out how to achieve it. It is a long term goal, of course. Just so long as Skynet doesn't come along first. 

Each "shell" is now a block. Each shell tries to do something that might fail. Each shell ends with a label. Each "goto" is essentially a return from the shell, as was noted by the OP and I also noticed. Each shell is immediately followed by cleanup from that shell. This is a special case, actually, since here the cleanup needs to be done both on success and failure of the overall code. If the cleanup were only needed on failure, the innermost shell could do an immediate return after success is achieved, though goto out here is equivalent as there is no code following that label. If you think about the code, while it doesn't use "helper" functions, in effect what it is is a bunch of helper functions expanded in place (inlined) rather than called explicitly. The lexical structure replaces arguments. This sort of thing (inlining) is often used for efficiency (and making Torvalds happy, I guess). But in most coding efficiency is the last thing you need to consider (after writing clearer code and then running a profiler to see where efficiency suffers). Kernel code in an OS is an obvious exception, of course. It is also important to note that each shell cleans up after itself. So both allocation and the needed deallocation take place within the same shell. Similarly for the file handling. Moreover, if you are going to code this way you need to be absolutely pure in your implementation of it. It is fine to add a new shell, inner to another as long as you keep the same discipline. You don't need to create the extra blocks as I've done here, but you do need to write as if they exist. If you use additional goto statements to jump between the shells/blocks you will have a mess. Also, if you treat the goto statements as "returns" from the shell, then the idea of "returning as soon as you can" is still in place. Here, you "return" when you notice a failure (say of malloc). But you also "return" at the end of the shell by falling through to the outer shell.