Consider that hamiltonian cycles of the bipartite graph are isomorphic (that is we can always permute the rows amongst themselves and the columns similarly to reach any other hamiltonian cycle). Consider the planes given by $(x,-,-)$ and $(-,y,-)$. Permuting these planes is exactly the same as permuting the rows and columns of the $(-,-,z)$ planes. Thus we may permute in this way to get any of the hamiltonian cycles on one of the $(-,-,z)$ planes, giving us $n!(n-1)!/2$ unique xyz-graphs. Further, we may then permute the (-,-,z) plane, fixing only the one we specifically permuted before, each of which also must give a unique xyz-graph. Thus in total we have: $H(n) \geq \frac{n!(n-1)!^2}{2}$ Which implies the bound $C(n) \geq \frac{1}{2}\sum\limits_{i=2}^n \frac{(n)_i^3}{i^2}\\$. EDIT: In fact, we can do better. We have only considered sub cubes here, but we may also consider xyz graphs inside ([n],[n],[m]). Since all simple cycles are hamiltonian on $K_{n,n}$, we take $m \leq n$ to avoid double counting. Then using the same construction for our first cycle and then the same permutation process above we get: $H(n,m) \geq \frac{n!(n-1)(m-1)!}{2}$ and then $C(n) \geq \frac{1}{2}\left (\sum\limits_{i,j=2 \ | \ i \geq j}^n \frac{(n)_i^2(n)_j}{ij} \right )$. 

Consider a function $F: \mathbb{F}_2^d \to \mathbb{Z}^n = (f_1,\ldots,f_n)$ with the property that if $y \in \mathbb{F}_2^d$ is a rotation of $x \in \mathbb{F}_2^d$, i.e. $y$ is $x$ permuted by an element of the cyclic group generated by $(1 \ 2 \ldots d)$, then F(x)=F(y), and the additional constraint that $f_i$ is of the form $ f_i(x) = \sum\limits_{j=1}^d \alpha_jx_j $. There are obvious examples of such functions, for instance $F(x) = \sum\limits_{1}^d x_i$. For any $x \in \mathbb{F}_2^d$ and $\pi \in S_d$, $F(x)=F(\pi x)$. We say that such a function is fixed under $S_d$. However, as you might expect from my initial explanation, I am interested in such a function which is fixed strictly under rotations, that is for any permutation $\pi$ which is not a rotation, then $F(x) \neq F(\pi x)$, or at least fixed under rotations and not fixed under all of $S_d$. Do such functions exist? I am having difficulty finding any example which is not the one I gave above. 

I am attempting to find a complexity for computing the order polynomial of partially ordered sets on a special family, and have come across the following problem. Assume we have the following values from a polynomial: $P(0)...P(n-k)=0$ and $P(n-k+1)...P(n)=y_{n-k+1}...y_n$: what is the complexity of polynomial interpolation in this environment? Looking at the Lagrange polynomials, the first n+1-k become 0, and the k last follow a simple form: $L_i = \frac{\Gamma(x+1)\Gamma(i-n)y_i}{\Gamma(x-n)\Gamma(i+1)(x-i)}$ This suggests to me the coefficients for each x should have some nice form. However I'm a bit lost at this point as to the complexity of computing the $L_i$ (which we need k of), perhaps there is a better method? 

The problem of giving an explicit formula for $A_q(n,d)$ is sometimes referred to as "the main problem in coding theory." The value of $A_q(n,d)$ is given by the maximum number of codewords in a q-ary code of length $n$ and distance $d$. More specifically, let the hamming weight of an element of $\mathbb{F}_q^n$ be its $l_0$-pseudonorm, the number of non-zero components, and the hamming distance between two elements $f,g$ the weight of their difference $d(f,g)$. Then $A_q(n,d)$ is the largest set $S \subset F_q^n$ s.t. for two elements $f,g \in S$, $d(f,g)\geq d$. There are a number of famous upper bounds on $A_q(n,d)$, including Hamming's sphere packing bound. The best are given by a linear programming approach (now improved to a semi-definite programming approach) given by Delsarte in the late 70s. I have recently been searching for an explicit formula for Delsarte's Linear Programming Upper Bound for $A_q(n,3)$ in the literature, which correspond to single error correcting codes, and have not had much luck for non-binary codes. For binary codes this appears to be well known, and shown as early as 1977 by Best and Brouwer. Non-binary codes seem to be a completely different story. There is a paper called "Some upper bounds for codes derived from Delsartes inequalities for Hamming schemes" by C. Roos and C. de Vroedt, which the authors claim deals with the q-ary case, but I have not been able to find a copy. There appears to have been a very large amount of work in this field so I would be shocked if no such formula exists (well, at least a formula for some special cases of n,q). Is there a body of work in this area I am missing? Do such formulae exist? Note: I have also posted this question to MO, since I think $A_q(n,d)$ has received significant attention from both communities. The link is: $URL$ 

Your statement is a little ambiguous: first you write that "...such that no edge is incident between the nodes in $R$", but the next paragraph implies that there are also no edges between vertices in $A$. I'll also assume that the stars are disjoint, and that you count all edges (including those initially present in the stars). Let's also assume there are at least two stars, and at least one of them has degree $\ge 2$. In that case, you cannot beat the $2N-4$ bound ($N$ = number of all vertices). Consider a slightly different scenario: start with any set of $N$ vertices, some red some black, at least two of each kind. At each step add arbitrarily an edge between a red and a black vertex, as long as it does not create intersections or duplicate edges. I claim that when you get stuck, all cycles have length $4$. Your scenario is a special case of this process where you start by first creating stars and then later adding the remaining edges. If all cycles have length $4$, the $2N-4$ bound follows. More generally, it shows that no matter what bipartite graph you start from, you can always complete it to a quadrilaterated (a word I made it up) graph. Now, let's show the claim. In this process, all paths will have alternating black and red vertices and each cycle will have length at least $4$. If the graph is not connected, you can connect any red vertex on the outer face of one component with a black vertex on the other face of another component. So we can assume the graph is already connected. Suppose you have a face $F$ of length $6$ or more. $F$ must have at least three black vertices (some possibly equal). If some vertex $x$ is repeated on $F$, take two clockwise consecutive appearances of $x$, say $x-a-...-x-b...$. $F$ must contain a black vertex $z\neq x$, so, depending on the location of $z$, we could connect either $a$ or $b$ to $z$ inside $F$ without duplicating edges. If no vertex is repeated, pick a clockwise section $x-a-y-b-z$ of $F$, where $x,y,z$ are black and $a,b$ are red. If $x$ is connected to $b$ then $a$ cannot be connected to $z$ (by planarity), so we can add one of the edges $(x,b)$, $(a,z)$ inside $F$. 

Perhaps I don't understand the question, but the way I interpret it, Colin's answer seems correct. It is enough to find the minimum possible k for which such partition exists, say k_0. (This is a partition with maximum number of K_21's.) There is a partition for any k between k_0 and 3n/2, because splitting K_21 into two K_11's increases the sum of cardinalities by 1. The K_21's in your partition induce a matching in the line graph of G, so this k_0 corresponds to the maximum matching in the line graph, and this matching can be found in polynomial time. 

Transform G into a weighted flow network N: connect the source s to all nodes in A by arcs of capacity n/2 and cost 0, connect all nodes in B to the sink t by arcs of capacity n/2 and cost 0, and connect each A-node u to each B-node v by an arc of capacity 1, with cost -1 if (u,v) is in G and 1 otherwise. The maximum flow in N is n^2/2. Its cost can be written as -|E|+d, for some d >= 0. This d is the minimum edit cost of transforming G into a balanced n/2-regular bipartite graph with partition A,B. 

Your Statement I is not true. You can have two non-isomorphic graphs G1, G2 with T(G1), T(G2) isomorphic. Basically, the problem is that there is no reason why isomorphisms between T(G) graphs should map vertex-cycles into vertex-cycles. 

Here is another example: Given a cubic graph G and a hamiltonian cycle H in G, find a different hamiltonian cycle in G. Such a cycle exists (by Smith's theorem) but, as far as I know, it is open whether it can be computed in polynomial time. 

This is just a very long comment to Joe Babel answer above. As said above Church invented $\lambda$-calculus to approach the Entscheidungsproblem (i.e. the decision problem for first-order logic) which asked whether it was possible to provide an effective (i.e. computable) method that for a given input formula can either prove or disprove the formula. In order to solve this problem it was necessary to define what computable means: Church gave a definition in term of computable functions which are called $\lambda$-terms. I guess that this choice was motivated by the intuitive notion of computation that they have at time: a computation as a process which takes some input and return some output, which is exactly the concept of function. 

In my understanding, algebraic data types are basically types whose terms arise as the terms freely constructed by an algebraic specification: the operations of this specification being the term-constructors. From this point of view it seems to me that the only possible structures you can represent with algebraic data types are only the free ones, that is those algebraic structures where no axiom is required: for instance magmas. Observe that the fact you can represent free-monoids (that is monoids of strings/lists) has algebraic data types comes from the fact that lists are ADTs for the algebraic specification with a $0$-ary operation (namely $\text{Nil}$ or $[]$) and a binary operation, $cons$ or $(:)$). Untill you work constrained in the setting of simply types you cannot add constraints (that is equations) in your data-types, hence you cannot represent more general algebraic structures. A possible way to solve this problem is to use dependent type systems with an identity type: in these type systems you can represent algebraic structures because equations(constraints) becomes terms (they are the same as programs). Hope this helps. 

The kind of approach to theory of computation you describe is what I like to call an abstract machine based computability theory: i.e. a theory that define computable functions/languages/etc via some abstract kind of machine (automata, linear automata, Turing machine etc). An approach that uses $\lambda$-calculus instead of Turing machines could be thought as an expressions based computability theory: i.e. a theory where one prescribe some basic operations which are intuitively calculable and some operators defined between them to build other computable operations. In this expression based computability theory 

I think I understand your difficulties, indeed if you consider just a programming language both a denotational semantics and a term transformation (into another language) are nothing but mappings of syntactic elements of the given language in mathematical objects (elements of a domain in the first case, terms of the language in the second case). Notheless differences between these two semantics start to arise if you put an operational semantics in your programming language and so you want that the denotational semantics and term transformations are compatible with this operational semantic. In the first case you would like that denotation of terms/programs that compute the same results have the same denotation, hence the denotational semantics should associates to operational convertible terms the same denotation. In the second case you would simply like that the term transformation maps terms/programs in such a way to preserve the derivations (if you reguard terms and reduction/derivations respectively as objects and morphisms of a category you can say that a term transformation should be a functor). In the first case we lost information about the reduction between terms in the second case we preserve it. In the first case semantically equivalent terms are mapped in the same denotation in the second they are mapped just in operationally equivalent terms but the term translation does not guaratee that equivalent terms are mapped in the same term (and usually that's not the case). Denotational semantics allows to easily find different terms, supposing that the denotation-mapping is easily computable, in order to distinguish two programs we just need to compute the denotation an see if they are different values. Nonetheless in this way we lost information about the reductions (computations of our operational semantics) which are instead preserved by the term transformations. I hope this helps.