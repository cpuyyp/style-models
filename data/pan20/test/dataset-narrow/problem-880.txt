Next, I attached script to OU Group policy and voila! I wrote Instructions for users, and still helping some to finish setting up the profile. Still much easier as manually configuring all clients. Anyway, the following site was crucial for my breakthru, so it deserves to be linked here: Pay them a visit Thanks to Matthew, his post pointed me in right direction. 

Further comments: The larger company is planning to implement seconnd solution internally for accountants and other "office" PCs. The infrastructure isn't there yet, but people with experience in this area will work on it. The smaller company would then also have about a third of its computers virtualized and put up on terminal server. 

I have a standalone Win 2003 server with Windows Sharepoint Services (WSS3) running on it. I had to rename the server and I had bunch of problems resulting from this. Note that the server is not in AD environment. I fixed the problems with Sharepoint (directly related to a rename) by using steps 1 & 3 from this site (TNX) Nevertheless, there are still strange references to old server name all over the place: in registry, in Windows Internal database, in Sharepoint Central Administration... Most disturbing problem is that Sharepoint isn't able to send email notifications to participants. This is IMO due to the fact, that Simple Mail Transfer Protocol service is still "answering" with old server name. When I try to telnet locally to the mail server (SMTP), I get a response: 

Following an acquisition we are switching from our local Exchange to an outside provider. I need to change account settings / create new profile so that users are able to access their new mailbox, and I hate the idea of doing it manually on every single client. I have tried quick and dirty solution with copying profile information from Registry on one computer to the other, hoping that I could fix user info later. Quite obviously, this didn't work: Outlook recognized the profile, I could select it at the application startup, but there the fun ends - the profile was corrupt. I couldn't change settings in Mail settings on Control panel, either. Didn't find any Group policy solution. Is there any application, script or other solution, that would help me save time commuting from one PC to the other and typing the same info over and over again? 

In this case you can play with and in SunOS . But best to block those attempts even before reaching with Solaris . Here you can find pretty often updated list of IPs to block: OpenBL I see attempts very rarely in logs, just using this blacklist. Then you can assemble cron job script to update FW rules or optionally there's formatted file available. 

option - when you want to stay with FreeBSD, check FreeNAS to automate complexity you are afraid of. option - NexentaStor, it is Solaris based storage appliance SW with great management web gui. Up to 18TB setup is for free. Again there you can easily manage complex vs. a lot of datasets configuration. 

It will inherit netmask from global zone interface. Of course you can setup more interfaces, or put zone only on 'internal' interface (no public IP) and the let provide . 

May be your old mirror set was a hardware one, not the ZFS. Depends on your HW. Check partitions table with if something is there. ZFS can reconstruct its pools no matter what order are disks placed in. 

Try to import that certificate to some NSS store. For example to Firefox, which is using NSS. It's other implementation of SSL (in fact the 1st one) and you can see attributes of certificate... of course if you succeed with import. Otherwise you got some wrong certificate. 

Try to precompile Ruby files to Java classes for WAR file. It is done during WAR deployment nevertheless, so for why it take a lot of time... especially on SPARC machines. Offload compilation files from server to your development machine. 

So you have to calculate values for those param to mimic behaviour you get by setting 4 params to Solaris net stack. Btw check in Linux. 

Use , but also add per every network you want to route through VPN. Btw note that DNS setting on other interfaces will stop work, when that interface will not have route to its DNS servers. This is what happens when drops default gateway from your (W)LAN interface and adds host route to VPN server IP through original GW. Depends on your setup, may be there is no working setup and you'll have to change DNS naming to include some subdomain for internal networks. 

Note that adding interface to bridge, sets promisc flag appropriately. Bridge interface need not to be in promisc mode. I got the same setup running, but on OpenSUSE, TAP interfaces are created during startup and OpenVPN just opens them - no start/stop script in OpenVPN. 

we used to have Exchange on the SBS 2003 server inside our AD environment. Earlier this year we moved to outside Exchange provider but for the time being our local Exchange was still up&running and forwarding email to the new email accounts. Now the time has come to turn it off and I'm not quite sure what that means for SBS environment and how to proceed. Specifically, there is a local e-mail account associated with every user in the domain. Can I simply change the e-mail address of every user to their outside address, or should I first delete the Exchange account for every user + their Mailbox, and only then update the e-mail address? What do you suggest? How do I proceed? TNX! 

I imagine that since actual server name and apparent email domain are different, sending mail is somehow considered open relay and actual message goes to void. Anyway, does anyone have an idea, how to fix discrepancies with name or how to fix SMTP server name? TNX! 

Well, I found the solution that works perfectly. It uses a simple Logon script, so Avery Payne, one might say you were at least partially right :) Outlook (2003 and later, don't know about earlier versions) allows importing the profile info through PRF file. It is a plain text file, so you can write it from scratch, or preferably - export it from existing profile and edit as needed. I used the second variant. I downloaded Office Resource Kit - I was exporting PRF file from 2003 version, so I downloaded Outlook 2003 version (ORK.EXE, download it here). Installed it and got the Custom Installation Wizard, which enables you to export existing profile to PRF file. Needless to say, you first need to configure a working profile on the PC you're exporting from. After successful export, I edited the PRF file to lose unnecessary stuff and to generalize some settings with Windows variables, so that I get user specific info after the PRF file is imported: 

I also wanted to be sure that default user profiles won't get overwritten, so I changed corresponding settings to match: 

SITUATION: A larger company acquires a smaller one. IT infrastructure has to be merged. There are no immediate plans to change the current size or role of the smaller company - the offices and production remain. It has a Win 2003 SBS domain server, Win 2000 file server, linux server for SVN and internal Wikipedia, 2 or 3 production machines, LTO backup solution. The servers are approx. 5 years old. Cisco network equippment (switches, wireless, ASA). Mail solution is a hosted Exchange. There are approx. 35 desktops and laptops in the company. IT infrastructure unification: There are 2 IT merging proposals. 1.) Replacing old servers, installing Win Server 2008 domain controller, and setting up either subdomain or domain trust to a larger company. File server and other servers remain local and synchronization should be set up to a centralized location in larger company. Similary with the backup - it remains local and if needed it should be replicated to a centralized location. Licensing is managed by smaller company. 2.) All servers are moved to a centralized location in larger company. As many desktop machines as possible are replaced by thin clients. The actual machines are virtualized and hosted by Terminal server at the same central location. Citrix solutions will be used. Only router and site-2-site VPN connection remain at the smaller company. Backup internet line to insure near 100% availability is needed. Licensing is mainly managed by larger company. Only specialized software for PCs that will not be virtualized is managed by smaller company. I'd like to ask you to discuss both solutions a bit. In your opinion, which is better from the operational point of view? Which is more reliable, cheaper in the long run? Easier to manage from the system administrator's point of view? Easier on the budget and easier to maintain from IT department's point of view? Does anybody have any experience with the second option and how does it perform in production environment? Pros and cons of both? Your input will be of great significance to me. Thank you very much! 

Note that x86 can get some accel for SSL from CPU. You can get listing of accelerators by running . Even kernel software provider has some optimizations. Those providers are the same ones running KSSL. To measure the difference run following for example: 

If you have speedy lines between sites you want to mirror, I can imagine something like you export iSCSI volumes from sites storages and put them mirror and add some local disks for ARC, ZIL, cache to lower read/write peaks running over iSCSI. If your storage is mainly for backups, then it would be OK. Nevertheless SUN once had such product behaving like that on ZFS. 

Is there any way to get network configuration of iLOM in Solaris SPARC? I want to get the IP address of iLOM console at least. It's pretty easy on x86 by , but for SPARC I can't find something that do the same. I found some mentions about and , but those are not available for systems with iLOM. 

I think it is more probably a DNS issue than GSSAPI. likes prompt DNS responses to work promptly during connection phase... cause of logging and access checks. 

Zabbix, when compiled with CURL support, can directly monitor web services including complex more steps scenarios. You can setup triggers on HTTP return code, returned data, response time... Documentation here. 

For this case is better choice. It is Solais derivate, that runs completely from USB stick and local disks zpool just store your data, nothing from OS. Upgrades are way you just copy new image to USB stick. is primary a hypervisor, but all other features are there too + relatively fresh prebuilt packages repo available. >SmartOS< Btw when you want full featured storage appliance and no problem for you to install appliance SW on disks, then is definitely your choice. Comparable with FreeNAS... but much more features. You can even make fiber channel storage device from your old PC... just click out on web GUI. >NexentaStor< 

Zone virtual interface has some features limited... some states can't be setup, packet filter doesn't work in zone too. If I remember right, zone interface can't send ethernet broadcasts, so then no DHCP. Btw why you doing that bloat about setting up zone interface? What about this? 

Configure status plugin and install collectd to collect system performance data. It's a very lightweight daemon in means of system resources it needs. There's plugin for nginx monitoring: Plugin:nginx and of course can monitor whole other system performance data. As far as is just collector of performance data (stores it in RRD DBs), a tool for displaying data is required. I'm pretty comfortable with CGP... git version is OK. is a PHP app thus it will eat you CPU just only when you will look at graphs. Example graph: Nginx_connections_and_requests.png Btw Amazon EC was always significantly slower than others and most notably for storage. That could be root of higher load. 

I would your suggestions for an effective solution for a person, who needs to access resources in two Windows domains and wants to use one computer. It's about our CEO, who has accepted a second position in another company. Accessing files and folders isn't big problem. The greatest challenge I see is that he wants to conveniently access Exchange accounts in both companies; he would like to send and receive mail in single Outlook if possible (two profiles?) There is also a challenge with calendars: he would like to have one calendar for all activities from both Exchange accounts. Creating a POP3 account for accessing second Exchange server is a last resort, because obviously there is a problem with scheduling meetings and other calendar related tasks. Forwarding and receiving all mail/tasks on primary Exchange server is inconvenient because simple replying to original sender is disabled; and also when manually changing the recepient, he will receive mail from the wrong address. We were considering Virtualisation, that is setting up an instance of virtual machine inside existing installation and then joining this virtual computer to a second domain. Then installing another MS Outlook. This would of course mean two different Outlook accounts, two different calendars, but would at least enable our CEO to access all information from a single laptop. Does anyone have any other idea? I know setting up two domains on a single computer is a no-go (without much hacking at least), but effective workarounds are appreciate. The thing I am looking here is high usage/efficiency/productivity, but also as elegant solution from the administration point of view. Thank you very much (if you managed to read this through, this is a good sign ^_^ ) 

If it is possible you could try moving WinSXS to another partition as a workaround. To my knowledge there isn't any way to get rid of the contents of WinSXS. This cute little thingy is in the heart of Vista/Win2008 operation, so... I haven't heard anything better as moving it to another partition. Here's a link to a blog describing how to do it: Click I would suggest you do a full backup (even better: an image) of your entire C: partition before trying the procedure. Mind you that I tried this only on Vista, not on Win2008 Server. 

I have a user in a domain who has access to multiple subfolders in multiple folders. His rights were defined pretty granularly. Now he's leaving the company but will continue to work for a firm as a contracted resource. I need to find all folders he had access to and revoke his permissions, then set him up with a different set of access permissions. Is there any tool (freeware, preferably) that lists all NTFS permissions for a given user? I've tried with AccessEnum from Sysinternals, but the list cannot be filtered by username and is useless for me. I've looked at CACLS, too, but as far as I can tell it displays permissions ordered by file, not by user. Any ideas? 

First one is pure software and second one is kernel accelerated provider accesible as PKCS11 token. Exactly those two on my old T1 Niagara are doing 8.4 sign/s versus 19740.0 sign/s. That's for sure huge difference. Modern x86 CPUs can accelerate AES for example and as far as I know it is used in software kernel provider. Check yourself what's the difference. More important is to have speedy asymmetric ciphers, because they are used during establishing a connection and are more CPU hungry... web applications close connection often. Btw KSSL is in fact just in kernel SSL encrypting proxy... a fact it happens in kernel contribute to speed too. Just to compare... on another machine, ~ same age as T1 noted above, but x86 in VMware is doing for me 42.1 signs/s versus 98.6 signs/s for rsa2048. So more than doubled speed. 

The most likely you forgot to enable forwarding. Add to , then or restart. Also try to add following to OpenVPN config: 

I got many DMA errors on drives, when air condition issue in datacenter and ZFS was able to fix that mess. And it was just simple mirror. I do remember promo video issued by SUN when they introduced ZFS... they made RAIDZ on USB flash drives deployed to 8 port USB hub and then randomly changed position in hub for few of them while doing IO on that pool observing no outage. 

Every chunk of data has fair checksum on ZFS. So ZFS know which drive holds correct data in redundant setup when failure. Running will repair data or spread data to all running drives for RADZ. ZFS employs Reed-Solomon's error correction which is best for bursts of errors. Missing drive is such burst of errors, which R-S can correct. 

Note that means command has to start in user login shell loading user environment too. In case that login shell is something like for security reasons, there should be a problem. Try to change to and potentially do fine settings in for that command. 

I'm running small Ubuntu devel virtual on VMware Fusion. 4GB disk and 512MB RAM is enough for development. Network of VM is in NAT mode, so I can access it even when not on Internet. I also configured AFPd so I can edit files directly mounting share. As far as I'm doing Django only that way setup is as following... Django app running under some user account I created, that user homedir is also a root (loaded on login), I use that user to login to AFP. When new project I just clone template machine and create new user account + . Installing to VMware Ubuntu chooses kernel that holds main virtualisation abilities... thus XEN, KVM, VMware. Deploymnet should then be DevOps way... just copying VM files to cloud and starting it online (maybe conversion of disk file or its growing to production size).