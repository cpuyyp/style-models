Indeed, this results from the van Kampen-Flores obstruction. This is explained in remarkable detail and clarity in Matousek's book Using the Borsuk Ulam Theorem. 

The answer is no. There are actually 3 different notions of embeddability: with straight, piecewise-linear and continuous (hyper)-edges. In the plane, they all coincide, but in general they do not. Regarding straight-line embeddings, a first counter-example is due to Brehm Brehm, U. (1983). A nonpolyhedral triangulated Möbius strip. Proc. Amer. Math. Soc., 89(3), 519–522. doi:10.2307/2045508 and several examples have followed using results from matroid theory. About the difference between PL and topological embeddings, this results from the general counter-examples arising from the Hauptvermutung: In dimensions 5 and more, there exist topological spheres which do not admit any piecewise-linear structure 

Since you're only comparing the lengths of the paths (and in the meantime forgetting what pair of nodes they correspond to if I understood you well), I think that very similar graphs should provide a counterexample : in the end you're just counting the number of paths of a fixed length and independently of the vertices they link. For example I think these graphs are a counterexample : $URL$ and $URL$ If I'm not mistaken (counting paths is tedious), they both have 9 paths of length 1, 18 paths of length 2, 48 paths of length 3, 30 paths of length 4 and 36 paths of length 5 

You might want to take a look at the Euler characteristic (jump to the topological definition), which relates the alternating sum of the number of $k$-dimensional simplices with the alternating sum of the betti numbers of your complex. 

As a first remark, your focus seems to be on hypergraphs but I think that most of the literature about embedding hypergraphs prefers to work with simplicial complexes. A good reference on these questions is this paper by Matousek, Tancer and Wagner. 

The most natural ways to represent knots are either to embed them piecewise linearly in $\mathbb{R}^3$ (just store the coordinates of the vertices and where you want to put segments) (any tame knot can be embedded piecewise linearly) or with a knot diagram, i.e. storing a projection on $\mathbb{R}^2$ as a graph where at every crossing you specify which strand is above. As Suresh pointed out, checking knot equivalence is highly non-trivial (not known to be in P) but experimental results for unknot recognition are polynomial-like -- knot equivalence looks much harder though. If you are looking for software, peek at Regina . 

The general problem when $H$ is not fixed is NP-hard: Take $H$ to be a cycle of length $|V(G)|$ and it amounts to testing whether $G$ is hamiltonian. I think that the state of the art on this is the FPT algorithm of Grohe, Kawarabayashi, Marx and Wollan. The dependency on $G$ is cubic, but the one on $H$ seems impractical, since it relies quite heavily on the Robertson-Seymour theory. 

It looks as though the case with a fixed $g$ has shown up under the name "knowledge of exponent assumption(s)"--Googling this phrase will turn up a few papers which discuss/use it. In particular I notice "Statistically Hiding Sets" by Prabhakaran and Xue claims to show the assumption holds in the generic group model. There may be more recent information out there, but that should serve as a starting point at least. Long story short, as far as I can tell: It's a nonstandard assumption, but it's not obviously false and some people have built things with it. 

Your question suggests the following tentative reduction to obtain a OWF from a secure KE: Given an input, interpret it as the private random coins of two simulated parties to the KE protocol. Based on their private randomness, there will be some sequence of public messages between them, and at some point they will stop and agree on a private shared key (with some high probability). Then the public transcript of their communications is the output of the OWF. You are right to be worried about this approach in the case when Alice and Bob may not agree with probability 1. In fact, this construction is NOT necessarily a OWF in that case. Rather, it is a weaker primitive known as a "distributionally one-way function," which is, informally, a function for which it is hard to generate a uniformly random preimage of $f(x)$, when $x$ is selected at random. It is known (but non-obvious) that one can construct a true one-way function using a distributionally one-way function. See e.g. Exercise 17 on page 96 of Goldreich "Foundations of Cryptography: Basic Tools," which is available for limited viewing on Google preview. To directly see why the above reduction does not suffice, we can use the common "make a stupid modification" technique. Namely, suppose there exists a secure KE protocol where Alice and Bob agree with probability $1 - \epsilon$. Consider a stupidly-modified KE protocol that works as follows: Alice and Bob first each flip 100 coins. For each of Alice, Bob individually: If all 100 coins are zero, their remaining randomness is interpreted as encoding a sequence of messages which they send to the other party, ignoring whatever the other one says; then they just output a random "shared key." (Otherwise they follow the original protocol.) Given any public transcript, it is possible (with negligible probability) that it was generated by an Alice and Bob who BOTH flipped 100 zeroes and happened to have their remaining randomness specify that exact sequence of messages. This is still a secure KE protocol, where Alice and Bob will agree with probability at least $1 - \epsilon - 2^{-100}$. On the other hand, it utterly fails to be a OWF in the hoped-for manner, since an attacker who sees some public transcript can always trivially invert by choosing 100-zeroes randomness for each of Alice and Bob. 

We know that linear programs (LP) can be solved exactly in polynomial time using the ellipsoid method or an interior point method like Karmarkar's algorithm. Some LPs with super-polynomial (exponential) number of variables/constraints can also be solved in polynomial time, provided we can design a polynomial time separation oracle for them. What about semidefinite programs (SDP)? What classes of SDPs can be solved exactly in polynomial time? When an SDP can't be solved exactly, can we always design an FPTAS/PTAS for solving it? What are the technical conditions under which this can be done? Can we solve an SDP with exponential number of variables/constraints in polynomial time, if we can design a polynomial time separation oracle for it? Can we solve the SDPs that occur in combinatorial optimization problems (MAX-CUT, graph coloring) efficiently? If we can solve only within a $1+\epsilon$ factor, will it not have an effect on constant factor approximation algorithms (like 0.878 for Goemans-Williamson MAX-CUT algorithm)? Any good reference on this will be highly appreciated. 

Suppose, we are given a graph $G = (V,E,d)$, where $V$ is the set of vertices, $E$ is the set of edges, and $d$ is a distance function $d: E \mapsto \mathbb{R^+}$. Let $S$ be the set of source vertices and $EX$ be the set of exit vertices in $G$. Further, we are given the integers $k, \gamma$ and $\delta$. A $(k, \gamma, \delta)$-hub is a set of vertices $H \subseteq V \setminus (S \cup EX)$ such that: 

I am interested to know the structure of random graphs generated by the preferential attachment model with degree bounds. Specifically, when a vertex is chosen with a probability proportional to its degree, the edge is added if and only if the degree of the vertex does not exceed some upper bound. What will be the vertex degree distribution of such a graph? What will be the size of the largest (giant) component, diameter and the average path length? Any reference will be highly appreciated. 

Can any tree on $n$ nodes be decomposed into a set of $O(\log n)$ caterpillars? If not, what is the maximum number of caterpillars required? Are there efficient algorithms for finding the decomposition? Any papers on this topic will be highly appreciated. 

The divide and conquer algorithm by Michael Shamos to solve the planar Closest pair of points problem in $O(n \log n)$ time. Not only is this optimal in the algebraic decision tree model of computation, it also illustrates the power of recursive thinking in a non-trivial setting. 

We know that Maximum Independent Set (MIS) is hard to approximate within a factor of $n^{1-\epsilon}$ for any $\epsilon > 0$ unless P = NP. What are some special classes of graphs for which better approximation algorithms are known? What are the graphs for which polynomial-time algorithms are known? I know for perfect graphs this is known, but are there other interesting classes of graphs?