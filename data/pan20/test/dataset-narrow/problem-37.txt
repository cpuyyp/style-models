Generally, uniformly-weighted samples with a variable distribution (importance sampling) gives lower variance in the final average than uniformly-distributed samples with variable weights. This is a common rule of thumb in Monte Carlo raytracing. However, another thing to consider is that you'll eventually be converting the images to RGB for display (I assume). So a potential problem might be that if a light source has very little energy in the blue part of the spectrum, for instance, then you'll put few samples in the blue frequencies, and the blue channel of the final RGB image could end up excessively noisy compared to the other channels. One way to resolve this might be to consider the product of the light source's spectrum with the RGB color-matching curves used to generate the output. You could normalize the three against each other to ensure you get enough samples in all three channels, but still distribute the samples to the most important frequencies for each channel. On balance, I suspect that simply using a uniform frequency distribution of samples will be simpler and give good results as long as the light source spectra are fairly smooth. But if you have spectra with sharp spikes (e.g. LEDs, lasers, fluorescent lamps) then spectral importance sampling will probably be necessary. 

One red flag is the use of several times within the loop. Memory allocation doesn't belong in a rasterizer! :) Certainly you should not need to allocate a object (which is used once and then immediately discarded) and do a method call on it, just in order to fill a single pixel! The pixels are hopefully stored as a flat array of bytes, so just write directly to the appropriate address in it. Similarly, don't allocate a every time through, just create one (ideally on the stack, if the language you're using allows for it), and re-use it. Secondly, the algorithm you're using doesn't seem to be a true scanline rasterizer. It iterates over the pixels in each line from left to right, performing edge tests on every single pixel to determine whether it's inside or outside, and recording when that state changes in the and variables. The way a scanline rasterizer is supposed to work (which is much faster) is to calculate the intersection points of each edge with the scanline (using good old school algebra line-line intersection math). Ideally you would have already categorized and sorted the three edges as left, right, or horizontal and therefore once you have the intersection points, it's easy to figure out the interval that the triangle covers on the scanline. Then you can iterate over that and shade or fill each pixel. Finally, I'm not sure if this is a real issue or not, but there are a lot of method calls for relatively trivial things like checking whether vectors are equal, or doing an edge-vs-point test. Hopefully the compiler is inlining all those, but you might want to check the generated code to see. If it's not, you could see a fair speedup by manually inlining that stuff, and possibly manually "destructuring" the vectors (i.e. replace a Vector2D variable by two explicit x and y variables). 

There are two cases I can think of where multiple blurs would be performed in succession on a single image. First, when performing a large-radius blur, it may reduce the total computation if you first downsample the image (which is a blur) and then perform a smaller-radius blur on the downsampled image. For example, downsampling an image by 4x and then performing a 10px-wide Gaussian blur on the result would approximate performing a 40px-wide Gaussian blur on the original—but is likely to be significantly faster due to improved locality in sampling and fewer samples taken overall. 

This makes the endpoint trace out a circle as the angle is changed. If you want the endpoint to be on the edge of the box, one way is to set up a ray from the center of the box at the desired angle, then calculate the intersection point of the ray with the box. This article shows how to calculate ray/box intersections. Another way is to loop over the points around the sides of the box, rather than looping over angles. You would have four separate loops, one for each side, and holding one of x or y fixed while iterating the other. For example, holding x = 10 and iterating y from -10 to +10 would go up the right side. As for the slopes outside [0, 1], you must extend your Bresenham algorithm for it. This can be found in any tutorial or sample of Bresenham, for example the implementations here. 

A 2D Fourier transform is performed by first doing a 1D Fourier transform on each row of the image, then taking the result and doing a 1D Fourier transform on each column. Or vice versa; it doesn't matter. Just as a 1D Fourier transform allows you to decompose a function into a sum of (1D) sine waves at various frequencies, a 2D Fourier transform decomposes a function as a sum of 2D sine waves. These waves can have different frequencies along the x and y axes. They generically have the form: $$ \exp \bigl(i \cdot (k_x x + k_y y) \bigr) $$ where $k_x$ and $k_y$ are the frequencies along the $x$ and $y$ axes. These two values form a vector called the wave-vector. In the spatial domain, the wave is oriented along the $(k_x, k_y)$ vector with a frequency along its axis of $\sqrt{k_x^2 + k_y^2}$. Just as for the 1D Fourier transform, there exist both discrete and continuous versions. The result of a discrete 2D Fourier transform is a matrix of complex amplitudes for a set of discrete $(k_x, k_y)$ values. This is commonly visualized (like in the paper you linked to) as an image where the pixel at coordinates $(k_x, k_y)$ represents the amplitude of that wave-vector. So, an annular shape in a 2D Fourier transform indicates rotational invariance of the distribution of frequencies (i.e. just as much amplitude for waves in every direction), with a narrow range of magnitudes (from the inside of the annulus to the outside). In other words, the paper is using the Fourier transform to demonstrate that their noise is reasonably isotropic and band-limited. 

This may simply be a typo or oversight. Note that in the previous section they've been discussing the microsurface BxDFs $f^m_r(\mathbf{i},\mathbf{o},\mathbf{m})$ and $f^m_t(\mathbf{i},\mathbf{o},\mathbf{m})$, which are naturally evaluated at a microsurface normal, but in this section they've moved on to talking about macrosurface BxDFs, which have the microsurface integrated out. AFAICT, the intent of equation 19 is just to say that the total BSDF is a sum of reflection and transmission parts, so it doesn't really matter ($\mathbf{m}$ is a free variable there and could be named anything), but to be less confusing it should probably have been $\mathbf{n}$. Maybe they just forgot to update it during a round of edits, or something. Yes, you can evaluate a BRDF/BSDF with any combination of input and output directions and it should give the correct answer. 

$N \cdot L$ is the scalar length of the projection of $L$ on $N$ (assuming $|N|=1$). $(N \cdot L)N$ is the actual vector with the length of $N \cdot L$ in the direction of $N$. There is often a confusion when people say "projection of this on that" whether they mean just its length, or the actual vector resulting from the projection. In this case you want to combine it with another vector, so you need the vector version. The correct reflection formula is thus: $$R = 2(N \cdot L)N - L$$ 

There are a couple of ways to answer this question: an algebraic way and a geometric way. Algebraically, we can identify the units that the BRDF must have by looking at its place in the rendering equation. The classic rendering equation is: $$L_\text{outgoing}(\omega) = L_\text{emitted}(\omega) + \int_\Omega L_\text{incoming}(\omega') \, f_\text{BRDF}(\omega, \omega') \, (n \cdot \omega') \, d\omega'$$ The output value on the left is a radiance, so the result of the integral must also be a radiance. The integrand contains a radiance multiplied by a solid angle $d\omega'$, so something else in the integrand has to cancel out that factor of solid angle. The $n \cdot \omega'$ factor is dimensionless, and the only other thing there is the BRDF—so to make the whole thing work out, the BRDF must have units of inverse solid angle. Equivalently, the BRDF can be seen as a ratio of radiance to irradiance, since they differ by a factor of solid angle in the denominator of radiance. Another way to see it is that the BRDF plays a role similar to a probability density. If you look at how probability densities work, they have units inverse to the volume of their domain. For instance, a 1D probability density has units of inverse length (probability per unit length, but probability itself is dimensionless), a 2D one has units of inverse area, and so on. The BRDF acts much like a probability density defined on the hemisphere, giving a likelihood for a photon coming in from a given direction to be reflected into some other direction. So, like any other probability density on a spherical domain, it has units of inverse solid angle. Geometrically, we can get right down to brass tacks and take apart what's going on in the integral in the rendering equation. Recall that an integral means to subdivide the domain into tiny pieces and sum the integrand over all the pieces (in the limit as the pieces get infinitesimally small). Let's look at one such piece. The integrand should result in an infinitesimal amount of radiance $dL$, since we're going to sum over many pieces to arrive at a finite outgoing radiance. So a single infinitesimal piece of the integral looks like: $$dL = L_\text{incoming} \, f_\text{BRDF} \, (n \cdot \omega') \, d\omega'$$ If we regroup the factors a bit, the combination $L_\text{incoming} \, (n \cdot \omega') \, d\omega'$ calculates the irradiance on the surface due to the light coming from the infinitesimal solid angle $d\omega'$. Since it's arriving from an infinitesimal amount of solid angle, it produces an infinitesimal irradiance $dE$. $$dL = f_\text{BRDF} \, dE$$ or $$f_\text{BRDF} = \frac{dL}{dE}$$ So the BRDF acts as a proportionality constant between the infinitesimal irradiance arriving at the surface from an infinitesimal solid angle, and the infinitesimal outgoing radiance generated thereby. It couldn't be a ratio of radiances, because we have a finite incoming radiance, and we need an infinitesimal outgoing radiance if we want to sum up many pieces of the integral and get a finite result. To make that happen, the BRDF would have to be infinitesimal-valued, which...isn't a thing, in standard mathematics. :) I hope some of this helps. There are a variety of equivalent ways to look at this problem, as with so many things in math and physics.