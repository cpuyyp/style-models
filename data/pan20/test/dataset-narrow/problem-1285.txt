My favorite game engine structure is the interface and object<->component model using messaging for communication between almost all parts. You have multiple interfaces for main engine parts such as your scene manager, resource loader, audio, renderer, physics, etc. I have the scene manager in charge of all objects in the 3D scene/world. Object is a very atomic class, containing only a few things that are common to almost everything in your scene, in my engine the object class holds only position, rotation, a list of components, and a unique ID. Every object's ID is generated by a static int, so that no two objects will every have the same ID, this allows you to send messages to an object by its ID, rather than having to have a pointer to the object. The list of components on the object is what gives that objects is main properties. For example, for something that you can see in the 3D world, you would give your object a render component that contains the information about the render mesh. If you want an object to have physics you would give it a physics component. If you want something to act as a camera, give it a camera component. The list of components can go on and on. Communication between interfaces, objects, and components is key. In my engine I have a generic message class that contains only a unique ID, and a message type ID. The unique ID is the ID of the object you want the message to go to, and the message type ID is used by the object receiving the message so it knows what type of message it is. Objects can handle the message if they need, and they can pass the message on to each of their components, and components will often do important things with the message. For example, if you want to change and object's position you send the object a SetPosition message, the object may update its position variable when it gets the message, but the render component may need to message to update the position of the render mesh, and the physics component may need the message to update the physics body's position. Here is a very simple layout of scene manager, object, and component, and message flow, that I whipped up in about an hour, written in C++. When run it sets the position on an object, and the message passes through the render component, then retrieves the position from the object. Enjoy! Also, I've written a C# version and Scala version of the below code for anyone that might be fluent in those rather than C++. 

It's probably a good idea to generate each type of ID in a different and unique way so that just by looking at an ID you can determine which type it is. For example, if all of your IDs are unsigned 32-bits, that gives you a range from 0 to 4,294,967,295. You could allow a few million or so values for local IDs, as you're not likely to generate a that many objects locally before restarting your client or server. Then split the remaining 4 billion or so between global and static IDs. If you have distinct ranges for your IDs you will know what is global, static, or local just by the value. 

You'll want to include the time elapsed during a frame in your calculations if you want to maintain a constant movement. 

For mobile phone games: - Unity 3 (Android, iOS) - Objective C (iOS) For Windows PC games (that aren't web), if you're looking for job opportunities, most of the industry still uses C++. A lot of 3rd Party middleware and Game Engines are written in C++ as well, so if you want to work for one of those companies or work for a company that uses that software, C++ is a good bet. Also DirectX is fairly standard, but some companies use game engines that support OpenGL, which is important if the game is going to be multiplatform. For multiplatform PC games: - Java (runs on Windows, Mac, Linux) - Some companies will contract other companies to write wrappers for their game so it can run on other Mac/Linux. For OSX games: - Java - C - Objective C - OpenGL I would focus on a part of the gaming field that most interests you, and start researching the pay for particular positions that you could be applying for in the future. Average starting salary in the gaming industry for a programmer is around $50k/year, rising to around $90k/year after 5 years, and can get up to $120k-150k/year for leads and directors. Bear in mind however that the industry tends to be clumped in certain geographical areas. In the US about half of the companies are on the west coast, where cost of living can be very expensive, so a high salary can be somewhat offset. Also, consider that not all game programmers are programming for the game itself. Many programmers are doing things like writing tools for designers, or writing scripts for automated builds, or creating web interfaces for linking tools, game, and database together. The list goes on. This kind of programming covers many languages, like SQL, Python, PHP, HTML, etc... 

In the above method we limit bouncing whenever it's along the same axis as gravity. Something else to consider would be detecting whenever a ball has collided with the ground, and if it's moving fairly slow at the time of collision, set the velocity along the axis of gravity to zero. 

You can see here we have a collision in the above list that is new (2<->5), I would send out events for that collision. There is also a collision from the first list that is no longer in the list after step 2, and that is 1<->2, which I would send out events for as well. Using a system like I've described above means that you only have to receive a collision event when a new collision occurs, or when a collision ends. You can see this system implemented in the QuickStart Game Engine, which uses XNA with JigLibX, it's a free download. I don't know of any way to make JigLibX not send collision events each frame. Each physics engine I've used did this every frame (simulation step). 

I have covered a lot of the base objects needed to start up the framework for network replication but there is a lot more to cover. Such other considerations are: 

You will need to configure your lighting for your project as well as for your objects when you want dynamic shadows. I suggest taking a look at this lighting section for UE4: Lighting and Shadows Reference Also, check your In-Editor Graphics quality as well as the buffer you are rendering in the Editor. 

This has been done before in a video tutorial for a "Horror Game". They label it 'True FPS'. Right now it sounds like the mouse movement is moving the camera and not the body. What you want to do is attach the Camera to a Socket on the Skeleton (if you want the camera to move with the animations as well). If not you can just position the camera where you need it, then attach it to a "None" socket when you attach it to the root component or the Skeletal Mesh. The tutorial mentioned is found here. It should give you what you want based on your question. To be clear, your question is to turn the body with the camera. This answers your question because your turning input will move both the body and the camera. On a technical note though, it is not the body that will turn with the camera, it is the camera that is turning with the body due to the attachment hierarchy. I mentioned this in case you want to have a separate input to cause a Local Transform on just the camera - kind of like in Legend of Zelda: Ocarina of Time where you can use a "Look At / Look Around" function 

And then the implementation (where MyUIIDGenerator is some kind of class that guarantees a unique value every time its MakeUIID method is called): 

Personally, If you want 1:1 scale simulations and need the lighting to work for that, I would suggest altering the culling of the UE4 shaders for this. Just remember that this may have a performance impact. If you are intimidated by modifying your shaders or creating an new one for your specific needs, and have access to the forums, I suggest giving this a good read: $URL$ even though it is just about a custom G-Buffer, it will help teach you about writing and binding your own shaders for pointlights. Or you could find the code that clamps your culling distance and edit that. If scaling your world, keep in mind that if you are using PhysX, the mass of the object is calculated from the size and you may run into issues if micro-scaling. 

this is a pointer to an Actor class (so your weapon). Now, the key code here is the ConstructObject template function. In Blueprints you would call "Construct Object from Class" using a class reference to the Component you would like to create. The outer would be a reference to the owning actor of the component (the Weapon for instance). With the return value you will cast it to the desired component. 

It is definitely the size of your scene and the culling of light that is causing your light to 'disappear' from the planet at that distance. There were a lot of suggestions that are good and answer your question of bypassing it. Another one would be to actually tweak the shaders in UE4 to accomodate lighting such a large simulation space as suggested by a UE4 staffer: 

Finally, you would need to define a network replication protocol. Could be something as simple as this definition: 

By setting this as the RootComponent, and assuming your Actor is set to Movable, is active, and allowed to update, your call to will move your actor to that location. 

Instantiate returns an Object reference then you can cast to the desired type using the as statement. In your case you would just do , then call on the returned and casted GameObject variable. 

Yes, you may spawn an actor component and attach it to any given actor. The C++ version of this would be: 

If you are making a single player game with only one sun (they cannot travel between solar systems) the suggestion of rotating the angle of your Directional Light based on the player's position between the sun and view is another way to go about it. 

One that I have also heard of is the potential of using Light Propagation Volumes that are built into the UE4 engine... but it seemed like a concern that such a large space could still prove to be problematic. Another suggestion would be to just turn off the Inverse Square Fall-off of your light to see if that works in your un-scaled simulation. 

Your question boils down to an answer that results in client prediction for replicated movement of remote entities in your game. There are several theories and implementations that you can go with for this. Linear interpolation is a popular one for having the client predict where the server is going to tell it where various objects are. Here is a nice list with some sources about this topic. Movement Queues Here is a good example/discussion that talks about different approaches and their success / failures. It is valid because it is not specific to any language and can be applied to any game engine. It has an approach where you save (client side) the client side movements. Then, as a packet, you send them to the server. The server sends this client movement packet to all interested parties (other clients). This is neat because if you have a huge delay, rather than teleporting the character, you simply replay those saved packets that the client received of the remote entity. Curves Then there is the approach that was seen in Planetary Annihilation with the use of Curves. (P.S. The link has a lot of links in the article discussion this very topic). What that is essentially the client tells the server where it was at a given time. From there, the server tells all clients where that entity is at a given time using a list of times and positions. From there the client can smooth the movement using the time and position pairs. What is really great, and they mention this too, is that you get free game replay data for free. Tick Rate Entity Interpolation A third method is one found in the Source engine Multiplayer Networking guide. This example is pretty straight forward. It involves some interpolation math and using tick rates. May be the simplest to implement.