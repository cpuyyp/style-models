In your post you didn't specify where your user list is coming from. It looks like you're getting the users of one group and seeing what else they're a member of. It's largely irrelevant to the solution so I'll assume you have a list of and go from there. What you want to do is combine properties from two commands into a single output stream. This can be accomplished by leveraging Calculated Properties like so... 

I'm using the built in SCSM cmdlets and the SMlets powershell module. I'm able to query Service Requests, but I can't seem to figure out how to get the Affected User of a given Service Request. I'm getting service requests in the following manner: 

The command is actually enumerating the methods and properties of the object created by Get-Service as well as it's TypeName. You can see the TypeName immediately after entering the command. That TypeName corresponds to a .Net class which you then google (no really). You have to drill through the msdn page a bit which requires a basic understanding of object oriented programming (I know, another google). Eventually you should land on the ServiceControllerStatus Enumeration page which lists all the possible value descriptions. The values returned are actually integers, but .Net is kind enough to turn those values into something we can understand. Hopefully if you practice this process a little, you'll be able to apply this same method to find info on other objects in powershell. 

The best way to encourage users to take up a new service, is to make sure that it is better than what you currently provide, otherwise what's the point. I would make sure they have the ability to store more than 200mb, or are trained in how to prune their mailboxes of large attachments, although lets be honest, who really does this? We moved away from Personal Folders some time last year, and despite the added few minutes a week I might have showing users how to clean their mailboxes up, I haven't looked back. It was definitely met with some scepticism at first, as most users had been used to a 500mb limit on their mailboxes and then archiving to .pst since long before I joined the company five years ago, but approaching it in gradual stages lessened the burden. The first step was to increase the disk space on the Exchange server, costs of which were quickly justified to management by explaining the cost of lost data in a corrupt personal folder as well as the time taken to attempt to restore corrupt .pst files, they bought it pretty quickly. The next step was to write some documentation for users on how to decrease the amount of data they stored in the mailboxes / personal folders, the best way to do this is to explain that it's not necessaries the amount of emails you have that take up the space, moreso the size of each email. I showed them that not all emails are the same size, and how they can free up 50% of data by cleaning up the largest 10% of their emails. I found that 70% of the users cleaned up their email after this Finally, after explaining to the users the pitfalls of personal folders and the benefits of mailbox storage, such as automated nightly backups of their data which could be restored to a point in time if they were to lose anything, the ability to access their emails from anywhere they needed, as well as stating (with management approval) that we would no longer be supporting personal folders corruption, as a superior service was now available (I should add, that I never refuse to support an issue if it arises, but I've found that sometimes telling your users something is no longer supported is enough to encourage them to move to the new system) I migrated their personal folder data into their mailboxes as a goodwill gesture, over the course of a few weeks. I then monitored the amount of data used by each mailbox for a few weeks and adjusted limits on a per user basis. Most remain with a 1gb limit, a small few require 2-3gb and quite a few others on 500mb. The reason I didn't set these limits prior to the migration is that I figured most users would delete a lot of older emails when they knew everyone else was doing it, which actually worked okay. 

The WMI class uses the MSI provider to collect installed program data. This means you're only going to get data on software/packages installed using MSI. Further, calling this class causes a repair action to be executed on every program it returns. Most of the time this isn't an issue, but it will fill up the event log and can cause issues for some software. You can get more detail on this link: Win32_Product Class Most scripters, coders, etc use one of two things; 1) Registry Query, 2) WMI query of the SCCM class . Obviously the SCCM class requires SCCM to be installed on the host. You can read more about that HERE. So that really only leaves the registry query for most folx. Don't fret though, because all the work was already done for you by TSG. Your pot of gold is "Use PowerShell to Quickly Find Installed Software" While I'd do things slightly differently than in that post, it has all the heavy lifting already written. With a little aptitude and some google searching you can customize as you wish. 

Mark, I had a lot of fun tracking this down for you. I can totally see where your line of thought is, but you're asking the wrong question. The question should be "Why can't I establish a 'servermanagerworkflows' session on my machine?" If you look in the and open the module and jump to line 383 there's an entry where Microsoft is intentionally trying to create a local session using the configuration. After the session is instantiated the magic happens in the following Try/Catch/Finally blocks. If you ran in a PS prompt on it's own, I'm betting you'd get the same error. To reinforce this, run and I'll bet you don't see as part of the list. So, next step is to get you the session config you need. Run cmdlet and agree to the prompts. If successful run again and see if the workflows are listed. If they are, you should be good to go, or at least generate a new set of errors. Cheers! 

I'm at the mercy of a sys admin who handles middleware config for an application I'm working on. Long story short I asked for SSL to be enabled for the application. The app is split up between a PHP layer being served from Apache httpd, and a set of REST services in Java, being served by Tomcat 8.5 (standalone) on port 8443. After the sys admin told me "your SSL is fully configured", I hit the base app at: 

Other online tools warn me that no reverse-DNS PTR record exists for my domain. I asked my hosting company about it and they basically said "Right now all email is going through your cloud.example.com domain and through the IP address of the server. That IP does have a PTR record, so email will be fine. We recommend this instead of having email go through each static IP address and associated domain". So...is that an 'ok' answer or should I politely ask them again to please configure email for the domain I have at the other static IP address, to use that IP address -- and have a PTR record for reverse resolution? 

still gives a warning on SSL. So, is there a hint of some sort or guidance, link to a good how-to, or anything I can share with this person to get her some help to understand how to get this SSL working on that Tomcat/port ? 

I have a site which is a combination of WordPress, phpBB forum and a PHP based shopping cart system. I have SSL running, and have always had it for the shopping cart, but would now like to simply redirect the entire site to https. As a test, I simply went to my browser and typed And behold, every page is being served over SSL - regardless of where I navigate. Seems perfectly normal. So, does this simple test mean I can safely do a .htaccess redirect like this? 

I think there's more than one way to tackle your problem, at least from what I see as the cause. Here's how I'd do it: 

You also want to check the status of your job once you've restarted and logged back in with the cmdlet. 

calls .Net and creates objects using a constructor in the class. You can find out what "type" the data is by piping the cmdlet to like this: 

Powershell is a parsed and interpreted language. The interpreter see's parenthesis as a control structure and is not expected or required at the Call Site. Consider the following example function: 

Which of course returns the cluster object. So, what's going on here? What's different with ? Edit Version info from Powershell: 

DHCP Server Not Offering to PXE Client BACKGROUND: I'm in the process of adding PXE services to an existing SCCM 2007 server. The SCCM server is separate from the DHCP server (Server 2008 x86) and did not have PXE services or WDS installed. I added PXE services in the Config Manager before adding WDS as a role. Because DHCP is on a separate server, I did not make any changes to DHCP Options (there is not a current 60, 66, or 67 configured). The WDS is configured with both a boot image (ripped from the Win7 install dvd and an install image which was created by someone else). SCCM has a TS configured and advertised to the Unknown Computers collection. The DHCP server is configured for both DHCP and BOOTP requests (I added BOOTP as part of my troubleshooting, the default lease time is set to 5 minutes). It also has NAP enabled for the IPV4 addresses but disabled for this SCOPE. My host, the VM, the DHCP server, and the SCCM/WDS server are all on the same subnet. Juniper routers move the packets. I'm testing PXE using a VirtualBox machine configured to network boot and it has an empty dynamically allocated disk attached. Wireshark is installed on both my host computer (running VirtualBox) and the DHCP server. PROBLEM: When the VM starts it performs a network PXE boot. I can see the discover request by the VM in Wireshark on both my host and the DHCP server. However, the DHCP server is not responding with an IP offer. If I could get some guidance as to where else to look for an error, or possibilities as to why it's not working, I'd appreciate it. EDIT: The dhcpsrvlog does not record an event regarding the request for an IP from the pxe client.