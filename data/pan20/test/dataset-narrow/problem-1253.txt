Since I don’t understand what you don’t understand, I will try to give a quite formal description, hoping it will help. $\newcommand{ket}[1]{\left|#1\right>}$ Let’s suppose the error is the unitary $U$ applied on the $k$th qubit. We have $$\begin{align} U&=aI+bX+cY+dZ\\&=aI+bX+icXZ+dZ, \end{align}$$ with $a,b,c,d$ being real numbers, $I$ is the identity, $X, Y, Z$ the Pauli operators. $X$ is a bit-flip, and $Z$ is a phase-flip. $Y=iXZ$ is a combination of phase and bit-flip. Let’s look at a coherent version of Shor error correction, one where there is no measurement, but a set $A$ of 8 ancilla qubits, initially in the $\ket{0}$ state. Their final state, if measured in the computational basis, contains the code syndrome. The error correction is described by a unitary $V$ acting the 9 qubits of the code ($B$) and the 8 ancilla qubits. Since the code corrects both bit-flips and phase-flips, we have: $$ \begin{align} V⋅(I\otimes I)\ket{\psi}_B\ket{0}_A&=\ket{\psi}_B\ket{0}_A\\ V⋅(X_k\otimes I)\ket{\psi}_B\ket{0}_A&=\ket{\psi}_B\ket{\phi_{k,X}}_A\\ V⋅(Z_k\otimes I)\ket{\psi}_B\ket{0}_A&=\ket{\psi}_B\ket{\phi_{k,Z}}_A\\ \end{align} $$ The action of $Y_k=iX_kZ_k$ is also corrected, since it is a phase-flip followed by a bitflip $^*$ : $$ \begin{align} V⋅(I_k\otimes I)\ket{\psi}_b\ket{0}_a&=iV⋅(X_k\otimes I)⋅(Z_k\otimes I)\ket{\psi}_b\ket{0}_a\\ &=\ket{\psi}_b\ket{\phi_{k,Y}}_a\\ \end{align} $$ If we apply this to an arbitrary error $U_k$ on the $k$th qubit, we have : $$V⋅(U_k\otimes I)\ket{\psi}_b\ket{0}_a=\ket{\psi}_b\left(a\ket0_a+b\ket{\phi_{k,X}}_A+c\ket{\phi_{k,Y}}_A+d\ket{\phi_{k,Z}}_A\right) $$ and the vector $\ket{\psi}_b$ is recovered. 

Peter Shor essentially suggested the formulation 1. in his comment above, and I’ll let experimentalists answer this question. The question 2. seems strange, but I bring it forward because its answer is positive : In a 2009 paper (arXiv:0909.4673, paywalled version), Dan Browne, Elham Kashefi, and Simon Perdrix showed that Measurement Based Quantum Computing (MBQC), is equivalent up to a classical side-processing of logarithmic depth, to the quantum circuit model augmented with unbounded fanout gates. They basically recall that the unbounded parity gate is a Clifford gate and can be therefore be expressed as a measurement pattern of constant depth (arXiv,paywalled PRA) and show that a fanout gate is nothing else than a parity gate “sandwiched” between two layers of Hadamard gates, and can therefore be simulated in constant depth. Therefore, your question 

Is unbounded fanout a reasonable approximation for realistic (quantum) circuits ? Is there a realistic quantum architecture which is effectively equivalent to the quantum circuit with unbounded fan-out ? 

The reference to [Odylzko 1995] is a “personal communication”, but I was not present when Peter Shor and Andrew Odlyzko discussed this... I perfectly understand why it is an improvement, but I don't know how to show the number of trials is reduced to $O(1)$. Do you know any proof of this? 

I complete here Peter’s answer with a characterization of physical maps as CPTP maps. As you know, if the system is isolated, the only operations you can implement are the unitary operations. But, as you noticed, if you use an ancillary subsystem and throw a subsystem away, you can implement some other operations. The set of physical operations are the completely positive trace preserving maps. (Following most of the literature, I’ll call them CPTP maps), and Stinespring’s dilation theorem indeed ensures that any CPTP map can be written as the partial trace of a unitary acting on a larger Hilbert space. Since we are looking at non isolated subsystem, its quantum state has to be described by a density matrix $ρ$. In full generality, a density matrix has to be positive ($ρ≥0$) and having a unit trace ($\mathrm{Tr}ρ=1$). Let suppose we have a generic physical map $\mathcal{E}:ρ↦\mathcal{E}(ρ)$. To be physical $\mathcal{E}(ρ)$ needs to be a physical state for any input state $ρ$, that is, we should have $∀ρ:ρ≥0$, $\mathcal{E}(ρ)≥0$ and $\mathrm{Tr}\mathcal{E}(ρ)=\mathrm{Tr}ρ$. In other words, $\mathcal{E}$ has to be positive and trace preserving. However, it is not enough. For example, the transpose $\mathcal{T}$, is a positive trace preserving map, which is unphysical. The idea is the one behind the Peres-Hordecki criterion: suppose you have a channel performing $\mathcal{T}$ on the thystem $A$. You can add another system $B$ of the same dimension, where you perform the identity $\mathcal{I}$ i.e. wher you don’t do anything. The global map on $AB$ is then $\mathcal{T}_A⊗\mathcal{I}_B$, which is not positive any more: some linear algebra shows $\mathcal{T}_A⊗\mathcal{I}_B(Φ_{AB})$ has $d(d-1)/2$ negative eignevalues, where $Φ_{AB}$ is a maximally entangled state. For a map $\mathcal E$ to be physical, any extension of the form $\mathcal E⊗\mathcal I$ has therefore to be positive. This is the definition of complete positivity. The Stinespring dilation theorem then shows that this necessary condition is sufficient, since it gives a recipe to implement any CPTP map with an ancillary subsystem and and a unitary. 

This paper came up on the arXiv today and it improves on the upper bound on $bs(f)$ in terms of $s(f)$. They prove the following bound: $$ bs(f) \leq 2^{s(f)-1}s(f). $$ This along with the connection that Marcos mentioned in his comment should give better bounds than previously known. 

Frederic Green, An oracle separating $\oplus P$ from $PP^{PH}$, Information Processing Letters, '91 James Aspnes, Richard Beigel, Merrick Furst, and Steven Rudich, The expressive power of voting polynomials, STOC '91 Adam Klivans, On the Derandomization of Constant Depth Circuits, RANDOM '01 

This doesn't directly answer your question about a definition of a complexity class that represents the model you describe. Still, the notion of quantum oracle has relevance in complexity theory: in their paper Aaronson and Kuperberg use a quantum oracle to give a separation between QMA and QCMA. 

I am talking about publications in journals, not blog posts or technical reports. Also, I tagged it as big-list, with the hope that it will actually be. 

Something that has not been mentioned so far (as far as I can see) and that holds in the unrelativized world is the following: $$PH \subseteq PP \quad\mbox{ if }\quad QMA = PP.$$ This was observed by Vyalyi in this paper and comes from the strengthening of two theorems: 

From what I understand, this can be proved by showing that "small" $AC^{0}$ circuits with a MAJORITY gate at the root fail to compute the PARITY function even on a (1/2+small)-fraction of inputs. I found such claim in Theorem 6 of [3]. Does this reasoning make sense? Am I interpreting Klivans' theorem in the right way? I wrote "largest" class in the title, because I am also interested in classes that have this same property and that are uncomparable with $PP^{PH}$. 

There isn't a one word answer to your question, but you can have a look at Xiaotong Ni's master thesis, where commuting circuits with several restrictions are considered and compared to classical classes. There you can also find the definition of the class IQP, which is a subclass of polynomial size commuting Pauli circuits. 

Toda's theorem - Vyalyi shows that one query to a $\sharp P$ oracle is enough for a "$P$ machine" to simulate $PH$. The inclusion $QMA \subseteq PP$ proved by Kitaev and Watrous. Vyalyi proves that $QMA$ is also in $A_0PP$, a class that is contained in $PP$. 

Green [1] showed that $PP^{PH}$ is properly contained in $PSPACE$ relative to some oracle. Around the same time, in the famous "voting polynomials" paper [2], it was shown that $PP$ is properly contained in $PSPACE$ for a random oracle. Question 

A lot of progress has been made on this question in 2015. First, in arXiv:1506.04719 [cs.CC], the authors have improved on the quadratic separation by showing a total function $f$ with $$ Q(f) = \widetilde{O}(D(f)^{1/4}). $$ On the other hand, in arXiv:1512.04016 [quant-ph], it was shown that the quadratic relationship between quantum and deterministic query complexity holds when the domain of the function is very small. 

Basically everything that is known about the Quantum PCP conjecture has been collected in this survey by Dorit Aharonov, Itai Arad, and Thomas Vidick: The Quantum PCP Conjecture See also Thomas' blog post on the topic. 

This is amazing and it's the first time that I have seen it. I have always wondered why authors of paper don't write how they got to the proof, including the failed approaches they tried before getting to the track that led the solution. When I saw Ryan's paper on the arXiv, I felt very motivated to read it. I consider it a revolutionary paper from this point of view. Most of the time the only thing you can do with a paper is verifying its correctness. The question is the following: 

Today Ryan Williams posted an article on the arXiv (previously appeared in SIGACT News) containing a less technical version of his recent ACC lower bound technique. My question is not about the technique itself (of course worthy of immense praise), but it's about the style of the paper. In the abstract, he writes: 

Moved my comment here after Suresh's request. An example of a natural problem for which we only know algorithms that require error on both sides is the following: given three algebraic circuits, decide whether exactly two of them are identical. This comes from the fact that deciding whether two algebraic circuits are identical is in co-RP. Reference: see the post How Many Sides to Your Error? (Dec 2, 2008) about the very same question on Lance Fortnow's blog and the comments below his post for a discussion about the naturalness of the problem. 

In his 1995 paper Polynomial-Time Algorithms for Prime Factorization and Discrete Logarithms on a Quantum Computer, Peter W. Shor discusses an improvement on the order-finding part of his factorization algorithm. The standard algorithm outputs $r'$, a divisor of the order $r$ of $x$ modulo $N$. Instead of checking if $r'=r$ by checking if $x^{r'}\equiv 1 \mod N$, the improvement is the following : 

I personally think the answer to the latter question is “yes”, but the opinions on the feasibility of a given quantum computing architecture tend to be subjective... 

Brief (negative) answer This claim is incorrect as soon as you have three (or more) qubits, as shown by the GHZ paradox, briefly described below, which shows a 3-partite Bell inequality which is beaten by a state stabilized by Pauli operators, which can be prepared and measured by Clifford operations. This paradox is named after Greenberger, Horne and Zeilinger, who found it in 1989 (2007 arXiv reprint here). The point is that the Gottesman-Knill theorem does not care about locality, but on simplicity. The Gottesmann-Knill theorem (wiki, arXiv) gives a polynomial hidden variable theory for a state constructed with Clifford gates. Nothing prevents this theory to be nonlocal, as the GHZ state shows, but its complexity is bounded : a $n$-qubit state is described by $2n²$ binary hidden variables. On the other hand Bell inequalities characterize local hidden variable theories, without taking care of their complexity. The violation of a Bell inequality by the GHZ states means that it cannot be described by a model where each player has access to a different local hidden variable. Details of the GHZ paradox The paradox can be explained by the following game, with 3 cooperating players and a referee. the referee asks a question, either $X$ or $Y$ to each player, which answers ±1 without communicating with the other players. The referee either asks $X$ to all the players or asks $X$ to one of them and $Y$ to the others. The players win if the product of their answers obeys the equality below corresponding to the question asked: $$\begin{align} XXX&=+1\\XYY&=-1\\YXY&=-1 \\YYX&=-1 \end{align}$$ It is easy to see that the above set of equation is not consistent, and tha no local hidden variable theory allows to win the game with a probabiliyt greater than 3/4. On the other hand, if each of the player has a qubit of a GHZ state $|\mathrm{GHZ}\rangle:=(|000\rangle+|111\rangle)/\sqrt2$, they can win with certainty. Indeed, $|\mathrm{GHZ}\rangle$ is stabilized by the following Pauli operators : $$\begin{align} S_0&=+XXX\\S_1&=-XYY\\S_2&=-YXY \\S_3&=-YYX. \end{align}$$ Therefore, measuring the Pauli operators corresponding to the referee’s question allows the players to always win the game, and therefore violate a Bell inequality with certainty. Furthermore, this state can be prepared from Clifford operations, which invalidates the idea expressed in the paragraph you cite. 

As suspected by Peter Shor, it is not true. Almost a counterexample Let $ω_{ABCD}=Φ_{AC}⊗ψ_{B}⊗ψ_{D}$, with $Φ$ being a maximally entangled state and $ψ$ a pure state. Let $U$ be the unitary $I_A⊗σ_{BC}⊗I_D$ swapping $B$ and $C$, so we have $ω_{ABCD}=Φ_{AB}⊗ψ_{C}⊗ψ_{D}$. All the systems are supposed to be of dimension $d$. Your assumptions are almost fulfilled, since $$\begin{align} S(ω_B)=0&<S(τ_B)=\log d \\ S(ω_A)=\log d&\ge S(τ_A)=\log d \tag1 \\ S(ω_{AB})=\log d&> S(ω_B)=0 \end{align}$$ but we have $$\begin{align} S(τ_{AB})-S(ω_{AB})=0-\log d&< S(τ_{B})-S(ω_{B})=\log d -0 \end{align}$$. In this case, the condition (1) is not fulfilled, since you asked for a strict decrease in $A$’s entropy, and kept $S(A)$ constant with a unitary not touching $A$. This can be changed by perturbing $ω$ and $U$, to have a slight decrease in $A$’s entropy. A real counterexample A concrete way to do this without a pertubative argument is to add another system $A'$ to $A$, which is entangled to another system $D'$ given to $D$. $$\begin{align} ω_{AA'BCDD'}&=Φ_{AC}⊗Φ_{A'D'}⊗ψ_{B}⊗ψ_{D}\\ U&=σ_{A'D}⊗σ_{BC}⊗I_{D'}\\ τ_{AA'BCDD'}&=ψ_{A'}⊗Φ_{AB}⊗Φ_{DD'}⊗ψ_{C} \end{align}$$ In that case, we have $$\begin{align} S(ω_B)=0&<S(τ_B)=\log d \\ S(ω_{AA'})=2\log d&> S(τ_A)=\log d \\ S(ω_{AA'B})=2\log d&> S(ω_B)=0 \\ S(τ_{AA'B})-S(ω_{AA'B})=0-2\log d&< S(τ_{B})-S(ω_{B})=\log d -0 \end{align}$$ Despite all your assumptions fulfilled by at least a $\log d$ margin, your final inequality is violated by a $3\log d$ margin The physical intuition begin these counter examples : conditional entropies The inequality you want to prove and your third assumption are thinly disguised conditional entropies. Moving $S(ω_B)$ to the left-hand side of our third assumption, one obtains $$H(A|B)_{ω}≥0,$$ which is verified by all state which are separable across the $A|B$ split (including my counterexamples.) Your final condition is equivalent to $$H(A|B)_{τ}\stackrel{?}{≤}H(A|B)_{ω}.$$ Since the right-hand side is positive by assumption, any negative left-hand side is a counterexample. $H(A|B)$ can only be negative for states which are entangled accross the $A|B$ split. In both my counterexamples $H(A|B)_{τ}=-\log d$ because of the entangled state $Φ_{AB}$. The increase in $B$’s entropy is provided by the move of the half EPR pair from $C$ to $B$. In the second counter example, in order to have a decrease of $AA'$’s entropy, I artificially increased the initial entropy of $A$ with the state $Φ_{A'D'}$. This entropy is sent to $D$ by $U$.