The 'messier details' in fact show that these $\{c^*_i = Enc(PK_2, m_i)\}$ are "fresh" ciphertexts under $PK_2$, meaning we have the full "bounded-depth" of $Eval$ available to us. Therefore, if $Eval$ can support at least the depth of the $Dec$ circuit, plus one, then you are able to perform unbounded-depth homomorphic computation (by further assuming circular security, and posting both $RK_{1\rightarrow 2}$ and $RK_{2\rightarrow 1}$, then toggling between the two keys with each recryption). In other words, you compute one step of the computation of some given circuit $C$, then you recrypt, and repeat. P.S. If you go through significantly more effort (involving program obfuscation techniques), you can also obtain FHE without the circular security assumption. See: $URL$ 

Here is a technical paper on the LMAX Architecture (I just followed a link found on the blog you linked here): $URL$ An example of a multicast graph is on page 9 of the PDF. There are also examples of multicast graphs (compared to various other options) here: $URL$ 

How interesting -- I just finished coding this exact algorithm up in C++ a few minutes ago. (So forgive the tangent from pure theory into a little practical discussion. :)) It costs $O(2^n n^2)$ time and $O(2^n n)$ space -- at least under my implementation. Practically speaking though, when your space requirements grow that fast, they become way more painful than the time requirements. For instance, on my PC (with 4 GB of RAM), I can solve instances with up to 24 cities -- any more than that, and I run out of memory. Of course, I could just be a bad programmer, and you might be able to do better than me in practice. :) Edit: A little more specifics on one detail of your question: The $k(k-1)$ term comes from the fact that you have to, in the worst case, calculate the partial, optimal distance from the previous subsets (there are at most $n$ of them; note that $k$ is summed over $n$ in the analysis you linked) to the current one. This requires, again in the worst case, $O(k)$ comparisons with subsets of size $k-1$ for a total of $O(k^2)$. Also, if my explanation wasn't clear enough, here are some nice lecture notes of Vazirani's (PDF). Scroll down to P. 188 for a discussion of TSP, including an analysis of Held-Karp. 

To somewhat restate what Ryan Williams wrote in his last paragraph: The Moshkovitz-Raz theorem shows that there is a function $T(n) = 2^{n^{1-o(1)}}$ such that if Max-3Sat can be $(7/8 + 1/(\log \log n)^{.000001})$-approximated in time $T(n)$ then the decision version of 3Sat is in time $2^{o(n)}$. It is commonly believed that the latter is impossible (this is the Exponential Time Hypothesis), in which case the former is impossible too. To put it not quite accurately, you can't beat $7/8$ for Max-3Sat in anything better than full exponential time. 

It might be conjectured that the Learning Parity with Noise Problem (LPN) at constant error rate requires time $2^{n^{1-o(1)}}$. The fastest known algorithm (Blum-Kalai-Wasserman) uses time $2^{O(n/\log n)}$. 

I believe that the smallest such classes known are $S_2P$ (Cai, 2001), $PP$ (Vinodchandran, 2005), and $(MA \cap coMA)/1$ (Santhanam, 2007). All of these are indeed known to not be in $SIZE(n^k)$ for each constant $k$. 

I'm not an expert in this area, but I think the random SAT / phase transition stuff is more or less completely unrelated to the industrial/practical applications stuff. E.g., the very good solvers for random instances (such as $URL$ are based on the statistical physics methods (belief propagation etc.) I believe, whereas the very good 'general' solvers (such as $URL$ are using unrelated techniques (more like what Kaveh was talking about) I believe. But, as I said, maybe don't take my word for it; this is coming from a definite non-expert. 

I think a good test case would be to generate random uniquely satisfiable 3XOR instances (planted instances) with $\Theta(n)$ constraints and then convert them to 3SAT instances. 

Perhaps you want what's sometimes called "Chang's Lemma" or "Talagrand's Lemma"... called the "Level-1 Inequality" here: $URL$ It implies that if $1_S$ has mean $2^{-d}$ then the number of linearly independent Fourier coefficients whose square is at least $\gamma 2^{-d}$ is at most $O(d/\gamma^2)$. (This is because an $F_2$-linear transformation on the input does not change the mean, so you can always move linearly independent Fourier characters to degree-1.) 

There is a more complicated theory of duality for SDPs that is exact: there is no 'extra condition' like Slater's condition. This is due to Ramana. (For another take on this involving SOS, see [KS12].) To be honest, I've never tried to understand these papers and would be happy if someone dumbed them down for me. One notable consequence of this work is that the problem of testing whether a given SDP is feasible is in NP if and only if it is in coNP. (However, I think the experts expect the problem is in neither. The best upper bound known is PSPACE.) 

This 2009 survey by Daskalakis surveys the complexity of computing Nash equilibria. His previous work with Goldberg and Papadimitriou demonstrated that exactly computing such equilibria is PPAD-complete. This is not as strong a statement as if the problem were NP-hard, but still provides evidence that computing Nash equilibria is intractable, throwing into doubt the predictive power of Nash equilibria. One salvation would be to demonstrate a PTAS for $\epsilon$-Nash equilibria for desired accuracy $\epsilon$. But the current best is an non-oblivious approximation algorithm that runs in time quasipolynomial in $1/\epsilon$. 

Discussion: I've been spending some personal time lately learning various things in communication complexity. For instance, I've re-familiarized myself with the relevant chapter in Arora/Barak, started reading some papers, and ordered the book by Kushilevitz/Nisan. Intuitively, I want to contrast communication complexity with computational complexity. And in particular, I'm struck by the fact that computational complexity has developed into a rich theory of placing computational problems into complexity classes, some of which can be in turn (from one perspective, at least) envisioned in terms of complete problems for each given class. For instance, when explaining $NP$ to someone for the first time, it's hard to avoid comparisons to SAT or some other NP-complete problem. By comparison, I've never heard anything of an analogous concept for communication complexity classes. There are many examples that I'm aware of, of problems "complete for a theorem." For instance, as a general framework, the authors might describe a given communication problem $P$ and then prove that a related theorem $T$ holds $iff$ the communication problem can be solved in $X$ or less bits (for some $X$ that depends on the specific theorem/problem pair in question). The terminology used then in literature is that $P$ is "complete" for $T$. Further, there is a tantalizing line in the Arora/Barak communication complexity chapter draft (that seems to have been removed/tweaked in the final printing) that states "In general, one can consider communication protocols analogous to $NP$, $coNP$, $PH$ etc." However, I notice two important omissions: 

In addition to ArXiv, you could subscribe to the Electronic Colloquium on Computational Complexity. It gets a lot of traffic from current research, and the email updates you receive are normally a succinct format of paper title/author(s)/abstract, so you won't have to invest much time to see what's just happened. 

No, and many practical languages are not context-free. For example C++ grammar is not, because in some contexts grammar resolution depends on typing information that is not context-free. 

Given an $m \times n$ matrix ($m$ rows) containing only $0$'s and $1$'s, what is the complexity of finding an $m \times k$ submatrix (of $k$ columns) such that within the chosen submatrix there is no row containing only zeroes, in other words, every row contains at least one $1$? For example, given the $4 \times 3$ matrix $\begin{bmatrix} 1 & 0 & 0 & 1 \\ 0 & 1 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ 1 & 1 & 0 & 1 \end{bmatrix}$ a subset of $k=3$ columns that fails to fulfill this condition is that of the first columns, as the third row has all zeros within this submatrix, but the column set $\{1, 3, 4\}$ would be a solution. I suspect this is a hard problem, but I haven't been able to find a direct reference. I'm interested in this problem because of its applications in cryptography. 

A classical result from automaton theory shows that even the problem of finding minimum-size DFA consistent with given positive and negative samples is NP-hard. This was shown by Gold in 1978. Your problem is much harder, as in practice you would have to learn data relationships in addition to any finite-state control of the system interface. 

If your LTL definition includes the "next" operator, then the following applies. You have two sets of traces $A$ and $B$ . Let $b$ be any finite prefix of a trace in $B$. $b$ must also be a finite prefix of a trace in $A$, because otherwise you can convert this to a formula that is just a series of next-operators that detects the difference. Therefore every finite prefix of a $B$-word needs to be a finite prefix of an $A$-word and vice versa. This means that if $A \not= B$, there needs to be a word in $b$ so that all its finite prefixes appear in $A$ but $b$ in itself does not appear in $A$. If $A$ and $B$ are generated by finite transition systems I think this is impossible. Assuming infinite transition systems, you can define $A = \{a,b\}^\omega$ and $B = A \setminus \{w\}$ where $w$ is e.g. the infinite word $aba^2b^2a^3b^3a^4b^4\cdots$. Any LTL formula that holds universally for $A$ will hold universally for $B$ because $B$ is a subset of $A$. Any LTL formula that holds for $B$ also holds for $A$; for the sake of contradiction, assume not, but that $\varphi$ holds for every element of $B$ (i.e. for every element of the universe expect for the word $w$) but not for $w$. Then $\neg\varphi$ evaluates to true on $w$ but not on any other word of the universe (and LTL is closed under negation), and there is no LTL formula that can be true only for $w$ as every Buchi automaton that accepts only one infinite word must be strictly cyclic whereas $w$ is not.