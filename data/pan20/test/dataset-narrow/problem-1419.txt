If you're prepared to do some pre-processing and eat the storage cost, then partitioning voxels into connected groups at build time gives an obvious answer to 'is there a path at all'. There is a path between two voxels if they're in the same group. The problem with that obviously is that you have to store group information somewhere, and that depends on your data layout. If you're storing a simple list, you can just break that into multiple lists, one for each spatially connected group. If you're organising in some kind of BVH, then you could probably get some reasonably good efficiencies if you can say "all voxels in this node and below belong to group X". Alternatively, you could do some spatial pre-partioning and store some smaller set of 'hub' voxels for each connected group. Then you can path-find from your source and target voxels to their nearest hub voxel, which should be a much shorter / cheaper to calculate path. If you can find a path from a voxel to a hub voxel, then the voxel is part of the hub voxel's group. With smart selection of those hub voxels, you can minimise the number of path traversals. E.g. a sphere might have just one hub voxel in its centre, but a long thin group might have a hub voxel every X voxels along its length. If your source and target voxels are at either end of the length, they only have to go at most X voxels to find a hub, and even though there might be a huge number of voxels between the start and end of the length, the pathfinding involved would be relatively short. It all depends on just how pathological your voxel groups are: if you expect a huge number of smallish disconnected groups, the increase in storage cost is going to massively outweigh the performance hit of just pathfinding. If you expect relatively few connected groups but of odd topologies, then naive pathfinding might be hugely expensive and the storage cost and minimal pathfinding is a much cheaper option. 

Fundamentally you're on the right track - you need to know how long an animation lasts to do this sort of thing. Animations are more than just a collection of frames, there is all sorts of other information around them that you need. E.g. how many frames are there, does the animation loop, how quickly does it play back (e.g. 10 animation frames per second or 25, or 60?). Every animation can be defined in terms of a few pieces of data, which some generalised animation code can look at and play back. You should be encapsulating the animation part in its own bit of code, which is aware of nothing except these animation definitions and how to display the individual image frames. That is, have an animation object which you can load, start playing, stop playing, and tell to render at a particular location on screen. A flexible approach is to use a sort of animation definition to encapsulate this sort of information. So rather than just saying "animation X is all of these frames, just play through them", you get something a bit more complex. E.g. with some sort of mocked up data format 

In every case where I have some bare bones geometry rendering but no real infrastructure, it's been something simple and obvious, and the geometry rendering part has actually been fine. Check: 

It seems to me that you're trying to achieve a graceful co-existence with other processes on a PC game? I.e. to not occupy the entirety of the CPU all the time, so as to allow other processes to run (and if you're running on a laptop, to allow the speed-stepping to power down the CPU and preserve battery life)? I've certainly tried to achieve this in the past, and never fully settled on a solution I liked. I never tried Crowley9's method of using the DONOT_WAIT flag, but to me that smells like closer to the right solution. If Present only blocks when the present can't be queued (because there's already another present queued), then you don't need to call Present 'just before' the VSync happens, you just need to sleep until it's likely that another call to Present will succeed (which will be any time after the next VSync). The root problem is that you don't really know when the VSync occurs, and a system like that needs to stay synchronised. The basic gist of my solution was: don't use Present to find out where the VSync boundary is, do the timing yourself, and make sure you're calling Present as close to the appropriate time as possible. If you're late, it won't matter because of the internal buffering D3D does, and if you're early then it will simply block and the worst you'll incur is some extra CPU usage. What I did do was to use (microsecond accurate) timers, track the elapsed frametime, and sleep accordingly. There's no magic flag or function I know of to say 'wake me when VSync's about to happen', because there isn't an event available that is signalled when a VSync is about to happen. So instead I looked at how long the frame had taken so far, figure out when I thought the next VSync would occur, subtracted a grace period (I think I left 3ms), and call ::Sleep. E.g. if the frame processing took 2ms, I would get to the Present call early. If I called it straight away, I'd expect it to block (at 100% CPU) for 14ms. Instead, I call ::Sleep(11), and then the subsequent Present only blocks for ~3ms). If the frame processing took longer than 13ms, I'd just call Present without sleeping. If it took longer than 16ms, I'd switch down to 30Hz rendering (with some hysteresis), and adjust the Sleep timings accordingly. BUT I was never particularly happy with this solution, for several reasons. If you're running on a loaded system, Sleep is by no means guaranteed to give you control back in that 3ms window, you have no good control over the OS time-slicing. Worse, the minimum sleep time is supposedly 10ms, anything less than that and it ends up sleeping for 10ms regardless of what you specify (in practice it's way more variable than that). So you also have to track how long you actually slept for, and factor that into your logic (so you avoid sleeping if you're running late). And then you end up calling Present late one frame, then avoiding the sleep the next frame and calling it early the next. E.g. 

This gives you, for any input position of x, what image should be underneath that position, and how far from the left of the image that position will be. When you're scrolling to the right, what you're really doing is moving a sliding virtual window along this infinite number-line, so that at any given point in time, your camera is showing the region between and . What you actually need is to know which backdrops are visible given your current camera position, and where they are relative to the screen. So you still need to iterate over the set of images you have, even once you know the starting position. 

Assuming that you're using OpenGL ES because you're on a mobile platform, I'd say that any rendering technique you use should avoid trying to use alpha, for performance reasons. On a system where fill-rate isn't the limiting factor, you can get some lovely looking effects by using alpha planes and animating textures. With that in mind, you're best off making long, thin opaque raindrop polygons (either lines or elongated droplets). You can probably make them alpha if you want, as they'll only be a couple of pixels wide and so won't cost that much fill-rate. But you're going to need a fair amount of them. The best performance would be to simply have one drop poly and just render it multiple times, but that might look a bit weird. You'd probably get better results having a few droplet polys of differing lengths. So each droplet is a vertical streak placed somewhere in your scene, and you want to animate it downwards at a relatively constant velocity (maybe < 20% variation in speeds between droplets), starting from offscreen at the top (so you don't see it pop into existence), and moving along its long axis downwards until it hits something at the bottom (the floor, an object bounding box, etc.). Doesn't have to be straight down, you can angle the rain as well to simulate wind. I'm also going to assume that although you say '2D side scroller', what you actually mean is some sort of faux-3D effect (think Streetfighter or Double Dragon), as I don't think I've ever seen a 'pure' 2D side scroller. That means you've got some sense of perspective on your scene: even though you can't move in 3D, the scene you draw has some sense of back and front, with the player somewhere in the middle. With that in mind, you probably already have 'layers' in your rendering (first you draw a backdrop (far away), then you draw things which are nearer but still 'behind' the player, then you draw the player, then you draw things which are in front of the player. Each of those layers will have some notional Z distance, but more importantly, they will each have a distance up the screen where the floor is (sort of a perspective effect). So items in the front-most layer have a floor at the very bottom of the screen, but the layer containing the player has a floor some distance up from the bottom of the screen. So every so many frames, a new rain droplet will be spawned into a layer, at a random horizontal position, and the droplets should be randomly distributed between the layers. You track the droplet by where its lower edge is, and when it hits the floor, you want to start clipping the lower edge of the droplet (so the top of the droplet continues to move downwards, and the drop itself gets shorter and shorter until it disappears). Once the droplet is completely gone (the top edge has also hit the floor), you remove the droplet from the simulation. You don't really need a full fledged physics engine for this, because the raindrops probably don't conform to natural physics anyway (they just spawn, move in one direction, then die once they hit something). Detecting when they hit something should be straightforward if you are following normal conventions of making a 2D side scroller. 

The historical reason for this is somewhat different from the current reasoning - previously it was to have a 'safe' screen to go back to which was always resident in memory, so that if the game had gone to a demo loop and the player touched the controller, it could instantly return to the start screen and let interaction commence with no delay. However typically these days it serves another purpose. For recent generation consoles, the start screen is deliberately user-agnostic. Nothing on the start screen requires knowledge of which user is actively playing the game. You get to the start screen without loading any save data, and without requiring a user to be logged in. So you can get to the start screen quickly and without having to show any TCR compliant messages. Requiring the user to press start gets you a key piece of information: which controller is the primary controller. It's not necessarily the first or only controller connected, and you might have several equally valid controllers to choose from. You don't know which one the user has actually picked up though until they've pressed a button on it. Once that controller is used, it will remain the primary controller for the rest of the gameplay session. On XBox 360 (and most likely other consoles), finding out what the primary controller is also typically gets you another bit of information: which user is playing the game. Because each user is bound to a single controller, you know which user is playing, and from that you know which save data to load. Many / most of the content is bound to specific users, so it's important to determine who is playing the game before continuing. If no-one is logged into the console, games will typically prompt at this point for a user to log in, or ask if the player is happy to play as a 'guest', i.e. without saving (because with no user, there's nowhere to save to). You'll also find that, typically, changing users (by signing out and back in) will cause you to return to the start screen. This is because the relevant user-specific data is loaded after this point in the game, and the start screen is the easiest point in the user interface flow where you know exactly what data is loaded (none). 

Octtrees (or even just quadtrees) and Kd-trees are both good general purpose spatial partitioning schemes, and if your build pipeline and/or engine is generating them, then you will find they come in useful in all sorts of different ways for optimising queries/iterations. They work by sub-dividing a fixed volume in a hierarchical way, which makes queries like raycasting into your object space very cheap to query for (great for collision checks). Bounding Volume Hierarchies work in a slightly different way (they aggregate the volumes of the objects in the tree rather than sub-dividing spaces), and are a simple way of trimming unnecessary things from being iterated over. But because BVH doesn't put any restrictions on how two sibling nodes are related, it's not such a good scheme for figuring out rendering order, or for arbitrary collision queries. BSP systems are good when you're subdividing the world based on individual polygons, but for larger objects a volume based approach makes more sense. Above all though, it's worth noting that none of these systems are perfect for determining render order for transparency, even the BSP approach. It will always be possible to construct geometry which breaks your algorithm, unless you are able to subdivide polygons on the fly. What you're most likely looking for is a 'best effort' solution, where geometry can be ordered correctly in the majority of the cases; and the art team can subdivide models for any of the cases which don't work (because the model/polygons are abnormally large, long, or self-intersecting). Smaller models/nodes are always much easier to sort 'correctly', but you pay for it in terms of iteration overhead. Kd-trees and Oct/quad-trees are both good general purpose solutions, for which a platform friendly implementation can be written, but in the end you are going to have to balance the depth/complexity of your spatial partitioning tree against the cost of iterating it, and the overhead per model (i.e. draw call cost). If you're targetting XNA, I'd recommend you keep it simple and high level, and if there is sorting problems with some of the content, then strongly consider changing the content before trying to improve your engine until it can cope with it; the returns diminish very quickly after the most basic render sorting is implemented.