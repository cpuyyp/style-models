Why are you using ? Why not just ? See perl's documentation on Finally, you can simply (and elegantly): 

You could run the following bash script. It will expect the list of schemas in the file, and your script in . It will run the script on each schema (as a default schema) in , and will produce, for each schema, a file named . For Unix, the script is: 

You could reduce that index even further by using a smallint calculated as the difference between a set date (e.g. 1/1/2010 +- 32768 days = Apr-1920 to Sep-2099): 

Your software is most likely not using the default database (that is a database that is normally reserved only to store the list of databases, users, and other globals). From psql, run to list the available databases. Your database will be something other than postgres, template0, or template1. Try connecting to one that is not one of the above () and then run again to list tables. 

You could significantly speed it up further if you have a fixed list of values that range in the dozens (or low hundreds), by turning the type of the column into an enum. You'll have to drop indexes that use this column prior: 

I found that your query had many redundancies in the conditions, and you used cross joins that were good candidates for simple joins. This might confuse the planner. Perhaps you could try the following rearrangement of the query (it is functionally exactly the same but uses joins and removes all the redundant comparisons) to see what the planner comes up with in both production and test? 

You could create a third table C, with a primary (or unique) key defined in it, and create before each row INSERT, UPDATE and DELETE triggers in both of your tables A and B that insert, update or delete their key into table C. You could use table C for foreign keys also, if you need to. 

All of the options above have a significant performance impact. A possibly better performing option could involve a table for this purpose: 

The query retrieves all the rows with unique fields (by ), prioritising the version you specify, or the draft one (which has its priority bumped to the top). If you want the draft or last version, then use instead of . 

Backups from a normal user are a nightmare. If you're using PostgreSQL on Linux, I'd recommend relying on (and the file) to accomplish this, so that a given specific user can with specific parameters, so that's all they can do as user (and therefore have no write access to the database). 

we are using vb application -- which will use ODBC connection to connect database - here no problem when we run the application -- while saving the data it returns database timeout error 

First it with one server now i am receiving more three server same issue NOT with one application we have another vb application I check is there any deadlocks or locking objects -- nothing is there I checked database log,windows log and Event viewer Before that it was working fine and superb Suddenly from last ten to fifteen days it is giving this errors Your help will be appreciable 

I have scenario Daily i run a sql job to apply a new updates to one table - this job will create one text file daily - text file contains all new updates I can send a mail to client that job is successfully completed - now i need to send him a text file as a attachment Is there any way to send attachment through GUI (SQL Server Job setting) I cann't run the script 

Two days back our client changed one of our Dev Server name After Server Renamed, All my maintenance jobs and other jobs are failing because server name mismatch. We are using sql server 2012 version and server 2008 OS So today morning i renamed my Sql server 2012 name to updated given name and made table, procedures updates I tried to update Local server connection in maintenance job but it is uneditable. Then i added new server connection,still no use i am getting below error, while executing jobs. After i tried with target page in jobs property option, there also only target server is selected and multiple target server is disable. Error below Executed as user: NT Service\SQLSERVERAGENT. Microsoft (R) SQL Server Execute Package Utility Version 11.0.2100.60 for 64-bit Copyright (C) Microsoft Corporation. All rights reserved. Started: 12:01:28 AM Error: 2013-12-16 00:01:43.98 Code: 0xC00291EC Source: {410F7661-F71A-4B68-9584-BA422AB00F02} Execute SQL Task Description: Failed to acquire connection "Local server connection". Connection may not be configured correctly or you may not have the right permissions on this connection. End Error Error: 2013-12-16 00:02:00.00 Code: 0xC0024104 Source: Territory_Update Description: The Execute method on the task returned error code 0x80131904 (A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: Named Pipes Provider, error: 40 - Could not open a connection to SQL Server)). The Execute method must succeed, and indicate the result using an "out" parameter. End Error Error: 2013-12-16 00:02:15.00 Code: 0xC0024104 Source: {4E2AF328-0B8D-4905-83BE-839FDDEFC09C} Description: The Execute method on the task returned error code 0x80131904 (A network-related or instance-specific error occurred while establishing a connection to SQL Server. The server was not found or was not accessible. Verify that the instance name is correct and that SQL Server is configured to allow remote connections. (provider: Named Pipes Provider, error: 40 - Could not open a connection to SQL Server)). The Execute method must succeed, and indicate the result using an "out" parameter. End Error DTExec: The package execution returned DTSER_FAILURE (1). Started: 12:01:28 AM Finished: 12:02:15 AM Elapsed: 46.641 seconds. The package execution failed. The step failed. Help me out in this guys, Thanks in advance 

Also, for inner joins, it is clearer if filter conditions that are not strictly part of the joining condition are specified in the where clause rather than the join, for clarity and for making debugging easier. Finally, even if it doesn't affect the final plan, for readability and clarity I place in the FROM whatever table it will be the "carrier" table, i.e. the one that will take the biggest filtering effort, and "hang" from it all the dependent ones, like small master tables, since I find it easier commenting these out for debugging. 

SQLServer can't work without a master database at all as it stores essential configuration information in it (such as the table of databases in the system), so it wouldn't allow you to detach it. However, provided the SQLServers being the exact same version, you'll probably run into no problems if you stop the SQLServer services in both ends, copy the master database files from the one system to another (keep the old ones just in case), and start the services agan. It will be safer if neither server has any other databases in the system. 

Something like that could be achieved through dynamic sql, or via using stored procedures instead of views (for selecting) or triggers (for controlling inserts/updates).alter But you can also create the memberview to return values according to the currently logged on user, which is probably more practical: 

Another advisable strategy would be separating this query in parts, using temporary tables, step by step. This is not necessarily faster, but convenient for finding problems with the selection logic, or using a strategy that best suits our own knowledge of the data: 

PostgreSQL can only make use of a function index when the comparison is against the results of the function, e.g.: 

Note that casting to is faster than the slution by @Sole021, but it is not UTF8 compatible (or any other encoding for that matter), returning simply the first byte, so should only be used in cases where the comparison is against plain old 7-bit ASCII characters. 

I had a really odd and unexpected behaviour in PostgreSQL. Debugging I found that the problem only occurred while including inside a function, and by using an alternative (in this case, I resorted to an array) the error would be gone. Perhaps any one experienced a similar error or knows what this error relates to? I might need to create temporary tables in functions sooner or later. I'm porting an old Delphi XE6 program from a legacy proprietary database to PostgreSQL, changing the TxxTable components (proprietary) to TFDTable ones (FireDAC) pointing to a copy of the database in PostgreSQL 9.5. Things were working peachy until I created this plpgsql function that inserts and updates some data here and there. I ran the function via , where is my TFDConnection to PostgreSQL (same where I have many other tables open and working well), is the function in question, and is an ID I send as a parameter. The function runs well, as it does when running it from PgAdmin, but the connection becomes unstable as any already open table afterwards trying to do anything (insert/edit/move) will raise the following error: