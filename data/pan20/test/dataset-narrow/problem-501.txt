There are three things I see as being significant issues with your code, and also a suggestion about your method's name. Orphaned Else When you have an if-statement with a guaranteed return in it, there's no need for an else-block. Your code would be better as: 

Multiline text processing takes some getting used to. First up, if you are going to do multiline processing, then you should read all the data in to a String, and forget about Scanners, etc. 1-line-at-a-time processing is convenient for many reasons, but mostly to reduce the amount of data in memory at any one time. Consider the following: 

I put this together in an SQLFiddle Bug When I compared my results against yours, I found my index was off-by-one. With the input you gave, I get the first index at field 6, but you have output showing field 7. I have manually gone through the parsing, and I am sure field 6 is right.... so I think you have a problem ... ;-) 

Note that the is an and not a ... use the highest form of the instance where you can. Declare variables where they are used.... You declare the result variable outside the try-block. This is because of how you do the error handling and you may want to return it when it has an empty value. This is not the best solution though, I would have: 

This is a bit of a pre-Java7 cheat I use. It is safe to close the inner stream, and let the outer Readers (BufferedReader,InputStreamReader) not be explicitly closed. In Java7 I would put them all in a try-with-resources, but, Android, alas!. With the above code you don't need to worry about closing the stream at all inside the try block. OK, so now the try-block is simple, I would put two conditions (the readLine first!) in to the read-loop: 

The actual apply method is not very robust though. I would include logging of any potential exceptions that are not declared to be thrown on the function itself...: 

There's two style comments, and one logic comment. The logic comment is the most significant.... you can rewrite your query as: 

Then, we have the 'worker' thread pool that processes the actual jobs, and a logger thread pool that awaits (and logs) the terminations.... 

Currently there are two answers to this question, and I am not happy that either solution is ideal. The initial question has a method with the signature: 

Your solution is, in fact, conceptually quite clever. There are some style issues, some bugs, and some optimizations... So ... Magic numbers You have the prepared list of primes, and you declare the array as length 3402. Why specify the length when if you leave it blank, the compiler will do it for you? Anyway, when I counted, there are 3401.... 

As per Bobby's comment, Vector is your problem, but not for the reason he says... Vector is a synchronized class. Each call to any method on Vector will lock the thread, flush all cache lines, and generally waste a lot of time (in a situation where it's usage is in a single thread only). The fact that you use Vector indicates that you are running some really old code, or you have not properly read the JavaDoc for it. A secondary performance problem is that each value is being converted to a Object. In cases where you have large amounts of data, and where there is a primitive available for you to use, it is always faster to use the primitive (in this case, instead of ). You should also be using the Java7 try-with-resources mechanism for your . My recommendation is to change the signature of your method to return a List... actually, no, my recommendation is to return an array of primitive .... if you are interested in speed, this will be a significant improvement: 

Atomic operations are fast, but they are not free. Additionally, since you are using the same atomic count in both the put and get, and also, since both put, and take lock both and (and access count), you are not actually accomplishing the stated goal of "i.e using two locks so that my take should not block my put." Your take does block your put, and visa-versa. In my experience, the value of is not related to the fact that it is in the concurrent package and "new", it is in the fact that the cost of a double-barrier (lock/unlock) when amortized over a long-running piece of code (which your code is not), is worth it for the cool features (like multiple signals on one lock instance, or in-the-middle-of-execution unlocking). You do neither of those things. Your use of the ReentrantLock is basically just slowing you down, and making your code complicated. Additionally, what you see as an 'optimization' for only notifying the other method if there is something new, is actually just slowing things down too. Your code would be simpler, and faster, and more concurrent with traditional synchronization... 

When running your code through the go lint-checker, it reported a number of problems in addition to the above (though the above code is what prompted me to run the lint checker): 

In exception handling: throw new IllegalStateException("Failed to process " + value); for logging program progress using things like log4j. when the JavaDoc for the toString() Method for the class you are using defines a specific, and non-alterable format for the result. e.g. String.toString() or Integer.toString(). If the class you are using does not specify what the toString() returns, and does not guarantee that it won't change, then create your own way to present the data. 

Matching Anagrams Your code is not matching anagrams. Your code matches words with the reverse of the word. An anagram is any rearranged form of the word. So, you have and in your list, but it should also match . Your code will not do that. The trick to solving this problem would be to reduce each word to its sorted array of characters. For example, to have a function like: 

Sometimes it is a good idea to abstract this sort of problem. In many languages doing array-based shifts is very expensive. Do you need to rotate the array? Why not just virtually 'rotate' your pointer.... 

This static class removes the need for the back-references to entirely.... The new iterator is called simply with: 

It's better because it stops streaming when the first problem is found - it does not need to check everything. String joining 

First thing I would do is separate the two concerns you have in the POST method. The POST method should have a different name (since does not match Java conventions), and the signature should be something like: 

there is no need for the labelled loop . Th places you use the label, you have , and those can simply be replaced with . You read a single byte at a time from the InputStream when you are processing the headers. This is really slow (especially since the input source is from the network, where the network stack is often not very fast for small requests). You need to create a buffer, and read a chunk of data at a time. When the data is in the buffer, you need to be smart about how you loop through it, looking for the newlines and header-end sections. This code is probably quite accurate, but could be simplified: 

It has been a while since I messed with SQL Server procedures, but, in principle, I don't mind your solution. The while loop is not set based, but that is not insanely slow, either. For a limit of 20 fields I don't see it being a real problem. SQL often ends up being a cacophony of copy/paste, and a set-based solution using raw operations is possible. @ckuhn203 has shown that. I am not a huge fan of all the UNPIVOT and other operations though. I would consider a much simpler (though heavily copy/pasted) version: 

Well, the problem statement is broken. Maybe this is a trick question? In the situation that the value to be inserted is at the beginning of the list (perhaps the list is empty, or the value is small), then you can't successfully control the changes needed to modify the head reference for everyone who has it. The code you have implies that the possibly new head is always returned after each call, but you run a risk of creating multi-headed lists with multiple heads, if the code outside your function does not do the correct assignments with the head. That sort of risk is not acceptable in a Java library/function, and thus your encapsulation is wrong, etc. In front of an interviewer, I would recommend that you say something like: "Well, this function would not be useful in a Java context, the data should be encapsulated and the node should not be exposed to the user. The function should have no return value, and should not take in the node as a parameter, but instead the function should be a method on a class that encapsulates a sorted list" Having said that, though, and looking at your code, your code does as good a job as can be done in the circumstances, and it has good style, naming, and formatting. If I was really picky, I would suggest that you reverse the if/else condition: 

if you use the StringBuilder approach (which is OK), then you should at least initialize the size of the internal capacity so that resizes are not needed later (for performance reasons). Use While looking at that, why have the variable name ... that's a poor choice. Consider using a array for the reverse as it reduces some more overheads (again, performance). StringBuilders are useful for many things, but their biggest benefit comes from their dynamic nature. In this case, that nature is not needed. 

Input Validation It is common in Java to validate the inputs. You should have this as your first lines: 

Now, using those loops, you have a basic sieve of Eratosthenes, where all true values left in the sieve are primes. If the sieve is large enough, and you count them as you find them, then you can pull the Nth prime easily. Note that the basic algorithm can be optimized in a bunch of ways. 

Here, you have a canonical constructor calling a convenience one . I would prefer the opposite, and have code like: 

This will significantly improve your performance for large lists. The performance of this option will scale in terms of \$O(n^3)\$ which means each time you double the input data size, you will take 8 times longer to compute a result. Wiki Version The second method uses the wiki algorithm, which is also the base of the algorithm I would recommend.... The Sort will take \$O(n \log{n})\$ time. For largeish lists the log(n) can be effectively ignored.... What's interesting here, is that you loop to the array size still in the loop. You can actually limit the outer loop to valeus less than or equal to 0. At least one of the values has to be 0 or less in order for there to be a zero-sum. Similarly, once you have a second number, chosen from values after , you should then be able to do a binary-search for the third number. 

The logical reading of that order is better, take this collection, map to that collection, and use this function to do it..... maybe it is not such a big deal...? The use-case seems to read better for me: 

The above code (included in a function) will encode each char to a key, and unmapped chars will return 1. 2. In memory lookup A second common way to do this is to prepopulate an array with the indexes for each char: 

I am not convinced that your 2-liner is as horrible as you make it out to be. It is relatively clear, and well structured. Do you really want to go in to the realm of regular expressions for this? If you make your 2-liner a function it becomes even better: 

don't select columns you don't need (the is bothersome) you should restrict the data much further before you start. The Oracle schema views are slow, and you should limit your schema selection in the first CTE, and then join that to the views for subsequent selections. order-by clauses in the CTE are often unnecessary. 

Since you are using printf to output the spaces, you may as well use a specific printf format for the output. Here's a replacement function: 

The math behind combinations is relatively simple. There are \$n\$ members in an input set, each member is either in the output set, or not in the output set. Now, because there is a 'binary' condition (either in, or out), you can think of the problem as follows: If there is just one input member, then that member is either in the set, or not. There are 2 combinations, the empty set, and the set with that one member. If we add a second input member, then we can have the same two combinations of the first member, but then we can also add the second member to the output, and get another two combinations. As follows (for the input data {a, b}): 

JDBC has always been a PITA when it comes to handling/closing resources. One of the big advancements in the past while has been the advent of ConnectionPools and abstraction layers.... If you are inside a framwork like tomcat, or WebSphere, these are built in. Otherwise you can use things like Apache DBCP or C3PO. For both of these frameworks, when you close the Connections it closes any created Statements. Using a pool like this allows you to trust in the pooling layer... but, I would still recommend that you use a 'clean' implementation for your code. What I have used in the past, and I think is the neatest method, is to have an abstract class like: 

The above variables should all be final too. Also, there's an uncomfortable mix of the "old" -based system, and the "new" based one. I recommend that you use , and stick to it. Simplifications This code is.... ugly. 

And then you can reference these micro-tasks from many places, perhaps even doing a static import on the class. 

The algorithm you use is OK, start at the end, and work backwards, add 'stubs' to a List, and combine them as needed as you come back up the stack. I don't like the sheer number of ArrayLists your create. Also, you are doing a lot of String concatenation. Your algorithm would be a lot better if you: 

Note how we simply add the data to the tree structure. The special note I have there is that the above code only supports input data where the parentID is always added before any child Id's that use that parent. If the data comes in a different order, it will fail with a NullPointerException. There are ways to alter the code to create a "phantom" record for parents that have not been added before, though. Since your example data is compatible with my suggestion, though, I'll leave that up to you. Now, once you have that tree structure right, the way to get all the descendents of a node, is simple: 

Why is that still there? Why have you not fixed it, or removed it? Now, your tool should also then be pointing out other a bunch of other issues that you are obviously ignoring.... why?