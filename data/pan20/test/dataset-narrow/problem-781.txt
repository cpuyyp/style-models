Try turning on error_reporting(E_ALL); and point your browser to the image URL. Comment the type header to see any error messages that may be hidden if your browser only displays a broken pict message. And fix that missing semi-colon Ben mentioned. Edit: And sanitize $_GET['src'] you may be opening a big security hole there. 

KVM for production is OK. Having a bunch of Windows and Linux VMs, including Remote Desktops, Databases (MS and MySQL), Router, Firewall, even Backups (guest to guest) and everything is running fine. What I like about KVM is the ability to scale management layers. I actually prefer managing the lot I have without libvirt, adjusting (and learning about) every single parameter kvm/qemu accepts. Others use the libvirt based tools and if you need full scale cloud management, there's Open Stack and friends. There are some settings to stay away from, though. Use the default cache=writethrough, do not enable native async, and stay away from qcow, qed or whatever file formats. Give your machines LVM volumes. 

My understanding of SCSI timeouts is that any read, write, flush and other commands have a limited time to complete. If exceeded, the command is aborted and an error is reported to the upper layer. While waiting for the command to complete, any application depending on the I/O will stall. My next layer would be mdraid, the Linux software RAID. From what I read, mdraid has no timeouts on its own but relies on the lower layer to timeout commands. The default SCSI timeout value is 90 seconds for Kernel 3.2 (Debian). A hard disk encountering a read error will try hard to correct the error within a time frame defined by firmware. That timeout is set high for desktop drives (typically stand-alone, so correction has high priority) and low for server drives (typically RAID, so report bad sector soon, let other drive answer). Sometimes it can be adjusted via smartctl (SCTERC, TLER, etc.). So I guess if an HDD is set to a high ERC timeout, kernel will wait for 90 seconds by default before aborting the request. Only then will mdraid redirect the application's request to another disk. 90 seconds is a loooong time for a webpage to load. Is it correct to assume the default SCSI timeout is meant for desktop purposes or non-hdd SCSI equipment (tape drive, tape library come to mind), and safe to tune down to, say, 7 seconds for RAID usage? 

Only few programs can use SOCKS Proxies natively. Some programs can be forced through the Proxy, though, with tools like tsocks. Nice alternative: Create tunnels listening on 127.0.0.X, X starting at 2 and being increased for every server, and edit hosts accordingly. 

You'll pry notice I have a couple routes specified on the main table when I setup the macvlan interfaces on eth1. I have a couple other routers on the same cable provider as my main server. They VPN back to the main server while the BigPipe is used for everything else (on the main table). The "t_" scripts are used to setup the individual rules and tables for the various services/clients that used the IPs setup by the macvlan interfaces. Simplified, they look a little like this. 

So putting that all together and as a quick recap, I've got the main server using 8 public IPs (4 on BigPipe and 4 on CBL). One of the BigPipe IPs and one of the CBL IPs are used for VPN services effectively creating a "ghetto internet exchange" if you will. That routing configuration exists on the main table. Then the remaining 6 IPs are used by various services or clients and those tables are frontdesk, pubwifi, mail1, scansrvc, jenkins4, skynet, and lappy386. I am masquerading on all public IPs to the various internal subnets. Here's where I just am dumbfounded... It all works until it doesn't. Meaning, when I startup the server everything gets setup correctly and I am able to see that the routing policies are doing what they're supposed to be doing. So, on scansrvc, which is a VM on the main server but with an internal ip (172.23.1.6/20) 

I have a server (ubuntu/debian) with two ISP connections. Both of these WAN connections have multiple public IP addresses. 

On eth0 I have 4 IPs assigned to me that are a part of a broader /24 subnet. 24.xxx.xxx.xxx/24 On eth1 I have 5 IPs assigned to me but here I am the only one on a /29 (the 6th IP is the gateway I hit) 71.xxx.xxx.xxx/29 My goal is to setup source/policy based routing so that VMs/clients on the various internal subnets (there are multiple actual VLANS on eth2) can be routed out to the internet on any specified WAN IP. Here's what I've done so far. First I have eth0 and eth1 configured in the interfaces file. 

From what I understand so far about martians, my hypothesis is that having multiple interfaces on the same subnet could be causing packets not meant for an interface to be sent to that interface... somehow... (I thought since they've got different MAC addresses that would be alleviated) What would cause this? Why when I freshly boot the system and the VMS will the setup work until all the sudden dies after a while? (Ex. if I leave a ping running to 8.8.8.8 on the scansrvc VM I'll get 100-1000 responses back before it dies) Could this be something with the ARP cache? It's not like I'm reassigning any IPs to different MAC addresses mid-flight. I'm stuck. I'm going to start to learn some tcpdump skills to try and shed some light on something I'm perhaps missing. If anyone that's better versed in networking setups could point out anything I'm missing it'd be a huge help! :) 

I'd like to add another, maybe more scary perspective on obfuscated URLs like this example. Even if your URL is not accidentially shared, it may be submitted to search engines by: 

Server not found means DNS resolution failed. Check your DNS. Do you have both www.domain.tld and domain.tld setup? Do the IPs appear in access.log? 

Using link-local addressing seems to be the only valid option. What most suggestions here ignore is the fact that the IPv6 prefix declares scope, and I would not want my presumably private addressing to be in global scope. So for Linux: 

D) A VPN solution would be superior in that it can be used for more than one service. But you'd have to bind the service to an internal IP which may become available only after starting the VPN service, thus complicating startup sequence. 

Unfortunately it does make sense, but I don't see how the card has much to do with it. The 5V / 12V line is provided by the power supply, and the drives might be drawing on 5V, which may be underrated or non-existant at all. So the drives won't spin up when the card tells them to. If you are very lucky, you only need to enable staggered spin-up in the card BIOS to lower the peak power consumption (you wrote it sometimes does boot). If that works, perform a random write load test before doing anything productive. I looked up your power supply, it's 560W which is a really low total (2U storage chassis have 900W or 1400W). I'm using a dozen Seagate Momentus 750GB in a 2U storage chassis with 900W and Adaptec 5445Z. Slightly different story, but the Momentus series is also "notebook class", so Seagate disabled the activity LED (now THAT's gonna stop me). The drives work very well (good overall IOPS). Can't tell anything about long-term, though. I planned to go for WD Scorpio next time, but now I'm going to reconsider this idea. Seems the manufacturers really don't want us to do this. 

Without knowing anything about mono asp.net, try disabling cookies when testing. It might be your application is locking session storage to keep things serial, thus consistent, per-user. Without cookies (also across domains), your tabs get unique sessions each. 

On two Supermicro 847E16-RJBOD1 enclosures, I have trouble accessing SATA disks on the rear backplane with 6gb/s. The only significant difference between rear and front backplanes is total cable length from HBA to backplane, which is about 1m + 30cm vs. 1m + 70cm. SAS signalling shouldn't be affected at these lengths, and I always assumed HBA and backplane will connect with SAS signalling whatever disk type attached. Is this assumption wrong? Do SATA disks limit HBA to backplane cable lengths?