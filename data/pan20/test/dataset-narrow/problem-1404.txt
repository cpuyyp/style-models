The text is now readable, but the advance and X-, Y-bearing still don't look correct. This is what it should look like: 

But now I would like to know how to set the Z position. I can set the proper height of the sphere by doing that: 

I wanted to know if it's possible to use a texture of an FBO for post-processing and using that texture again for writing or do I need at least two textures? I hope you understand what I mean. 

But the problem is, that the sphere is only moving up and down and the moving towards the camera is ignored. How can I fix that? 

I'm looking do make an FPS-like camera, but I'm encountering some problems. If I'm first rotating and then translating the camera, everything works fine, but the coordinate system. For example, if I want to go backward with the camera, I have to set the Y coordinate positive. But when I'm translating a model matrix on the Y coordinate in a positive direction, it is moving forward. So somehow the coordinate system is flipped. When I'm first translating the camera and then rotating, the coordinate system is the same, but now the camera is rotating around the origin, which makes sense, but when I'm looking at examples, everyone does that and no one is complaining about rotating around the origin. I hope you understand what I mean and I hope you can give me some advice. 

I'm doing some transformations on to move the origin to the top-left corner and flipping the coordinate system on the X-Axis. Then I divide every pixel value by a constant factor, to have the font having the same size on every resolution. The ratio of the glyphs is correct, but not the alignment. And here is my vertex shader: 

I would expect glDrawArrays to be fastest on both the GPU and CPU for this scenario, primarily because you're saving the GPU memory bandwidth otherwise used for fetching the index data and the CPU cost of managing the index buffer. I do not expect glDrawRangeElements to be any faster than glDrawElements - in fact, I would expect it to be slightly slower. The range passed to the function is intended to be used to allow a driver to know which sections of the vertex data need to be made available to the GPU. However, if you're using a vertex buffer, this is not useful information. Further, it's also just a hint - drivers are expected (although technically not required) to render correctly even if the range is wrong, and it's surprising how many applications do get it wrong. So, we generally ignore those parameters. As for why glDrawElements is faster with client index data, that's odd, but really depends on the sequence of calls. You say your overall mesh has 600K+ vertices, but it's broken into groups. What is the size of each group? Each time you switch states (such as binding a new index buffer), the driver needs to validate the contents of the buffer, which takes time. If you're rapidly switching between two states, then this could be where your CPU time is going. When you use an index buffer, each switch is (potentially) a new buffer and is more work for the driver to validate. If you use client indices, even though the driver might be transferring indices to the GPU, it's all technically the same buffer - a gigantic buffer that starts at CPU virtual address 0. Of course, it's also possible that the driver doing something silly. Ultimately, 40 FPS is pretty low for drawing 600K vertices. Something bad is happening. Here are a few things you can try to improve performance: 1) If your fragment shader and fixed function state is basically order independent (depth test on, stencil and blend configured for order independence), sort the groups in the mesh by textured vs. untextured, then draw all of one set followed by all of the other with no state changes in between. You can even sort further - by texture or other parameters, for example. 2) If any state is common between groups (mvp matrix, for example), make sure you're not setting it redundantly. 3) Make sure all groups in the mesh are using the same vertex and index buffers, ideally bound into the same VAO. When you draw, you can use the {first} or {baseVertex} parameters to offset into a larger vertex buffer. You can even use the same buffer object for both index and vertex data - just subdivide it. 4) As a last resort, you could try making all groups use the same shader by simply binding a dummy texture with an opaque white pixel into it for the untextured groups. If you're really CPU bound here, the extra GPU cost of fetching the (unneeded) texture data and a few extra shader instructions probably won't matter. Once you do get the glDrawElements path going as fast or faster then the glDrawArrays path, do consider optimizing the vertices for reuse. A triangle soup mesh with perfect reuse can perform up to three times better than the same mesh rendered with no reuse. 

That's not really beautiful but it works. If someone knows a way to get precision in desktop shaders, that would be better though. 

Very simple as you can see. It runs fine in webGL, but it seems it won't compile in OpenGL. I am no expert in shaders so I have no idea what might be wrong. Am I using some syntax that only exists in webGL? Also just in case, here is my vertex shader (which compiles fine): 

I am programming in (language compiling to multiple platforms) and I have written some shaders. My fragment shader runs fine in html5, but when I try to compile for native (OS X and/or Neko, a VM for Haxe) I get a shader compilation error, but no details (I am using which is a platform abstraction that does these things for me). Here is the shader: 

I ended up with a simple idea that worked surprisingly good, so here it is: In my particle engine, I generate particles per gameloop tick, and running at 60 FPS we have, for an elapsed time in seconds, particles generated. This could vary if your game isn't fluid and frames drop, but we assume it runs correctly. Now what happens is that the prewarn function is launched once the particle emitter starts, and emits this number of particles. Then we have to simulate where they are, because they should have been all generated at different dates, when in truth they haven't. All of this is done with a simple for loop (example in ): 

So now imagine I want to apply a force to jump, I will use at the moment the player presses the jump button. But: What happens is that the amount of movement depends on the gameloop speed, since the force is applied for a single frame. I feel like I missed something about how you should use forces, but I don't see how I should manage it properly. In which cases should we use a force, considering this deltaTime issue? And also, what should I use instead?