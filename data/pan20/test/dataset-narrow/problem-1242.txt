Parametrised complexity: kernelization, iterative compression, bidimentionality, ... Approximation algorithms: randomised rounding, scaling, ... In graph theory, based on structural hierarchies of graphs like bounded tree width graphs/excluded minor graphs/ bounded expansion graphs / nowhere dens graphs, there are different tools (like decompositions) and meta theorems (like Courcelle theorem). 

In general, if the problem is in such a way that needs more than one dimension for dynamic programming and also those dimensions are depended to each other then the problem has potential to be hard in graphs of bounded tree width. We can see this pattern in both of problems in the question as well as for the sparsest cut problem. (In the first problem we want to keep previous coloring on the other hand keep coloring as small as possible, in the second problem obviously there are two functions which are dependent to each other) 

I wonder how to find the girth of a sparse undirected graph. By sparse I mean $|E|=O(|V|)$. By optimum I mean the lowest time complexity. I thought about some modification on Tarjan's algorithm for undirected graphs, but I didn't find good results. Actually I thought that if I could find a 2-connected components in $O(|V|)$, then I can find the girth, by some sort of induction which can be achieved from the first part. I may be on the wrong track, though. Any algorithm asymptotically better than $\Theta(|V|^2)$ (i.e. $o(|V|^2)$) is welcome. 

As others said, If you have good and upto date Profs in your interests in university you can ask them or also you can ask from their previous students. but in the case in your interest fields there isn't good prof, my experience tells find nice people in this topics around the world, and communicate with them, they will help you without expecting anything, after a time you can narrow your field to what you want. For start-up is good to look at this sites (cstheory) Q&A, may be you can't understand too many of questions and their answers, but by reading your master courses and being fan of this site you can understand them after a while, after that, you can find what is good in your case, and then find related Profs or good students in your field and communicate with them. 

As there is no answer yet, I turn my comment to answer, Marathe et al. in their ICALP93 paper, defined some problems which are PSPACE complete but they admit constant factor approximations, they also provide some inapproximability results. For this particular question, consider MAX3SAT, corresponding decision problem is PSPACE-complete even if the corresponding SAT graph has hierarchical structure as they defined in their paper, but this problem has a 2-approximation guarantee algorithm in hierarchical structure. 

I think Sparsest cut or edge expansion, is good enough for you, because deals with both edges and nodes. The task is to find a cut, with $S\subset V$, $|S|\leq {|V|\over2}$ in one part such that: $$\alpha(G) = \min \{ {E(S,S^c)\over |S|}\}$$ is minimized over all possible set of $S$. You may look at Sparsest cut and bottlenecks in graphs by Matula,Shahrokhi for proof of NP-Hardness (proof is by using max cut). Also P. Bonsmaa et al, shown that it's NP-Hard even in uniform case (means all edges are of weight $1$). 

Answer my own question: The answer is (probably; please let me know if I am wrong) negative: it is impossible to simulate sequential registers from causal registers. Note: the following proof is indirect. And I am still interested in a direct proof. 

In the Conclusion section, the author of this paper "Stability of Approximation Algorithms for Hard Optimization Problems" by Juraj Hromkovič, 1999 claims that 

Quoted from "Idit Keidar", the editor at that time: Game theory and fault tolerance offer two different flavors of robustness to distributed systems – the former is robust against participants attempting to maximize their own utilities, whereas the latter offers robustness against unexpected faults. This column takes a look at attempts to combine the two. It features a review of recent work that provides both flavors of robustness by Ittai Abraham, Lorenzo Alvisi, and Joe Halpern. Ittai, Lorenzo, and Joe discuss how game theory-style strategic behavior can be accounted for in fault-tolerant distributed protocols. They make a compelling case for bringing a game-theoretic perspective to distributed computing problems. 

I think the confusion arises from the fact that the two definitions of serializability ($\textrm{SR}$, for short) adopted in [Lin et al@TODS'2009] and [Berenson et al@MSR-TR'1995] are different. The SR in [Lin et al@TODS'2009]: In [Lin et al@TODS'2009] (at least in the test of $H_{example}$), the serializability is the classic One-Copy Serializability (or, $\textrm{1-SR}$) introduced in [Bernstein et al@TODS'1983]. To tell if an multiversion (or MV) history is $\textrm{1-SR}$, we should first decide on a version order $\ll$ (which is a total order) for each data item. Given a history $H$ and a version order $\ll$, an multiversion serialization graph $MVSR(H, \ll)$ can be constructed. As a consequence, we have 

I am studying on distributed transactions, mainly on the correctness criteria (e.g., serializability (SR) and snapshot isolation (SI) in replicated settings) and their implementations. To avoid unnecessary efforts, I would like to know that 

high-level operation: operation on simulated object $R$ (i.e., $read_r(R)$ and $write_w(R,v)$ in the pseudocode). low-level operation: operation on $TS[i]$ and $Val[i]$. 

It should be "Let $\hat{w}$ be the $(s[i] - 1)$st write." By definition, $s$ is the timestamp of the write operation $w$ of process $i$. According to the rule of in Fig.3, we have $s[i] \ge 1$. The problem is what if $s[i] = 1$. Well, it seems that the authors have missed the edge case. Fortunately, it is obviously true that $t[i] = 0 = s[i] - 1$. 

Background: Transaction processing has been a traditional research topic in database theory. Nowadays distributed transactions are popularized by the large-scale distributed storage systems which typically involve data partition (also called sharding) and data replication. 

The article in Distributed Computing Column 42 attempts to bring a game-theoretic perspective to distributed computing problems. 

Basically you have been mislead by the errors in the proof in the edition of the paper you are referring to. Please refer to the published edition on "Distributed Computing'1995". 

Seems this is a FPT algorithm for a fixed $k$. First of all we can just consider a block which contains $s,t$. If we have a $k\times k$ grid minor which contains $s,t$ then we can find the corresponding chain. As otherwise, as Chekuri et al. shown, the graph has tree width at most $O(k^{1/\delta})$ where $\delta > 0$ is some constant. So we can compute the tree decomposition of graph then check whether that chain exists or not. I'm not sure if with usual dynamic programming on graphs of bounded tree width is possible to find the chain. Also if is not bounded tree width, their algorithm can find the corresponding grid in polynomial time. P.S: Note that I didn't use the fact that there are $n^k$ s-t paths, may be by some trick inside this fact is possible to obtain better algorithm. 

I don't know if there is any pure graph theoretic problem which is hard in bounded vertex cover, and if there is any it is very interesting for me to see such problem. However, here is a problem of weighted disjoint paths with congestion, a natural practical and theoretical problem. Input: 

Thor Johnson, et al, in their paper: Directed Tree Width, introduced a definition for directed grid $J_k$, and they conjectured: 

Shortest 2-Vertex disjoint path problem in undirected graphs recently solved (ICALP14) by A. Bjorklund and T. Husfeldt. But the deterministic solution is for the case of existence of a unique solution. In the case that there are more than one solution, they showed that the problem belongs to RP. As authors of the paper mentioned, it is not known if the problem is in P in general scenario. 

May be this is not exactly answers your question, because currently I can just remember some heuristics, but I'm sure there are some approximations, because I saw them before. In some fields like FPT(Fixed parameter tractable) you have a problem, normally in graphs, which can be solved in $O(f(k)*|G|^\alpha)$, like solving TSP in bounded tree width graphs, Or finding tree decomposition of graphs with small tree width. But actually they aren't good enough and $f(k)$ is too large to be used in real world. So using approximations or heuristics are fine here, for example you can take a look at heuristic for TSP in bounded tree-width graphs, or some algorithms for Maximum Agreement Forest problem and its later approximations/heuristics (simple google shows results in 2010, 2011), or algorithms for finding tree decomposition of graphs. 

Minimum number of cops (pursuer in your definition) needed to win in similar game is equivalent to Kelly width of $G$, and it's NPC to determine that minimum number, it's similar to path decomposition for undirected graphs, but I don't know about minimum number of moves needed such that $k$ cop wins. But there are some works around similar games, if you are interested to know more about them maybe a good search term is cops and invisible inert robber game. Note that we can add loop to every vertex of a graph $G$ to skip the most move condition, then the game is in fact invisible robber game or the kelly width game or for undirected graph it's a well known path-width game (invisible robber is inert by nature). The maybe main difference between Kelly width game and this game is that robber can walk along edges not a single edge (I didn't read the question carefully at first, I read evader walks along edges, but still I don't think it makes totally different game, one may find a gadget to simulate walking along edge by walking along paths, e.g something like turning vertices to complete graphs). 

Note that process $Prod$ reads $c$ and writes $p$ while $Cons$ reads $p$ and writes $c$. It is not hard to find out that $\mathcal{Y}$ alternately performs $\mathcal{P}$ and $\mathcal{C}$. The protocol $\mathcal{Y}$ can also be described as a state machine: 

Edit: Actually, I don't quite understand why my answer (instead of that of @Marzio De Biasi) was accepted. Maybe the OP only want to know whether his/her greedy strategy is correct or not. Whatever, please refer to the answer of @Marzio De Biasi (and also other ones) for a complete solution. 

The algorithm uses vector clock to compare the values written by the writers and find the most recent one among them. The pseudocode appears in Figure , where 

You can post other greedy strategies and prove (or disprove!) them by employing (maybe combining them) classic proof strategies such as mathematical induction, contradiction, and exchange argument. 

Background: Atomic snapshot memory is a shared memory partitioned into words written (updated) by individual processes, or instantaneously read (scanned) in its entirety. The Gang of Six algorithm shows that such an atomic snapshot object has wait-free implementation with $\Theta(n^2)$ reads and writes to the component shared registers (when they are restricted to single-writer, $n$-reader registers) in the worst case. This time complexity is then reduced to $\Theta(n \log n)$ using a more clever algorithm. Questions: The two algorithms are both concerned with the most general structure of the underlying single-writer, $n$-reader registers. That is to say, they are simply an unorganized array of registers. However, in many situations, they are in tree structures, like in a file system. For instance, in ZooKeeper, the in-memory znodes are organized in a hierarchical namespace referred to as the data tree. My questions are: 

I guess the answer is negative. However, I have no idea how to prove/disprove it (Googling does not help on this). 

In my opinion, if we schedule the writes to take place at the same instance as it is scheduled to take place in the underlying $k$-atomic single-writer register (i.e., the code line ), the write of $\langle 4,3 \rangle$ will be ordered after the write of $\langle 1,5 \rangle$ and the staleness of is guaranteed to be less than or equal to 6 (ordering $\langle 1,5 \rangle$ before $\langle 4,3 \rangle$ which is before $\langle 1,6 \rangle, \langle 5,6 \rangle, \langle 4,7 \rangle, \langle 6,6 \rangle, \langle 5,8 \rangle$ and returning $\langle 4,3 \rangle$). However, because all the three operations of $\langle 1,4 \rangle, \langle 1,5 \rangle, \langle 1,6 \rangle$ by Writer 2 interleave with the of $\langle 4,3 \rangle$ by Writer 1, it is also legal to order the latter write of $\langle 4,3 \rangle$ before the former three. In this circumstance, the staleness of the can be 8 (also returning $\langle 4,3 \rangle$). I am quite confused about the two above-mentioned arguments. Which is correct? How to identify the staleness of this execution of the multi-writer construction? 

bit representation of $i$ is smaller than bit representation of $j$ (w.r.t. the definition of $\le$ in the question), and bit representation of $j$ has exactly one additional $1$ compare to $i$. 

I'll provide a naive approach which give $O(m^2 \cdot max_f)$ running time but shows the problem is P. First turn the graph to undirected graph. Suppose one edge is in first graph and the other in the second graph, contract both of them and name them $s,t$. We can find a minimum edge cut that separates s and t in time max_f which is a running time of best maximum flow algorithm on unit weight graph. We run this algorithm for all possible pair of edges. But why this works? trivially there is no smaller cut and the two sides are not edgeless. On the other hand if a graph G is connected minimum edge cut C between two vertices s, t always cuts the graph into two connected subgraphs. 

Additional functions, like here the weight function. But still there are some problems with weight function that are not very hard in undirected graphs of bounded tree width. The nature of the sparsest cut problem. Actually existence of more than one dependency for dynamic programming in the definition of the problem. Intuitively the good solution is the one that we partition a graph (by removing some edges) into two almost equal size, on the other hand in this partition we delete as fewest number of edges that we use. The reason that the problem is hard in bounded treewidth graph is that we should apply dynamic programming in two direction, but both directions are depended to each other. 

If the cost is $|P_1|+|P_2|+|P_1∩P_2|$, then a simple reduction to the shortest pair edge disjoint paths gives us a polynomial time solution. For each edge $e=(u,v)$ add two edges $(u,uv)$ and $(uv,v)$ each of them with same edge weight as $e$. The shortest pair edge disjoint paths in the new graph corresponds to the required solution in the original graph. The algorithm for shortest pair edge disjoint paths is known as Suurballe's algorithm. $URL$ If the cost is some arbitrary function the problem can be NP-complete. e.g assuming edge weights one, let the cost function be as $|P_1| + |P_2| + |P_1∩P_2| + 2\cdot |G-P_1\cup P_2|$. Then the cost is always $ \ge |G|+2$ (if source and terminal are distinct vertices). The equality holds iff the graph has a Hamiltonian cycle. 

There are many general techniques and meta-theorems. Unlike software engineering, in TCS we don't want to repeat things similar to what the others did, we want to create something new or solve an unsolved problem, so it's not as easy as using lazy propagation in software development. Here I provide some examples but it's surely way far from the complete list. 

Every planar graph can be colored by 4 color, take dual of graph, the faces of dual are able to be colored by 4 color because of 4 color theorem, but they are also vertices of original graph.