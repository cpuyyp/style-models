My guess is that the developer simply didn't consider the possibility of concurrent updates and the complications around that. 

The Agent service depends on the SQL Server service, so it may not yet be running when your startup stored procedure runs. Probably better to monitor the service some other way. See a similar discussion at $URL$ 

You have to consider whether or not you actually want your trigger doing all that though, and I can't speak to the stability. For the comparisons, any particular reason why CHECKSUM instead of say i.colname=d.colname OR (i.colname IS NULL AND d.colname IS NULL) ? 

Having a column named "EmiAmount" that also indicates finance availability (a interrelated but separate concept from EMI if I understand your post correctly) is bound to cause confusion. Even your post seems to confuse the terms. And there's probably no compact name that can alleviate this. If you choose to use a single column, I would at least suggest a non-nullable column, and using -1 instead of null to indicate "no finance". The reason is that it's generally best not to assign an actual meaning to null, as the standard interpretation is "data optional and not available/applicable". Also, when you can avoid nulls it's best to do so due to the complications they cause. (Note I'm not suggesting to avoid nulls when "not applicable/available" is fully valid from a data modelling standpoint, which is very frequently the case.) 

Many SQL Server configuration features are not implemented in the UI. Scripting is your only option for these (aside from possibly some third-party UI that implements them). 

It's not the fanciest or even best way, but is the easiest to start learning with. By the way, your code won't work if @UDF_1 is null, you need to assign '' to @ALL_UDF before working with it, or add other checks. 

For something like this it would be much safer to script an update of just the column(s) that need updating in your user table. Cloning any part of your test environment user data into production could be disastrous. Is it not possible to use the script with which you (presumably) updated your test environment in production as well? 

If I understand correctly that you only want to Archive the files produced in case you need the occasional one for referring to later, then cloud file storage would be cheaper and simpler than storing them in a DB. 

I believe type = 4 only applies to pre-2008 fulltext files which have been upgraded, because since then there has been no way to create separate fulltext files -- only separate filegroups. (See type = 4 doc for SQL 2012 at $URL$ which confusingly says the same as for 2016 except version number.) Something like $URL$ may technically do what you are looking for, but won't actually be relevant for your report. 

This is an old question, but I came across this and was appalled at one particular comment made, suggesting the original asked was "confused". The question is perfectly clear, just not strictly about database administration. It falls into the fields of server virtualization and storage provisioning in virtual environments more than anything. It may well be that this question had been better suited for a different StackExchange site, but arrogantly dismissing the question because one does not understand the issue is unacceptable. Let me attempt to explain the question better and give my best advice on the subject, in an attempt to leave something useful here for any others that may get dropped here by a search engine. When deploying a database server, it has been considered best practice to put the OS, data files and log files on separate sets of disks. Just as a random example, let's say we have a server consisting of three RAID arrays: 2 HDDs in RAID 1 for the OS 4 HDDs in RAID 10 for the database data files 4 HDDs in RAID 10 for the database log files This setup would separate the IO and create separate points of failure for the data files and logs, as well as keep it separate from the OS. This was done for performance, resilience and maintenance reasons. Simple enough, right? But what then, if we are deploying a database server in a virtual environment? There are no physical disks in a virtual environment. No there really aren't, unless you are mapping the virtual machine disk 1:1 to a physical disk, which is not what you'll see done in your typical virtual server farm. Even then, there would be a virtualization layer in between the physical disk and the virtual server, presenting the physical disk as attached to a virtual disk controller rather than the physical controller the disk is actually attached to. So what is the problem? Let's take a small virtual server deployment as an example. A bunch of rack servers running in a virtualization cluster and one SAN with a bunch of disk groups in RAID 5 and RAID 6 with automatic storage tiering. All virtual disks are stored in the SAN in this example. How do you go about assigning separate physical disk groups to your virtual database server now? Or maybe you don't? That was the question asked here. No useful answers were given, and understandably so, since it's a complex question where the answer depends a lot on your particular deployment. Some setups might give you very tight control over what kind of and what specific physical disks your virtual disks end up on, whereas others might be more of a black box that handles everything automagically. In the simple "one-SAN" example I outlined above, I'd say that you don't really need to. But you might still want to. Even if you can't actually control what physical disks the IO ends up at, there are other benefits to splitting the data up. What if you migrate to a new virtual environment in the future, where you do get separate LUNs with different and known performance characteristics? If the data are already split over several virtual disks, moving them to new LUNs with the appropriate IO capability is much easier. In many hypervisors you can also give different IO priority to virtual disks. Again, this gives you some extra control. More accurate control over snapshot behaviour also becomes possible. Each database gets it's own separate underlying file system, that it doesn't need to share with other databases on the same server or even the OS itself. Basically, this boils down to your performance requirements, size of the database, hypervisor and storage solutions at your disposal and many, many other factors. I hope I've pointed out a couple of useful tips. Plan ahead. While virtual environments with SAN/NAS solutions might seem like black boxes in many ways, many of them do have ways to achieve the same performance and redundancy goals as traditional direct storage. 

You can't use a SP in a default, but you can use a function. But presumably your SP code has to increment the value in the NextNumber table, so that won't work for you. Your best bet for doing this within SQL is probably to have an INSERT trigger on MyTable which calls the SP and sets MyColumn. However you'll have to carefully consider the behaviour of your SP code when multiple concurrent inserts are involved. For example, you'll probably need to select the current value from the NextNumber table using an UPDLOCK hint to prevent another user reading and using the same value. (Note that the UPDLOCK hint will only prevent reads in this way if it's within a transaction [which triggers run within in by default], and if other selects on the NextNumber table use UPDLOCK as well.) 

A comparison of the values in the inserted and deleted tables is your only option, because UPDATE() and COLUMNS_UPDATED will be true even if the value hasn't actually changed (i.e. has simply been overwritten with the previous value). To (largely) future-proof your trigger you could dump inserted and deleted into temp tables, and generate dynamic SQL for the comparison based on the temp table structures (in conjunction with Update()) which you can obtain with this: 

I'd suggest the first thing to determine is whether or not the server workload actually struggles during those spikes. Do you see for example IO being maxed out, or other queries being blocked (due to the splits increasing the time the write transactions take to complete) or slowed? If not, the page splits are not an immediate concern, but still may be worth looking into. The question is, are these "good" or "bad" page splits. This link might help you determine what you're seeing. Logging your index fragmentation levels before and after a spike might also be a simpler way. "Good" page splits are simply inserts to the end of an increasing index (clustered or otherwise)that require a new blank page, so it's really not a page split as generally thought of, even though SQL Server counts it as such--presumably because there is some overhead, but probably not more than the inserts cost in general. "Bad" page splits are updates or inserts to the middle of an index that overflow the page, and are the ones that cause both internal and external fragmentation, with external not much of an an issue with SSDs and/or shared storage, and internal being of more potential impact due to the IO and cache memory they waste. It could be that you've got a mix of good and bad, perhaps good into the clustered index and bad in multiple non-clustered indexes. That's pretty much unavoidable, and you'll just need to consider your index maintenance and possibly a specific fill factor on indexes that are frequently affected. But read $URL$ first. However if you find your clustered index is being bad-splitted, then it may be worth considering whether a clustered index that better supports your inserts would be in order. Or if the splits are caused by updates adding more data during the life of a record, a specific fill factor might be in order, but really only if the updates are evenly distributed throughout all your data, since a fill factor to support only your recent data would waste a lot of space/IO/cache if most of your data is static over time. The ideal clustering config really depends how your table is used overall though, not just on how it's written to. 

Using Azure Sql Server, and in C# if that's relevant, is there a way to get an event when data in specific table changes? In one table we need an event if any column changes in a row. In a 2nd table we need an event only when either of 2 columns change (although any change would be ok). And we need to know which row. Is it possible to do this? If so, how? Update: We need a call into our C# code for this event. A database trigger where the database can do something doesn't help, our program needs to take action on a change. thanks - dave 

What I'm totally stopped on is I don't see any equivalent of a List is SQL. Is there a way to build all this up in a list? Or is there a delete/insert/update I can do where the select uses the list I pass in? I am passing in a list in the form of a defined type(table) that is the new list of domains. From that list: Any domain in the passed in list that is not in CompanyDomains is added to CompanyDomains. Any domain in the CompanyDomains table that is not in the passed in list is 1) removed from CompanyDomains and 2) added/updated to the DeletedCompany table. Any domain that is in the liast and in the DeletedCompany table is deleted from the DeletedCompany table. The DeletedCompany.Domain column is unique in that table. So additions to it must be an upsert. The CompanyDomains table also has a CompanyId column and everything there is where CompanyDomains.CompanyId = @CompanyId (passed in parameter to the proc). This is for Sql Server 2008 & Sql Azure. It does not need to run on anything else. thanks - dave 

where I get back all rows in the table that do not have an EmailDomain value matching any of the values in @domains (and the CompanyId has a set value). Is there a way to do this? Sql Server 2008 & Sql Azure. thanks - dave 

I have some code in C# I'm trying to move to a stored procedure - Sql Azure does not like multiple calls. So everything needs to get moved to a proc. Here's the C# code: 

We are setting up a new SAAS application on Azure and while we have used Azure before, not at this level of multiple apps, etc. We plan to have both a web app and a cloud app in both a US and EU data center. They need to hit a common database because requests will go to the closest data center via traffic manager and a lot of the data works off of the customer table. And a customer (company) can have users in both the U.S. and E.U. Is there a way to set up Azure Sql Server so it has instances in both data centers, and Azure keeps them synchronized? If I understand sharding right, that is not what we need as someone hitting either data center could be requesting any of the data in the DB. thanks - dave