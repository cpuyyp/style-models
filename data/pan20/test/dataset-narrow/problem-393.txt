I have several access databases that I'm copying over to the sql server, connecting to as a linked server, and then pulling data from each night. I need to be able to identify if the current access db the linked server is pointing too has a particular column. If not I'll need to create the column before copying the next access db over. Is it possible to check if an access column exists through a linked server connection? 

There were also several queries with a status of running but none of these had been running for a significant amount of time. SQL Server threw no alerts during the time frame and nothing looked out of the ordinary in the logs. There were also no alerts for Blocking processes at this time. Finally the decision was made to fail over the SQL Server cluster. This cleared up the issue. I've exhausted the places I can think of to look to come up with an explanation for the outage. Has anyone experienced similar behavior? Is there something I should be checking that I haven't mentioned? 

The old-school workaround for this was to have your SQL Trace log to a table, then once the trace started, create an AFTER INSERT trigger on that table. The trigger would then write out the Execution plan to a different table. 

That warning is just checking to see if you've ever backed up your encryptor certificate using T-SQL. This could put you in situation where the database backup would be unreadable if you were to lose that SQL Server instance for whatever reason. No, you don't need a regular backup cycle for the cert. You wouldn't need to back it up after the initial one unless you've lost your copy. That warning is just checking to see if the pvt_key_last_backup_date IS NULL. 

SQL SERVER 2008 R2 When attempting to connect to the default instance of sqlserver on our local server from SSMS on my desktop I'm receiving the following error. 

To use the CustomApp credentials, the user adventure-works\tengiz0 executes the following statement. 

I've installed 2 instances of SQL Server 2008 R2 onto our local windows server. For the purposes of testing I've turned off the firewall. I'll get the firewall back up after I manage a successfull remote connection. The server isnt exposed anyway. TCP\IP is turned on for both instances. The default port is assigned to the Default instance and that one is working fine. I've assigned 4143 to the named instance but I'm still unable to connect remotely. I can connect remotely to the default instance just not the named instance. What step or steps am I missing? 

Whenever you want to see what SSMS is running, you can always fire up a Profiler/Extended Events trace and filter on your login. Doing this from MSX master and viewing a Multi-Server's job history gets you this query: 

However, since you are on SQL2014, you should really be using Extended Events. There are several ways to do this with XE that are all superior. Here's an example of exactly what you are trying to accomplish. 

Perhaps that backup was taken with a different certificate than the one you've backed up? You can check to see which Certificate was used with this query: 

I'm not certain about the service broker que but it is possible to setup a user without a login. This user will not be able to authenticate but you can still assign the user rights. The examples below are from the microsoft article for createing users $URL$ D. Creating and using a user without a login The following example creates a database user CustomApp that does not map to a SQL Server login. The example then grants a user adventure-works\tengiz0 permission to impersonate the CustomApp user. 

I'm receiving the data 1558.39999999999 However, investigation of the data shows that all data points only go out to two decimal places. In this case it should be impossible to receive the number above. using another query: 

The exec @distproc section is roughly at Line 537 of sp_MSrepl_helpsubscription. It's building the proc call and should be something like [SeverName].distribution.dbo.sp_MSenumdistributionagentproperties From the error, it appears that @distproc variable is not getting set properly, or at least getting set to an empty string. Why? That's hard to know without more information or being able to test on your system. Some unusual setup with the distributor, perhaps? But this will hopefully point you in the right direction so you can walk through it. (Run that code on the Database that is being published). 

Once these views had been created we could pull the column listing from sys.columns joined over to sys.views. 

In this case you dont need to update the records for people who havent returned a car. You only update the record to contain the date when they have returned the car. 

My Boss requires that we keep up to date scripts of all database objects in svn. This results in constantly trying to find the object in the current script and copy and pasting the changes. Is there an easy way to set sql server to script database objects and write them to a file on the drive? If not then I've built the following sql script as a test run for creating a tables file but I'm not sure how to capture the output string that sp_executesql is creating. 

Short answer is yes, that is the default behavior. SQL is a data access language that will run statments in batches, you'd have to use other features (Service Broker for example) to run statements asynchronously. One of the main concepts of the language is the idea of Transactions. There are several articles out there which explain this concept in detail with straightforward examples. For Example. I'd highly recommend practicing this because understanding how to use Transactions becomes especially important when one statement relies on the successful execution of the previous statement. 

My company is changing from a distributed Access Database model to using a centralized SQL Database. The datatables were designed such that all of the tables have a modified date. In discussion it was suggested that since we will be creating a trigger on each table to handle the modified date perhaps we should have the trigger also log some information to an audit table. Is this the best way to setup auditing so that we can track who is changing information or is there a better way? Links to articles on the subject are welcome. For the audit I'm looking at capturing the table name, column name, date modified, row id and the username of the person making the change. Is there any information I'm not thinking of that I should be capturing that might help me avoid future pit falls? 

The trick to Resource Governor is thinking about what you want to protect rather than what you want to throttle. You set minimum/reserve resources for your good users which protects them from the bad users. My advice is to start conservative and slowly turn the knobs. You'll likely just need one Resource Group for your "Good Users". You would set their minimum CPU and/or Memory to, say 10%. Everything else, including your Bad Users, will go to the Default pool. If Bad Users were all running CPU heavy queries, and the Good User's query came along, it would throttle the Bad so the Good would be guaranteed to at least have 10% of the CPU. You may decide that a 10% minimum isn't enough and you need to increase it. Just be measured in your approach. I personally have never found the need to touch the Maximums, though I suppose there are use-cases. Also, the Resource Governor DMVs provide some great information. You can create your "Good Group" and just leave it at the defaults to see the stats. They are quite interesting on their own. Another thing to be aware of is to make your Classifer function very simple. Remember, this function will get called on every connection so SQL will know which Group to route the connection, so don't put a lot of crazy logic in there. Typically you'll just do simple CASE compare based on Application Name or Host Name or Login Name. for example: 

To revert back to the adventure-works\tengiz0 credentials, the user executes the following statement. 

The server needed to be added to the LMHosts file so that SQL Server could resolve the path to the directory that the Transaction logs were being saved to. 

Car rental now stores the relationship between the client and the car that they rented and for each record stores the datein and dateout. If you dont want to script all of this out you can use the table designer to create the table by right clicking on tables and then choosing new table. You can use the database diagram to drag and drop columns in order to create your foreign key relationships by right clicking database diagrams and chosing New Database diagram. If you use this structure then You would leave the DateIn field as NULL untill the car was returned. Your query to find out which clients and cars have not been returned would be