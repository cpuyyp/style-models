In my case, this cleared up the issue and allowed me to "hack" the query and force a bitmap scan. If this does solve your problem, you could build this as a function as well: 

yet no values from the table are in your . The good news is that this is not affecting your performance, because the query optimizer has wisely left the table out of the query entirely. This does concern me a bit just in principle. Odd Query Plan In your query plan, it chooses to enforce the conditions of 

I'm concerned that we may not have a clear picture of how a group is defined. I only say this because, depending on some unstated conditions, the dates above will either form one giant single group, or 3 groups where one group dominates the set. Missing grouping conditions? 1) Does this 15 day rule cascade? If a record starts 10 days after another record , and then there is another record started 10 days after that, then does this form one group of three records , or two groups each containing two records and ? I made the assumption that the 15 day rules cascades to form larger groups. 2) Are the dates inclusive? For example, if one record has a start date and then a dead date many months later, do all days within that range get merged into the group? I treat both possibilities in my quick analysis below. Potential Groupings So, if we begin with id , we see that the start date is 1/27. Clearly, the next entry starting on 1/28 falls in this group. Notice however that ends on 5/15, so anything which starts within 15 days of 5/15 must be added to the group. Thus, through get added to the group, which via cascading leads to being subsequently added to the group. The cascading has consumed nearly all entries in the set. Call this . If, however, the grouping is date inclusive as well, all entries from up to must also belong to , and now all ids are in a single group. If the dates from aren't inclusive, but actually strictly adhere to the '15 day after' rule with cascading, then instead you would have a second group composed of through , and a third group with a single entry, . Essentially, my question is, do any of these match your intended grouping, or is there some other information we're missing in the group definition? I'm sorry for such a long-winded answer, but it doesn't appear that your tentative requested output meets your grouping definition. With clarifications, I'm sure that we can sort this problem out. 

So, in brief, the function takes three input arguments, and uses these to generate a dynamic SQL statement, which it then executes. Inputs - Exactly what you think it is. The json entry you want to update with. - The target table you want to update. - As I mentioned above, since I made the assumption based on your description that you had pre-established predicates, that entry goes here. Operation The function searches for any columns in the table , searching for any columns whose names match keys in the field, by performing the sub-select . For any json key which matches a column name, that column name is returned by the outer select . The loop iterates over each of these matching column names, adding on to the dynamic SQL statement the necessary info for updating the relevant column data. NOTE that 'extraneous' fields have been ignored. That is, if there is a json key for which there is not a matching column name, or there is a column name which is not in the input, these fields are ignored. Calling the function The function can be invoked by simply calling 

OK, so you've listed a few questions here, so I'll try my best to answer them. Is your query correct? First, you said: "I am interested in finding out how many (pl_namespace,pl_title) pairs in the pagelinks table show up in the page table as (page_namespace, page_title)." Is the query you're performing correct for that, or did I misunderstand the description? If you run 

then Postgres will optimize and decide if using the index or performing an explicit sort will be more cost effective. Keep in mind that there is no guarantee that Postgres will use the index; it will seek to optimize performance and choose between using the index or explicitly sorting. If you create this index, monitor it to see if it is being used enough to justify its creation, and drop it if most of your sorts are being done explicitly. Still, at this point, your 'biggest bang for the buck' imporvement will probably be using more , but there are cases where the index could support sorting. 

Replication cannot work in your case, because developers databases will often change, and conflicts with the master break replication (by design). Also, developers cannot rely on data that are constantly changing. You need to take some form of backup and send it to developers machines. Here are the best solutions in my opinion: 

I will answer what you asked, but first let me tell you that I don't understand why you want to do that. An autoincremental id is very good for this task. But it is correct to also use a timestamp column, because it is a bad practice to rely on an id for sorting. Why? Because there are cases when its order might not be chronological - for example, if you use Galera cluster and you have failovers. To do what you asked, first create this index: 

First of all, I discourage you from using the slow log with output, in production. The reason is that writes are locking, which limits the concurrency of your workload. Moreover, CSV stored engine does not support indexes. Any non-trivial query will be very slow, so I don't see any advantages in doing this. Of course you could use MyISAM and add indexes, but then writes will become more expensive. That said, the correct way to "rotate" the table is copying it and than truncate it. You will probably lose some queries every time: the ones ran after the copy but before the statement. 

As another answer highlighted, Query Cache is not the only cache. Its use is not even advisable in most cases - in fact, it was removed in MySQL 8.0. The reason is that it has scalability problems (it's governed by a global lock) and it invalidates data far too frequently to be useful in a normal workload. But InnoDB buffer pool contains indexes and data accessed frequently. After your first query, some indexes and data are cached, so next time they will be read from memory. Probably some data/index pages are accessed only once per query, in which case you should be able to see a slighter difference between second and third execution (first time these pages are not cached). How to avoid the difference between query execution times? Well, there is no way to make the query faster the very first time it runs, as it needs to read from disk. But then, if your buffer pool is big enough, your query will always be fast. Keep in mind that a big buffer pool is very important for MySQL performance. The general recommendation is to keep it 75-80% of total memory. But in reality, things are more complex: 

If you eventually decide to use master-master, I suggest to regularly test failover during normal work hours with a non-crazy traffic. So you will avoid bad surprises when the situation is bad. Hope this helps. 

This query doesn't take advantage of the primary key in any way. The number of rows examined (about 160K rows) shows this. So your assumption that your does nothing is incorrect: it examines several rows. The reason why your SELECT is faster is pretty clear. This expression is computed once, at the beginning of query execution: 

I don't think that someone can give you magic numbers like the acceptable number of columns, or information too strictly related to your workload, like if it is a good idea to split the table. There are too many variables: number/types of existing columns and indexes, number of queries, how many columns you read per query, and so on. Proper tests will give you a good answer. All we can say is that, yes, common sense says that such a table should be split if possible. But then, every query will need to read from multiple partitions? Every new row will have matches in all partitions? This could slow down your application. Ideally, most of the queries should be able to read from only one partition. So the first suggestion would be to check with developers if some queries can be rewritten so that they will read less columns - possibly by rewriting some . You also ask about the best possible match condition. Here the answer is easy: join by primary key. All matching rows should have the same . It should be an columns on only one table. You first insert new rows into the table, then to the others, in this way: 

I don't think that your approach is wrong, but I don't have much information. Your question is clear, but this space is limited compared to the complexity of your system. Definitely you shouldn't consider using Clickhouse for OLTP. Not only because and are not (yet) supported, but also because this database is designed to provide good performance for analytics. It lacks more or less everything is needed to optimize an OLTP workload. Kafka is a good idea? Maybe. But you won't have transactions, for example. I suggest to try to optimize your MySQL environment first. Some very generic points - sorry if they sound obvious to you, but of course I can't know your skills lever: 

by performing two s, followed by a subsequent . This seems like a highly inefficient way to perform this operation when the returns approximately 5637 rows, but the returns over 3 million! Is there any chance that you have a very large number of entries in for which is not ? In this case, I would think the optimal plan would be to use the to extract a set of candidate rows, and then simply filter this small set of results for . I'm surprised the optimizer has chosen this plan, but I have a wild guess that it's because the is actually highly selective on that column (such that maybe only 10% or less of the listings are Active). To try and address this, I suggest trying the following query: 

With such an index defined, if you make a query with a matching predicate, an index scan is performed rather than having to perform all the calculations for the statement. (2) Another denormalization option is to use triggers during on your table to verify if certain conditions are met, and when they are met, store the of that entry in another table, thus making a simple table scan all you need to do at a later time to find matching entries. Both of these cases will require additional storage space, as well as some minor overhead for predicate checking, but it allows you to distribute your predicate checking over time, rather than being forced to do it all at once when a query is issued. Conclusions As with any advice on the internet, take mine with a grain of salt! :P I've done some work in both of these areas, but that doesn't make me an expert in your application area. Run some small scale tests on either approach to see what works best for your application. 

Your issue appears to be that you are applying the same (named ) for both your and your . When you use a which contains an clause, and you then apply certain aggregations such as or , it applies the aggregation continuously across the ordering, which is why your and are identical. If you modify your query have multiple windows as 

There are a few different strategies you could take, where on one end you pursue aggressive normalization to, on the other end, full denormalization. The full denormalization would be equivalent to your second example where all relevant info simply ends up in the transaction table without references to other tables. Full Normalization So, to completely normalize, you would still want a table, but you want to even eliminate the storage of redundant information in this table, so you would need a table and a table as 

I'll venture a guess at what you're looking for. I've made the assumption that the table is called , the column which contains the entries for , , etc. is called , and of course you have your other columns. So, with a simplified table and some data defined as 

I'm going to add my answer, which was correct in the comments, as the answer here. Be specific about your types! In your master table, you have as a . In your constraint, you have used . Then, in your query, you just use , thus using a type in your predicate. To fix your problems, make sure that all of these entries are referring to a consistent type. In your comments above, you indicated that you changed all entries to refer to the type , and that it fixed your issues. 

I changed the subselect to return , and removed the table altogether, since in your original body text you stated no conditions on the table. Is this what you are looking for? 

There aren't many cases where I'd recommend this course, only if this is a tiny project which doesn't warrant much of your time. Dimensions and Facts So, if you've cleared the hurdle of question (1), and you want a more performance schema, this is one of the first options to consider. It includes some basic normailization, but extracting the 'dimensional' quantities from the measured 'fact' quantities. Essentially, you'll want a table to record info about the trips, 

Nick, based on the information we've gathered, I'm going to venture a guess, but if I'm wrong, come back and let us know and there may still be something we can do. I wouldn't say I'm confident about the internals of auto-vacuum processes on hot standby servers. Streaming Replication, aka Log-Shipping Streaming replication, hot standby, log shipping...there's a lot of different names that people use, but the general idea is that you replicate your back up server by implementing a system where the transaction logs from your primary server are sent and re-implmented on a secondary server to keep the two identical. Now, you've stated that when you your table on the primary, you have significant lag on your standby, and also that your configuration for is set to -1, which disables logging of autovacuum actions. As a potential remedy, you could set this value to 0, indicating you wish to log all autovacuum operations. My guess is that, while autovacuuming is occurring periodically on your master, since it isn't being logged, it isn't replicated on the standby. When you run a manual , only then does the logged become replicated, which may be what's eating into your performance on the standby. How are things if you run a on the master, followed immediately by another on master? This will give us some indication of if I'm right or if I'm full of hot air.