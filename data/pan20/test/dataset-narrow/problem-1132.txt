There is a linear time algorithm. Contract all strongly connected components, then you get a DAG. Find all the source vertex in the DAG. For each source vertex in the DAG, pick a single vertex from the strongly connected component represented by the source vertex. 

You can even get $O(|V|)$ time if the edge weights are sorted. See the following paper: Erik D. Demaine, Gad Landau, and Oren Weimann, “On Cartesian Trees and Range Minimum Queries”, in Proceedings of the 36th International Colloquium on Automata, Languages and Programming (ICALP 2009), Lecture Notes in Computer Science, volume 5555, Rhodes, Greece, July 5–12, 2009, pages 341–353. 

The problem is NP-hard if $\alpha$ is part of the input. We can reduce the Steiner tree problem to this. Given a graph $G$ and terminal vertices $T$, consider $G_0$ to be a complete graph on $T$, and $G_1=G$. Let $|T|=k$ and the size of the minimum Steiner tree of $T$ in $G$ be $h$. If $\alpha=k/h$, we claim that $V_0'=T$. Assume not, then $|V_0'|<k$. $|V_0'|+|V_1'|\geq k+h$, so $|V_1'|> h$. But then $|V_0'|/|V_1'|<\alpha$. A contradiction. Also, $|V_1'|=h$, as anything larger violates $|V_0'|/|V_1'|\geq \alpha$. $V_1'$ also gives us the vertices of a minimum Steiner tree on $T$. We can obtain $h$ by guess every possible $h$, there are only $n$ possibilities. Hence we reduce Steiner tree problem to your problem. 

One can solve the decision problem in $\tilde{O}(nA)$ time. Let the sequence of numbers be $S$. Define $F_S$ to be a set such that $(i,j)\in F_S$ iff there exist a subsequence of $S$ of length $j$ that sums to $i$. If we have computed $F_S$, then we just need $O(nA)$ additional time to go thorough $F_S$ to solve your problem. If $S_1$ and $S_2$ are two subsequences that partitions $S$, then $$F_S = F_{S_1} + F_{S_2}$$ where $A+B=\{a+b | a\in A, b\in B\}$ is the minkowski sum, and addition between tuples are defined coordinate-wise. Claim: Computing $F_S$ from $F_{S_1}$ and $F_{S_2}$ takes $\tilde{O}(|S|A)$ time. Proof: Apply 2D convolution on two tables of size $A\times |S|$. The algorithm partition the sequence to two equal sized sequences, apply recursion to each, and take the minkowski sum of the result. Let $T_A(n)$ be the worst case running time when the input to the algorithm has $n$ elements and $A$ is an upper bound of the sum. We have $$ T_A(n) = 2 T_A(n/2) + A \tilde{O}(n) $$ Which shows $T_A(n) = \tilde{O}(n A)$. The hidden $\log$ factor is $\log n \log nA$. 

You are looking for the shortest straight-line program to compute a set of formulas involving xor. This is NP-hard. There are papers on how to efficiently solve this problem with SAT solver. For example, Fuhs and Schneider-Kamp had this recent paper on Synthesizing Shortest Linear Straight-Line Programs over GF(2) using SAT. There is a proof that this problem is MAXSNP-hard by Boyar, Matthews and Peralta, see here. 

Although I'm late to the game, it's still useful to have a reference. This is a variation of the dart board design problem. The $x_i$s are the scores for each wedge of the dart board. The goal is to make sure if one decide to hit a particular slice, there will be a huge penalty if the player misses: A large gap in the scores between two adjacent wedge. Hence it is formulated as maximize $$\sum_{i=1}^n |x_{\pi(i)}-x_{\pi(i-1)}|^p$$ where $p\geq 1$ and $\pi$ is a permutation and $\pi(0)=\pi(n)$. Your version that maximize $$\sum_{i=2}^n |x_{\pi(i)}-x_{\pi(i-1)}|^p$$ is the hoopla board design problem. Curtis have a greedy algorithm for both problems, and it is very close to your algorithm$^1$. The only difference is you are growing the list in only one direction, but Curtis grow the list in both direction: add an element that maximizes the difference to either end of the list. Update : Actually, this follows directly from an much older result that keep getting rediscovered: (maximum) TSP problem where the distance matrix is a Supnick matrix. 

This answer gives a determinstic $O(n~\mathrm{polylog} n)$ algorithm. It appears that Sariel and David's algorithm can be derandomized through an approach similar to this paper. [2] While going through the process I found there is a more general problem that implies this result. 

Frederickson and Johnson obtained an optimal result in the 80s. Let $p=\min(k,t)$, then there exist an algorithm solves your problem in $O(k+p \log \frac{t}{p})$. Reference G.N. Frederickson, D.B. Johnson "The complexity of selection and ranking in x+y and matrices with sorted columns" J. Comput. System Sci., 24 (2) (1982), pp. 197–208 

For a language $X$, define $ss(X) = \min_{x\in X} |x|$, the length of the shortest string in $X$. For simplicity, we define $ss(\emptyset)=0$. Let $L$ be a context-free language generated by a context-free grammar with $k$ non-terminals. (assuming all context-free grammars are in Chomsky normal form.) Let $R$ be a regular language recognized by an NFA of $n$ states. 

There is an $O(n \log^2 n)$ time algorithm. [Aggarwal and Suri 87] It seems to be the state of the art. 

Let $A$ and $B$ be subsets of $\{0,\ldots,n\}$. We are interested in finding the Minkowski sum $A+B=\{a+b~|~a\in A,b\in B\}$. $\chi_X:\{0,\ldots,2n\}\to \{0,1\}$ is a characteristic function of $X$ if $$\chi_X(x) = \begin{cases} 1 \text{ if } x\in X\\ 0 \text{ otherwise}\end{cases}$$ Let $f$ be the discrete convolution of $\chi_A$ and $\chi_B$, then $x\in A+B$ if and only if $f(x)> 0$. Hence $A+B$ can be computed in $O(n\log n)$ time by discrete convolution via FFT. Sometimes it is important to find out the actual pair $a\in A$ and $b\in B$ that sums to $x$. $a\in A$ is called a witness of $x$, if there exist $b\in B$ such that $a+b=x$. A function $w:A+B\to A$ is called a witness function if $w(x)$ is a witness of $x$. 

I'm only going to talk about the constraint matrix part of the problem, I don't know much about the linear system (TDI) part. Call a matrix $A$ good if $\{x|Ax\leq b,x\geq 0\}$ is a integral polytope for all integral $b$. TUM is precisely the set of good integral matrices. This is a result by Hoffman and Kruskal. see this for how the theorem comes about and the original paper. If we relax the requirement that $A$ is integral, then we get a larger class of matrices. Call a good matrix $A$ trivial, if it is a scaling of a TUM matrix (i.e. $A=\frac{1}{k}B$ for some TUM matrix $B$ and integer $k$). Sadly, I don't know of any natural non-trivial good matrices. But there is a characterization of good matrices. A matrix $A$ is $1$-regular if for all non-singular square submatrix $R$, $R^{-1}$ is integral. We have the following by Appa and Kotnyek. 

The representation of $f_i$ matters. If $f_i$ is given as the list of values $f_i(0),\ldots,f_i(C_i)$, then the problem is in $P$. Let $D(k,b)$ to be the maximum value of $\sum_{i=1}^k f_{i}(x_i)$ under the constraint $\sum_{i=1}^k x_i = b$. The answer you looking for is $\max \{ D(N,b) | b\leq C\}$. One can write a recurrence for $D(k,b)$ use idea similar to the knapsack problem. It's not difficult to get $O(NC^2)$ time. 

You just have to solve the following problem: Find a matching of size exactly $k$ with minimum weight. It can be solved by reducing to min weight perfect matching. See the paper by Ján Plesnı́k. There is a constant blow up in the number of vertices. So your original problem can be solved in $O(n^3)$ time. 

Hao, Jianxiu X.; Orlin, James B. (1994). "A Faster Algorithm for Finding the Minimum Cut in a Directed Graph". Journal of Algorithms 17 (3): 424. doi:10.1006/jagm.1994.1043. 

Is this problem studied? I'm interested when $k$ is a constant. When $k=1$, this is the same as checking if there is a Eulerian trail from $s_1$ to $t_1$. 

This is equivalent to two ray shooting queries. There is a tradeoff in space and query time. For any $n< m<n^2$, there is an data structure that returns result in $O(\frac{n}{\sqrt{m}} \log^{O(1)}(n))$ time using $O(m^{1+\epsilon})$ space. [1] [1] Pankaj K. Agarwal and Jiří Matoušek, Ray Shooting and Parametric Search, SIAM Journal on Computing 1993 22:4, 794-806 

We are given a $n$ vertex directed graph $G=(V,E)$ and also given a cost function $c:V\times [n]\to \mathbb{R}$. Consider a topological ordering of the vertices, $v_1,\ldots,v_n$, the cost of the ordering is $\sum_{i=1}^n c(v_i,i)$. Is finding the minimum cost topological ordering NP-hard? 

See this paper. I think adopting their technique, many(usually scaling based) min-cost flow algorithms with running time $O(f(n,m))$ can run in $O(f(n_1,m))$ time. Here $n_1$ is the size of the smaller bipartition. If $f(n,m)$ is the best possible run time for min-cost flow on general graphs with $n$ vertices and $m$ edges. There is an easy argument that you can't expect anything running in $o(f(n_1,m))$ time. (with some reasonable assumptions, like $n\leq m$, $f(n,cm)=O(f(n,m))$ for any constant $c$) Proof: Otherwise, you can apply the standard vertex splitting operation to the input graph and use the bipartite min-cost flow algorithm and get a better running time. Finally, if you are restricting cost and capacities things, these scaling algorithms is still pretty much state of the art(difference is at most $\log c$ for w/e parameter $c$ you care about). You can decipher that Theorem 3.5 to see which one of them gives you the best result. 

We want to maintain a dictionary of $m$ elements with insert/delete and lookup in the word RAM model. Assume $m=O(n)$ at all times, so there can't be too many inserts without deletions. The universe has size $\{0,\ldots,n^c-1\}$ for some constant $c$. How fast can we support these operations deterministically (in either worst case or amortized time) if we are restricted to $O(n)$ space? How about $O(n \mathop{\mathrm{polylog}} n)$ space? A few simple observations: 

The case where all gaps have the same parity was solved by Jácint Szabó. There is a very recent arXiv post by Szymon Dudycz and Katarzyna Paluch. They claimed to have solved the problem. 

A naive upper bound is $2^{kn^2}$: find a context-free grammar for $L\cap R$ with $kn^2$ non-terminals. Motivation: Answer to the above question can lead to a better bound for the following problem. Let $L$ be a fixed context-free language. Let $\mathcal{R}_n$ to be all the set of all regular languages that can be recognized by an NFA of $n$ states. Define $f_L(n) = \max_{R\in \mathcal{R}_n} ss(L\cap R)$. 

the walks form a partition the edges of $E$, and there exists a permutation $\pi:[k]\to[k]$, such that the $i$th walk is a $s_it_{\pi(i)}$-walk. (A $st$-walk is a walk that starts with vertex $s$ and ends with vertex $t$) 

The problem is in $P$ by reducing the problem to submodular minimization. Let $v(A)$ be defined as the size of the maximum matching in $G_{|A}$. $v$ is submodular. One way to see this is convert the problem to a max flow problem, and use the fact that the set function $c(U)=$ max flow from $U$ to $t$ defined over $V\setminus \{t\}$ is submodular. I will use $f(A)$ to mean the $f(G_{|A})$ in your notation. $f(A) = |A| + |V| - 2v(A)$. $|V|$ is a constant, so we can maximize over $f(A)-|V| = |A| - 2v(A)$, which is the same as minimize $g(A) = 2v(A)-|A|$. $g$ is a submodular function(difference of submodular and modular function), and you can apply any polynomial time submodular function minimization algorithm. This can be extended to weighted case if weighted analogue of $v(A)$ is submodular. 

$\lambda(G) = \min_{x,y\in V(G), x\neq y} \lambda(x,y)$ to be the (min) edge connectivity. $\bar\lambda(G) = \max_{x,y\in V(G), x\neq y} \lambda(x,y)$ to be the max edge connectivity. 

It is NP-complete for directed graphs. Even deciding if there exist a path from $s$ to $t$ using vertex $u$ is NP-complete. The 2-node disjoint path problem is NP-hard for directed graphs$^1$. 

Consider an undirected graph $G=(V,E)$ and two sequences of $k$ vertices $S=s_1,\ldots,s_k$ and $T=t_1,\ldots,t_k$. A set of $k$ walks is called a $(S,T)$-walk partition if 

It is strongly NP-hard to decompose the flow into a minimum number of path flows. There is a simple reduction from 3-partition. See $URL$ 

Because of max-flow min-cut theorem, the first problem is much easier. We just need to find a global min-cut, namely a partition $(S,V\backslash S)$, such that the number of edges from $S$ to $V\backslash S$ is minimized. The global min-cut for both undirected and directed graphs can be solved in $O(nm)$ through Hao-Orlin's algorithm. $^1$ Max edge connectivity seems harder. I do not know of any algorithm that does less work than find all $\Omega(n^2)$ possible $\lambda(x,y)$ and take the max. This means $\Omega(n)$ max flow computation in undirected graphs by constructing the Gomory-Hu tree, and $\Omega(n^2)$ max flow in directed graphs. Is there an algorithm that solves this problem faster? It seems that $\Omega(n)$ max flow is required. Since for each component we need to compute at least one $\lambda(x,y)$ for $x,y$ in the component. Or something equivalent. There are graphs with $\Omega(n)$ components, and one must determine which component contains the largest local edge connectivity. (although in that case, most max flow computation would incur constant cost. )