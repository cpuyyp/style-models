If you have to worry about PCI compliance, then putting the red5 server on another (virtual) machine will save you a bunch of administrative headaches. Or, if your virtual machine can't handle the load of both servers at once, then you should separate them. Otherwise you should be fine. 

Hmm. A careful examination of my EPEL mirror shows that the package is now named beginning with EPEL 7. 

You got that error because your system still has the package installed. After you remove this, you can continue. As for webtatic, I would never recommend that. I always recommend you use the remi repository. He also builds the official Red Hat packages, and provides repos with newer versions of PHP for those who need them. 

The grub configuration is found in on CentOS 7 systems. Within you will find the default kernel command line parameters, which you can edit. 

Merely adding or removing vCPUs after installation of the guest OS is not an issue with any version of Linux or Windows that's recent enough to still be vendor supported. This warning dates back to the very early days of VMware and is mostly irrelevant now. In the early days of Linux, though, the kernel had to be specifically compiled with SMP support, and occasionally UP kernels didn't like running on SMP/NUMA systems, or vice versa. Those days are long since mostly forgotten. These days Linux kernels are almost always compiled with SMP/NUMA support by default and run fine even with one processor. This has been true for all of 2.6 and most or all of 2.4. Windows has behaved similarly since Server 2003. I wasn't able to quickly find definitive information on the Internet about how 2000 and NT 4.0 behaved, though I seem to recall from distant memory that they may have had issues when switching from a single CPU to multiple CPU configuration. If you plan to P2V a very ancient system, though, it's theoretically possible you might run into such issues. 

My current EL7 systems have roughly 200 MiB used in /boot, but I usually don't install kernel-debug packages. As the Linux kernel continues to grow over time, mostly due to adding hardware device drivers, this recommendation is likely to continue to grow as well. And again, as noted by others, a /boot partition isn't strictly required anymore for most installations. VMs generally do not need it, for instance, and UEFI booting systems also don't need it (though they have an EFI System partition which must exist and be large enough to hold various UEFI files). A /boot partition is required for some very old legacy systems and for using LUKS full-disk encryption. 

There's no difference; is optional provided the device name can't be mistaken for another keyword that the command understands. For instance, if you had an interface named then you would have to use as is also a keyword that uses. This is undocumented behavior, but it certainly appears to work. You'll know if you ran afoul of 's option parser if you get a (slightly grammatically incorrect) message like: 

The [END] flag is not relevant here, since you are serving 301 redirects. And as the documentation you linked to states... 

In case you hadn't noticed, OpenSSH ships with a large number of pre-generated moduli, all the way up to 8192 bits. While we're certainly concerned about 1024-bit primes today, 2048-bit ones are believed to be safe for the foreseeable future. And while that will eventually change, it could be next week, but it's more likely to be long after we've become pensioners... There is also this curious bit in the man page: 

You have placed your directives in the wrong places. should be defined in the block, not in each block. This is one of the most common nginx misconfigurations. To resolve the issue, remove all of the directives from each block, and place the correct directive within the block, not within any . 

These were taken from this question on SO, the answers to which may contain other ideas for people in similar but not quite the same circumstances. 

You have two different versions of PHP installed, judging by this and your other question. You should remove one of them. 

This service is not "disabled", it is "static". This means it cannot normally be launched directly, but is launched by systemd in response to some event. Since this service is meant to drive a fingerprint reader, it's a good bet that it will be fired during a console login attempt. If you don't have a fingerprint reader and don't intend to ever have one, you can mask the service, so that it can never be started, even if it is uninstalled and reinstalled, and even if a dependency asks for it: 

The vagrant documentation does not appear to suggest to use 33.33.33.10. Digging deeper into the official documentation, I was only able to find RFC 1918 addresses in use. Given the apparent close association between Vagrant and this incorrectly-used address, I can only surmise that the docs did refer to it in the past, and were later corrected. Oh, and you definitely should not use someone else's public IP address, even on your own private network. Very Bad Things can (and probably will) happen. 

You appear to have hit a long-standing issue in Android. In particular Android will only load the autodiscover XML over HTTPS. If you serve it over HTTP then Android will refuse to even attempt to use it. As described in the bug, Android does not use DNS SRV records to locate mail services. 

You would only theoretically have problems if you live migrated your VMs from an AMD processor to an Intel processor (i.e. vMotion), so vSphere just won't allow a vMotion in this scenario. If you shut down the VM and then start it up again on the new processor, you will be fine, provided the guest OS isn't particularly processor-dependent. (For the most part this is Windows 2000 and older operating systems.) 

Close port 3000 in your firewall. Then make sure you start thin in such a way that it is bound only to the localhost. This absolutely prevents inbound connections not originating from the local machine itself. For instance: 

You're looking for . The standard Linux commands for user and group management (from shadow-utils) are: 

You cannot use a domain name that someone else controls. If you attempt to do so, you get the errors shown here. Instead, use a subdomain of your own domain name. If you do not have a domain name, one can be obtained very cheaply from numerous domain registrars. 

Your rule never takes effect because you have added it to the end of the chain. Immediately preceding it is a rule to drop all traffic, thus your rule is never reached. In iptables, rules are matched in order; this is different than many other firewalls. To resolve the problem, move the rule up to earlier in the chain. And if you really want to blacklist those addresses, it should be as early as possible in the chain, e.g. the first rule. 

You're missing a level of indirection. A logical volume is created in a volume group, which itself is comprised of one or more physical volumes in various possible topologies (not all of which can be constructed in kickstart, but that's irrelevant here). To put the LV in a different PV, the VG containing it must be on the desired PV. So, you need to create a second VG, and assign the PV to only that VG. For example: 

This is just a common CR1632 coin type battery which can be bought virtually anywhere in the world for a couple of dollars US. It keeps the system clock running whenever the system is powered off. What's surprising is that (1) it lasted this long, and (2) your company is still using that ancient server. You replace it like any other such battery: pop the old one out and pop the new one in. Then be sure to reset the system clock, as it will most likely be wrong. But there's no need to hurry about this; you can do it whenever the system is next powered off for some other maintenance. Of course, given its extreme age, you should just decommission it before it blows up... 

You appear to be running an old first-generation Rackspace Cloud virtual server. You have a couple of options: 

If you want to access port 82 directly, you'll need to open the appropriate port in the server's firewall. You can do this with the command line tool. 

Recent versions of can also listen on IPv6 and then forward the connection to an IPv4 address. A sample configuration which listens for IPv6 connections on port 3389 and forwards them to port 3389 of an internal IPv4 address: 

Note also that you're missing a address. You need to specify this as well, or the gateway given by SLAAC will be used instead. Or you just won't be able to talk to any hosts except the one you set up a static route for. 

Current versions of OpenSSL on CentOS 7 include secp256k1. If you are missing the curve, update OpenSSL on your system. 

Did you check the permissions of all of the containing directories? One of those is likely where the trouble lies. 

Today, Microsoft Azure doesn't support nested virtualization, the technology required to run virtual machines inside other virtual machines. However, this technology is being rolled out with Server 2016 and Windows 10, so it may eventually become available. Keep in mind that nested virtualization has a performance penalty which on modern hardware isn't very large, but is larger than virtualizing on bare metal hardware. Your best bet is still to virtualize on physical servers when possible. Further, Azure limits the number of global IPv4 addresses you can use, and VMs you resell to customers will need their own separate global IPv4 addresses. Moreover, Azure doesn't support IPv6, which is a critically important feature in the market you are proposing to operate in. In short, Azure is a poor fit for what you want to do. 

You're trying to install packages meant for EL6 onto EL7. This will not work and there is no way to make it work. They are not compatible. If you really want to run an old Varnish version, then use EL6 to begin with. The version of varnish included with EPEL for EL7 is 4.0, so it is not likely there will ever be 3.0 built for EL7. 

For this, in addition to proper firewalling, you really need sVirt, which comes out of the box with a RHEL6/CentOS 6 KVM host. It's even enabled and working by default. I have no idea if it's even available with an Ubuntu setup. 

You still have the MariaDB yum repository on your system. As long as you do so, MariaDB will continue to replace MySQL. To resolve the issue, remove the MariaDB repository. Do this by locating the file (it may be named something like ) in the directory. Once you locate the file, you may remove it, or you may edit the file and change to . 

You haven't defined inter-zone forwarding between LAN1 and LAN2, thus the default forwarding policy (reject) is used. You simply need to open this up. Click Edit next to the LAN1 line, and in the Inter-Zone Forwarding section, make sure you enable LAN2 in both directions. 

Before we get into solutions, a few words about your company's security standards. Put simply, they're very difficult to work with, and so outdated as to be nearly irrelevant. It's obvious why they're difficult to work with, so I won't say any more about that. As for being outdated, it's clear that they do not take into account modern technologies such as virtualization, Linux capabilities, containers, SELinux, etc., all of which help to solve the same security problems in much more elegant and usable ways. By way of example, binding httpd to a high port and then redirecting traffic to it with iptables, rather than simply letting it bind and then drop privileges, as it does by default, borders on paranoia and gains you virtually nothing. It also complicates using SELinux with httpd, since this sort of setup wasn't envisioned with the design of the httpd SELinux policy. In the same way, just blindly requiring packages to stuff themselves into or gains you nothing, as RPM already maintains the separation you require regardless of where packages are installed (unless the package is broken, which may be the case with third party vendor packages, but such would refuse to install) and loses standards compliance, possibly making relevant SELinux policies unusable, and creating a maintenance nightmare. Red Hat Software Collections is designed along these lines, and while it has some usability issues, building your own packages by this design could be a stop-gap measure while you work on the real issues. The biggest problem I see, though, is maintaining a "big iron" sort of server, or servers, on which everyone's applications run side-by-side. This alone introduces its own security issues, which is probably the origin of these "security practices." Virtualization is quite mature at this point and simply separating applications into their own VMs, e.g. with KVM on RHEL 6 or RHEL 7, will eliminate the need for the majority of these "security practices." Along those lines, since you almost certainly have a very large number of applications, creating a private cloud with OpenStack is probably going to be your best bet in the short to medium term. These would use RHEL 7 hosts and run RHEL 7, 6 and maybe even 5 guests as you probably have a bunch of those still alive and kicking. It would also give you a platform to experiment safely with new applications and operating systems, as well as allocate resources more easily by business unit, department, etc. If virtualization is too heavyweight for some things, then move to containers (e.g. LXC/Docker on RHEL 7). These are much lighter weight and can be stripped to virtually nothing but the application package itself, and then isolated with their own filesystem, network and uid/gid namespaces, effectively cutting them off from any other container except via whatever you happen to open in the respective firewalls. Adding SELinux to either KVM virtual machines or Linux containers provides a second layer of protection, and can be turned on with about one click. Plus, your company is full of developers who will love you forever if you start offering them OpenStack and/or Docker. In short, it's time to evaluate modern Linux distributions and the capabilities they provide, and reassess all of the security practices in light of those capabilities. With respect to licensing, Red Hat now offers unlimited virtualization licenses, allowing you to run unlimited RHEL VMs/containers, and of course there's also CentOS which will drop-in replace RHEL about 99.9% of the time. So there's no excuse there.