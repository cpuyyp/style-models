Why provide a password at all, when you are going to use public/private keys. Public keys are meant to be shared, so this is what you should use to securily exchange credentials, not hashed passwords. 

Using the 'principle of least privilege' you should only run a program with root privileges if it needs them, and then drop them again as soon as you don't need them anymore. So yes, there is a difference, if there is an exploit for nice, an attacker could run code with the same privileges as the nice program. Also, sudo resets your environment, so it migh thave side effects, try 

If you do not trust these people, is dissallowing them to change the Jenkinsfile enought? To have proper testing the jenkins server will at some point have to run your code, so if they can push a change to a certain file that they know will be executed on your Jenkins machine, they could alter it at will and make it run whatever you are trying to block them from in running in the Jenkinsfile. Taking away their github owner status doesn't even solve this problem, they can make a pull request with bad code in it, which your jenkins machine will merge and run. Also, your Jenkins shouldn't run as root, have a jenkinsuser without sudo rights to run the tests. 

All of this in a command line tool that can be run from our laptops, that will connect to the right master node, run the right command for the right node, and return the output, with an additional list of errors if any (based on output on stderr and/or exitcode) This has proven to be very handy, and adding support for a new class of hardware is relatively easy now (Thanks to the fact that most vendors do fully support ipmi and DMTFSMASHCLP now) This is not suited for initial configuration (it needs the bmc to have a unique ip and correct gateway, but this is what our vendors need to supply us with on delivery) but can do almost anything else (also run arbitrary commands on the host operating system, and automatially schedule downtime in icinga/nagios when you reboot a node, and/or acknowledge 1000 hosts and services in icinga/nagios at once) Updating the bmc firmware and adding support for our switches are outstanding issues that are planned. UPDATE Since at least some people seemed interested I have given it a last polish today, and open sourced this at $URL$ Whilst this is very much targetted towards our own workflow (quattor and/or pbs) I hope it at least can be interesting. 

I have written a small python tool to run command's on our 1000 machines, (and their bmc's, drac's, ilo's and imm's) What I did was write a python-framework called vsc-manage where I can run command's that are either sent to the server, or the bmc, and then configured what type of machine needs what command. I have several classes that combine a mix of these command's, So for machines with an imm it will ssh to the imm, and run (in an expect-script kind of way) For our imb blade chassis's it will run this on the chassis 

Should still work, so don't go hardcoding your path anywhere please! Some libraries are wrapped into some other tool that makes them also executable and usable as a library, but they are still libraries, and not in your $PATH, so it is ok to puth them in /lib I guess. 

You don't have to install software to /usr/local, you can install all software in a different prefix, which might be in /home. Most software can do do this when you compile it from source, by running e.g. Since you're a biologist you might be interested in a lot software that's not properly packaged in an rpm or deb and you will have to compile it from source anyway. I'm a sysadmin for an HPC system with a lot of biologists among our users, we install all the software they request under a /apps/ filesystem, so I know it is possible to do this for most software, however, sometimes it might be very hard. To solve this problem my colleages and I have been writing on a tool called EasyBuild (Free and open source) It can compile and install software from source, and install it in a different folder, and automatically create an environment module file for you, so you can actually have 2 different versions of the same software installed, and have no conflicts. Have a look at our list of packages we can install with just one command, as a biologist you might recognize a lot of them ;-) Disclaimer: I'm a developer of EasyBuild 

The problem does not seem to be gone, roughtly 75% of your packets are getting dropped? If TCP goes into slow start all the time, your average bandwith might be rather low. Btw, do you have benchmarks for London to LA, and London to London? 

If after this your smart values seem ok I would trust the disk. To know what each smart value means, you can start looking here $URL$ 

Here is an interesting blog post from BackBlaze on how they do this (they proably don't need as much disks as Google or Facebook, but still a whole lt), and what they needed to do when there were floods in Thailand that made harddisk expensive and harder to get by: $URL$ 

The kernel is detecting that it is running out of memory, possibly because some process is running wild. Usually OOM killer will try to identify this process, and kill it. The reason it is killing mysql is because this is probably the process that is currently taking the most amount of ram, so it's a very likely candidate for the running wild process. However, it also seems like snmpd is the culprit. (it is taking 160MB's which is a lot) snmpd is a deamon responsible for listening for snmp traffic, it seems weird for it to take this much memory. Since this is happening each day at the same time, check your daily cron jobs. And check your snmpd log file. Also check for incomming connections around that time. (from sshd) All these log files should be showing up somewhere in /var/log/xxx If this turns up nothing unexpected, look in the log files for the other processes mentioned in the log. (mysql and rsyslogd) Also, from your graph you only have 66MB free on average, and are running in to memory issues way more then just at 6.40, almost 20% of the time you seem to have less then a few MB's free, never more then 100MB free. (if I correctly see that the magenta bar is the free memory?) 

What mount options do you use for your nfs? Removing options like (and allow the default instead) will allow the clients to cache a lot more aggressively, we noticed this can confuse users when a file in their home directory is added and it takes an hour before it is visible on the remote machine, but for binaries turned out to be fine. We also set and on our applications mount. Home folders: 

From an IBM guide on LVM: "The mechanisms for defining and expanding logical volumes attempt to make the best possible default choices. However, satisfactory disk-I/O performance is much more likely if the installer of the system tailors the size and placement of the logical volumes to the expected data storage and workload requirements. " see $URL$ and $URL$ 

You install your libraries in , your binaries in , your header files in , man pages in , pkgconfig files in or , your cmake .m4 files in Then let package manager decide on the prefix. If you are distributing rpm's/deb's yourself, is a good choice for a prefix. 

I had the same question 2 months ago. After sending in a failed disk, the replacement disk failed in my NAS after 3 days. So I decided I would now test the new replacement before putting it in production. I do not test every new disk I buy, only on 'refurbished' disks, which I do not completely trust. If you decide you want to test these disks I would recommend running a badblocks scan and an extended SMART test on the brand new hard disk. On a 2TB disk this takes up to 48 hours, The badblock command writes the disk full with a pattern, then reads the blocks again to see if the pattern is actually there, and will repeat this with 4 different patterns. This command will probably not actually show up any bad blocks on a new disk, since disks reallocate bad blocks these days. So before and after this I ran a smart test, and check the reallocated and current pending sector count. If any of these have gone up, your disk has some bad blocks already and so might prove untrustworthy. After this I run an extended SMART test again. You might want to install smartctl or smartmontools first. Warning, the badblocks -w flag will overwrite all data on your disk, if you just want to do a read check, without overwriting the disk, use 

For our newer hp systems that do ipmi (and I see more and more these days) it will run this on the master: 

I personally would benchmark the speed you're getting from the TU2-ETG, this will probably not be a bottleneck to your service provider, but since you're saying you get faster speeds after removing the 100mbps switch this might be your next part. The TU2-ETG claims to have a Gigabit link, but the other side of this link is USB 2.0, which has a maximum signaling rate of 480 Mbit/s (effective throughput up to 35 MB/s or 280 Mbit/s), I for one have never been able to get speeds higher then 20MBps over a usb connection. I could not find any real benchmarks from this device, so try to do a benchmark or two and see what this gives you. This is probably only relevant if your internet uplink is faster then 100mpbs, but then again, I see your provider offers 150mbps packages. So be aware this is definitely not a gigabit network card. 

Programs that rely on these assumptions may behave weirdly when is cleaned all of sudden. So you shouldn't just symlink it to /tmp 

Usually the client using most IO will also doing most network traffic, so what I do is: dump all traffic for a few seconds, and then create a sorted list of the hosts (limited to the nfs hosts) that used most traffic: 

There isn't such a tool I know of, usually this is inculded in your backup software. What backup tool do you use? I would recommend rsnapshot This can be configured to do these smart things you ask for, and keeps backup size small by extensive use of hardlinks. If however you have your own cronjobs/system for creating backups, you could just create a few more cronjobs. 

When sending your public key, verify the fingerprint over a second channel, like a phone call, so you know nobody altered it on it's way in. Since you won't have a password now to use sudo, you need to also alter your line in the sudoers file to 

It will try to suck cool air in from the front, and blow hot air out at the back. Since hot air rises I recommend mounting it with it's front facing the floor. I've seen people mount servers this way (e.g. the folks at $URL$ ) and they tell me there are no drawbacks to this, other then possible inconvenience when having to replace a component. 

Use the -q --queryformat options from rpm as said before, if you want to do this on a non installed package you can specify the rpm with the option, like this: 

If you're not comfortable with having no password for sudo, and really want a password, there still is no need for you to send your hashed password, let the account be created without password, set your public key, and once your account is set up you can log in over ssh and run to set your own password. 

I have expierenced similar issues I noticed that and will not return the same results, Using strace I found that checks data in wheras will connect to and get it's data from there. This is really confusing me, since both approaches seem to hit different caches. These caches seem to get updated when I run but seem to otherwise be valid for hours. The result in practice is that e.g. ssh access won't work for a user a few minutes after it is removed from the ldap, but getent passwd will keep on showing it for hours, so it's hard for me to check if this users is in fact removed or not (without clearing some caches manually all the time)