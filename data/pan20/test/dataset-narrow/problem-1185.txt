The variant where the swaps don't need to be of adjacent elements is also of interest. Note that it's not hard to reduce this problem to edge-disjoint paths (or to integer-valued multicommodity flow); what I don't know is a reduction in the other direction. Update: OK, checking Garey & Johnson, their problem [MS6] ("Permutation Generation") is as follows. Given as input a target permutation $\sigma\in S_n$, together with subsets $S_1,\ldots,S_m\in [n]$, decide whether $\sigma$ is expressible as a product $\tau_1 \cdots \tau_m$, where each $\tau_i$ acts trivially on all indices not in $S_i$. Garey, Johnson, Miller, and Papadimitriou (behind a paywall, unfortunately) prove that this problem is $NP$-hard. If the swaps don't need to be adjacent, then I believe this implies that deciding whether $p>0$ is also $NP$-hard. The reduction is simply this: for each $S_1,S_2,\ldots$ in order, we'll offer a set of "candidate swaps" that corresponds to a complete sorting network on $S_i$ (i.e., capable of permuting $S_i$ arbitrarily, while acting trivially on everything else). Then $\sigma$ will be expressible as $\tau_1 \cdots \tau_m$, if and only if it's reachable as a product of these swaps. This still leaves open the "original" version (where the swaps are of adjacent elements only). For the counting version (with arbitrary swaps), it of course strongly suggests that the problem should be $\#P$-complete. In any case, it rules out a PTAS unless $P=NP$. 

I have some "real-world experience" in this nascent industry (and no, I'm not talking about my $200,000 offer to Deolalikar :-) ) In January, a software developer emailed me that he had an attempted proof of P≠NP, and that while he was almost sure there was an error, he couldn't find it. He asked if I knew any grad students who'd be willing to find the error for him in exchange for a few hundred dollars. To give you some context: I get a proof of either P≠NP or P=NP in my inbox roughly once per month. Many of these emails go to a long list of complexity theorists (Cook, Karp, Fortnow, Sipser...); they often include religious or metaphysical ruminations as well as dark hints about academic conspiracies. (In one case, there were graphic death threats against me, which led to my contacting the police.) Virtually none of them acknowledge any possibility that the proof might be wrong, or that the author might have misunderstood the question. And when, back in grad school, I tried to correspond with the authors, I found all of them to be fervent believers in Churchill's maxim "never, never, never, never give up." So the software developer's request really impressed me! This was the first time I'd ever seen a P≠NP proof accompanied by this level of self-awareness---both about the imposition being made on people's time and (more importantly) about the likelihood of error. As it happened, my PhD student Michael Forbes sent the author a beautiful, detailed report explaining the problems with his approach; the author thanked Michael and (I think! :-) ) paid up as promised. So yes: for amateurs who want someone to examine their P vs. NP proofs (or similar work), I think paying a grad student a few hundred bucks is a great way to go. (Note that grad students are a much better choice than professors: not only do they have more energy and enthusiasm for such things, they also need the money more.) I wish more amateurs availed themselves of this option. 

I don't know a reference, but I think both of these should be doable. For your first oracle: for starters you'll want an oracle (call it $A_1$) that encodes exponentially-large $MAJORITY$ instances, and that thereby separates both $P^{A_1}$ and $NP^{A_1}$ from $PP^{A_1}$. Then you want a second oracle (call it $A_2$) that encodes the solutions to all $PH^{A_1}$ problems, in a "staggered" fashion such that accessing the $k^{th}$ level of the hierarchy requires queries of size (say) $n^k$ (and hence you can only get a constant number of alternations in polynomial time). This second oracle should cause $P^{A_1,A_2} = NP^{A_1,A_2} = PH^{A_1,A_2} = PH^{A_1}$. (Note that $A_2$ is just an "outer" layer, meaning that any queries to $A_2$ can be simulated by $PH^{A_1}$ queries.) Finally, you'll want to appeal to Yao's and Hastad's $AC^0$ lower bounds (i.e., the switching lemma) to show that a $PH^{A_1}$ machine still can't solve the $MAJORITY$ instances in $A_1$, and therefore $PP^{A_1}$ (and certainly $PP^{A_1,A_2} = PP^{PH^{A_1}}$) remains larger. For your second oracle, you'll want to construct $B$ in such a way that you need to solve an $NP$ search problem in order to "unlock" a part of the oracle string that then boosts your power up to $PSPACE$. (Here we exploit the fact that $NP^{PSPACE}$ and $PP^{PSPACE}$ are both $PSPACE$.) A subtlety is that the secret part of the oracle can't just decide an unrelativized $PSPACE$-complete language: it also needs to provide the answers to $PSPACE$ computations that query $B$ itself. Fortunately, it's known how to achieve that in stages, avoiding the circularity: basically, you encode the outputs of the $PSPACE^B$ machines that only query $B$ on inputs of size $p(n)$ or less, in a part of $B$ that requires queries of size $>p(n)$ to access, and that's therefore "out of reach" for those machines (but not for other $PSPACE^B$ machines). Meanwhile, the $P^B$ machines are left "completely in the dark" by all this. 

Sorry I'm late -- it's a wonderful question! As others have already pointed out, that's exactly why I asked the question in my BQP vs. PH paper, and why I spent 4 or 5 months working on it without success back in 2008. One way to answer the question would have been to prove a much more general statement that I called the "Generalized Linial-Nisan Conjecture"---but unfortunately, that conjecture turned out to be false, at least for circuits of depth 3 and higher. (I still think it's probably true for depth-2 circuits, which would at least yield an oracle separation between BQP and AM.) For more recent ideas (the latest, as far as I know) toward an oracle separation between BQP and PH, see the nice followup paper by Fefferman, Shaltiel, Umans, and Viola. 

OK, James Lee has pointed me to this 2011 paper by Samir Datta and Rameshwar Pratap, which proves that my language $L$ (encoding the digits of $\pi$) is in the fourth level of the counting hierarchy ($\mathsf{PH}^{\mathsf{PP}^{\mathsf{PP}^{\mathsf{PP}}}}$; thanks to SamiD below for pointing out a missing $\mathsf{PP}$ in the paper, which I'd simply repeated in my answer!). The paper also explicitly discusses my question of lower bounds on the complexity of computing the binary digits of irrational numbers, though it only manages to prove a very weak lower bound for computing the binary digits of rational numbers. This is exactly what I was looking for. Update (April 3): An amusing consequence of the digits of $\pi$ being computable in the counting hierarchy is as follows. Suppose that $\pi$ is a normal number (whose binary expansion converges quickly to "effectively random"), and suppose that $\mathsf{P} = \mathsf{PP}$ (with the simulation involving only a small polynomial overhead). Then it would be feasible to program your computer to find, for example, the first occurrence of the complete works of Shakespeare in the binary expansion of $\pi$. If that sounds absurd to you, then maybe it should be taken as additional evidence that $\mathsf{P} \ne \mathsf{PP}$. :-) 

Today, there are lots of interesting examples of physical systems that seem able to implement some of quantum computing, but not all of it (yielding complexity classes that might be intermediate between BPP and BQP). Furthermore, many of these systems might be easier to realize than a full universal QC. See for example this paper by Bremner, Jozsa, and Shepherd, or this one by Arkhipov and myself. 

Let $L = \{ n : \text{the }n^{th}\text{ binary digit of }\pi\text{ is }1 \}$ (where $n$ is thought of as encoded in binary). Then what can we say about the computational complexity of $L$? It's clear that $L\in\mathsf{EXP}$. And if I'm not mistaken, the amazing "BBP-type" algorithms for computing the $n^{th}$ bit of $\pi$ using quasilinear time and $(\log n)^{O(1)}$ memory, without needing to compute the previous bits, yield $L\in\mathsf{PSPACE}$. Can we do even better, and place $L$ (say) in the counting hierarchy? In the other direction, is there any hardness result whatsoever for $L$ (even an extremely weak one, like $\mathsf{TC}^0$-hardness)? An interesting related language is $L' = \{ \langle x,t\rangle : x\text{ occurs as a substring within the first }t\text{ digits of }\pi \}$ (where again, $t$ is written in binary). We have $L' \in \mathsf{NP}^L$ and hence $L' \in \mathsf{PSPACE}$; I'd be extremely interested if anything better is known. 

There are no "natural" complexity-theory questions that have been proved independent of really powerful formal systems, such as ZF set theory or Peano Arithmetic. (One could certainly construct such a question artificially, by playing games with Gödel sentences.) On the other hand, yes, you can interpret the statement that a sentence S relativizes as meaning that S can be proved from a certain restricted set of axioms (basically, the "Cobham axioms" that characterize closure under polynomial-time reductions). Conversely, the existence of oracles making S either true or false is equivalent to S being independent of those particular axioms. Here's the paper to read about this, by Arora, Impagliazzo, and Vazirani. This is a very pretty connection mathematically---but it's worth stressing that we do have techniques (such as arithmetization) that go outside the relativizing axioms. And I don't know of any results of the form "if natural open problem P can be solved at all, then it can also be solved in a relativizing way." 

Prove the theorem. Observe that your proof relativizes! In other words, that nothing in the proof changes at all if all the machines mentioned in the proof get access to the same oracle A. 

Nice problem! It's not hard to give a reduction showing that, if one could solve your problem, then one could also solve the following problem, call it ISOLATED SUBSET SUM: Given integers a1,...,an, is there a subset S of the ai's whose sum is not shared by any other subset? The reduction works by first reducing ISOLATED SUBSET SUM to ISOLATED PERFECT MATCHING, where given a weighted bipartite graph G, we want to find a perfect matching whose weight isn't shared by any other perfect matching. This reduction is simple: for each i, create a 2x2 complete subgraph Gi in G, such that which of the two possible matchings we choose for Gi encodes our choice of whether or not ai is in the set S. Next, reduce ISOLATED PERFECT MATCHING to your problem as follows: