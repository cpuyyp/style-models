My best advice is to use any game/networking engine that already exists and has some good documentation, reviews, and tools. Writing your own networking for anything but a simple game could take quite a bit of time, so you'll have to weigh that against what kind of time/money you have, and what kind of game you're making. 

Alternatively, you should be able to iterate through each part in your model, and each of those have a that you can query. From that you can call , for each of the bounding spheres on the objects, and combine them to get your final bounding sphere. 

This is largely an opinion post, as "difficulty" is subjective, some people find things difficult that others find easy, and vice-versa. And honestly networking of games is such a huge topic I'd probably have to write a book about it to fully answer your question. The difficulty of networking a game depends largely upon the game type. The most difficult would probably be real-time MMOs (massively multiplayer online game), and then FPSs (first-person shooter game), then RTSs (real-time strategy game). Turn-based games like Chess, or other strategy games are usually state-based and much easier to network. Debugging difficulty depends on a lot of factors: 

Any game requiring strategy requires many iterations to get right. Having worked on multiple games that required balancing, I've learned that you start extremely early during production on the creation of different rules and abilities and immediately start balancing them. There is no "silver bullet" that will guarantee a well-balanced game. Each time a new ability is created you must weigh it against your existing set to make sure there will be little to no chance of exploiting with it. The Pokémon card game, specifically, is a relatively simple strategy game in terms of what the abilities do compared to a card game like Magic: The Gathering. Many of the Pokémon abilities do damage only, others just apply poison, or some other simple thing related to damage. You can only have two cards in the "active" position for combat. Compare this to magic where you can have a whole field of cards that can attack, many cards respond to events that occur, cards in hand can interrupt other actions. Long story short, some games are much easier to balance than others based on the range of abilities a player has at their disposal, and for most strategy game there's no way to cover every possible case without plenty of testing and iteration, reworking things until they feel fair and still fun. 

I would recommend making your mutator for your camera class do this, or make a helper function. If you have a class for your camera, I would use a mutator: 

If this code was taken from the XNA sample, then you can be almost certain that the code from the sample is not part of the problem you're seeing, so either you have changed something in the sample code itself, or you're passing unexpected data into the methods from the sample. I can't pinpoint exactly where the problem is, but my best guess is that it lies somewhere in the function where the result is being modified. 

XNA should allow you to do something like this to create your , so long as you get grab the vertex buffer for your model. 

The full range of what we could have gotten is 6 - 12 with the above algorithm. And if you wanted it even more random you could randomize the percentage used in place of the hard-coded . 

I do this by giving all of my game entities a position (Vector 2D/3D), and a rotation (Matrix 3x3). Your rotation matrix will have either a column or row for its forward, up, and right vectors. In the case of a 2D game, the 'up' vector is unnecessary. First you get the vector from your square's center to the ball's center. 

As others have said, this question isn't entirely meaningful as it stands, however this type of question I've heard many times over the years, so a meaningful answer may still be beneficial to future readers. The gaming industry is extremely broad, and even moreso recently with the huge growth of game-capable smartphones. For web-browser games: 

Then all I store in my level files for each unique object is the template ID, position, rotation, scale, and optionally any custom data by using strings. So if you have 2 trees and 1 crate in your level, the level file would look something like: 

Now we have a vector (70.7, 70.7) that represents the velocity of the bullet, in units per second. If we say that our bullet starts at position (0, 0), then after 1 second our bullet would be at that position plus the velocity vector. This means that we can now just take that velocity vector and multiply it by any amount of time to figure out where our bullet will be. So each frame we just multiply the fraction of a second that has elapsed by our velocity, and add that to our position to determine where the bullet's new position is. Let's say that our game is running at 60 frames per second, that means that a single frame would be 1 second / 60, or (0.16667 seconds). Starting our bullet at (0, 0), let's see where that puts the bullet after a single frame. 

Make sure the angles you're calculating are always in radians. If you need to calculate the radius of the circle, you can use vector subtraction, subtract point 'c' from point 'o', then get the length of the resulting vector. 

Try this: (You'll need to call this three times, once for Roll, Yaw, and Pitch). This should work, I've used it in my own game, and it has been unit-tested. Of course, if your vector/point class has its overloaded operators defined differently then it may not give similar results. Here is my vector implementation (as of a few months ago). 

Where is generally a 2D/3D vector representing a point, is a 2D/3D vector representing velocity in units per second, and is elapsed time, generally in seconds, represented by a float or double (e.g. 0.016 is 16 milliseconds, which is the elapsed time you'll generally see when v-sync'd to 60 frames per second). Now let's plug in some numbers for an example. We'll say that our bullet travels at 100 meters per second, and it's traveling in a direction of 1 x-unit and 1 y-unit. The first thing we'll need to do is convert the (1, 1), into a direction represented by a vector. We need our vector to basically be a line segment that is 1 unit in length, this will allow us to multiply that 1 by the speed of the bullet to get a line segment that represents how far the bullet will travel in 1 second. If we picture the (1, 1) as sides of a right triangle then to figure out the length of the line connecting those sides we can just use the Pythagorean Theorem, which is: 

Here's something I whipped up in about 20 minutes. We take the direction from the walker to the target, pick a direction within a certain amount of degrees of that direction (an amount that decreases as the walker gets closer to their target). This algorithm also accounts for distance to target so that it will not walk past the target. Long story short, it basically wobbles left and right a small random amount and homes in on the target as it gets closer. To test this algorithm I placed the walker at (10, 0, 10), and the target at (0, 0, 0). The first time the algorithm ran it randomly chose a position for the walker to walk to of (3.73f, 0, 6.71f). After the walker reached that position it chose (2.11f, 0, 3.23), then (0.96f, 0, 1.68f), then (0.50f, 0, 0.79f), then it walked straight to the target because it was within a minimum tolerance distance. Graphed out from a bird's eye view the path would look like the points in the image below, starting at 'W' (walker) and ending at 'T' (target). If you want a more natural movement you would precalcuate a few points ahead of time, and create a spline, giving you many more points you can have the walker follow. I've estimated what this path would look like after being made into a spline, and that is represented by the line in the image. 

I'm looking to make a water shader that colors the water based on its depth. Up until now my water shader that I've used has basically been extremely reflective and only looked somewhat blue because it was reflecting a blue sky. The effect I'm shooting for looks something like the one from the first page in this article. I don't necessarily need exact shader code, just the gist of how I calculate the color of the pixel based on the depth, while still getting a proper reflection and refraction. I should mention that I already have the water's depth calculated, per-pixel, and I also have working reflection and refraction. All I'm lacking is a color based on depth. I've tried a bunch of stuff, the next thing I'm considering is actually coloring the terrain that is underwater, and coloring it based on depth. 

Microsoft has created animation skinning samples that, with all code included that you can look at. The sample works on PC, Xbox, and Windows Phone 7. $URL$ 

What the above code would do is take that actual difference and then add +/- 0-30% to it. You should be able to use as your final result. Let's plug in the numbers in your example as see what we get. 

Your level files should end up being relatively small by doing this. You could probably manage to pack the data even tighter if you placed all matching template IDs sequentially in your file so you didn't have to continue specifying template IDs for every matching entry. You could also compress the level files, uncompressing them only to load a level into memory (or parts of a level). You can also break up your level files by physical locations within a level. For example if a level is very large then you could break up the level file into multiple smaller files, making each file easier to load into memory. Heightmaps can be done fairly cheap. Generally only grayscale is required to get enough elevation detail for a map, so using a grayscale PNG file should keep the files fairly small, even for large maps. Another technique is to scale your terrain horizontally. As you convert the heightmap image to actual vertices, multiply each X and Z coordinate by a scalar value (e.g. 4). Using a scalar of 4 would get you a terrain that is 4 times the size of your heightmap image. So if your heightmap image is 1024x1024 then your terrain will span 4096x4096 in the world. This allows you to have larger worlds, or the same size world with a smaller heightmap image. You lose detail on your heightmap as you scale, so I recommend finding the highest scale possible that is still an acceptable quality for your game. If you're using texture splatting through an RGBA texture, to achieve multi-textured terrain, you can save on memory by breaking up the splatting texture into many smaller textures and using a RAW format instead. Let's say your terrain is 256x256, and your terrain can have up to 4 different textures that can overlap. By subdividing the splatting texture you may find that some of the 128x128 quadrants of the terrain only have 1, 2, or 3 textures in use in that section, so you can now store less information in those quadrants. If one quadrant only had 2 textures, for example, let's say using the Red and Green parts of the RGBA texture, then storing information for the Blue and Alpha for that quadrant would be a waste. So you break up the 256x256 texture for your terrain into four 128x128 raw files, and the quadrant using only Red and Green can now store only the raw data for those two colors, using nothing for the other two colors. If you use this method you also only have to load up the raw files for the portions of terrain that are visible, rather than the larger texture for the entire terrain all at once. Games like World of Warcraft use technology similar to this. 

¹ Minimum corner: Refers to the corner of the box with the lowest X, Y, and Z values. Please note, I created this algorithm off the top of my head, it may not even compile exactly as written, but hopefully you'll get the gist. An algorithm like this checks one block at a time, rather than moving in segments that could step over the edges of blocks. EDIT: Just realized how similar my algorithm ended up being to Blecki's answer. Maybe that gives some merit to each answer as being a good possible solution, seeing as how we both came to similar conclusions. 

Form a triangle using the two sides you already have (one side is from 'c' to 'o', the other from 'o' to 'a'), and the third side goes from 'a' to 'c'. You don't know where 'a' is just yet, just imagine there is a point there for now. You'll need trigonometry to calculate the angle of the angle that is opposite to the side 'd'. You have the length of the sides c<->o and c<->a, because they're both the radius of the circle. Now that you have the length of the three sides of this triangle you cannot yet see, you can determine the angle that is opposite to the 'd' side of the triangle. Here's the SSS (side-side-side) formula if you need: $URL$ Using the SSS formula you have the angle (which we'll call 'j') that is opposite to side 'd'. So, now we can calculate (aX, aY). 

In the image here you can see the overlap distances are 5 and 7. From this you can create determine how far to push the player so the they will not be overlapping any longer, you would move the player up 5 units and over 7 units. The tricky part can be when you're overlapping multiple squares at once though, if you resolve them all one at a time, pushing out of one box can push you into another. To solve this, combine all the results from each rectangle into a single position change, and once you have all of those results you'll know the final position to move the player to this frame. 

What you need is to create a system to manage this for you. I have a list of bodies that each body is colliding with at any given time, I build this list based on the events I receive from JigLibX. At the end of each physics simulation step I update the list. Any new entries in the list that weren't there during the last step are new collisions, and I will send out an event for each of those that I find. Any collisions that were there during the last step that aren't there now are collisions that have ended, and I send out an event for all of those. And any collisions that I receive that were already in the list I do nothing for. Here's a visualization 

My terrain shader does quite a bit, but I don't know how to break it up in any way that will reduce my instruction count without removing key features of the terrain. It does the following: 

I use a template model. Every object in my game has a template ID, which is an integer. You can use the template ID to look up from a database or spreadsheet (or whatever you'd like), all the information about that kind of object. For example 

I'm not familiar with the particular platform you're working on, but I would imagine that a simple rectangle intersection function would solve this. 

I've worked with about 50 different game programmers in the last 5 years, all of them have a bachelors in CS or Math. I can tell you that most interviewers don't care much about the exact school you went to, they care more about experience, and skills that you have. It's somewhat of a double standard, most interviewers want you to have at least a bachelor's degree, but they could really case less which school you got it from. Without a degree I would estimate that you'll miss out on more than half of your job opportunities just due to not even getting an interview. To properly cover your bases in the case where game programming doesn't work out for you, I would recommend a decent 4-year college that focuses particularly on computer science in some way, this will leave you with a degree that you can use for programming in any field. There are some colleges that offer degrees specific to game programming, however they're rarely accredited and you'll be left with a degree that makes it hard to move to non-game programming. Apart from just the college, here's some general advice for getting into the industry. If you want to get into game programming I suggest determining which part of game programming you enjoy most and want to focus on, and spend time on that (e.g. A.I., physics, gameplay, graphics). Become an expert in that specialty, learn cutting-edge techniques, make demos and videos for a digital portfolio, and learn the languages that most companies are looking for. Also, keep in mind that most colleges you choose from will be teaching programming practices in general, not something specific to games, so you're going to have to take the initiative to apply the programming you learn to learning how it applies to games, in your spare time. The language(s) and game engines you choose to learn will likely be based on the type of games you want to focus on. If you want to make web-based games then something like Flash, Unity (C# and Javascript), HTML5, and WebGL would be the likely choices. If you want to make AAA game titles for PC, Mac, and/or consoles then C++ is probably the most used. If you're making mobile games for platforms like Android or iPhone, C++ (iPhone), and Objective-C (iPhone), Java (Android-based devices), and Unity (iPhone and Android) are good choices. I highly recommend looking through job listings at all kinds of gaming companies around the country, see what kinds of things they're looking for, find out what is most in demand so that you choose a specialty that is more likely to land you a job. Also be mindful of the future, technology is always changing very rapidly. The iPhone came out a little over 4 years ago, if you had just graduated from a 4-year college today the gaming industry would already be vastly different than when you had started school. Make sure you choose to learn languages and skills that will be relevant 5-10 years from now, not ones that are on their way out the door already.