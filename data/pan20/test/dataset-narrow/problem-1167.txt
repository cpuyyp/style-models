I've recently attempted to implement Aaron's Cedille-Core, a minimalist programming language capable of proving mathematical theorems about its own terms. I've also proven induction for λ-encoded datatypes on it, which made clearer why his extensions would be necessary. Nether less, I'm still left wondering where those extensions came from. Why they are what they are? What justifies them? I know, for example, that some extensions, such as recursion, ruin the language as a system for proofs. If I decided to also extend CoC with other primitives, how would I justify? I understand a proof of normalization is necessary, but that doesn't prove those primitives "make sense". In short, what specifically what qualifies a language (and its type-system) as a system capable of proving theorems about its own terms? 

It seems that even that way, deriving induction wouldn't be possible. I've attempted the following (using Morteish syntax): 

Suppose we have an arbitrary term, , in Lambda Calculus, or in an equivalent turing-complete system. Suppose we ask an oracle what is the normal form of that term, and it answers . Is it possible to determine, in finite time, if the oracle answer's ir correct? Secondary question: is there any system (non-turing complete, perhaps) where that would be possible? 

Lets define the simpler of two terms as the one with shortest description length on the untyped λ-calculus. Trying to find the simplest solver for a np-complete problem, I've got this: 

From this question, the answerer states EAL-based languages can use arbitrary fixpoint types without losing strong normalization, because their normalization (and complexity) properties comes from linear types and the stratification of terms. I wonder, though, if the same can be done for value-level fixed-points; i.e., is it possible to express things such as infinite lists without losing strong normalization? If one could mechanically restrict the unrolling of in the same style that duplication is restricted by and boxes, then, I believe, that could be doable. Is it? 

Or, in other words, after pattern matching a variable as , the system doesn't understand that equals . Similarly, it doesn't understand that . Is there any inherent reason for that, and is there any further extension that would allow this to check? 

On similar evaluators such as BOHM, it takes much less beta steps, but more interactions. If optimal evaluators are optimal, how can they evaluate terms asymptotically slower than existing evaluators? This link has an explanation about the origin of the term, as well as an implementation of the same function that behaves the opposite, almost bizarrely so: it should run in exponential time - it does run in exponential time in most evaluators - yet, optimal evaluators normalize it in linear time! 

Reads back as , the church list of the numbres 1, 2 and 3. The readback procedure is trivial, but it uses the tag annotations: for a lambda node, for an application, for root, for garbage, for fan (duplication). Now, suppose that we erased those tags: 

The lambda calculus is an untyped language that is often extended with logical frameworks such as the vertices of the λ-cube. Is there something similar to it, but for interaction nets? What about interaction combinators? 

Suppose that we take the Calculus of Constructions as a basis, but take away exponential functions (allowing only linear functions), and add the controlled duplication rules of EAL. That'd, I believe, give us a simple core with dependent types that can be reduced on the oracle-free fragment of Lamping's abstract algorithm. Now, it has been shown [1] that adding type-level fixed points to EAL do not affect its complexity bounds. Doing so would make the language more interesting, as one would be able to define induction and inductive types. Problem is, the Calculus of Constructions makes no distinctions between types and values. As such, adding Fix would imply its existence on the value level (except if we make an exception of the rule, which looks inelegant), which may cause non-termination. As such, it is not obvious to me how to add Fix to the language of the first paragraph without inhabiting all types. Perhaps a restricted version of it, with fix variables only occurring on non-application positions (i.e., only as arguments) would suffice, but I'm not sure 1. if that's true, 2. if that'd be the right way. [1] J.-Y. Girard. Light linear logic. Information and Computation, 143:175–204, 1998. 

I think , as presented there, isn't typeable on EAL. I can't prove that, but it doesn't work on Lamping's Abstract Algorithm without the oracle. Moreover, while the term is somewhat clever and brief, it uses very wacky strategies that are not EAL-friendly. But behind this question there is a more interesting one: "can a nat-sorting function be implemented in EAL"? That was a very hard question back then, but now it looks pretty trivial. Yes, of course. There are many simpler ways to do it. For an example, one can just fill a Scott-encoded with Church-encoded s, and then convert it to a list. Here is a complete demonstration: 

Does that mean that, for all terms of λEA, there is a valid type derivation? Is this a common phenomena, i.e., are there other systems with this same characteristic, or is it something particular of linear logic based proof languages? 

It is widely known that interaction combinators can implement any interaction net. My question is, can they do so efficiently? I.e., is it possible to prove that there is no interaction net system that can't be emulated on interaction combinators with the same number of reductions up to a finite constant? 

The untyped language of System-F and similar is the λ-calculus. That language has terms that can't be typed on System-F, being the most obvious example. The λEA-calculus, as described here, and its variants, has an interesting property that all stratified terms of the untyped language are total and strongly normalizing. That raises 2 questions: 

I've been thinking: computing systems such as the Lambda Calculus and its variations are usually very simple and can be implemented in as few as ~80 lines of Haskell code. There is a self-interpreter for the Binary Lambda Calculus in 210 bits. Considering PL research mostly consists of the search of similar systems with desirable characteristics (such as being supercompilable, or capable of expressing proofs), and taking in account how information-starved those systems are, wouldn't it be interesting to use automated search techniques such as genetic programming or just breadth-first search to find those? Has that been tried already? 

The problem of unifying interaction combinators is probably undecidable since those are turing complete. As opposed to the lambda calculus, there is nothing like a simple type theory for interaction combinators nor a subproblem of them that is known to be decidable. When is it possible to unify interaction combinators? 

Now this function is obviously terminating, but it includes a recursion that is not applied directly to a sub expression of a pattern match, namely, , so you can't express it on the suggested system. My question is: is there a more general way to introduce recursion that will still guarantee termination without making some valid cases illegal? 

Elementary Affine Logic is a type system which captures the class of λ-terms that can be reduced in elementary time. Moreover, EAL-typeable terms can be reduced using the abstract fragment of Lamping's algorithm, which is particularly interesting to me because I'm exploring the corresponding interaction combinators. My question is, how can one make a practical programming language using EAL as the underlying type system? I.e., what kind of extensions (fix-points, polymorphism, dependent types, datatypes, etc.) could be made to the core type system without affecting that characteristic, and would such a language be usable in practice, or would it be somehow too restrictive for reasons I'm not aware? 

The problem here is that, when pattern-matching on the definition of , we need to specify a return type. By specifying it to be , we get an error because, on the first case, 

Interaction combinators can be evaluated using a path traversing strategy. That is, instead of applying annihilation/commutation rules to active pairs, one simply walks through the graph using a 2-stack machine to keep track of the exit ports. It is known that this strategy, used naively, can have an exponential slowdown in relation to the former strategy. But that doesn't consider the possibility of jumps. Suppose that, instead of merely walking through the graph, the cursor also keeps track of the nodes it passed through. It it comes back to the same node, it jumps directly to the node whose active port would-be to interact with that one. Is it possible to use this strategy to evaluate interaction combinators? Can it be as efficient as the graph-reduction view? 

So, yes, turns out it is possible, as can be seen on the function of my abstract algorithm implementation here. Basically, Lambda and Apply nodes are given the same tag (here, I use ), and you can infer which is the case based on their positions. Each Duplication node, though, requires an unique tag. Note some terms such as will reduce to a net which has Duplication nodes with the same tag. That is not an issue; when decoding, just treat anything with a tag different from as a Duplication node. 

Suppose we extended the CoC with primitive recursion; that is, we added a term such that equality allowed unrolling recursive terms: 

I have recently asked if there is a simple functional core that is consistent and expressive. In another question, cody pointed out that this is an open problem to have a language that is: 

Interaction combinators have been proposed as a compile target for the λ-calculus before. That paper implements the full λ-calculus. It is also known that it is possible to optimize interaction-net encodings of the λ-calculus for the subset of λ-terms that is EAL-typeable. That paper implements that subset of the λ-calculus by translating EAL-typeable λ-terms to interaction nets that are arguably more complex than interaction combinators, since they use an infinite alphabet of labels to group duplicators. I wonder if it is possible to combine both proposals. That is, is there any encoding for the abstract algorithm - that is, λ-terms that are EAL-typeable - as interaction combinators? 

Now, suppose you want to add recursion to that language, while still guaranteeing termination. Someone suggested a "Recur" primitive, which can only be applied at sub-expressions of pattern matches, making the following legal: 

If we extend the Calculus of Constructions with Fix, we gain a lot of expressivity for barely no added complexity. That includes being able to derive induction, perform large eliminations, prove and so on. This system is, moreover, very user-friendly and comfortable to program in. Sadly, nothing of that because the resulting system becomes inconsistent. Making it consistent again requires, it seems, a lot of added complexity such as, for example, inductive types, or positive recursion checks + constructor-constrained recursive types + lift. Suppose, though, that someone gives me a term of type , programmed in that language (), and that this term successfully pass through a totality checker. Wouldn't I be able to, then, trust, with absolute certainty, that holds? And, if that is true, doesn't that mean that, as long as that totality checker is used, one can just program on that comfortable language instead of dealing with the added complications of induction types and so on? 

This λ-term takes 2 arguments, a church number telling the arity of a church-encoded boolean formula, and the formula itself, and returns "true" if it is satisfiable. Of course, this term is quite long, but serves as an upper ceiling. My question is: what is the shortest known term that solves an NP-complete problem?