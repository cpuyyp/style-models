This should be very straightforward, since you are already loading the TGA yourself, and assuming you only want to deal with true-color TGA files (the TGA file format allows for alternative color map types; true-color is the one where pixel colors are stored directly, without a palette or anything). TGA files have an 18-byte header, after which is an optional image ID string (usually not present). Palette data follows the ID string, and may exists even in a true-color image. After the palette data is the RGB pixel data you are interested in. All of this should be old-hat if you have actually written the loader, because you'd need to account for all of this to get to the pixel data that you're loading into your textures. The rest of the file is either raw or RLE RGB pixel data. The TGA format stores the blue component in the least-significant byte of the pixel, followed by the green byte, the red byte and finally the alpha byte (if present). Consequently, you can read the RGB color data by simply modifying or reusing the portion of your RGA loader code that finds the offset of the pixel data, and then reading the bytes linearly from the file (using the information in the header to know how many bytes are in the file total). More information about the TGA file format is available here. 

Your actual computation to increment the FPS counter happens outside that frame-limiting code, above. So you're computing the "unlocked" FPS rather than the locked one you are expected. To fix this, you can move the increment inside the loop. 

The experience of making a game will be beneficial to your education. However, the class itself isn't necessary to get this experience and will not likely factor much into your hiring potential upon graduation. Since you've never made a game before, this can be a great learning process, but you don't actually need the classroom context to do it unless you feel you won't be motivated enough otherwise (in which case you may need to seriously rethink your choice of career). In fact, because of your relative inexperience with that process you may find yourself at a disadvantage to your peers, resulting in your struggling in the class. My advice is to take the non-project course and start trying to make a simple game or two on your own as an extra-curricular activity. This will get you some experience with the task of actually building and completing games, which will make you feel more comfortable when you eventually work in a team environment to do so (either later as part of a different class, or as another independent study type of project). It will also be something you can refer to upon graduation, while you're looking for jobs, and say "I did this on my own because it interested me," and that's usually a interesting point for employers. 

They do rather different things, but can be used to achieve the same results. Setting the body's sets its speed and direction. As long as the body is being updated by the physics system, it's velocity will be (effectively) added to its position in order to arrive at a new position for the frame. This causes the object to move at constant speed over time until you change the velocity to something else, or to zero. The method of the type adjusts the translation stored in the body's transformation matrix by adding the provided translation to it. This causes the object to move instantly to the new position, once, ignoring the physics system. This will not cause the object to move over time unless you constantly call it every frame. Use the one that makes the most sense for the semantics you want when interacting with the object. If you just want to position it once (or occasionally) and leave it there, using is fine. If you want it to move constantly, and nicely interact with other physical objects, setting is probably less work overall than manually translating it every frame yourself. 

You should have some rough idea of the minspec just by developing your game -- for example if you made an explicit choice to use D3D10+, you obviously are culling out XP machines. So that's a place to start. Find a way to test on as many machines as possible, ideally after implementing some way to gather performance metrics automatically (as users can be unreliable) as well as non-identifiable information about the machine the game is running on (processor(s), core count, GPU type, RAM, OS, et cetera -- take a look at the kind of data the Steam Hardware & Software Survey collects). One of the best ways to do this is to give your game to friends and family, as has been suggested many times already. Another way might be to approach a community of hobby game developers and see if they are interested in testing your game. I'm not sure such a thing would be an appropriate question here on GDSE, but you could probably find a few people in the 'chat' area and you could also look around/post on websites like: 

It refers to using OpenGL's direct (immediate) mode of rendering (the family of functions that includes and as well as all the immediate vertex attribute specification functions like and ). Immediate mode functionality is deprecated in modern OpenGL/ If available, something like vertex buffer objects should be used instead. is not an immediate-mode function, but it is a utility function that makes use of OpenGL's matrix stack, which is also deprecated. 

is true. Using this equation you can color any points inside a circle one color (such as "transparent") and anything outside the circle a different color (such as "black"). You can even fade the edges of the circle, if you are so inclined. You can write a custom shader to do this, and apply it to a full-screen quad. Set up shader constants defining the center of the circle and the current radius, and draw your quad. Every frame, decrease the radius by some factor to animate the circle getting smaller. contains the fragment position in D3D10 and up, but it's not available in D3D9 (which is what XNA is based on). Instead you can use the semantic (more information here). This will give you the position of for the above equation. and come from your shader constants. You can use the function to return 0 or 1 based on which side of the equation is greater. This will allow you to avoid an actual branch in the shader, so you can compute the alpha component of your final color like this: 

Basically it seems like you are only missing the step involving configuration and attaching the depth-stencil state; the state object controls whether or not the depth testing is enabled, what comparison function is used, and all that other useful stuff. The MSDN has a good overview of the process that includes reasonable default values (for example, it's odd that you're trying to use a multi-sampled sample description in your depth-stencil texture resource). SharpDX is just a wrapper around the native API, so if you are familiar enough with the nomenclature mapping it uses to rename all the native API interfaces, you can usually just follow along with information for the native API and translate it. 

Ⓡ and ™ refer to trademarks, not copyright, and are for the most part likely to be irrelevant to your asset search; a trademark is basically a recognizable symbol or design used to identify a corporation or brand. This means, for example, the Nintendo logo or similar. The © symbol indicates copyright, although it is not necessary to include it (in the US it was required up until the late 80s, but that no longer applies). 

Of course, in some cases you might absolutely have to circumvent the API, perhaps to work around a bug in shipping software for which the official patch will not be released in time. If you absolutely have to do this, you should take the soft approach: try to scope your direct access as narrowly as possible, and make sure you try to leave the state of the underlying API as unchanged as possible when you are finished with your meddling. It's not a guarantee of success, but it can help. Ideally you'll avoid this kind of thing entirely, though. 

Store the components and compute the matrix on-demand when you need it. Storing the matrix itself is inferior if you're ever going to be manipulating the transformation in any interesting or useful way, because floating point error can creep into the matrix after repeated successive mutations (such as rotations). This can result in a matrix that doesn't do what it logically should, such as a matrix that is the result of nothing but rotation operations applying a non-uniform scale because of the accumulation error. Many of your other "pros" for the matrix approach aren't really that big of a deal, or sort of come out in the wash (it's pretty trivial to do operations on vectors and quaternions as well, for example). 

Having graduated from DigiPen, I would not recommend attempting to specialize your educational as early as your undergraduate work (I also went to a "regular" school to work towards a "regular" computer science degree prior to DigiPen). The proper place for specialization is at the graduate level, either by attending a masters or doctorate program somewhere or studying on your own -- and this seems to be what your question is about. If you are looking for a job in the game development industry, a graduate degree probably won't help you much. It certainly will not automatically translate into a higher starting salary or a more-senior initial job offer. If anything, you may run the risk of being considered overqualified for the entry-level positions you'd be vying for. If you study graphics or physics, there may be a place for you in some studios that want to push the boundaries in those fields, but that's kind of a gamble; such positions would be highly competitive and there will also be plenty of industry veterans looking at them. If you are interested in the study of the industry, or want to teach or do research, a graduate degree can be useful (and indeed, is often a requirement). But if you just want a career making games, I wouldn't recommend it. 

So if Bob's Shop is shop ID 23, and it has 4 copies of Awesome Longsword (item 2) and two copies of Potion of Hangover Resistance (item 73), the ShopInventory table might look like: 

First, I would hardly consider the practice of making entities IDs to which a component is attached a "hack," it is rather a conscious design decision that has pros and cons -- none of which are really relevant to your actual problem, though, so I won't comment further except to note that this goes towards Byte56's comment about the subjectivity of the term. It seems to me that your problem is that you made too large of a leap between stages 1 and 2 of your example. You don't need go directly from unrelated and types to having them inherit a super-generic interface you will then use for every type ever in your game. You just need an interface that covers your immediate needs right now: 

When you go to prepare a frame for rendering, you take the focus point of your viewport, and use that plus the known size of the viewport to figure out where the edges of the viewport within the world are. Something like 

For every (settled) block on the field, you are checking if the block is above the recently-cleared row (assuming row 0 is the top of the screen and your rows count downward to 19 at the bottom). If a block is above the cleared row, you move it down by increasing its row index. You then update the count of blocks in its new row to account for the fact that you moved it. But you don't decrement the block count from the old row. Over time this will cause your row counts to creep outside your expected ranges as more and more settled blocks fall into the spots vacated by cleared rows. You should probably before you to handle this. I think your general approach is sound, although your code might be more readable if you chose to eschew the "list of settled blocks" and "blocks per row" structures and instead simply stored a simple (2D) array of blocks. Checking, clearing, and moving blocks down would then require only one data structure for reading and writing, which is less prone to these sorts of errors. The actual act of displacing the blocks when a row is cleared would be slightly less efficient, but for Tetris I don't think that's going to hurt you much. 

I think the above are two reasonable reasons, although there are certainly others. You have to be careful though because many reasons for avoiding Boost, the standard libraries, or whatever boil down to "not invented here" syndrome, which can be an indication that the reason isn't very well grounded in practical realities. Also remember that the needs of a large-ish studio are usually very different from the needs of an individual developer. For example, an individual developer probably has less legacy code floating around to maintain and so perhaps porting from a home-grown version of the Boost or standard library functionality will not be as big of a time sink and will save that developer from having to maintain that code as extensively in the future -- thus invalidating my first bullet point. In the end, it is all about evaluating your requirements and time investiture against your desired goal and determining which option meets your needs the best. Developers who aren't using Boost or the standard library have usually done so and reached that conclusion -- perhaps you will too, and perhaps not. 

This will render the avatar into the current render target. If you want to animate the avatar, the object has an method you can pass your elapsed game time into. If you just want to capture a single frame and re-use it, you may want to look into setting up a texture render target and rendering via the above into that target once, then drawing that texture as a sprite. 

Simple linear algebra will provide you the equations needed to rotate any given point by some about the origin: 

First, it is perfectly acceptable for a component-based system to support components with logic, or to support components without logic. There is no codified standard for component-based implementations used in game development. There are advantages and disadvantages to either approach, but in the end none of the advantages really outweigh the others. The right choice for your game will be to choose the pattern that best expresses how you want to, or need to, reason about your components and their place in your larger architectural space. Components as "pure data" allow you to make certain assumptions about them: for example, you know there is no execution state (such as "where they are in their update method") that you would need to persist if you wanted to serialize the component out to persistent storage. This can result in a simpler, cleaner system of serialization for components (both for save data and for sending across a network). If you really implement them as pure, plain-old-data objects they can be faster to copy around in bulk (depending on your language and its idioms regarding "objects" versus plain data). However, components as "pure data" also mean you need a third-party (a "system" in your parlance) interface to drive any behavior or processing you want associated with the components. This can be disadvantageous if the overhead of creating a new "system" in your API is large. If the overhead is small, then this problem is essentially reduced to the issue of syntactic sugar for OO operations ( as a member function is not much different then ; both can be used to implement OO design). Now, there are fairly compelling advantages to processing components in external "systems" objects versus within the entity itself ("foreach entity, foreach component in entity, update the component"). Externalizing the processing provides for potentially better cache locality, makes concurrent processing easier, and other sorts of things. That is orthogonal to the concept of requiring that components only be data though; you can have components with behavior that are also bulk-processed by a "system" interface. 

"Recreating the game in a modern language," doesn't sound like a modification to me. It sounds like it's own project, using (probably illegally) somebody else's intellectual property. This seems like a bad idea. 

XNA is the only method for a consumer (such as your yourself) to get a game onto the 360, and it requires managed code. Licensed developers can use native code toolchains, which provides access to an API much like Direct3D (but which isn't exactly Direct3D). 

By ensuring the texture dimensions are a power of two, the graphics pipeline can take advantage of optimizations related to efficiencies in working with powers of two. For example, it can be (and absolutely was several years back before we had dedicated GPUs and extremely clever optimizing compilers) faster to divide and multiply by powers of two. Working in powers of two also simplified operations within the pipeline, such as computation and usage of mipmaps (a number that is a power of two will always divide evenly in half, which means you don't have to deal with scenarios where you must round your mipmap dimensions up or down). It's true you "waste" some space this way, but the extra space is usually worth it for the tradeoff in render performance. Additionally there are techniques, such as compression or packing multiple images into a single texture space that can alleviate some of the storage waste.