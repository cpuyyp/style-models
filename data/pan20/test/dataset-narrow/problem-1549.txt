Well, you can use this approach for stacking (AFAR this is how the process you are trying to perform is called): 1) Prepare a dataset in the format: 

2) Train your stacker - on that dataset from #1 - for example the decision tree. Or any other classifier which will be able to accurately predict the number of the estimator which should be used for that specific input. 3) When using in combat mode - first run the stacker trained in #2 on new input and obtain an id of an estimator which best suites this example. Than run that estimator against new input record and get your response. Hope that makes sense. I tried it and it worked nicely for one of my problems. Also you could try to employ some kind a 'blending' of these 4 predictors. Here is an approach you could take (my usage of terminology here becomes a bit frivolous since I am an engineer and not a scientist, so if someone provides a more elaborate answer on blending - please do). First of all, recall how ANNs for classification work - and would work for you example, if you will use ANN as a stacker. You have input layer which reads the input values, some hidden layers and an output layer with a set of neurons, each neuron is associated with a specific class. For our case it would be 4 neurons. After you feed input each of 4 output neurons will output some real value, for example: Neuron 1 - 5.4 Neuron 2 - 0.3 Neuron 3 - 15.3 Neuron 4 - 3.3 That output means that ANN thinks that the input belongs to 'class 3' and that you should use 3rd predictor for that example to get best results. But! Let's think about probabilities. What is the probability of input to belong to ANY of 4 classes? It is 1.0 (since you have only 4 classes). And by default ANN doesn't have the knowledge that this the case. So for us it would be good if the ANN will output probability of data belong to X class instead of just some real value. For example we would like to obtain such output: Neuron 1 - 0.6 Neuron 2 - 0.2 Neuron 3 - 0.15 Neuron 4 - 0.05 Which will read as 'I am 60% sure that you should use estimator 1 for that input, 20% sure - that estimator 2' etc. Such objective is called 'cross-entropy'. Modern libraries for building ANNs support it and you could tell network to train to output these probabilities. By now I believe you already got what I suggest to do. Prepare the dataset as I described at the beginning of the answer, than train an ANN with cross-entropy objective to output the probabilities. When you run it in combat mode: 1) For new input run it through ANN and obtain probabilities, like these: Neuron 1 - 0.6 Neuron 2 - 0.2 Neuron 3 - 0.15 Neuron 4 - 0.05 2) Run each predictor against input and obtain their predictions 3) Multiply each prediction by the associated probability and sum the results: predictor1_result*0.6 + predictor2_result*0.2 + predictor3_result*0.15 + predictor4_result*0.05 And get you final result. Why do that? First of all, we can't be sure that each time we realy pick up the best estimator, since our stacker (ANN in our case) could make mistakes. By using such approach we give the stacker a chance to compensate for possible mistakes - which minimizes the average prediction error. Also, consider that you get such output from ANN: Neuron 1 - 0.45 Neuron 2 - 0.45 Neuron 3 - 0.05 Neuron 4 - 0.05 In such case the best option for us is to almost average the predictions from predictor 1 and 2 - since ANN is not really sure which of predictors to use. 

Yes for clustering K-Means algorithm is good choice. The only thing is that you should select the number of cluster that you want as result. exp: k = 4 As i see you have categorical variables in your data, you can use "One-Hot-Encoding" to convert them to numerical feature. I would suggest you scale your data after that too. keywords here: "encode categorical feature", "One Hot Encoder", "feature Scaling". i Suggest you read more about those. 

Please let me know if you know what I'm doing wrong, or if you have better idea to do the some thing i want to do. 

Extrapolation? Happens a lot when your data distributions change over time, so a system that is well modeled in the training set wont know how to deal with values that are not in a similar range. More of a general term, so it might be what you're looking for. It also has different effects depending on the technique you use. Something like random forests is not very good at extrapolation, where others like logistic regression can still perform OK. 

Do you have enough data where you can play with dropping data, or maybe if you simulate how much the $SR$ is inflated at low $T$ you can try to adjust for it somehow. It looks like after about 1000 trials the high success rate issue begins to mellow out, and after 3000 or so you start getting more reliable measures. 

By working with your features you could make the ML algorithm (maybe regression or SVR or whatever) to learn this fact (that sequental races are increasing the performance of athlete). To do this you may want to drop out the date column and introduce some new column, maybe 'race number' with 0 for first race, 1 for second, 2 for third etc. In such case regression model will be able to learn what you say 'that the second race had an effect on the athlete, which meant he performed better in the third race'. It is all about feature selection. 

now your is scaled and centered according to the training data set parameters. Another way to do this without using caret: 

should have instead of . Your model had already seen your test samples, so the validation error is not an accurate assessment. 

Well -9999 can matter more or less depending on the variability within your data (is -9999 an extreme outlier value, or a moderate value somewhat close to the mean/median>) Depends a lot on your data. A value like that can skew it a lot, and can affect modeling quite a bit depending on the technique you use. Are the NA's biased for a class? Consider decision trees that classify on optimal splits. They would detect a bias (e.g. if 90% of your NA's a certain class) and split at -9999 value to manifest that bias. also check out Pareto scaling, which emphasizes small to medium changes in your data. Might be along the lines you are looking for. 

Playing with LSTM cells, i found that the model is not able to learn to generate sequences that looks like the original data. It only predict next value then start converging to an 'equilibrium' or static value which is the same whatever the input sequence is. I'm wondering if Stateful LSTM would help to learn better from past values and try to predict something close to what it have already ? My goal here is to generate sequences that looks like something that the model have seen already. Please let me know if I'm missing something or if you had a similar situation and you found the best approach to generate timeseries sequences that looks like what the model learned in the past. 

Situation I am doing a data science project for my client. Due to NDA I can't disclose anything to the nature of the project, but let's imagine that they manufacture and sell slow cookers. I faced the need to get the dataset which will cover all of the 'slow cooker' products in the selected market. The information we want is the list of features of each product. For example a record should have product name and brand + capacity, material, color, cord length etc., everything you could see on a product listing page in something like Amazon. The more detailed it is the better. Beyond that we want either a comprehensive set of product review texts from leading ecommerce platforms. If not available - at least average (also min and max) customer sentiment of such reviews. Issue I already did a prototype research by just doing a web-scraping of one of eCommerce web-sites. The issue is that: 

Help meet assumptions In your case of a linear regression, you have several assumptions that you have to meet including things like linearity and residuals have a constant variance and appear independent of each other. Transforming your response can help make your relationship more linear and help with your residual assumptions, while a transformation on your predictors primarily helps with those residuals. Typically if you are doing inference, you need normal residuals (or large sample size for CLT to kick in) which you can assess with a qq-plot or a test for normality, but if you are doing predictions you don't have to worry about this. Trying a few popular transformations (sqrt, square, log) is a good idea, as is the Box-Cox transformation (on predictors) which basically finds a transformation that maximizes the normal likelihood function of the residuals. The box-cox goes through several power transformations in a systematic manner, and it primarily used to make the residuals normal, though it can help the other issues too. Improve predictive power This is more of an open game, and I would be wary of over fitting. See what works best and go with it (can be tough, might have to go with cross-validation if you're data isn't too big). Your Case Usually your x-axis for those plots is the fitted values (you can plot a glm object, not sure about lm, so run through most of your basic diagnostic plots). just with those plots its also tough to assess normality, which is typically done with a qq-plot or a hisotgram of the residuals. It looks like your response variable new_users is a count; maybe a poisson model would be another option. "best" transformation is the one that helps you meet your assumptions as noted in (1), its more of finding the transformation that makes you feel most confident that your assumptions are met. If you are looking to increase performance, $R^2$ will help indicate a helpful transformation, but again be wary of overfitting. The power transformations e.g.$(x^{1/3}), log(x+0.1), x^{2}$ are usually a good route to go. 

For both: 100 batch size, Dataset size : 50000, adam OR RMSprop, mean_squared_error I do prediction recursively: 

I'm trying to use LSTM on time-series data in order to generate future sequences that looks like the original sequences in term of values and progression direction. My approach is: 

Its about how the neural net learn inside. Usually in deep neural network you have multiple layers, the first layers will learn the low level feature then the more you approach the output layer the more the layers will learn the high level feature. Here its identifying faces task, that's why you see that in the first layers small patterns are learned (mainly edges ...) then faces components ... How to obtain them : you should watch what makes neuron activated in each layer depending on the input. As you know each neuron will be activated (once the DNN is trained) for specific input combinations. By visualizing that you can get an idea about what exactly each layer has learned in term of high-low level features. 

Record the Out-Of-Bag (OOB) accuracy for each tree. "shuffle" or permute the values of that variable. This means you take all the values of that variable in the data, and assign those values randomly back out to the observations, which is a way of introducing noise and getting rid of the signal that that variable provided. Now it finds the OOB accuracy again, but this time the values for that variable are incorrect since we permuted it. By introducing noise where your model expects signal, you should see a decrease in performance. Compare the original accuracy in (1) to the accuracy in (3) for each variable. If the model performance decreases a lot for a variable in step (3) compared to (1), then it is deemed to have greater importance. 

As a conclusion, I think, if you can cover the requirement with regex go for it. If regex will not be a good solution then start thinking in machine learning solutions. 

Based on different Timeseries Data for similar products, I'm trying to build a model that will learn different patterns from all these data and try to generate sequence for new product based on "x" available data points related to it. For that I thought about training a recurrent neural network on the available data from all products but the result was not as expected. I know that there is a pattern between all products to how they progress that's why i was expecting good results. What I tried :