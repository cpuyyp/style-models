I have a main backup server running rsnapshot, with ~2TB of backups stored on it. After the nightly backups, I copy the contents of the rsnapshot directory to an offsite server, using . However, this seems to copy the entire contents of the backup directory every night, as the offsite copy takes ~9 hours to complete. I assume my rsync command doesn't have the right switches, but there may be something else I'm missing. Any ideas? 

I think that the /isolinux/ ones are for booting a live CD using ISOLINUX, whereas the pxeboot ones are for booting CentOS from a PXE server. PXE booting is when you obtain the kernel and initrd from another server using a TFTP client built into the network interface. Typically you'll see something like "Network Boot" in the boot list in your BIOS. 

When you restore with Clonezilla, the partition letters it's showing for the source system are just there so you can remember which partition is which. It won't actually restore sda5 to sda5, for example. However if you are going to restore partitions from a Clonezilla image, you need to first create corresponding partitions on your destiation disk. For example, on your source computer you cloned /dev/sda5 and /dev/sda7 to an image. On your destination you have 2 existing partitions, say /dev/sda2 and /dev/sda3. You will need to create two more partitions, which may end up being /dev/sda8 and /dev/sda9. Then you will launch clonezilla and select "device to image", and then "restore from parts". You will then select which partitions in the image you want to restore (i.e. /dev/sda5 and /dev/sda7), and then it will ask you where you want to restore them, so you'll select the new partitions you just created (e.g. /dev/sda8 and /dev/sda9). And that should be it! 

I have Asus WL-500g and I use DD-WRT. I currently have v24 SP1 installed and there are no issues with it. I find it really easy to configure and it supports Asus hardware quite well. Torrenting from it is little bit harder with DD-WRT, but there is support for installing additional packages. VPN is supported just fine. 

It is not supported as such. However, you can use command to create new drive letter out of folder. If you do on root folder, that would give you desired results. E.g. 

1) no 2) yes 3) maybe For home server, I would go with desktop motherboard since it is much cheaper. 64-bit drivers were problem for quite a while since desktop motherboard manufacturers didn't bother much. However, if you search for little bit better desktop motherboard with Intel chipset, you cannot go wrong. 

You will not be able to cache Windows Updates in that manner. For cacheing them, check Microsoft's WSUS. 

These conflicts are usually resolved through locks. It is upon application to ensure proper locking. That said, it needs to be noted that most of applications do tend to lock files, especially during writes. 

Use BCDEdit to set truncatememory option. That will limit your memory. To use it first check what BCD entries you have with 

Is there some command line function within FreeNAS (FreeBSD) derivative which could return my external address? Since that same address is synchronized with DynDns (via router), in C# I retrieved that via DNS query like this: 

I would assume that this is issue with drivers. However, IDE has same size limit as SCSI on Hyper-V. Usually IDE disks are a LOT easier to use in Linux and that solves problems with visibility in most cases. In your case that is a problem since you use first Hyper-V Server 2008 release. If you can, I would recommend moving to Hyper-V Server 2008 R2 which will allow you to have big disk on IDE interface and thus avoid any driver issues with Linux and SCSI. P.S. You can just disconnect already existing VHD and re-attach it as IDE since format is not dependent on interface. 

This seems to indicate that nginx is crashing immediately, if it had been started earlier. Have you checked the contents of to see what the process is doing? EDIT: Also, if you tell us your OS and version of nginx, we can give more detailed answers. 

Also, they state "Mixing components operating at different internal clock frequencies is not supported and will not be validated by Intel. Combining processors from different power segments is also not supported." $URL$ (page 165) $URL$ (page 28) $URL$ (page 25) 

Yes, your hosts file will always override DNS resolution, as it is the first thing checked by your local DNS resolver. However this should not be an issue in any network configuration I can think of, unless you need your client to ask the DNS server to resolve the client's own hostname for some reason. 

I've searched high and low trying to find a method that allows me to store GPG keys for existing users in an OpenLDAP server. The only relevant how-to I've found is this. However, I'm unable to get this method to work with the existing OpenLDAP database. I've successfully imported the schema, but I can't figure out how to actually add information to the fields specified in the schema. If I can provide any additional information, please let me know. 

I forget I ever asked this question! I figured out the problem with the help of tech support. The issue was that we were monitoring the OpenVPN TCP port on the server with Zabbix, which was opening a connection every minute to confirm the port was open. Once it confirmed the port was open, Zabbix would close the connection, causing the "Connection reset" messages. In retrospect the ephemeral port numbers of the connecting client should have been a bigger clue that the issue wasn't with OpenVPN itself. Nothing like finding out that your problem was caused by you all along. 

NTLDR error can arise for many different things, but fragmentation is not one of them. In this case I would go with "disk failing" reason since, as you noticed, even TrueImage couldn't read it. Since TrueImage reads everything sector-by-sector, it would not mind fragmentation. Try to backup everything you can since I assume that drive will completely fail very soon. Fragmentation will have effect here since it is much harder to recover data from fragmented drive than from non-fragmented one, but it is definitely not the cause. 

P.S. I know that 89.172.197.320 is not real IP address. I wrote it like that in order not to share mine IP address (or IP address from someone else). P.P.S. Thanks for help to Kronick and Avery Payne since their ideas pushed me in right direction. 

You can try DynDns. It will enable you to connect your dynamic IP with your DNS address (given to you by DynDns). It only requires small utility on your side at worst. If you have access to router, it gets even easier since almost all routers have support for it. 

You may wish to enable offline files for that network location. This will not prevent disconnects but it will give you offline copy to work with even if connection is lost in middle of editing. Once connection is restored, file will be copied back to server and synchronized. Only issue here may be if another user modified that file while connection was down since that would cause synchronize error and you would need to resolve it automatically. 

You can try using VHD attach. It has option to attach VHD after each boot. Since one part runs as service, no UAC prompt will bother you. 

I use robocopy for rsync-like behavior in windows. Basically, I wrote a backup.bat file that I have on an external drive. I regularly run the file to back my desktops up to the external drive. Then I store the external drive in a fireproof safe. 

I just installed Windows 7 RC1 and want to move c:\users to d:\users. What's the best way to do this? 

Due to the fact that Windows 7 creates a reserved partition that is mounted as C: in the recovery console, I had to use the following commands 

If the host machines are all on the same network, you may be able to configure DHCP to assign the MAC addresses used by VirtualBox (or VMWare) VMs to a different 'virtual' network. For example, say all your host machines run on 192.168.0.0. You could configure DHCP to assign all computers with MAC addresses beginning with 80:00:27 to the 192.168.99.0 network. Hope this helps. 

I would like to tinker with OS X in a VM. It doesn't have to be VMware, but I do want it to run under Windows. I tried the instructions at: $URL$ but couldn't get the OS X install disc mounted. What's the best way to get OS X to run in a VM? 

I have a server running some VMWare VMs that I built a couple of years ago for around $700 in parts from online vendors. I just built a gaming/development desktop that I run several VMs on. Case Shuttle is fine. My VM server is in a shuttle case stuffed under a table behind me. CPU Cheapest 64-bit i7. Memory 1G per Core. The new i7's are hyper-threaded, so it looks like you have 8-cores. Motherboard If you're not testing graphics intensive OSes/Apps, get a motherboard with integrated video. I've found an eSATA connection to be handy. Drives Largest you can buy for less than $100. Operating System Windows 7, Fedora 10, or CentOs 5.2. I've found that VMs are a bit faster under windows than Linux. Also note that regardless of OS, if your VMs are all doing IO operations, they may slow your system to a crawl. Virtualization Software I prefer VirtualBox because it's lighter weight than VMWare server or player. If your new machine is headless, I'd recommend VMWare.