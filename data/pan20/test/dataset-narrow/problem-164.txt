After you do that, you will be able to test and repeat MAC overflow attacks in GNS3 with router-based switches in a stable and predictable manner. Here are two final notes: 

I will now take each of these point individually. Knowing where difference with real gears lies For performance reasons, a lot of switch things are actually not part of the IOS code but are implemented in hardware. This includes the ARL, or Address Resolution Logic, which provides all the methods to add, remove and lookup entries in the MAC address table. Therefore, for the NM-16ESW module to work in GNS3, Dynamips had to reimplement all these normally hardware provided services, or at least push this far enough to allow an unmodified IOS to run on it correctly. The sad thing is indeed that this is unfinished work, as stated in this module's source code header: 

For the short answer: yes, CAM overflow attacks can be simulated in GNS3, however this goes with a few requirements: 

This flag is re-enabled whenever the switch receives a new packet from the corresponding MAC address, keeping active addresses in the table. You will have to take this behavior into account in order to design a successful CAM overflow attack: 

Now, let's see how a switch works when the CAM overflow condition has been triggered and he did fallback into the so-called "hub" mode... Actually all of this is just nonsense: there is no hub mode and the CAM overflow triggered strictly nothing. The switch just continues to work as it always did: 

This is a limitation with packet tracer it seems. I quickly replicated your set up in PT 7.0 with no luck. If you put a server on a new switchport, put the port on the correct vlan and mark that port as trusted DHCP will work fine. I think if you did this with real kit it would work fine. 

On IOS/IOS-XE you can use either reflexive ACL's or use stateful inspection with Cisco Context Based Access Control (CBAC) or Zone Based Firewall (ZBF). ZBF is the current way to do stateful inspection. It works by creating zones and applying the zones to interfaces. Then you create a class-map to identify traffic and use a policy map to inspect the traffic that you identified in the class map. You then create a 'Zone Pair' in which you define a traffic flow (inside to outside) and apply the policy map to that pair. IOS will then perform stateful inspection on that traffic like any other firewall. Documentation for ZBF on IOS XE is here: $URL$ 

I think you're not understanding that the DNS query and the HTTP request are different packets and thats whats confusing you. If you try to visit www.cool-site.com and you do not know its IP address then DNS happens first. The DNS process follows the whole encapsulation/decapsulation process like any other packet would. Your machine will realise it does not have an IP for www.cool-site.com. Your machine will build a DNS query and send it to the DNS servers you have specified (statically or ones it obtained via DHCP). Assuming the DNS server knows the address it will respond back to you with a DNS response containing the domain name and the IP address. Now the machine knows the IP address it can build a new packet for a HTTP request and put the IP address as the destination IP in the packet. The server knows where to respond because in the HTTP request packet there is a source and destination IP within the IP header (like all packets). The server will respond and put its own IP as the source and use the source IP in the previous packet as the destination. How exactly the packet is built in regards to grabbing the IP that was received from the DNS query and putting that in to a packets destination IP field I'm not clear on. The operating systems network stack obviously handles this but I can't give more information than that because I'm not sure on the whole process. Maybe someone can comment with some extra information. 

fails on these three requirements and is therefore not a suitable tool. A quick search did not revealed any relevant alternative, so I went the Scapy route (Scapy is a Python library and interactive tool allowing to freely build and manipulate network packets). Here is the code I used to successfully test CAM table overflow in a GNS3 environment: 

First and foremost, I must indicate that I am mostly active on the IT Security StackExchange website. Since this current website may reach a different public I find it wiser to tell that, while I adopt the point of view of a potential attacker, all information in this post is given only for educational purposes, in particular in order to understand the concrete threats that are affecting networks beyond myths and oversimplified discourses. I do not encourage nor do I approve the use of the methods described below on any unauthorized network (and I really mean it: if you want to learn get GNS3, that's what this whole thread is about :) !). Sorry for the length of this answer, but despite my researches I did not manage to find any satisfying resource on the web on this topic. Most "proof-of-concepts" are biased either by stopping at the CAM table being filled step and assuming but never really demonstrating the switch reaction, or by using some artificial tricks like clearing the switch MAC table before flooding. My goal here is to provide concrete steps suitable both for simulated and real environments, focusing on the issues related to GNS3 virtualization and common wrong approaches, and most importantly to provide sufficient background information to understand why things are the way they are. 

We have a scenario where a customer is having a managed L3VPN installed and would like to run OSPF internally. The issue is that the provider will not allow us to provide and manage the CE device and they will only use BGP as the CE-PE protocol. They've told us that we can run OSPF internally and form a neighbourship between our L3 switch and their managed CE. They will then redistribute the routes into BGP and in turn, advertise those routes to their PE. That doesn't seem like a valid design to me. That means at each site we'll need to run an instance of OSPF in area 0 and as far as OSPF is concerned every site will be a different autonomous system, right? Due to the BGP in the middle (between managed CE - PE) the routes will be external OSPF routes and we wont be able to connect our area 0's together. I think it will work for now but I imagine it will cause headaches in future if we try to scale or make the solution slightly more complicated. I think if we ever decided to have a backup leased line or VPN tunnel the LSA's would be type 2 and therefor a preferred path than the external routes caused by type 5 LSAs. I know OSPF as a CE-PE protocol is valid and would essentially address all the concerns above but I think that option is probably off the table. Are there any caveats/concerns with the solution above? Should we be pushing harder for the provider to run OSPF as the CE-PE protocol? 

This is a quick-and-dirty, few-lines examples which could be improved in several ways. For instance, would it be used against real gears it may make sense to use two successive sending iterations, the first one being quick in order to rapidly take over CAM tables, and the second one working at a far more slowly pace, taking full advantage of the 5 minutes aging delay to stay below the radar as much as possible (when this default delay is changed, it is generally to be raised and no diminished, and moreover I have some doubts that someone who do not take care of enabling port security on his switches will really bother changing such kind of setting). Correct a bug currently affecting dynamips Sadly, when you are through all this, you will discover that when their CAM table is properly filled, the switches in GNS3 will not start to flood packets through "all" of their ports, but they will drop them instead. This is due to a bug affecting the function in charge of handling received packets and located around line 2170 of the dev_nm_16esw.c file: 

The switch receives an incoming packet on a some port, The switch then checks if the source MAC address is already stored in the MAC address table. If it isn't and there is a free slot, it records this new MAC address associated to its incoming port (and by the way if the address is already present but associated to another port, it will update the record with the new port). This is also the occasion to reset the aging timer associated to this entry, no matter if it is new or not. The switch then checks if the destination MAC address is already stored in the MAC address table. If it is, then this is all good and the switch outputs the packet on the interface associated to the matching CAM table entry. If it isn't, the switch will output the packet on all interfaces except the incoming one (all interfaces belonging to the same VLAN + trunk ports as long as this VLAN is not pruned). 

Ok, so I have to admit I am not an expert in how Juniper networked devices work, so this entire issue might be why I am having issues understanding something I am seeing on a pair of clustered SRX210H's. So, when I SSH to one of these clustered Juniper devices, I am presented with a standard BSD/Unix prompt. If I run the command, I get a long list of interfaces, and the last two interfaces are as follows: 

Sorry for asking multiple questions in a single post, I can break it up if needed - it just seems like all of the questions are a part of the overall question regarding configuring SPAN across a switch stack. 

We have a stack of 6, 48 port 3750 cisco switches and I would like to setup mirroring across the stack to send the data to a network analyser. I have done mirroring before on a single switch, but never on a stack of swtiches. My question is, what sort of things do I need to consider when trying to monitor a stack of c3750 switches with multiple vlans if I want to monitor all of the traffic on all VLANS with my network analyzer? Since each switch is already stacked, do I only need to setup a single monitor port on one of the switches? When I specify the port range that I want to monitor, should I just set the source port as being the various vlans I want to monitor, and then set the destination port as being a single port? 

I'm not sure that's a loop. I'm not really sure what that is. The ACL looks fine so you probably want to talk to HP about this. I had a case similar to this where a procurve based L3 switch would not manage its arp table properly. I think it was on the same software branch as you too. Called HP and 5 minutes later it was confirmed as a known issue and due to be fixed in next release. If you check the release notes for the next firmware version does it mention anything about ARP being fixed? Or is it listed as a known issue in the current firmware release notes (firmware release you're running now). The next morning it happens, try clearing the arp table/cache with clear arp. Try to ping from vlan 120 to a server again and see if it works. I think the firmware versions are free from HP (at least on the lower end models). We were looking at the 5400 to use at the core and ended up going with a Comware based HP switch instead and its been solid. Procurve is great (we have customers using a lot of them at the access layer) but I've seen odd issues like this crop up, especially on the newer firmware versions. 

I install certificates so infrequently that I do this all the time and I never bother trying to restore it. It's trivial to just re-do the CSR and request another cert. Most SSL cert providers will give you unlimited re-keys and even if its an EV certificate they'll re-issue the certificate within minutes. You'll probably save a lot of time by just starting from the beginning. 

If, for whatever reason, a fabric interface was accidentally plugged into a production segment, the fabric traffic would still not be routed out, as it would not get processed at layer 2. PURPOSE: Implementation That being said, why exactly is the expected behavior? Why would Juniper decide to use public IP addresses owned by the DoD Network Information Center to preform this function for clustered networked devices? My primary concern is this, earlier this year the DoD publically disclosed security backdoors in Juniper products. I would not find this to be too odd if it were any other organization, but the fact that the DoD was invloved in calling out Juniper on having backdoors in their products. See the following URL for more info on the backdoor that was exposed earlier in 2016. $URL$ Can anyone explain what the purpose of using public IP address space owned by the DoD on Juniper equipment is? Why wouldn't they just use a point to point private ip address range for communications between two clustered devices? I would like a technical explanation if at all possible (not sure if a non-technical explanation even exists considering the question being asked). Any Juniper experts care to chime in? I should mention that when I look at the packet counters for both interfaces, there is a lot of outgoing packet traffic, absolutely 0 incoming packet traffic on the fab0.0 and fab1.0 interfaces. If it were being used for just failover/clustering, wouldn't there be both incoming and outgoing packets? Another question is why in the KB article from Juniper do they refer the public IP address range as being 30.0.0.0/8 when the line from the config they show in the example clearly shows that the network is using a /24 (254 hosts)?