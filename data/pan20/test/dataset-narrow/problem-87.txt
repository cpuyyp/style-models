SysAdmins often try to convince me that x86 general-purpose OS's can perform just as well as routers with low MHz CPUs and dedicated silicon (i.e., ASICs) at 1Gbps line rates. This thinking is carrying over into the SDN realm such as virtual switches in VMWare. I think I intuitively understand the differences between the benefits of ASICs vs x86 in handling traffic particularly with respect to microbursts. Is it correct in assuming that ASICs for router or switch interfaces will outperform the use of an x86 CPU for all packet processing which will greatly suffer from CPU interrupts? I know the OS (Windows, Linux, or specialized) greatly contributes to the hardware's performance to route or switch too. And I know the x86 bus-speeds impose theoretical maximums to switching bandwidth especially once rates exceed 1Gbps. 

Switches are where you typically find PoE especially in enterprise-grade equipment. You should have no issue extending your LAN with a switch on an available port on your cable modem, but you really should have a router/firewall function sitting between your LAN and the WAN from your modem to protect your network. You can confirm that you are directly connecting your LAN to the modem by the presence of public IP addresses which is a good way to get hacked. A firewall provides a baseline of protection that you seem to be lacking now. Be aware that the firewall (on your router) will be providing a NAT function that doesn't always play nicely with SIP packets from your VoIP. You may need a firewall capable of handling SIP properly or a VoIP system that can support STUN. 

The carets represent the wildcard mask, showing which bits MUST match. Since they do, 10.190.1.200 would match this ACL statement. 

If a AS has a single peering point with another customer ASN, learning 500 prefixes from that customer, and that session goes down, it could trigger a mass withdrawl. 

Possibilities I can think of: Depending on how the route is making it into OSPF, and what OSPF route-type is used, cost to ASBR router may/may not be factored into the route selection process (for ECMP to work, both route cost, and cost to ASBR have to match). Seeing the metric on the actual LSA for both may help. I was able to reproduce this on IOS by mimic'ing your configuration -- placing the anycast on an interface, and placing the interface into an area. If you do need ECMP, consider redistributing the route into OSPF, as that does appear to work. 

I can't reproduce this in my lab, using 12.4(24). Same topology, RCore area 0 loopback, R1 with lo0 and interface in area 1, R2 with lo0 and interface in area 2 (both NSSA), redistributed route gets picked up for ECMP on Rcore: 

If you are not tied to CallManager, Asterisk is an open-source solution to provide SIP telephony, and can automatically email voicemails to users. 

You might also be able to manually resize the image. Go into , then on the bottom-left, you'll see your 200x800 map. Use the to drag the blue edges to your desired size. 

I have stacked 2960X switches trunked to a single ASA 5515X in routed mode, and I've captured the drops with after seeing the l2_acl counter incrementing in . Does the ASA support spanning-tree in routed mode? Should spanning-tree be disabled on the port-channel on the switch going to the firewall? Should I add bpdu rootguard to be safe? I either want the ASA to handle/ignore the BPDUs silently from the 2960X's or stop the switches from sending them, but add some loop protection. ASA asp drop capture -- first three packets shown matching BPDU MAC: 

If you have 802.1X in your environment, you could push the VLAN assignement to the port based on a username used to authenticate after the imaging is done. One username per vlan for imaging to make the VLAN assignments automatic. If the imaging is done in a central location, get a L2 switch and trunk that back to the production network, and then simply have different ports tied to different VLANs. The automatic part comes from you physically using different cables from a different ports or swapping your one cable out from one port to another. Script the VLAN switchport change via SNMP or CLI. 

We are looking at Cisco ME3600 to provide connectivity between our datacenter fabrics for some software defined networking. Due to the platform having a higher limitation on EoMPLS xconnects than VRFs (512 vs 128), we are considering the approach of allocating a vLAN in each DC to a software router, and using EoMPLS to connect these two software routers together to route Layer 3 traffic. For redundancy, we want to have 2 PWs for each connection between a pair of software routers, and I'm curious how best to have this, given the interactions between various spanning tree implementations. One of our datacenters has MSTP deployed as a single region, odds in instance 1, evens in instance 2, CIST in instance 0. The other datacenter still operates R-PVST. The current plan is to create a trunk from the switch fabric into the ME3600, and use a EFP for specific vLANs and assign them to a xconnect. I'm curious how the switch fabric on each end will handle this -- will I have to setup a vLAN 1 EFP on both sides, and pass PVST traffic? Will this be enough to set root/block/alternate on both sides? Diagram below of the physical layout, and the logical idea behind connecting two software routers. 

It's treated as a fresh session up when the peers restart. TCP handshake, capability re-negotiation, address family advertisement, and then NLRI exchange. If the hold down timer expires, the peer is marked as dead, the session goes into the IDLE state, and follows its own rules for transitioning from IDLE to Active (actively attempting to establish a TCP connection). Note that a peer in the IDLE state can still accept an inbound TCP handshake from the other router. Exact time needed for a specific route to be available again is dependent on the total # of NLRIs to be exchanged between the two routers. If you're exchanging full tables (500K+ NLRI), depending on processor size on both routers, it could take upwards of 5 minutes. If you only have 20 routes to announce, they'll process the NLRI real quick like. 

After talking to a few hosted VoIP providers, they all state that "ALG" or SIP inspection in the case of the Cisco firewall should be disabled. How is SIP not broken after leaving the firewall over the public Internet when being NAT'd from a private to public address if the SIP payload contains a private address that inspection would normally fixup -- using the older inspection terminology there ;-) ? Is STUN or TURN the only way preventing this breakage and can I assume that these providers support that or does that have to be confirmed? Is it not better to have inspection? I know that certain SIP implementations don't add addressing in the application layer, but in the these cases they do. I have SIP inspection enabled and don't see any issues with it and I gain the benefit of not only being able to do a show SIP but the necessary pinholes are dynamically created instead of opening wide static holes these providers often request, but the providers still insist having ALG creates more problems. 

When creating VLANs for just L2 on a switch -- routing will be handled by a device within that VLAN such as a load-balancer -- it isn't necessary to create the vlan interface. As a matter of habit, I always create the interface anyway-- no IP address - so I get all the interface bits and packet stats in "sh interface". Are there any negatives to what I think is a best practice to just create the L2 interface? When do you create or not create the interface for a L2 VLAN? I am looking for answers that discuss only L2 VLANs, not the merits and use cases for L3 VLAN SVIs. Cisco reports a L2 interface as EtherSVI on my 6500 -- no IP address. Is it correct or incorrect to still think of a L2 interface as an SVI though the we all know the usual use-case is to have an IP address for routing? The question is only about whether or not I should have this L2 interface in the first place. You can see only the L2 counters are incremented, but still giving some value. 

You either have to statically assign an IP address to your client or setup a DHCP server. If the client is setup as a DHCP client and there is no server available, it will auto-assign itself a 169.254.x.x addrsss. 

It is basically an extra layer of security. If you do not have a version of IOS that supports service password-encryption, then only enable passwords are encrypted while the console and VTY passwords are plaintext. If someone were able to get a copy of your config (say from a backup, or an unattended computer that was telnetted in), the encrypted enable password would make it more difficult getting control of your router, even if they can telnet in. Even with encrypted VTY and console passwords, you should still have a different enable password to be on the safe side and provide an extra barrier. 

The easiest way to do this is to get a second router, assign it an unused public IP address, and forward the appropriate ports to your server. The server would be physically separated from the rest of your network. As an example, lets say you have a cable modem with a built in 4 port switch and a block of 5 usable IPs 100.0.0.2 through 100.0.0.6. You'd plug the WAN ports of the two routers into the cable modem, assign 100.0.0.2 to one router and 100.0.0.3 to the other. To access the server, you'd either have to physically be in front of it, use a program like TeamViewer, or forward port 3389 to the server so you can use RDP. A more sophisticated way of doing it would to get a router supports 1 to 1 NAT. That would allow you assign one public IP address to your server and another for the rest of your network using only one router. Depending on the router, you could either create a separate sub-interface for your server to keep it separate or use VLANs. If you don't have much experience, I'd probably go with option A unless you have a need for computers on your network to be able to access that server locally. 

Is "mpls bgp forwarding" configured on the interface facing your transit provider? Same on their interface facing you? edit: Just reviewed your config, and you do have it -- would check with your peer to see if they have it configured as well 

I would strongly recommend moving to an OSPF/iBGP design for something of this scale, with the core switches acting as BGP route reflectors. BGP has so many more administrative handles for tinkering with routes over OSPF, allowing better scale and filtering. If you scale to the point that you have more networks than your ToR switches can program into CAM (unlikely if each is a different stub), you run into issues. Each additional zone is more CPU load on your ABRs (core switches) as well. Have one OSPF area 0, with all loopbacks and router-to-router links in it. Then setup iBGP sessions between your cores and ToR, advertising default-only to ToR, and redistribute connected/static routes on ToR into BGP. 

That is a valid wildcard mask. It will match any IP with the format 10.(160-191).1.(0-255). Whether or not this is intended, or good design, is unknown. Wildcard masks are just "do-we-care" bitwise masks used when looking at an IP -- a value of 0 means "do-care", and 1 means "don't-care". In this case, 0.31.0.255 translates to: 00000000 00011111 00000000 1111111 So the IP listed in the ACL (10.160.1.0) will have a binary value of 00001010 10100000 00000001 00000000 Testing an IP (10.190.1.200): 

The best you can usually do is look for communities with your provider that allow you to indicate prepends per peer of your provider. This assumes your provider has such communities and has the peering relationships for this to work. Prepending your own announcements to your peer would have no variation upstream from your provider. Though this method does not alter localpref one AS removed from your provider, it has similar impact in making that path back to you less desirable. There is an exception to influencing localpref upstream that I'll describe at the bottom, though it's probably an edge case. Some providers such as XO [AS2828] allow you to advertise your prefixes in such a way that your provider announces your routes with with specific prepends for certain peers of theirs. For example, XO accepts: prepends once for AT&T prepends twice for Level3 preprends thrice for Sprint On Savvis, the community is which prepends once for AT&T. These providers usually have communities to indicate the well-known communities of NO_EXPORT or NO_ADVERTISE to specific peers. One Tier 2 provider I know, InterNAP, is able to influence localpref upstream because they buy transit, so they are a customer of the Tier 1's. They have communities that you could use where they attempt to translate those into specific Tier 1 communities for your upstream advertisements which set localpref to peer-, mid-, or high-level values. See $URL$ Example References: XO Communities that Change Customer Announcements to Certain Peers at AS2828 Border Savvis Prepend Community Attributes I have no affiliation with the providers used in the examples other than direct experience as a customer. 

You can do this from the Auth. Policy section in the USG (where you can also find the Help link.) FYI: I've worked with USG 20s, 50s and 100s and am fairly familiar with them, but haven't tried doing this. 

Network devices can only see MAC addresses of devices on the local network (broadcast domain, actually.) ARP traffic is broadcasted and not routed. When your Computer A is trying to communicate with Computer B on a different network, it doesn't need to know the MAC address of B. It only needs to know how to route to that IP address and the MAC address of the local router. 

They are on different networks (192.168.0.0/24 and 192.168.1.0/24), so in order to communicate, you either have to change one of the IPs to be on the same network as the other, or place a router in between them. In a nutshell, the subnet mask lets clients know which addresses are local and which are remote. So, 192.168.0.1 with a mask of 255.255.255.0 can communicate with anything else with IPs between 192.168.0.2 and 192.168.0.254. If you were to subnet to smaller network*, an IP at 192.168.0.1 with a mask of 255.255.255.248 would only be able to communicate with 192.168.0.2 through .6 and would need a router to communicate with, say, 192.168.0.10. *192.168.x.y addresses cannot be supernetted up to a larger subnet mask, such as 255.255.0.0, but that's another discussion.