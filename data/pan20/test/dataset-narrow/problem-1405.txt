I am not a modeller, more into the programming side. However say I wanted to create an open world type of game using U4. Is there a way to create very rough models, say of buildings, cars, trees, terrain etc, without having to fine detail them, so I can lay the skeleton of the game as a blueprint. I know all these models would have to be redone properly but I would want to experiment creating the overall structure of the game world environment in a very rough way first. I take it I would just be creating block(cube) like structures in say Blender, exporting these models and then loading them up in the U4 editor for placement? 

For example say you wanted to draw a 3D cube you can define an array of hard coded vertices using float3, here is an example. $URL$ But you obviously can't define by hand large and complex changing geometry vertices such as you would have in a game. So I am trying to understand the mechanics behind how these vertices are loaded/interpreted into the Engine. Another example, you could create a model in say Maya and export this vertex data to say an XML file, then load up the model using GL/DX. So Maya is doing all the work determining the vertex data. You could do this for terrain also, any vertex geometry. However a game state is constantly updating, it is not static, the camera is constantly moving with user input. So what is the mechanics behind constantly re-evaluating new vertex data depending on user input. 

For example, take bullets, sparks, fireballs, light sabers, lightning bolts, any kind of special effect in a game. Are there various ways to implement these effects in a game. As far as I can see you create either an animation is some modelling package like Maya and then load these animations, you also seem to be able to do these kind of effects using layer upon layer of textures(images). So where does the particle engine come in in a game, what is the relationship with pre-made animations. Lets say I wanted to have some custom effect like the player could have a Thor like hammer and smash it on the ground as special power. Now when it hits the ground, everything rumbles and bolts of lightning appear from the hammer which propagate in a every increasing circular motion away from the hammer, like a circular lightning bolt and eventual fade away. What options do I have to create a special effects like this, is it mainly done in animation software or mainly done in the engines code. 

Since you have already solved the first problem, I will only address the second problem The code you have does not really show where you generate the model, view & projection matrices, so it is difficult to exactly pin-point the problem position for you You should maintain separate View & Projection matrices. If you use a library such as glm, which is fully compatible with iOS, you can easily calculate your view matrix 

As far as I understand, the problem is that these lighting calculations are done in Camera space, and hence change when the camera changes position. So, my question is How would I change that to get the light to be at a fixed position, ie: do the light calculations in World space 

I can't find a direct problem with your code, but here are a few pointers on dealing with Android Multi-touch Input 

I hope these pointers at least give you a starting point on where to look further into solving your problem 

I have implemented a simple Phong shader without specular highlights for now (just ambient + diffuse components) The problem however, is that the calculations seem to be done in camera space; as I move the camera around, the light source seems to move along with it. This is evident by me not being able to see the dark side of the models (Note: Image is a gif, if it is not animating, open in a new tab) 

If you look at your images alpha channel, you can see how it already has all the information you might need for pixel perfect collision 

This way, you will update your x, y & z angle rotations (around their respective axes) in as you'd expect them in the model space (If I understand correctly, feeding them in from the pan / rotation gesture values), and the matrix calculation / multiplication will handle the translation for you Hope this helps If you wanna take a more full look at this code in action, you can checkout a small sandbox I'm building (for other purposes really) that has this code in action 

On PC the sales boost you are going to get from Steam will always surpass the cut they take so you are going to be using . If you have been rejected by Steam, I would recommend that you use the over install shield. I found it easy to use and a far superior product. (It is also free.) There may be a third option that is even better, but I am not familiar with it. $URL$ $URL$ The NSIS installer feature set claims to now also support patching and "an optional silent automated installation" mode. I haven't used these features personally, but given my excellent experience with that software in the past I have no reason to believe they wouldn't work. Someone else will need to answer your Mac questions. 

It sounds like you need to modify your XML file that defines your spritefont. You want to ensure that the and tags are correct. Below are the ones that I use in my file. 

What you need is called a painter's algorithm. You want to draw the furthest tile first, including any doodads or characters on it. Then draw the next closest, and repeat until finished. Your objects that span more than one tile must have an anchor/origin point declared. This is the grid cell that when drawn, will result in your larger object also being drawn. The origin point is chosen so that it is drawn after all cells the object bleeds into are drawn first. Based on your question, your origin point will be the tile that is closest to the camera. (If you are using square, rather than diamond-shaped tiles, either the bottom-left or bottom-right tile should be chosen.) Example code for a square-grid. Alter the loop direction for your diamond-grid. 

Regarding the jumping problem: You need to incorporate the time since the last frame into your calculation when you apply velocity to position. Assuming you have perfected things for 60fps: 

Pixel perfect collisions are usually expensive, so doing a rough estimate at first with a bounding box or a more detailed collision figure (Like the one Anko suggested) may save you some precious time The "finer" detailed collision bounding box Anko suggested: PS: If your image has a halo, an effect or other non-0 alpha channel around it that you don't want to collide with, the algorithm threshold can easily be adjusted to accommodate that 

And then simply pass in the model matrix (along with view & projection matrices) to the vertex shader, and you can do the multiplication there (bonus speed boost for multiplying on the GPU might occur) 

If you can generate proper matrices for the objects for translation & rotation, you can solve this pretty much straight-forwardly Let's assume object A has the translation & rotation matrix mat_A and object B has translation & rotation matrix mat_B You need to loop over pixels in A and if it has an alpha value > 0 (or a custom threshold you want) check which pixel of B is at this very position and check if this pixel also has a non-0 alpha channel Using matrix mathematics, you can move the 2nd object into the first objects world space, to get the mapping between the pixels You need to transform the global location to a local location in the space of object B. This is the inverse of mat_B. So, we have to transform the local position in A with the following matrix: 

PS: GLM is also Opensource, so if you want to take a look at how it is implemented and do it yourself, you can definitely do so When you have your view & projection matrices (which are indifferent for your entire world) the thing you want to be modifying per each model is, as you'd expect, the model matrix 

Any slowness in this situation would be caused by the switching of texture states, as another poster also mentioned. If you are finding that you have performance problems you can combine all of your small textures into a larger sprite sheet texture to eliminate the switching of which texture is on the GPU. You will just need to use a rect to access the correct portion of the sprite sheet when you make the call to ContentManager.Load(). 

I am looking for a tool that will output spritefonts for XNA consumption that have an outline effect. I know that this can be done by rendering the text multiple times, but I'd like to take care of it in the content pipeline. The options that I was able to find reference to were hosted at sites that are now offline. I know Nuclex has a vector font option, but again, I'd like to stick with sprite fonts and handle the rendering at compile time. If anyone can link to an archived copy of those free tools, it would be appreciated. 

If you decide to allow diagonal movement someday, you can just change the range variable's calculation. 

Number the tiles. You could derive this information by calculating row*8+column or something similar. Take modulus 16 of the grid number. (There are 16 positions before the tiles repeat.) Color the tile based on if it has an even or an odd number. Flip the tile color if the result is greater than 7. 

No, fetching them from the hard drive is very time-intensive. It is possible that you have so much texture/model/animation data that everything will not fit concurrently on the GPU, especially for someone using an older graphics card or laptop. Main memory is probably the cheapest resource you have to work with on a modern computer. You should leave things like unloading textures from memory for when you are switching maps. 

This could almost be said for almost all areas of the game development. There has to be enough tutorials about AI, UI, graphics, sound, networking and all other fields of the development that you could argue the same thing. However, these samples are either too generic to be optimised, or too optimised to be easily plugged into your code, without extensive knowledge from your side on what the code expects, does and achieves So while you may find a shader somewhere that does exactly what you want, if you don't have a moderate understanding of its code, you might come across a bug that will just block your progress completely. And this might not even be a bug, but just coming out of different expectations between you and the code author 

A two step check process On the first step, you check the bounding box, and if there is no collision there, then the test is over. If there is collision, you move over to the second pass On the second pass, if you want more precision, and you want a true pixel perfect solution, then you can do just that, a pixel perfect check pass Since your image is a PNG (or any other file format that contains an alpha channel) this would be rather easy 

My light is a point light, that I would like to have fixed somewhere in the world. It has a defined position. To my shader, I also pass in the M, V, P matrices, as well as the normal matrix, which is the inverse transpose of the MV matrix 

Shader programming is a highly specialised section of general Graphics Programming. Like any other highly specialised section of development, it depends on two factors; namely the Team-Size and the Goals you wish to achieve 1. Team Size: On smaller teams, having an entire resource (read: person) dedicated to ONLY shader programming might be a huge overkill. In smaller teams, your general graphics programmer (and in some cases, THE programmer) would probably be enough handling most of the coding needed in that direction On larger teams and as we go towards AAA development end where there are usually multiple graphics programmers on a team, having highly specialised people usually leads to more efficient and better optimised code; meaning you can squeeze more performance out of the hardware 2. Goals: Here, by goals, I mean the graphical goal of the project. If you are creating a game with not much new stuff going on on the graphics side, then you might be able to find something to fit your needs specifically On the other hand, if you are going for a more unqiue, new or innovative technique (like implementing a SIGGRAPH paper) then you very likely would need a more specialised coder dedicated to the shader coder alone Also, on the note of