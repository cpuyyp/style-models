The first one is accomplished with the principle of least privilege: giving folks only the permissions they need, and nothing more. The second one is accomplished by giving each person their own login, not allowing shared logins (like letting everyone use the same username/password), and ideally, auditing the logins. You probably won't do that last part right away, because it's kind of painful, but let's put the pieces in place first so you can add auditing later after somebody drops a database and your boss wants to know why. I know what you're thinking: "But we're coding apps, and the app needs a login." Yes, give the application its own login, and the developers need to know that password, but that login should be so stripped of permissions that nobody in their right mind would want to use it. For example, it might need to be in the db_datareader and db_datawriter roles alone, nothing else. That way it can insert, update, delete, and select data, but not necessarily change schemas, add indexes, change stored procedures, etc. "Does this only apply to production instances, or to our internal development instances, too?" I think it applies just as much to development instances because I'm usually worried about people breaking things. People just love to break servers in development. And of course, when it's time to bundle up the list of changes to migrate to production, I need to know whether a particular index really is vital to the app or whether some bonehead just ran the Database Tuning Advisor and told it to apply all changes. Proper permissions helps lessen that pain. 

It's hard to know this for sure given the limited information here, but I don't think you're quite down to root cause yet. 

You need to download the right ISO/EXE from your licensing site. (Could be MSDN, for example.) The one you want is Core-based, and it'll have the right installation key embedded in it. (You may also be able to check with your license admins to get it.) Then, you can do an edition change (Books Online). For more practical details, check out Kendra Little's post on changing editions. For folks who stumble across this question and just wonder what's going on, Aaron Bertrand has a great blog post with more background on the 20/40-core limit. 

Yo, man - your top wait is coming up on TEN TIMES LARGER than your storage wait. Forget the storage: you're barking up the wrong tree. Focus on your top wait type. To tune parallelism, go to $URL$ The short story: 

The SQL Server was probably renamed in the past. Here's a better article from Microsoft on how to change the server names: $URL$ 

You've got a few different questions in here. Q: Can I have Always On Availability Groups without a listener? Yes, and I know some folks who prefer to do it that way just to avoid the problems with listeners. They code their apps to directly point to the normal primary SQL Server, and if their app fails to connect, their app code tries another server name. I'm not a big fan of that approach in most scenarios because it takes away your flexibility to add/rename/move replicas at the DBA level. But when you've got a lot of really savvy developers, and a willingness to recompile the code if necessary (or play with DNS CNAMEs) then it can work. Q: If I add a new replica, do I need to add a new listener? No. However, if the new replica is in a new subnet, you'll need to add an IP address in that subnet to your existing listener. Q: Can I get away without adding that IP? Yes, but you're probably going to run into support problems down the road. If you're going to use a listener, I would configure it so that it can fail over to any replica. If you're not going to use a listener, then this part of the question doesn't matter. 

Just use a trace template. Click File, New Trace, and choose the Replay template. That'll get you everything that happens. 

Unfortunately, Microsoft is aware of the lack of replacements. You can upvote & watch these Connect items for more details: Deprecation of sysprocesses - DMV's doesn't fully replace all columns - by Tony Rogerson SQL There is no real alternative to master.dbo.sysprocesses - by GV1973 

First, patch: make sure you're on 2012 Service Pack 1 Cumulative Update 10 or newer. In SQL 2014, Microsoft changed TempDB to be less eager to write to disk, and they awesomely backported it to 2012 SP1 CU10, so that can alleviate a lot of TempDB write pressure. Second, get exact numbers on your latency. Check sys.dm_io_virtual_file_stats to see the average write stall for your TempDB files. My favorite way to do this is either: 

In that case, the answer isn't a distributed transaction - it's a staging database and a 2-step extract/transform/load (ETL) process: 

Then use the SQL Server Management table designer to change the CustomerName column to a VARCHAR(200) instead of an NVARCHAR. By default, when you try to save the changes (or even just generate a change script), you get a warning: 

No, but what the presenter was probably doing was using Grant Fritchey's technique to search the plan cache for a string. You can search the plan cache for your view name. That technique has a few drawbacks. It's very slow on a busy/large production server - it doesn't hold folks back by blocking, but it can just take a really long time to search, say, 10-100GB of query plans looking for a string. Also, it only searches the literal plan - if you have a view calling another view, the nested view's name may not show up in the query or the plan. 

I have a confession to make. Once, when I was young, I built an ETL process started with changing read-only filegroups to read-write, doing its ETL work, and then setting them back to read-only. So just in case you have a coworker who was diabolical like I was (I was young, I needed the money), you can test by: 

And yes, if you try to get data out of a VARCHAR(MAX) field, and somebody stored 2GB in there, buckle up. 

Don't try to do that with T-SQL - RegEx is no match for the creativity of end users with a text field. If you need to do it production-quality at scale, check out the Melissa Data SSIS components. (I have no relationship with that company at all - just heard excellent things about it from people who have to do this exact sort of thing for a living.) 

If you can add columns to tables, you can try persisted computed columns, and index those. For example: 

That way you just get the rows you want. If you find yourself doing this kind of thing frequently, run a job to cycle the error log periodically (I like weekly) so that you don't have to sift through so much stuff. Plus, make sure you're not logging successful backups or successful logins to the error log. 

Instead of looking at indexes, start looking at what queries are causing the high CPU use. Start with Michael J. Swart's DMV queries to find the top CPU-using queries. Look at what indexes the queries are using, whether they're doing things like implicit conversion, etc. But generally no, fragmentation by itself probably isn't doing this. 

There's a blocked-by column that shows you who's blocking who. The lead blocker won't have anyone in their blocked-by column. Once you've found the lead blocker, click on the locks column - it's an XML field that expands to show you the full list of locks held by that session. It could be that the select is part of a longer transaction (there's also an open transactions column), or that the select isn't really what's blocking. Your best bet for getting specific, actionable advice here would be to post a picture of the sp_WhoIsActive output, including the blocking columns, and then the contents of the XML for the locks. 

Both transactions in the two different windows are working on two different tables. So far, so good. Now continuing in Window #2, run an update on Window #1's table: 

Because of those, running queries against a mirror isn't usually cost-effective. If you're willing to stomach the Enterprise Edition price tag, SQL 2012 added Always On Availability Groups, which let you read directly from the secondary with nearly real-time data at a much lower management cost. Still has the EE price tag, though - readable secondaries are an EE-only feature. Generally speaking, performance tuning is easier than licensing more EE cores ($7k/core USD.) 

Putting All the Clients in the Same Database It’s simple: just add a Client table at the top of the schema, add a ClientUsers table to make sure people only see their own data, and away we go. Benefits of this approach: Easier schema management. When developers deploy a new version of the application, they only have to make schema changes in one database. There’s no worries about different customers being out of sync or on the wrong version. Easier performance tuning. We can check index usage and statistics in just one place, implement improvements easily, and see the effects immediately across all our clients. With hundreds or thousands of databases, even the smallest change can be difficult to coordinate. We can check our procedure cache contents and know for certain which queries or stored procedures are the most intensive across our entire application, whereas if we’re using separate databases per client, we may have a tougher time aggregating query use across different execution plans. Easier to build an external API. If we need to grant access to our entire database for outsiders to build products, we can do that easier if all of the data is in a single database. If the API has to deal with grouping data from multiple databases on multiple servers, it adds development and testing time. (On the other hand, that “multiple servers” thing starts to hint at a restriction for the one-database-to-rule-them-all scenario: one database usually means all our load impacts just one database server.) Easier high availability & disaster recovery. It’s really, really simple to manage database mirroring, log shipping, replication, and clustering if all we have to worry about is just one database. We can build a heck of an infrastructure quickly. Putting Each Client in its Own Database or Shard You still need a client listing, but now it becomes a directory - for each client, you also track the shard it lives in. On startup, your app queries this table, and caches it in RAM. When it needs data for a client, it connects directly to that shard (database & server). Benefits of this approach: Easier single-client restores. Clients are unreliable meatbags. (Except mine – they’re reliable meatbags.) They have all kinds of “oops” moments where they want to retrieve all of their data back to a point in time, and that’s a huge pain in the rear if their data is intermingled with other client data in the same tables. Restores in a single-client-database scenario are brain-dead easy: just restore the client’s database. No one else is affected. Easier data exports. Clients love getting their hands on their data. They want the security of knowing they can get their data out anytime they want, avoiding the dreaded vendor lock-in scenario, and they want to do their own reporting. With each client’s data isolated into their own database, we can simply give them a copy of their own database backup. We don’t have to build data export APIs. Easier multi-server scalability. When our application needs more power than we can get from a single server, we can divide up the databases between multiple servers. We can also spread out the load geographically, putting servers in Asia or Europe to be closer to clients. Easier per-client performance tuning. If some clients use different features or reports, we can build a specialized set of indexes or indexed views just for those clients without growing everyone’s data size. Granted, there’s some risk here – by allowing schema differences between clients, we’ve just made our code deployments a little riskier and our performance management more difficult. Easier security management. As long as we’ve properly locked down security with one user per database, we don’t have to worry about Client X accessing Client Y’s data. However, if we just use a single login for everyone, then we haven’t really addressed this concern. Easier maintenance windows. In a global environment where customers are scattered around the globe, it’s easier to take customers offline for maintenance if we can do it in groups or zones. Which one is right for you? There’s no one right choice: you have to know your own company’s strengths and weaknesses. Let’s take two of my clients as examples. Company A excels at hardware performance tuning. They’re really, really good at wringing the very last bit of performance out of hardware, and they don’t mind replacing their SQL Server hardware on a 12-18 month cycle. (They refresh web servers every 4-6 months!) Their Achilles’ heel is extreme compliance and security requirements. They have incredible auditing needs, and it’s just easier for them to implement bulletproof controls on a single server, single database than it is to manage those requirements across thousands of databases on dozens of servers. They chose one database, one server, many clients. Company 2 excels at development practices. Managing schema changes and code deployments across thousands of databases just isn’t an issue for them. They have clients around the world, and they’re processing credit card transactions for those clients around the clock. They need the ability to spread load geographically, and they don’t want to replace servers around the world every 12-18 months. They chose one database for each client, and it’s paying off as they start to put SQL Servers in Asia and Europe for their offshore clients.