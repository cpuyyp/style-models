Dmitry and I have been discussing for a couple years about what the upper bound is for the shortest string accepted by a PDA. You can get a lower bound of $2^n$ and an upper bound of $2^{n^2}$, but can you improve either of these bounds? Even just a small improvement on the upper bound to $2^{\frac{n^2}{\log(n)}}$ would be a breakthrough. Sorry for such a long reply and for excluding many details. Feel free to shoot me an email if you would like to discuss offline. Thank you and I hope you have a great week! 

There are two distinct concepts: (1) Efficient simulation of deterministic machines by non-deterministic machines. (2) Speed-up results that are obtained by applying a simulation over and over again. I don't know of any efficient simulation of deterministic machines by non-deterministic ones, but I know of several speed-up results that could be used if efficient simulations exist. 

Getting Started Consider a parameterized problem $F$. We use $n$ to denote the input size and $k$ to denote the parameter. Consider the fixed levels of $F$ which we denote by $\{F_k\}_{k\in\mathbb{N}}$. Definitions We say that $F$ is in non-uniform $FPT$ if there exists a constant $c$, a function $f(k)$, and a family of algorithms $\{A_k\}_{k\in\mathbb{N}}$ such that for every $k$, $A_k$ solves $F_k$ in $O(f(k) * n^c)$ time. We say that $F$ is in uniform $FPT$ if there exists a constant $c$ and a function $f(k)$ such that there exists a parameterized algorithm that solves $F$ in $O(f(k) * n^c)$ time. Remark: One could construct unnatural examples of paramterized problems that are in non-uniform $FPT$, but are not in uniform $FPT$. For example, take an undecidable language and define the parameter $k$ to be the input length. Question Does there exist a natural parameterized problem $F$ that is proven to be non-uniform $FPT$ and suspected (yet not proven) to be uniform $FPT$? A More High-level Question Does uniform vs non-uniform parameterized complexity have any relationship to uniform vs non-uniform circuit complexity? 

This is a great question and it really lies within my interests. I'm glad that you asked it Max. Let $n$ DFA's with at most $O(n)$ states each be given. It would be nice if there existed a PDA with sub-exponentially many states that accepts the intersection of the DFA's languages. However, I suggest that such a PDA might not always exist. Consider the copy language. Now, restrict it to copying strings of length n. Formally, consider $n$-copy $:=$ $\{ xx \, | \, x \in \{0,1\}^{n}\}$. We can represent $n$-copy as the intersection of $n$ DFA's of size at most $O(n)$. However, the smallest DFA that accepts $n$-copy has $2^{\Omega(n)}$ states. Similarly, if we restrict ourselves to a binary stack alphabet, then I suspect that the smallest PDA that accepts $n$-copy has exponentially many states. P.S. Feel free to send me an email if you would like to discuss further. :) 

Here's a little more detail from the perspective of simulating time-space bounded Alternating Turing machine. Suppose that $P = NC$. Since $NC = ATISP((\log(n))^{O(1)}, O(\log(n)))$, we get $$P = ATISP((\log(n))^{O(1)}, O(\log(n))).$$ Now, consider the linear time universal simulation problem $LinU$ where we are given an encoding on a Turing machine $M$ and an input string $x$ of length $n$ and we want to know if $M$ accepts $x$ in at most $n$ steps. We know that $LinU \in P$. Therefore, there exists a constant $c$ (sufficiently large) such that $$(*) \; LinU \in ATISP(\log^c(n), c\log(n)).$$ As a result of a padding argument (a little tricky see comments), we have $$(1) \; DTIME(n) \subseteq ATISP(\log^c(n), c\log(n)).$$ Extending the padding argument, we get $$(2) \; DTIME(n^k) \subseteq ATISP(k^c\log^c(n), kc\log(n)).$$ $$(3) \; DTIME(2^{n^k}) \subseteq ATISP(k^cn^{kc}, kcn^{k}).$$ Further, there are known results about the simulation of Alternating time-space bounded Turing machines. In particular, we know that $$ATISP(\log^c(n), c\log(n)) \subseteq DSPACE(O(\log^{c+1}(n))).$$ Therefore, we (essentially) have the following for all natural numbers $k$: $$(2^{*}) \; DTIME(n^k) \subseteq DSPACE(k^{c+1}\log^{c+1}(n))$$ $$(3^{*}) \; DTIME(2^{n^k}) \subseteq DSPACE(n^{k(c+1)}).$$ From $(3^{*})$, we would get that $EXP = PSPACE$. ====================After Thought=================== It is important to notice that $P = NC$ implies $$ATISP((\log(n))^{O(1)}, O(\log(n))) = ATISP(\log^c(n), O(\log(n)))$$ for some constant $c$. Any comments or corrections are welcomed. :) 

(1) What we already know: As you've already stated, QBF with $\log(n)$ alternations of quantifiers is hard for every level of the polynomial hierarchy. (2) I think that we can also prove the following: The problem is $NSPACE(log^2(n))$-hard. (3) Here is my informal justification for the preceding assertion: Given a $log^2(n)$ space bound NTM and an input string, we need to determine whether there exists an accepting computation on the given input string. Each configuration in the computation can be represented by essentially $\log^2(n)$ bits. In other words, we can represent a configuration by a group of $\log^2(n)$ variables. The idea is that we have a start configuration and a final configuration and we need to guess the computation that happens in between. We recursively guess the "middle" configurations using exist quantifiers and recurse verifying that the "left" configuration goes to the "middle" and the "middle" configuration goes to the "right" using for all quantifiers. Now to make this work, instead of picking one "middle" configuration, we need to pick a group of equally spaced "intermediate" configurations between the "left" and "right" configurations. In particular, we could guess $\sqrt{n}$ equally spaced "intermediate" configurations using exist quantifiers with $\sqrt{n} * log^2(n)$ variables and then recurse on every gap between configurations using for all quantifiers with roughly $\log(n)$ variables. The recursion only needs to continue on to depth $2 * \log(n)$ to be able to cover a computation of length $\sqrt{n} ^ {2 * \log(n)} = n^{\log(n)} = 2^{\log^2(n)}$ where each configuration has at most $\log^2(n)$ many bits. Since the recursion is of depth $O(\log(n))$, we only have $O(\log(n))$ groups of variables i.e. alternations. Since each group of quantifiers only has $\sqrt{n} * log^2(n)$ variables, in total we have $O(\sqrt{n} * log^3(n))$ variables. Feel free to offer any feedback or corrections. Thank you very much and I hope this helps a little bit. (4) A more general assertion as suggested by Ryan's answer: You should be able to carry out the preceding construction in a more general way. Consider the following: At each step of the recursion, break up into $g(n)$ groups of "intermediate" configurations using $c(n)$ bits per configuration. Then, do the recursion to depth $d(n)$. As long as we don't have too many variables and too many alternations, this seems to work fine. Roughly, we need the following to be satisfied: 

Note: the existence of such an oracle may have ramifications in structural complexity theory. See the following update below for further details. Update with details on a lower bound technique Claim: If $PSPACE = PH$, then for all oracles $A \in P/poly$, $PSPACE^A = PH^A$. 

If $DTIME(f(n))$ is defined as the class of all languages decidable in $O(f(n))$ time by a two tape Turing machine, then I suspect that the answer is no. In other words, I think that there does not always exist a strictly intermediate time complexity class. Note: This answer might not be exactly what you are looking for because I'm considering non-computable functions and I don't include every detail of the argument. But, I felt that it is a good start. Please feel free to ask any questions. Maybe I can fill in these details further at some point or maybe this will lead to a better answer from an interested reader. Consider functions of the form $f : \mathbb{N} \rightarrow \mathbb{N}$. We refer to these functions as natural number functions. 

To show this, it seems that you would need to provide a reduction from an intersection problem instance of size $n$ to a SAT instance of size $2\cdot log_2(n)$. This kind of reduction would be very interesting because it would take an instance of one problem to a much smaller instance of another problem. As a result, this reduction would not be one-to-one. Actually, there would be exponentially many inputs that map to the same output. If you know of any interesting reductions of this form, please provide a reference. Thank you. :) 

In the following, we will describe what seems to be a parameterized version of the minimum circuit size problem (MCSP). 

The following notion of a distillation algorithm comes from "On Problems Without Polynomial Kernels". 

It made my day when my friend James told me that this thread from long ago was rekindled. Thank you for that. Also, I had an urge to share some interesting references that are relevant to L vs Log(DCFL) vs Log(CFL). Have a great day! $URL$ $URL$ $URL$ $URL$ 

For every natural number $n$, consider a function $B_n: [n] \rightarrow \{0,1\}^{\lceil \log(n) \rceil}$ such that $B_n(i)$ is the $i$th bit string in $\{0,1\}^{\lceil \log(n) \rceil}$ according to the lexicographical ordering. (Example: $B_7(5) = 100$) Now, let a bit string $x$ of length $n$ be given. Let a boolean circuit $C$ with $\lceil \log(n) \rceil$ inputs and $1$ output be given. We say that $C$ computes $x$ if for every $i \in [n]$, $C(B_n(i)) = x_i$. In other words, $C$ computes $x$ one bit at a time. 

Using fast matrix multiplication, we can solve $k$-Clique in $O(n^{.792 k})$ time. Therefore, we can solve CNF-SAT in $2^{.792 N}$ time. In fact, there is a trivial algorithm for solving CNF-SAT in $2^{.5 N}$ time. However, it is not known if we can solve CNF-SAT in $poly(N) \cdot 2^{(1-\epsilon) \cdot n}$ time. Question: Does there exist a constant $c$ such that for every fixed $k$, we can reduce an arbitrary instance $\phi$ of CNF-SAT to an instance $G$ of $k$-Clique with roughly $2^{\frac{c \cdot n}{k}}$ vertices and $2^{\frac{2 \cdot c \cdot n}{k}}$ edges. Relevant Links: 

It has been shown that if there exists a distillation algorithm for an $NP$-complete problem, then $coNP \subseteq NP/poly$. Moreover, $PH = \Sigma_3$. 

The decision problem CNF-SAT can be described as follows: Input: A boolean formula $\phi$ in conjunctive normal form. Question: Does there exist a variable assignment that satisfies $\phi$? I'm considering several different approaches for solving CNF-SAT with a non-deterministic two-tape Turing machine. I believe that there is an NTM that solves CNF-SAT in $n \cdot \texttt{poly}(\log(n))$ steps. Question: Is there an NTM that solves CNF-SAT in $O(n)$ steps? Any relevant references are appreciated even if they only provide near linear time non-deterministic approaches. 

We will prove a stronger theorem and then the simple answer will follow. Theorem: If we can solve the intersection non-emptiness problem for two DFA's in $O(n^{\delta})$ time, then any problem that's non-deterministically solvable using only n bits of memory is deterministically solvable in $poly(n)\cdot2^{(\delta n/2)}$ time. Justification: Suppose that we can solve intersection non-emptiness for two DFA's in $O(n^{\delta})$ time. Let a non-deterministic Turing machine M with a read only input tape and a read/write binary work tape be given. Let an input string x of length n be given. Suppose that M doesn't access more than n bits of memory on the binary work tape. A computation of M on input x can be represented by a finite list of configurations. Each configuration consists of a state, a position on the input tape, a position on the work tape, and up to n bits of memory that represent the work tape. Now, consider that the work tape was split in half. In other words, we have a left section of $\frac{n}{2}$ cells and a right section of $\frac{n}{2}$ cells. Each configuration can be broken up into a left piece and a right piece. The left piece consists of the state, the position on the input tape, the position on the work tape, and the $\frac{n}{2}$ bits from the left section. The right piece consists of the state, the position on the input tape, the position on the work tape, and the $\frac{n}{2}$ bits from the right section. Now, we build a DFA $D_1$ whose states are left pieces and a DFA $D_2$ whose states are right pieces. The alphabet characters are instructions that say which state to go to, how the tape heads should move, and how the work tape's active cell should be manipulated. The idea is that $D_1$ and $D_2$ read in a list of instructions corresponding to a computation of M on input x and together verify that it is valid and accepting. Both $D_1$ and $D_2$ will always agree on where the tape heads are because that information is included in their input characters. Therefore, we can have $D_1$ verify that the instruction is appropriate when the work tape position is in the left piece and $D_2$ verify when in the right piece. In total, there are at most $poly(n) \cdot 2^{n/2}$ states for each DFA and at most $poly(n)$ distinct alphabet characters. By the initial assumption, it follows that we can solve intersection non-emptiness for the two DFA's in $poly(n) \cdot 2^{(\delta n /2)}$ time. You might find this helpful: $URL$ 

I'm looking for more problems in $P$ with classical time complexity lower bounds. Some people might wonder how you could prove such a lower bound. See below. Exponential Lower Bounds: Claim: If you have a problem $X$ that is $EXPTIME$-complete under polynomial reductions, then there is a constant $\alpha \in \mathbb{R}$ such that $X$ is not solvable in $O(2^{n^{\alpha}})$ time. Proof Idea: By the time hierarchy theorem, there is a problem $Y$ in $O(2^n)$ time that is not in $o(\frac{2^n}{n})$ time. Further, there must be a polynomial reduction from $Y$ to $X$. Therefore, there is a constant $c$ such that this reduction takes an instance of size $n$ for $Y$ to an instance of size $n^c$ for $X$. The lower bound for $Y$ of $O(2^{n^{1-\epsilon}})$ time shifts to a lower bound for $X$ of $O(2^{n^{\frac{1-\epsilon}{c}}})$ time. Polynomial Lower Bounds: Some $EXPTIME$-complete problems have nice parameterizations into polynomial time problems. Consider the problem $X$ from before. Suppose we have a parameterization $k$-$X$ for $X$ such that: 

Quick Answer: Yes, there is a really lovely algorithm that solves non-emptiness for pushdown automata that does not involve constructing the equivalent CFG. Possible Drawback: Correct me if I am wrong, but it doesn't appear to be more efficient than the approach where you convert to a CFG. Basic Idea: It can be viewed as a sort of dynamic programming algorithm where you solve reachability without ever constructing the possibly exponential length paths that you need to consider. You start with a state diagram for a Pushdown Automata. Let's call a transition that doesn't manipulate the stack a resting transition. You proceed with a series of stages. Start of Stage: You combine all compatible push and resting transitions. Next, you combine all compatible pop and resting transitions. Then, you combine all compatible pairs of resting transitions with each other. Finally, you combine all compatible push and pop transitions. Now, you throw in all of the new transitions into the state diagram. End of Stage. You go through stage after stage repeating this process. There are only so many possible transitions. Eventually, you either get a transition that leads from the start state to a final state or you must run out of possible transitions to add. At this point, you know whether the automata's language is empty or not. Question: Can you provide me with any books or papers that give a good exposition of this algorithm? Whenever I searched for it several years ago, it seemed that this algorithm is unpopular or not well known. I personally really like it. Thanks for asking the question! I really appreciate it and I hope this helps a little bit. Have a nice day! :)