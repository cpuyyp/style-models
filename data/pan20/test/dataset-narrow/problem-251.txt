The important portion was . Since I would never need to support IPv6 I removed it from the network adapter and restarted the server to ensure all services were updated accordingly. While it might not be the ideal solution I was able to recreate the EM dbcontrol successfully after that change. 

Windows 2008R2 with firewall disabled for testing (not that it changed anything). Listener.log doesn't show anything of worry. Just evidence of me restarting the listener many times. I am aware that I could configure a static listener with but I would like to understand why this is not working. This is the 4th time around that I have been doing this and I have not run into this problem yet. I am basically stuck since I am not sure where else I should be looking. 

For testing I have been trying to install Oracle 11g on a test system with a single database several times with the aid of snapshots. This most recent iteration I have been having issues getting the database to register with the listener. I am to understand that PMON, as long as the database is running, will attempt to register itself at regular intervals with a listener that is running locally on the same machine using port 1521. I have such a listener running but the service is not registered it seems. 

Shutdown . Start with . Use to connect . (Type only, No need to input password , maybe No need to input username , either) 

Before the first hang, I copy the DB backup file to Slave DB, because the replication was far from current, I wanted to restore the database and made replication again. In copy progress after 10 mins, the services start to hang. Before the second hang, I started replication and said Queuing logs and then Waiting logs, and after few mins the services hang again. 

The MariaDB version 10.1.18 has been installed on MicroSoft Cluster Services (MSCS). (Windows Server 2012 R2) There are 2 VMs for The MSCS with active-standby mode. The shared storage (Data Files) is on NetApp Storage, using raw device mapping (RDM). There is a Slave DB VM for DB replication. (read-only) 

Is your database suddenly gain more big these day? It shows 2G allowed. If your data more than 2G will hang the process. No no-lock table hint You can try or in to disable table locked. 

Which also looks OK. Most of the solutions point to SERVICE_NAME mismatches. However I don't appear to have one. v$parameter output 

Much to my surprise that actually fixed the issue. My problem is that the documentation for account permissions on the SSRS account do not mention this permission is required. They only state that "Log On As A Service" is required. All my other SSRS environments, which I inherited, use a domain admin as the service account so I have nothing to compare to. I am trying to get away from that setup. Is this just a flaw in MS documentation or did I cover up the problem (XY)? I do not understand how "Bypass Traverse Checking" fixed "ERROR: Failed to initialize listener" 

Which made sense since I had changed the account that was being used. I simply deleted encrypted content to address that since it was a new SSRS instance anyway. The second error was the one that took me for a loop 

Sorry, I don't have enough reputation to comment on the question, but from my experience if the client application raises a transaction for a query which uses cross database joins then it would promote the transaction to distributed and have the overhead of a DTC transaction. The DTC overhead in this case could be viewed as a negative to performance. Generally the difference would be negligible although Microsoft describe DTC transactions as such: 

So the question is, what is the best way to set this up in the project so that the developers can create a user which can be named whatever they like within the database users and then how would we re-map this to a windows auth login? thanks in advance! 

Which is great, as I can create a user which is mapped up to no login, and then when it's deployed I can run: 

I think you can calculate each 15 min time slot before doing transaction backup, because after transaction backup, the previous transaction logs will be rewriteable, and that will be the maximum of the transaction log file size. DBCC Shrinkfile sometimes could not work well because there are some transaction not write down to database already (transaction will be wrote to log file first and then write to database), you can wait a while and DBCC again. 

Because the reputation limit for comment, I guess there are 2 options to test, and I think to safely to stop mysqldump is not good way to solve this problem. 

When the service hang, I logged into the DB VM, and I could see the DB service (mysqld) was active, and the port was bound by mysqld service. From localhost of DB VM or console I could not telnet or used tool to connect DB service. There was no error message in Mariadb errorlog or windows events. In order to recover services quickly, I rebooted the DB VM to force the cluster hand-over to another DB VM. In the recent DB VM or standby DB VM, there was no errorlog or error events in windows event. (there is only mysqld normally shutdown messages) 

I have a SQL Server Database Project (.NET 4.5) in TFS 2012. As a DBA, i'm looking for a mechanism whereby the developers can create 'CREATE USER' sql scripts and assign their permissions within the database to match the application without needing to know what login it eventually maps up to. This is because I want to hide the logins from live and test environments from them and have the DBAs create these logins in each environment as necessary. If I go into the project and create a new user i.e. [MyApplication] the default script suggests the following template: 

Will that perform a single or multi-threaded write? Our Server support company advised us that if we were to multi-thread our backups we would get better disk write performance. They advised us that SQL Backup is multi-threaded, but i think the above statement would be single-threaded. If we specify multiple DISKS to write to, then it will stripe the backup across multiple devices and therefore be multi-threaded by my understanding. If I perform the following T-SQL while the backup is processing, i can see that the SPID performing the backup has multiple processes, but only one seems to write to disk, the others i presume are reading and doing other things. It's just the write threads i'm referring the question to. 

Really new to Oracle and being a DBA in general. I am trying to set up a development environment so that I can play an learn oracle better. Enterprise Mananger failed to configure itself when I first created the database using the Database Configuration Assistant. No biggie. Just need to user emca.exe I had some issues with the Listener but those might have just been me being impatient in waiting for the service to register or the service not running. Right now my issue is this from the emca log: 

That tells me that the database registered itself dynamically correctly. prodbkp is my SID. This might be a case issue since I named the DB "PRODbkp" but everything else seems to be fine since I can connect with just fine. Case should not be an issue with service names as per docs.oracle.com tsnnames.ora 

As part of the troubleshooting I was doing to try and address the issue I ran Process Monitor while I was trying to start the service. I tracked as event that also had a result of "Access Denied" which was the service trying to read files inside the directory where reporting services was installed an running from. In my case it was: "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services" I check the security of the folder and the service account I was using had no rights to the folder. That is why giving it local admin rights fixed it because that group did have access. I gave my service account Modify access to the folder and its contents. After that I was able to start the service. 

which is fine as long as the user is to be mapped to a SQL login. If the login is to be mapped out to a windows login, SQL throws an error when we try to remap: 

...which would suggest a performance degradation if your server cannot offer the resources it requires. Just to clarify, the article above describes local transactions being promoted when remote systems are introduced, but I have seen this become the case for transactions on the same server when using cross database queries. As Thomas Stringer points out in his comment, there will be extra overhead in authentication although I think as this will be SID-driven there will be minimal overhead there unless you have to use separate credentials to access the other database. If there were difference in database settings which caused additional overhead in the join that could impact larger than the previous suggestions - for example database collation. Database collation could manifest as a functional difference, not just a performance difference. I think Aaron has the strongest argument for performance with the optimizer not having the advantage of using relationships for cross-database queries whereas self-contained within a database you could use relationships to your advantage. 

I was having an issue getting SQL Server Reporting Services 2008R2 SP3 working under a domain service account on Windows Server 2008R2. It started with this What am I missing for my SSRS Service account local server permissions? and I have progressed from there some. I have a domain account setup as the service account for SSRS and the service is running. However on the /ReportServer and /Reports pages I am getting page cannot be displayed on my local server. Looking at the logs under "C:\Program Files\Microsoft SQL Server\MSRS10_50.MSSQLSERVER\Reporting Services\LogFiles" I saw two errors 

So it would seem the issue was not the service name specifically but that the request was going to the IPv6 address which was not set up in any of the required files. Looking at listener.log ( which for me was located D:\app\Administrator\diag\tnslsnr\dvp-oracle\listener\trace\listener.log) I found these entries associated to my connnection attempts.