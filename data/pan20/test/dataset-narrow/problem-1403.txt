I am looking for an example site with a Perlin Noise implementation in both CPU and GPU, that generates somewhat the same results in those two places. I see many CPU implementations of Perlin Noise, but they don't match up with the GPU implementations that I found. The reason I need this is for physics. The map is generated with Perlin Noise on the GPU in 2D, but this also means that to do physics, I must have a CPU version of the algorithm that generates the same results. 

Now, physicsTexture is a RenderTarget2D. This texture already has some of its pixels colored by the CPU before it gets set as the render target. So when my pass in the HLSL pixel shader runs, my question is: Can I get the current pixel color of a given texture coordinate using tex2D or something similar on the render target, before drawing a new pixel at that area? 

Due to the order of drawing, borders around the window are drawn after textures, which (for the tooltip that appears when my mouse is over the textfield) makes it look weird. 

I am trying to generate an ellipse outside two points (two-dimensional vectors). Is there a formular for that, or a cool way of doing that in C# XNA? What I am trying to do is have a particle circle around one player and another. 

I'm developing a game where the map is generated with Perlin Noise, but on the CPU. I am generating some perlin noise onto a texture with a small size, and then I stretch it out to the whole screen to simulate a map. The reason for the CPU generating the noise is that I want it to look the same on all devices. Now, here's the end-result. 

I am playing around with the bloom shader from the XNA sample page, to do some glow shading. I am rendering primitive vector-ish squares of linelists/linestrips, on a background. However, I am facing a few problems. With a black background and white squares, I can actually see the squares. However, with a white background and black squares, I can't see them at all. Why is this happening, and is there any way of me fixing it? Can I modify my bloom shader to also "glow" dark elements, if that's what is causing it? 

Which kinds of culling and clipping does XNA do for me as default, and which kinds does it not? Z-culling? Backface culling? etc. 

I've been working on a tower-defense game for some time now, and so far I am really satisfied with the results. However, there's one thing I'd like to add. I've seen a video of GeoDefense for Windows Phone 7 here: $URL$ Notice how (when a unit gets killed or a projectile hits a unit), the background ripples in some kind of wave effect. How can I make an equivalent? I'm thinking that I somehow need to do it in the vertex shader, with a quad made of many vertices. What's your call? Edit It is important to note that my XNA game is not made for Windows phone, but for Windows PCs. 

I would like to know how to get a specific point on the circumference of a circle, given an angle. The diameter of the circle is 1, and the center point of the circle is . 

I am wondering if I can (if possible) make a vertex shader that will always make the pixel shader draw everything in 1 pixel, at position 0,0. I know this sounds crazy, but it's needed in the situation I'm in right now. Let's say that I am drawing a line with 2 vertices that each have the color blue. For every vertex, I tried attaching a TEXCOORD that specifies what pixel I want this vertex to be drawn in. However, I can't get this to work. The reason I am doing this is that I am making experiments where the physics of my game (which is very intensive) is drawn onto a texture, and handled by the GPU. 

I have successfully made a Perlin noise algorithm on the GPU. It works as expected, and generates great results. Now, as part of the physics calculations in my game, I need to replicate the exact same algorithm on the CPU, so that I can (given an X, Y and Z coordinate) determine whether or not that is inside a wall, or a walkable area. I have debugged the shader through PIX, and I've gotten everything almost right, except for the part below (seen in shader code). GPU (shader) code (HLSL) 

But it doesn't disable the multisampling while drawing, because setting "PreferMultiSampling" to true under the presentation parameters when starting the program apparently overwrites this. Or am I wrong? How can I do this? 

I'm using XNA 4.0. How can I load and save settings when on the Xbox? And can I write to and read from files? 

The map itself (the one that is Perlin Noise generated on the CPU) is saved in memory as two-dimensional bit-arrays. A 1 means a wall, and a 0 means an open walkable space. The current tile size is pretty small. I could easily make it a lot larger for increased performance. I've done some path algorithms before such as A*. I don't think that's entirely optimal here though. 

I'm trying to make a quick installer for my XNA 4.0 game which should be able to install silently. I did some research and figured out that WiX would probably be best for me. I don't like the setup projects inbuilt in Visual Studio 2010, and InstallShield LE doesn't have an XNA 4.0 redistributable. So, where can I find resources on how to make a WiX installer for an XNA 4.0 game? I've tried these links, but with no luck. They are targeting a different XNA version, and I want to make sure that a silent install would be supported (while still installing all prerequisites). $URL$ $URL$ 

There's a few things that come to my mind. First of all, the SpriteBatch object is quite large. Is it nescessary to instantiate it for every cube? The same could be said about the VertexBuffer. If the cubes are similar, you can re-use the vertex buffer. As for the effect, again, if the cubes are similar, re-use it. 

And my elements are rendered with the Z-coordinate 0. Edit: I just figured out something weird. If I do not call this spritebatch code above doing my textured quad rendering code, then it won't work on Nvidia cards either. Could that be due to culling information or something like that? 

The white areas you see are walls, and the black areas are walkable. The triangle in the middle is the player. I've implemented physics in this game by drawing it onto a texture (white or black pixels), and then getting that from the CPU. However, now I stand with a different problem at hand. I want units (or creeps, whatever you call them) to spawn constantly, at the edge of the screen. The point here is that in the final game, there will be a "fog of war" that doesn't allow the player to see that far anyway. I figured that I could just scan the pixels at the edge of the screen and see if their physics texture is black, and then spawn stuff randomly there. However, if you take a second look at the screenshot, there is (in the upper-left corner) an example of where I wouldn't want the creeps to spawn (since they wouldn't be able to reach the player from there). Is it possible to somehow have the GPU determine these spawn-spots for me, or some different way? I thought about making vectors between the proposed point at the edge of the screen and the player, and then following it every 10 voxels, and see if a wall collides, before spawning a unit there. However, the above proposed solution may be too CPU intensive. Any suggestions on this matter? Note 1 For the units spawned, I do not want to be using any form of pathfinding to avoid wall collisions as these units run towards the player. Therefore, the units must spawn at the edge of the screen, at a location where walking in a straight line towards the player would not collide with any walls. 

I often develop 2D games. I would like to know if there's a program like EvalDraw out there, that makes it easy to quickly make (for example) a square, out of a black quad, and then write some shader code, and see how that shader code modifies the square in realtime. That would be really great for my future development processes. Edit: The shader tool must work with HLSL. 

I'm rendering textured quads to an orthographic view in XNA through hardware instancing. On Nvidia graphics cards, this all works, tested on 3 machines. On ATI cards, it doesn't work at all, tested on 2 machines. How come? Culling perhaps? My orthographic view is set up like this: 

I've been experimenting with a shader that transfers the small picture on to a texture as a variable on the shader. I got that far. Now I just need it to take that texture using tex2D or something else, and scale it up. How would I do that? 

At the particular area (in the exact same pixel with the exact same seed used to generate the map, where it returns the incorrect results, PIX reports that the GPU returns "{0.035, 0.067, 0.365, 0.408}" from the perm2d function whereas the CPU code returns "{X:0,7450981 Y:0,345098 Z:0,5137255 W:0,09803922}". Other than that, the rest of the functions produce the right outputs. 

XNA seems to be ignoring my Z coordinate. There is no form of Z-culling at all it seems. How come? I am doing an orthographic projection, and clearing the depth stencil buffer for every draw-call. My elements rendered are quads with textures, through instancing. These elements have 1 difference in the Z-coordinate in order to eachother, based on theri Z-index. 

I am looking for a function to generate a random tile-based map as the visual boundaries of the map change (by going through the map). I want the map to be infinitely large, and have maze-like structure. However, if the world is infinite, going back to where a player has already been before raises a problem. The game must remember how everything back there actually looked like. So, I was thinking - "How does Minecraft solve this issue?" and I thought to myself that they must be using some kind of random-number function with a seed, that can both go forward but also backwards, and in that way, re-generate old tiles exactly as they were, but in new instances. What are your thoughts on this? 

I'm trying to load a texture given a swap chain, and then populate that texture with data. I already have some bitmap data (although not sure if it is in the correct format) that I want to populate the texture with. However, XNA's method of the object is obviously not present in SharpDX. What do I do to populate my texture with data? I load the texture using the following code. 

I'm using the tex2D function of HLSL, and I am wondering what will happen if I try to grab a pixel from a pixel coordinate outside of my texture (as an example 1.1). Will it clamp? Will it repeat the texture and grab something else? Will it return transparent? 

Please ignore the bullets and the explosion on the picture. What matters is the background (the black/gray pixels) and the ground (the brown-ish pixels). They are rendered to the same texture through perlin noise. However, this doesn't look very pretty. So I was wondering if it would be possible to double the amount of pixels using a shader, and rounding edges at the same time? In other words, improve the DPI. I'm using SharpDX with DirectX 11, through its toolkit feature. But any help that'll lead me in the right direction (for instance through HLSL) would be a great help. Thanks in advance. 

I'm doing some experiments on my own to improve my general skills with HLSL and so forth. In other words, I'm not doing any serious game development, but only looking to expand my knowledge within the field. I'm trying to figure out how I can increase the resolution of a texture, and multiply it X amount of times. Consider the following low-resolution picture: 

As said before, all this works as expected, until I run the code on the CPU to get the noise data back later. According to PIX, the part that fails is indeed perm2d on the CPU (as seen below), which produces incorrect results. CPU code (XNA C#) 

A typical scenario for me would be to scale up this picture 3 times in the shader without interpolation, and draw the new result: 

I'm looking for pseudo-code examples of the A* pathfinding algorithm that actually works. I tried plenty of different ones where it's not really clear how to implement them at all times. Keep in mind that I'm a newbie, so if everything could be detailed, that'd be great. 

I have a world made by Perlin Noise. It's created on the CPU for consistency between several devices (yes, I know it takes time - I have my techniques that make it fast enough). Now, in my game you play as a fighter-ship-thingy-blob or whatever it's going to be. What matters is that this "thing" that you play as, is placed in the middle of the screen, and moves along with the camera. The white stuff in my world are walls. The black stuff is freely movable. Now, as the player moves around he will constantly see "monsters" spawning around him in a circle (a circle that's larger than the screen though). These monsters move inwards and try to collide with the player. This is the part that's tricky. I want these monsters to constantly spawn, moving towards the player, but avoid walls entirely. I've added a screenshot below that kind of makes it easier to understand (excuse me for my bad drawing - I was using Paint for this). 

There's some issues that I've come across in my Perlin noise-based game. Take a look at the attached screenshot below. 

Learn the math as you need it. That's how I did, and it will "save you time". The math needed depends a lot on the game you are making (whether or not it's 2D or 3D, whether or not it has advanced physics, etc etc). 

I am trying to render some elements in my game. First, I render the textures (the textures of the textboxes themselves etc). Then I render the primitives (borders around controls etc). Then I render the text. However, by doing so, this gives a weird result in my user-interface when showing tooltips (by hovering over a textfield), as seen in the screenshot below. 

permSampler2d samples a texture that I generate out of Color structures and then pump to the GPU. The way I generate the texture on the CPU is the following: CPU code (XNA C#) 

I use this algorithm by doing threshold detection (at specific values, it will generate tiles, at other values it won't). However, the results I have right now are not as I intend them to. I would like more "space" between the "walls". Scaling is not an option, because I like the size of the tiles now. See my attached screenshot below.