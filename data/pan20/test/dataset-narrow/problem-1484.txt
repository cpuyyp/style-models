I think students might fail to appreciate the benefits of TDD if they are working primarily alone. They probably just view it as an impediment to doing the "fun stuff", up-front grunt work they have to do before they can start coding. Even in the real world many developers fail to appreciate the benefits of thinking about testing up front until they've been through a few projects and see the chaos that can ensue when insufficiently tested code gets deployed to upper environments and/or production. In the full software lifecycle, time will be spent identifying bugs and fixing them. If you employ TDD and write test-driven code, you spend the time up front. If instead you just start hacking away, don't test your code, and throw it over to the testing group, time will still be spent finding and fixing bugs. It might not be spent by you but someone, somewhere will hopefully discover your bugs through testing, filing bugs, and fixing bugs. But it's usually more time effective to think about it up front. So while spending time doing TDD may seem annoying, it usually leads to overall time savings from the perspective of the entire project. TDD in my opinion addresses two challenges that are present on almost every software project: 1) It's hard to collect requirements, document them, and turn them into test cases with a sufficient amount of detail that the software can be tested against actual requirements. While it may sound simple, many requirements are identified through conversations, meetings, industry research, ideas, etc. In a team environment, not everyone is aware of every requirement. And usually business people don't make good developers, developers don't make good testers, and testers don't make good business people, but all 3 groups have to work together. And nobody wants to write a super long and comprehensive requirements document and try to keep it up to date, and documentation tends to become obsolete immediately. Test driven development tries to address this by making every developer and team member part of the solution. 2) This last point is probably the most important point, many developers prefer only to do the "fun stuff" which is the coding, and have a tendency to assume that things like testing, accuracy, performance, integration, etc. are "someone else's problem". They can develop a mentality of writing code, doing limited testing, and then checking it in, assuming that someone else will somehow complete it. Some people say that this is the difference between being "done" and "done done". Software needs to be "done done" before it can work correctly but many developers only get it "done". TDD serves to address this problem by introducing a different mindset to the team, to make every developer aware that their code must be tested, and requires them to understand the context within which their code was developed and participate in all aspects of the software lifecycle and not just the coding. 

I know that this might not be the answer that you're looking for but I have been a software engineer for over 20 years and I feel that coding and software engineering is just simply not for everyone. I believe that it takes a certain mindset and interest to grasp and pursue coding and software, and this is more true the more sophisticated the topic. This is not to say that software engineers individually or as a group are smarter than other people, which I don't think is true either. My wife has a master's degree in a non-technical field (I myself have only a BS in CS), and when I try to describe what I do at work her eyes just glaze over. She will sometimes watch over my shoulders as I'm working and all she says is, "wow your job is really tedious!". This is just how it seems to her. I know countless people in the industry who started out as developers and did it for a year or two even though they did not like it, and later moved on into other related positions such as project manager, trainer, technical writer, etc. Doing hard core problem solving 5-10 hours a day dealing with things that are only in your mind and don't exist in the real world isn't something that everyone can relate to. 

I've been a software engineer for over 20 years and over time I have finally gotten out of the habit of taking notes by hand. Part of this is because my handwriting is terrible, and part of it is that I am literally always in front of a computer. I do not find that I retain information any worse when take notes on the computer, and I type much faster than I can write so I can record more information. That said, I am a doodler and a visual thinker and being able to draw pictures and diagrams is important for me to understand, remember and communicate things. It is hard to find good programs on the computer that let you do this as easily as whipping out a pen and paper. At my kids elementary school, they stopped teaching cursive in favor of typing. I think that speaks volumes. If you do let the kids use a computer you will need to lock that down somehow or they will be surfing the web or playing games or texting their friends. 

Given the type of software development that occurs these days, such as on mobile phones and with "big data" technologies, I think concurrency, threading, etc. should be introduced very early. Basically as soon as you start talking about what a program is, how it's invoked or executed, and what happens when it completes, I would discuss all that in the context of a concurrent environment. You don't necessarily need to get into all of the details initially but I would try to avoid teaching new students that all programs are sequential and uninterruptible. 

Break the project up into separate, independent components that must work together and assign each one to a different person or group. This simulates how software is written in the industry. This could be one person doing a different layer of the stack (front end, middle tier, database), or it could be different stacks/services that must operate together (one to authenticate, one to place an order, one to fulfill an order, one to send a receipt, etc). Using contract driven development, the project could start with a spec being defined for how the different parts of the system will operate with one another and then each developer or team would be responsible for their part and no other parts. If you use version control such as git it is also a simple matter to see who checked in what code, and how often. In my experience in over 25 years in the software industry, 80% of the work is usually done by 20% of the people, sometimes even more extreme (90/10 or 95/5). The best developers are not 10% or 20% more productive than the worst, but 10x or 20x. Too many people get good at asking other people to do their work for them rather than doing it themselves. I think it would be great to teach every student to pull their own weight. 

If the students are getting caught up on the difference between a compiled vs. interpreted language (the difference you've described), I would say that they're missing the forest for the trees somewhat. While this is an important difference in the languages, there is a lot more to the comparison of the two besides this. They both have a lot of the same common concepts, especially with the streaming API's introduced in Java 8 which are similar to Python's comprehensions. I think it can be an interesting discussion to understand how two languages that both reduce source code to bytecodes can be different, but in terms of learning to program in both of them that is probably not something that needs to be emphasized. 

I am not sure if your post is a statement or a question. However it is my opinion (after more than 25 years in the software industry) that some topics are just not for everyone, and computer science and programming is one of them. I think it is an admirable goal to strive to teach every student in every class, but a more realistic goal might be to improve each student's understanding in some way in every class. Due to the focus on STEM in schools and the prevalence of software/IT related jobs, I think an idea has emerged that anyone can be a software developer if they are simply taught well and if they apply themselves. I unfortunately don't believe that this is the case. To me it is somewhat like singing or running. Some people can naturally sing in tune and others can comfortably run a few miles at a good pace. You can hold singing or running classes and you can definitely improve anyone's ability to do either. But you aren't going to teach every single person to have perfect pitch or to run a 5 minute mile. Computer science / software engineering is a hard science and in my opinion requires a certain type of thinking, problem solving, patience, and fascination with things that exist only in your mind. It also tends to require long hours of concentrated effort usually working alone. While I believe most people can learn enough about the topic to at least have an appreciation for it, this kind of activity is simply not something that everyone can do successfully. I know many people that I readily admit are far more intelligent than me and have skills that I will never have who are successful in fields such as law, medicine, business, education, and music. Some of them have tried programming or engineering and did not like it which is why they pursued other fields. 

Just like any field, the theoretical aspects of it can be inaccessible and a bit dry, I would say especially to kids this age. AI, automata, and computational theory are often college masters level courses, indicating that not only do you need some years of background in the mechanics in order to appreciate the theory, but you just need to be older and more mature. I didn't get into AI until my 4th year of a BS in CS. While I think kids should come out of classes with more than just coding skills, I don't think they should be expected to necessarily know a whole lot of theory. If you do introduce theory, I think it should be something that they can more easily relate to. For example rather than starting with the high level theory of NFA and DFA you could start with regular expressions, which are an embodiment of NFA's. Once they grasp regular expressions, you can give them a peek behind the curtain and show how they are implemented. Similarly you could start with encryption and cryptography which can serve as an intro to that kind of theory. I think the most applied type of AI these days is machine learning, and that can be introduced by starting with "big data" technologies. Many software engineers go a long way in their careers, or perhaps their entire careers, without an understanding or appreciation for theory. Everyone must at some point grasp architecture, design, and larger concepts than coding but theory doesn't always come into play. 

I have seen people with some background in, but not necessarily extreme proficiency in, programming be successful in the following fields: 

I got my CS degree in the 1990's and at the time (and perhaps still today) there was a lot of crossover between math and CS. By just taking the minimum math requirements to meet my CS degree I was one math class away from a math minor. Subsequently in 25+ years as a software engineer I have never used most of that math, the only math I've actually used is geometry, trig, and probability/statistics. Especially these days with "big data" being a popular topic in computer science, and map/reduce being a primary technique, the concepts of frequency, concentration, correlation, regression, distribution, expected values, etc. are very applicable to problems that you see every day. Also the type of thinking and reasoning you need for stats and probability is much more applicable to real-world problems since it has more to do with estimation, approximation and trends. One of the faults in my opinion with math is that you are often expected to arrive at a single clear and concise answer, when in fact few real world problems are solved that way. Conversely I've never once used all of that calculus (which is a shame because I liked it) and related math. It was fun to take and probably a good (extended) mental exercise and weed-out for students but I think the stats and probability should have been emphasized a lot more than it was. 

Depending on what you are trying to teach, Java has a very extensive and comprehensive open source community, and one way to introduce students to this is to come up with a technology "stack" which will probably be made up of 5-10 different open source technologies. You could either start from scratch and introduce one open source technology after another to build up a full working application, or start with a partial project and add new technologies to it. A typical stack is a database such as MySQL, an application lawyer such as Spring, and a front end / HTML technology such as Angular. This kind of application might be more accessible to students because they'd be writing a web application that they can view in their browser. 

I think it depends on what the goals for the course are. You are teaching an intro programming course, so what are the students expected to know when they finish? Data types and structures, loops, functions, syntax, etc? If so you don't need to teach web development skills as part of this since arguably HTML, CSS, etc. are not really "programming" in the computer science sense. Also the technologies and languages available in web development are lightweight and limited compared to back end technologies and so using them to teach programming concepts is like teaching someone to cook using prepared food. It has been said that "Java is to JavaScript as ham is to hamster". However, basic text-only coding can be boring and may not be very accessible to many people. The advantage of front-end technologies is that they are literally visible and people can see the results of their programming efforts as something besides text in an editor. Also if the goal is to provide people with the shortest path to a possible job, it is probably far easier to teach them the basics of web development than it is to teach them true software engineering and computer science concepts. Which isn't to say that these concepts are always needed on a job.