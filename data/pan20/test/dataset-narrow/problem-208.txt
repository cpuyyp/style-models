I have a SQL Server 2008 R2 SP2 test server that I have to refresh the databases on fairly often, but every time I have to do a restore on, it will hang on me. I use a custom script to check the progress of where the restore is at, and it hangs at various times. One time it may complete 56%, the next time 64%, the next time 17% and so on. It does not stop at consistent times. And when I say that it hangs, it just stops writing. As far as SQL Server is concerned, the restore is still running though. So its like it still doing its thing, but nothing occurs. If you leave the restore running without killing the process it will run forever. I have let it run for 12 hours before with no progress Eventually, I can get the restore to complete after trying again over and over, and eventually it will go one time and finish. But it takes what should only be an hour, and turns it into 5 hours of constantly retrying. So here is some information on the server - It is a Virtual Machine, Windows Server 2008 R2 Standard, SQL Server 2008 R2 sp2 Standard, 32 GB RAM, 4 Proc Here are the database sizes that are the problem. While not really, they are not overly large either. Database A - 71 GB, Database B - 11 GB, Database C - 27 GB Here is what I have done: I have checked all the logs (SQL Server and Windows) to look for any errors or any messages that looked suspicious. There is nothing. I have tried to run the restores at nearly every hour of the day, but it does not matter, it will hang at any point. I have tried dropping the databases\deleting the .mdf & .ldf files and recreating the databases and then restoring, still get the issue I have traced the restore to see if anything is occurring. Nothing. I have made sure all connections where killed before starting the restore. Also, have placed the databases in single user mode before starting the restore. I have no problems restoring the exact same backups on other servers, so no issue with the backups Storage guys looked at the datastore\LUN and checked NAR files and said everything looked good. They also migrated the vmdk to another LUN, but we still got the issue. Storage guys sent the NAR files from the Array to EMC for examination and they say no issues with the storage VMWare guys looked at the Virtual Machine and saw no issue with it. I also disabled all the Anti-virus software and then tried it again, still will hang I have ran the restores using the GUI, writing out the script, and using custom scripts, same result Ran a repair on SQL Server Nothing unusual when looking at the Wait Stats. Shows same thing as you would see when doing a successful restore. Any thoughts on anywhere else to look or possible reasons here. Or any tracking or counters that you can recommend to pinpoint the issue. My thoughts are an issue with storage or the server, but the Ops guys are adamant there is no issue with either of those. Also, rebuilding this server at this time is NOT an option. Even though it is Test, it is part of a farm of servers that makes up a Claims environment. We will eventually rebuild this entire environment later this year, but it is a large undertaking. The next step is getting on the phone with Microsoft, but waiting on the Ops guys to take one more look. So thought I would check here. Thanks for your help! 

I'm working on a custom application that needs to determine changes to a particular column, on particular rows in our database (MS SQL 2008R2). When the row is created a created & modify timestamp are inserted. Anytime any of the columns change, the modified timestamp is updated. I' need to be able to fetch all the records where one particular column was changed between the time my application last ran, and now. Further more, i really only care if this one particular column value changed from a "N" to a "Y". I want to do all this, without altering the DB schema, or using triggers due to their overhead. My research led me to Change Data Capture, would this be a good use case to use Change Data Capture? Is it possible to limit the overhead on CDC to an item only changing to a specific value, my table has approx ~200k rows, with 300mb in index and 200mb in data, and rows are heavily modified, so i'm concerned about the amount of data that will be captured. The only alternate approach that i am aware of, is to capture the parent event (row created) in a separate audit table, and then compare it to the original table each time the application runs to surmise the change, is there an advantage to doing it this, or is there any simpler way to do it? 

The issue is you're restricting on the instance field, which is resulting in the roles only appearing in one column or the other. To get around this, remove the restrictions on and the roles from the second database to the roles in the first, like so: 

Trick question! The answer is neither. Sure few_vals is a long string. So you can get good compression out of it. And you (might) get an index skip scan for the queries using (few_vals, lots_vals) that only have predicates on lots_vals. But I don't here, even though it performs markedly better than a full scan: 

Your view has to apply some form of function to start and end dates to figure out if they're the same year or not, so I believe you're out of luck with this approach. Our solution to a similar problem was to create materialized views over the base table, specifying different partition keys on the materialized views. We've tailored ours to match common base queries so that we get query rewrite benefits as well. You may need to get users to use the MVs directly to ensure you get the partition pruning working as you need, rather than relying on query rewrite. (Updated to remove incorrect example and add info regarding applying functions to partition columns) 

I'm interested in using Zapier to automate some processes that should be fired upon certain records appearing as the result of a custom query. Zapier seems to be a good tool as it can do things based upon said query. In this case i need to fire off some data to a webhook, and then update the original record. I could build this out myself, but why re-invent the wheel? What am i concerned about is their security. Their documents require you to open up port 1433, and whitelist their IP address, then supply a username and password to them that they use to connect. As long as our security is configured properly: 

I have a SISS package running on MS SQL Server 10.5. The package runs on a schedule through the SQL Server Agent. I had to drop and recreate the package task. After i drop and recreated the package task, i reconfigured the package to include the password in the connection strings. Now when i run the package i'm seeing this in the log files: 

I'm worried about this security, my solution was setting up a simple Azure DB, and using Azure DB Sync to replicate the tables from the onpremise database to the azure cloud DB, and then have zapier connect to that. Azure Sync seems to be a bit more secure in the way it transports data. Am i just complicating my life without actually increasing security? Is there a better way to do this? 

If you do this without ROWDEPENDENCIES they will come out with the same ORA_ROWSCN because the rows are on the same block: 

So it's unlikely to be worth indexing on its own. Queries on lots_vals return few rows (just 1 in this case). So this is definitely worth indexing. But what about the queries against both columns? Should you index: 

If this returns anything, move the objects to another tablespace if you want to keep them before dropping the tablespace. 

1: In some cases it may be worth including a column in an index if this means all the columns in your query are in the index. This enables an index only scan, so you don't need to access the table. 2: If you're licensed for Diagnostics and Tuning, you could force the plan to a skip scan with SQL Plan Management ADDEDNDA PS - the docs you've quoted there are from 9i. That's reeeeeeally old. I'd stick with something more recent 

Note the ORA_ROWSCNs are the same in the second example. You can't index the ORA_ROWSCN, so filtering on this will result in full table scans. If combined with filtering on an insert timestamp you could overcome this however (which should also help prevent updated rows appearing, if that's the behaviour you want)