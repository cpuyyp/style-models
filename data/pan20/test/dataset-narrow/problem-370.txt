I am running an old production application which has a backend DB hosted on SQL2008R2 in Compatibility Mode 80 (SQL2000). When I run bits of TSQL to view actual execution plans SSMS is giving me suggested indexes which are only legal for SQL2005+ e.g. ones with included columns. How can I prevent it from doing this? I would like to view sensible indexes it might suggest. NB: The Compatibility Mode can't be changed. Yes we are replacing the application, this will remove the need for the DB entirely but not for some time. NB: Already tried, SSMS is configured "Script for server version" as SQL Server 2000. 

I'd have a table sit between users and messages with a one-to-one many relationship to both. Call it users_messages for example. Each row in users_messages would describe all the users who have an involvement in any particular message. For example if a message had 3 users involved then the table would have 3 rows for this. Each row linking to the same message but linking to a seperate user. When a row in users_message is deleted/deactivate you could check if any active entries for that message still exist and if not delete that message. Edit: Missed the 2-user requirement but this is still valid and more future proof. 

There is a further method that will give output in a single semi-merged result set. First open Registered Servers and create a new group under Local Server Groups then register your server once for each DB, in each case setting the default DB to the one desired. Once complete right click on your group and select New Query. The query window that opens will have "multiple" where you would normally see a server name on the status bar. Any queries run in this window will operate on each registered server that was in the group. The first column of the results will be the name of the registered server. The result set will be fragmented by that first column and order by wills only operate within that fragment. Very powerful but overlooked piece of functionality for when you routinely have to run the same SQL on multiple servers. 

Possibly the ANSI 92 definition held at $URL$ gives the answer. Section 3.1 Definitions seems to draw a distinction between the idea of a result set and a result sequence. The distinction was not in my awareness when I wrote the question using the former phrase 

Create a new computed column on the underlying table that is an RTRIM of the column in question. Add an index on this column. Adjust the view to use this computed column. 

Where databaseName is somehow set at a server level. I understand synonyms are the wrong solution for this. Is there something similar we can use that doesn't include writing a synonym for every single object? 

My scenario is I look after an old system with a VB6 based front end and a SQL back end (good news, the replacement is being developed but in the meantime I need to keep this up). Now the application is used at a dozen or so sites most of which are on SQL2000, one is on SQL2008 and one on SQL2008R2 (all Standard). Changing versions/editions would be a big ask. The one hosted on SQL2008R2, as it happens, is also the largest site. We now have a table with over two billion rows and 700GB of data. It's a small number of columns, one being a 256 char varchar used to store serialised blob data. This is now of a size that when people try to insert, delete and update to it (via the app) users occasionally lock each other out. This can only get worse as time goes on. Also however, the next largest is on SQL2000.. I need to get the size of this table down. What are some methods or techniques I could use to achieve this? Ideally the technique would be compliant with SQL2000 Standard edition so I could use it at all sites. However just fixing the biggest offender on SQL2008R2 Standard would be something. The table does have an identity column and as the table definition is controlled by the app this can not be changed (I mention this as I believe this rules out a partitioned view- the rows are INSERTed, UPDATEd and DELETEd by the app). My current thought is to delete all data past date X months in the past (50% of total) and hive it off to a table not exposed to the user or the app. Then in the app I can put a method for a user to request items of data to be copied back across and this would be done via a scheduled job (overnight possibly). This feels clunky to me however. 

I'm dealing with a 3rd party app that I can't change or get support on. I've altered an underlying table in several ways to enhance it's functionality 1- I renamed the table PRE_CASE to PRE_TCASE 2- I created a view named PRE_CASE which is a select on to PRE_TCASE with a UNION ALL on to a linked server DB and table named OTHERSYSTEM_CASE This works to the extent the app is now fooled into displaying data from PRE_TCASE and OTHERSYSTEM_CASE to the end user when it believes it's looking at the table PRE_CASE. It fails however on inserting data. To try and fix this I created a trigger (I only require to insert to PRE_TCASE, never OTHERSYSTEM_CASE) 

Then it will work, the 0 will be ignored and an identity value generated. But as the question scenario states the insert statement is set in stone by the 3rd party executable then it is unworkable. 

The boss has asked for a list of DB names along with size and name of last person to use that DB. I've found resources for when a DB was last accessed but for by whom. How would I solve this? SQL2008R2 being used and so far I have this: 

You're probably looking at needing an OUTER JOIN instead of the implied INNER JOINs that you're using. e.g. suppose 

So the best result I've managed to come up with is adding the following improvements - optimising the queried table (creating a new temporary table with suggested indexes) - adding a path element to check I'm not revisiting an existing part of the path - adding a depth counter as a limiter. This does however mean I'm consciously choosing not to have the full result set 

Or you could compare the length of data against the length of data when '"' is replaced with an empty string (''). 

I would like to move the tables in my database from one filegroup (Primary) to a another (a new one). I can find lots of advice on this concerning tables with clustered indexes but all these tables in question are heaps. So far I implemented the solution found here: $URL$ which essentially provides a script to create a clustered index for the table on a secondary filegroup (which essentially moves the data) then removes the index to return it to being a heap. This seems to work fine but may be too slow for our production requirements. Are there any alternative solutions? This doesn't feel quite elegant enough for me to believe as the only method. Note1: The tables must remain heaps. A 3rd party app enforces this. Note2: The DB is about 150GB in size across 200 tables. 197 tables and 99.9% of the data will move to the secondary filegroup. 

In looking at a historical SQL Agent job on my employers server I noted a job with 4 steps. The Databasefield was set as master for the step 1 and not set at all for the other 3 steps. Yet each of those 3 steps contained simple SQL statements (exec SPs, inserts etc.) that all worked on a specific database. When I scripted the job out to a query window each of those 3 steps had the element: 

At our organisation we have several non-Production environments where Developers run free and wild with TSQL code and databases. The DBA team do not normally monitor or maintain them. Recently several developers using one server have had to write procedures that throw around mountains of code such that their log files are growing to 10-20GB (on DBs approx 15-40GB) until they run out of space on the drive volume we have provided for the log files. The databases are all in Simple recovery mode and backups are (almost) never taken. As a bandaid I've created a SQL Agent Job that can be run by anyone to shrink all user log files on the server. What are some valid Log File Management strategies that might be used? For example it is my understanding that as the users generally do a blitz of intensive work that checkpoints are probably being throttled back and that thus issuing manual checkpoints would see no advantage. Is that the case or should we in fact investigate adding manual checkpoints to their code? And just to be clear it is log file space on disk we are interested in not space within the log file. 

If we have code in an SP Database1 then queries Database2 (on the same server) we want the same code to work on the databases Database1Dev and Database2Dev. But this currently means editing the full SP each time we push to Live. We want a single of line of code such as 

The initial purpose of this data is "fluffy", I'm generating a graph-map out of it to show our workflows so a limited depth is fine in the first instance at least. But better answers accepted if anyone has any 

Whilst reviewing code on a SQL 2008R2 Instance I inspected the Date Last Modified of the System Stored Procedures of the databases. The ones in the DBO schema had a datetime that predates the installation however the ones in the dbo schema come later than the installation date. Specifically the machine was built December 2013 and the date of these SPs is 09/07/2014 17:16 (both for Date Last Modified and Create Date). The DB in question was also created December 2013. Now I assume this was something benign, but how can I understand and determine what caused this date stamp? I've checked the Windows logs but can't find any installations going on at that time. 

No value/reference is made to the ID column. On the underlying PRE_CASE the column ID is an integer primary key (PK, int, not null) with a valid identity seed. Direct inserts onto PRE_CASE work, but not ones onto the new view and trigger. What have I overlooked? (My end solution will be deployed onto SQL2000, SQL2005 and SQL2008R2 boxes, but I'm testing/developing on SQL2000) Edit: I created this model to test in a more isolated way. Turns out the error occurs on SQL2000 and not SQL2008R2, personally I'm giving up at this point. 

This is my current answer in my environment. This works for me as the greater script this is a part of runs on a daily basis. It does feel like a better answer or explanation should be available. 

Is it possible in SQL Server to set collation on individual rows in a table (as opposed to by column, database or server)? If not, perhaps does anyone know if this is a planned feature for SQL Server 2016? The only problem this solves is curiosity between two colleagues. 

If you wanted them randonly side by side you could use an adhoc ID value. If there are different numbers in each table then some will appear at the end without a partner. 

To understand this error you need to understand that the SELECT is actually being parsed last. At the time WHERE is being parsed the SELECT statement hasn't been run and so valid_license has not been set up as an alias/computation. Discussed more here: $URL$ or google Logical Query Processing 

In my current work position I've been given a desktop with SQL2014 tools installed including SQL Profiler. For some time we are still however supporting production SQL2000 machines and when using Profiler against these the following error is received: 

My question is would this ever create two identical values for the Date? Does this answer change if parallelism is in use? (Assume value never specified, always comes from GetDate()) I believe I'm correct in assuming it wouldn't matter due to the behind-the-scenes uniqueifier being added, right? But I'm interested anyway. I'm asking from a SQL2008R2 perspective but would be interested if the answer differs for any version of SQL Server from 7.0 up. 

I would like to know if there are any dangers or relevant precautions before changing the IP address of a SQL Server 2008 R2 box. We have built a virtual PC with Windows Server 2008 R2 and SQL Server 2008 R2. The purpose of this machine is run a job that restores a backup file (copied by a different server), manipulates it, backs it up again and then copies it out to other servers. We've run it a few times in our test/dev DMZ and are now considering deployment. The simplest option would be to re-IP it. The server name would remain intact. My problem is a colleague has suggested this is unsafe (to re-ip a SQL Server). My question is a) Is this true for the OS and SQL I'm using? (Win 2008 R2 & SQL 2008 R2?) b) Is it true for any other combinations of OS and/or SQL? c) Is there anything special we should do in preparation? My research thus far indicates it will be fine but I trust the folks of DBA StackExchange more than those social MSDN people. $URL$ $URL$