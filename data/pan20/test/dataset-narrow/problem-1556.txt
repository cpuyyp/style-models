Based on my experience you can almost do everything that can be done using pandas in your sql. I've not seen recent versions of pandas but I remember that sql is even better because using pandas you are restricted to the size of memory. If memory fills out you may crash, something that does not happen using sql commands. You can save your pandas data frame in a file and manipulate that file using your sql. This link and also here may help you. Also for importing your file to your sql, you have not specified what sql you have but this link may help you. Other sqls also provide this behavior. 

Maybe reading papers is a bit hard, because they usually don't explain everything. I suggest you watching deep learning specialization by professor Andrew Ng, which is brief and easy to figure out. If you insist on reading papers, this three sequential articles may help you. Choosing neural networks highly depend on your task. For most computer vision tasks convolutional neural nets are used. You can also take a look at here which contains different resources and discussions and many other useful stuff. 

We use freezing to employ transfer learning. Deep learning has a great hunger for data. In some tasks you may not have so much data, but there may already be a pre-trained network that can be helpful. In such cases you use the model and its weights and by replacing the soft-max layer, in situations where you have small amount of data, you try to customize the network for you specific task. If you have more data, the more number of layers can be trainable. Take a look at here 

It uses same padding which means the output of max-pooling is padded with zeros in a way that the output of next layer preserves the width and height. for information take a look at here. 

Based on the answer here and the blog post here there are two variants for using bias in convolutional layers. Tied biases if you use one bias per convolutional filter/kernel and untied biases if you use one bias per kernel and output location. 

After training, your learning algorithm has learnt to deal with the data in scaled form, so you have to normalize your test data with the normalizing parameters used for training data. 

In deep learning context different methods are for dealing with the problems which may happen during training such as high bias and high variance problems which have their own specific solution. Drop out is for dealing with over-fitting problem. In that case, it means that you've memorized some data very well but your model cannot generalize well. If you are familiar with learning curves, increasing sample size does not affect when you have same error rate for training and testing. Increasing the sample size can help. Suppose that your classifier has flexibility to learn complicated shapes and your training data may not be completely representative of the real distribution, by increasing you can have better performance. The other solutions are using regularization techniques or drop-out and maybe batch normalization for some extent. By the way increasing data may have cost. Consequently I suggest changing drop-out hyper-parameter first. 

It should be considered that adding noise to the input should be without changing the distribution. The ratio of signal to noise also should not be small because the information may be lost compeletely. Depending on your problem each of them make work well but I guess there is no consensus which one is the best but in deep-learning the first one is so helpful. 

Ensure that your output vector for training and test data is exactly what you need, continuous for each element of output vector. Use what you said and familiar for the layers before the last layer. For the last layer use a dense layer with n, number of outputs, outputs each having linear activation, y = x. 

It does the normalization, reducing mean and dividing by standard deviation, and more things like . So it seems that you don't need to do normalization. That method does that, and normalizing features is required for accelerating training process and caring about all features with different scales the same. 

Actually I guess the question is a bit broad! Anyway. Understanding Convolution Nets What is learned in tries to minimize the cost function to categorize the inputs correctly in classification tasks. All parameter changing and learned filters are in order to achieve the mentioned goal. Learned Features in Different Layers They try to reduce the cost by learning low level, sometimes meaningless, features like horizontal and vertical lines in their first layers and then stacking them to make abstract shapes, which often have meaning, in their last layers. For illustrating this fig. 1, which has been used from here, can be considered. The input is the bus and the gird shows the activations after passing the input through different filters in the first layer. As it can be seen the red frame which is the activation of a filter, which its parameters have been learned, has been activated for relatively horizontal edges. The blue frame has been activated for relatively vertical edges. It is possible that learn unknown filters that are useful and we, as e.g. computer vision practitioners, have not discovered that they may be useful. The best part of these nets is that they try to find appropriate filters by their own and don't use our limited discovered filters. They learn filters to reduce the amount of cost function. As mentioned these filters are not necessarily known. 

I have a suggestion for you. Maybe not complete enough to be a complete solution but that is exactly what I've experienced. Suppose that you have writings in a paper and the paper is a part of a scene, or you have boys with nice mustaches which are beside a wide scene. In such cases which you have special information which are significant for classifying, the first one may help the classifier recognize book and written things and the second one can help the classifier find the gender of people in the scene, try to resize the images in a way that such significant things be recognizable to the human. If humans can understand them, you can hope that your classifier will be able too. Consider that you shouldn't resize the images to small pixels to avoid your net being with lots parameters. If you resize the images to too small ones, you may loose important information. 

It plots the scatter plot of each feature separately and together. It is like the correlation matrix. You can take a look at here. 

I suggest you using the pre-trained model and freezing all the convolution layers. You should just train the weights of your dense layers in this situation. So use and freeze the convolution layers and replace the dense layer with your desired one and also the last layer which is . The reason is that the image-net already can find the features of a basketball play very well. You just need to classify each game. If you want to see an explanation, read this paper. 

You can take a look at here. You can also use if your task is sequence classification, but based on comments you have referred that your task is unsupervised. Actually, can be used for unsupervised tasks too depending on what you want. Take a look at here.