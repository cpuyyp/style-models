Once you have the bound $2^{2n^2}$ on the number of classes, you can note that each state in the complement automaton corresponds to an $\omega$-regular language of the form $L_{f}L_{g}^\omega$, with $L_f$ and $L_g$ being functions from $Q$ to $2^Q\times 2^Q$. Each such language is determined by $L_f$ and $L_g$, and there are $2^{2n^2}$ options for these functions, so you get a total of $(2^{2n^2})^2=2^{4n^2}$ options. UPDATE FOLLOWING COMMENT: The correspondence of the number $2^{4n^2}$ to the states of the constructed automaton is not exact. Observe that for every language $L_f$, we can construct a nondeterministic NFA $A_f$ (as is done in Theorem 1 in the Wikipedia link you posted). Moreover, the size of $A_f$ is polynomial in the size of the original NBW $A$. Thus, the size of an NBW for $L_fL_g^\omega$ is polynomial. You then take a union of $2^{4n^2}$ such automata, and obtain the complement NBW, so the size of the complement NBW is: $$2^{4n^2}\cdot poly(n)=2^{4n^2 +\log poly(n)}=2^{O(4n^2)}$$ So it's a little less tight than $O(2^{4n^2})$, but it's still only singly exponential (perhaps there is a tighter analysis, but I'm not aware of one). 

I encountered the following question, which is an easy exercise (spoiler below). We are given $n$ instances of the halting problem (i.e. TMs $M_1,...,M_n$), and we need to decide exactly which of them halt on $\epsilon$. That is, we need to output $\{i: M_i\text{ halts on }\epsilon\}$. We are given an oracle for the halting problem, but we have to use it a minimal number of times. It is not hard to show that it can be done with $\log (n+1)$ calls. 

In light of Stephen Hawking passing away today, I was wondering whether any of his results have direct impact on cs? The obvious candidate would be in quantum computing, or rather the construction of a physical quantum computer, but perhaps there are results that have other impact. I am familiar with his work only on the popular-science level, so this is not really a research-level question, but perhaps it has research-level answers. EDIT: following the answer, I don't mean his recent concerns about AI. That is not really a contribution to CS, more of a philosophical/sociological point. I aim more for mathematical results, or connections of physics to computing. 

Depends what you mean by "class". I don't know of any natural class that satisfies that, but certainly one can do the following: Consider the set of languages that are decidable in time $2^n$ (exactly, not just any exponential). This is strictly contained in EXP by the time-hierarchy theorem. Take the union of this set and PSPACE, and you have a class that strictly contains P (again, time hierarchy), contains PSPACE, and is contained in EXP (and presumably, if PSPACE$\neq$ EXP, then there is also strict containemnt here). 

As TAs in an undergrad course on computational models, every year we are faced with a dilemma of what material to teach in the last few weeks of the course. To be specific, our typical syllabus is as follows (basically the first few chapters of Sipser): 

There is even a stronger result than your request: There are exponentially-ambiguous NFAs for which the minimal polynomially-ambiguous NFAs are exponentially larger, and in particular the minimal UFAs. Check this paper by Hing Leung. 

This concept is called the ambiguity of the NFA. Typically, there are 3 classes of ambiguity in this context: Bounded, polynomially bounded, and exponentially bounded. Every NFA has at most an exponential number of runs on a given word (this is easy to see). Interestingly, there is a simple syntactic characterization of polynomially bounded NFAs: An NFA has a polynomial number of runs on a word $w$ iff for every state $q$, there is at most one cycle from $q$ to itself on every word $x\in \Sigma^*$. See this for details. Testing for bounded ambiguity is PSPACE-complete. A good starting point is this paper 

The answer is yes. To prove this, consider the complement language: $$\{w: w\notin L(A) \vee \exists x: h(x)=h(w)\wedge x\notin L(B)\}$$ Now, we construct an NFA $C$ as follows. Given a word $w$, $C$ has $\overline{A}$ as a component, such that if $w\notin L(A)$ then $C$ accepts. It remains to check the rest. Let $D$ be a DFA that recognizes $\overline{B}$. In order to check if there exists a word $x$ as described, $C$ guesses (i.e. has a nondeterministic transition), for every letter $\sigma$ of $w$, a transition in $D$ that can be taken with a letter $\tau$ such that $h(\tau)=h(\sigma)$. The accepting states of this component are those of $D$. It is not hard to prove that $C$ accepts the language above, and by complementing it you get an automaton for your desired language. 

Well, this is not exact. Clearly there exists an irrational number that contains all patterns - simply concatenate all finite patterns (e.g. in lexicographical order, from shortest and up) However, not every number contains all these patterns. Indeed, you can construct an irrational number by concatenating the binary sequences "000" and "111", which will give you a very limited set of patterns (albeit infinite). Also, your question seems to assume that if a number contains all possible patterns, then it is also computable where each pattern starts - this is most likely untrue, unless it is a very specific number (e.g. the one described above). A somewhat related idea is Chaitin's Constant, perhaps you will find it relevant. Also, observe that the term "quickly calculate the decimal sequence" is not well-defined. You cannot calculate in the sense of writing it down, as it is infinite and might not have a finite representation. What you can ask is for an algorithm that gives the $i$-th digit, in time polynomial in $i$ (or indeed, just that the $i$-th digit is computable for every $i$). The link above demonstrates a number for which it is provably impossible. 

Note that this problem has some resemblance to the matrix mortality problem. Thus, it may be the case that determining whether a certain vector is reachable is undecidable. Example of when such vectors are meaningful: consider a semantics for a weighted NFA where there are weights on the edges, and the value of a word is the sum of the edges along all the runs of the NFA. In such NFAs, the state in the middle of a run is captured by such a vector and the accumulated sum along the run so far. 

Take a look at the following paper: Relating hierarchies of word and tree automata. They cite the result you are interested in. As a more concrete answer, consider the following argument: let's look at the language $M_n=\{w\in \{0,...,n\}^\omega: \limsup w_i \text{ is even}\}$ (the same as your language with $i=0$), and assume it has a parity automaton $A$ with ranks $1,...,n+1$ (note that proving it doesn't have a parity automaton with ranks $1,...,n$ is not enough, as it's still possible for it to have ranks $0,...,n-1$). We will construct a word that is accepted by $A$, but is not in the language (or vice-versa). Denote by $k$ the number of states in $A$. Consider the run of $A$ on the word $0^\omega$. It's accepting, so the limsup degree is even, and so at least $2$. Moreover, it must occur during the first $k$ steps, otherwise, since $A$ is deterministic, we have a non-accepting cycle. In addition, this is true for every $0^k$ infix of any word. Now, consider the word $(0^k1)^\omega$. This word is not accepted, so the limsup degree is odd, but must be at least 3, since the $0^k$ infixes induce the degree $2$. Finally, this odd degree must occur within the first $k$ cycles of $0^k1$, for similar reasons as above. We can repeat these alternating examples, constructing a word of the form $(0^k1)^k2$, and so on, with each word requiring a higher degree. However, since we only have degrees $1,...,n+1$, then eventually we will have a word that uses the letters $0,...,n-1$, whose limsup degree is $n+1$. From there, continuing this construction will still leave the limsup degree $n+1$, but will change the word from accepted to non-accepted, or vice-versa. In either case, the automaton fails to recognize the language.