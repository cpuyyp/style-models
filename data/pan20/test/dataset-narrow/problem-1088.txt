If the above definition is not recursive, then it is really a shorthand for (I am switching to OCaml notation to make things a bit less ambiguous): 

It just so happens that $=$ on reals is not classified by a map into $2$, but it is classified by a map into $\Omega_{\lnot\lnot}$. So in principle one could implement equality as a map which always returns the unit . That's useless. Perhaps $=$ is classified by a map into a smaller part of $\Omega$? Yes, it is a theorem that inequality $\neq$ is classifed by a map into $\Sigma$, so we can do better and implement $\neq$ as a map which takes (realizers of) two reals $x$ and $y$, and returns a map which attains iff $x \neq y$. But this is actually a very sensible thing: tests and for inequality "up to precision ". That's how people actually implement exact real arithmetic. I think a lot of confusion arises from the fact that people speak about "computable" relations without telling us wha that means. And when they do, they usually end up defining decidable relations. But that's just a very limited view of relations. There are semidecidable relations, and $\Pi^0_2$ relations, and arithmetical relations, etc. 

The computation of the fundamental group of the circle. Development of category theory, as you observed. The definition of cardinals is conceptually clean and well-motivated when we use truncation to define them, see chapter 10. Some homotopy-theoretic theorems, such as Blakers-Massey and the Freudentahl suspenion theorem. 

Sure, category theorists know such things, but I think for the difficult results that graph theorists care about, the generalities of category theory may at best help as an organizing principle. This is a bit similar to the theory of combinatorial species, which is a way of doing combinatorics inspired by category theory. Here are some other basic observations, you can read more about such things in Lawvere's Qualitative distinctions between some toposes of generalized graphs, Categories in computer science and logic (Boulder, CO, 1987), volume 92 of Contemporary Mathematics, 261â€“299. American Mathematical Society. The category of directed graphs is a presheaf topos on the site consisting of two parallel arrows (so that a presheaf is given by two sets $E$ and $V$ and maps $t : E \to V$ and $s : E \to V$), see A Guided Tour in the Topos of Graphs by Sebastiano Vigna. For any given $n$, the category of $n$-colored graphs is a topos, because it is just the slice of the topos of graphs over the complete graph on $n$ vertices (an $n$-coloring of $G$ is just a morphism $G \to K_n$). As Lawvere explains, several other categories of graphs are toposes because they are (equivalent to) toposes of monoid actions for a suitably chosen $M$. Let's just do one. Consider the monoid $M$ of endomaps on $2 = \{0,1\}$. There are four maps $2 \to 2$, we give them names: the identity map $i$, the constant map $0$, the constant map $1$, and the twist map $t$. An object in the topos of $M$-sets is a set $S$ with a right $M$ action, which is a map $s : S \times M \to S$ satisfying $s(x, i) = x$ and $s(x, f \circ g) = s(s(x, f), g)$. Since there are only four elements in $M$, we might as well figure out what this means. Let $S_0 = \{x \in S \mid \exists y \in S \,.\, x = s(y, 0)\}$ be the set of those elements of $S$ that arise as actions of~$0$. We define $S_1$ similarly. Because $0 \circ g = 0$, it follows for every $g \in M$ and $x \in S_0$ that $$s(x, g) = s(s(y,0), g) = s(y, 0 \circ g) = s(y, 0) = x.$$ So, the elements of $S_0$ are fixed by the action. Similarly, the elements of $S_1$ are fixed by the action. To every $M$-set $(S,s)$ we associate a graph $G_S$ as follows. The vertices of $G_S$ are the elements of $S_0 \cup S_1$. The half-edges of $G_S$ are the elements of $S$. Given a half-edge $e \in S$, its source is the vertex $s(e, 0)$. The opposite half-edge of $e$ is $S(e, t)$, and because $t \circ t = 1$, tit follows that the opposite of the opposite is the original half-edge. An edge is a half-edge together with its opposite. The target of a half-edge is the source of its opposite half-edge, i.e., the target of $e$ is $s(s(e,t),0) = s(e,1)$. (There is an anomaly which we allow: a half-edge may be its own opposite.) What sort of graphs did we get? They are symmetric graphs in which each edge consists of two half-edges. An edge may be degenerate when it is composed of two copies of the same half-edge. In addition, the graphs are reflexive in the sense that each vertex has a distinguished degenerate loop starting and ending at the vertex (this is because $S_0 \cup S_1 \subseteq S$). Exercise: figure out what the morphisms are, and then show that the description in terms of reflexive symmetric graphs gives a category that it equivalent to the topos of $M$-sets. Is this the sort of thing you were asking about? 

Algebra in the classical sense of the word is used in modeling of computational effects as algebraic operations, see for example these slides by Gordon Plotkin, or you can read real papers and Ph.D. theses, if you actually meant to ask the question. And to blow my own horn, have a look at Eff and read about it, a language designed around the idea that computational effects are algebraic operations and that handlers are homomorphisms of algebras. 

Caveat: I am doing all this under the assumption that we are working in a fragment of Scheme which is purely functional (no side effects other than divergence). 

You are touching on some very interesting basic questions about mathematics in general. Do we construct mathematical objects and later discover their structure, or do we construct objects with a specific structure in mind? I think the answer is not simple. Sometimes we "design" structures to order, and sometimes we discover them. I believe the quarternions were discovered, but at the same time Hamilton knew what sort of structure to look for. So I think your observation that we discover the structure of the objects we constructed has a lot of merit. But why do we discover some objects and not others? What makes the ones we pay attention to important and interesting? Presumably their structure. Let me clear up something about equality versus addition. They have exactly the same status. The reals are equipped with equality, which is a binary relation, and they are also equipped with addition, which is a binary operation. We make no assumptions about equality being decidable, or not decidable, and neither to we make any assumption about addition being computable. We just state the axioms for the reals: they form a structure consisting of such-and-such relations and operations, satisfying such-and-such axioms. Then we ask whether such a structure exists in our (realizability) model. If it does, then we have an implementation of its parts. Addition is implemented by a program which takes realizers for two reals and computes a realizer for their sum. But how is equality implemented? Equality is a binary relation, which is just a predicate on a cartesian product. So we might as well think about how to implement a predicate on a set. Well, there are two views of predicates. The first one is that a predicate $P$ on a set $X$ is just a subset $P \subseteq X$. The second one is that it is a map $P : X \to \lbrace 0, 1 \rbrace$. In intuitionistic mathematics, we have to replace the booleans $\lbrace 0, 1 \rbrace$ with the set of all truth values $\Omega$, which is much larger. In fact $\Omega$ is so complicated that it does not exist in the simple realizability models (although it exists in a realizability topos), which is a fancy way of saying that it cannot be implemented (feel free to have a go: implement the initial complete Heyting algebra; mind you, it has to have suprema of families indexed by atbitrary datatypes). So in general we cannot implement predicates as maps into the subobject classfier. We can of course implement them as subobjects, but that is rather useless, e.g., equality on $\mathbb{R}$ would be implemented as the map $x \mapsto (x, x)$. Fortunately, certain pieces of $\Omega$ still exist in realizability models. If a predicate $P : X \to \Omega$ happens to factor through such a piece of $\Omega$, then we get to implement its classifying map. Some examples: 

I presume that by extensionality you mean the law $$(\forall x . f x = g x) \implies f = g.$$ If this is what you mean then the graph model $\mathcal{P}\omega$ is not extensional, while Dana Scott's $D_\infty$ is (I presume $D^\infty$ is Dana Scott's model of the $\beta\xi\eta\lambda$-calculus). To see this, recall that $\mathcal{P}\omega$ is an algebraic lattice with the property that its space of continuous maps $[\mathcal{P}\omega \to \mathcal{P}\omega]$ is a proper retract of $\mathcal{P}\omega$, i.e., there are continuous maps $$\Lambda : \mathcal{P}\omega \to [\mathcal{P}\omega \to \mathcal{P}\omega]$$ and $$\Gamma : [\mathcal{P}\omega \to \mathcal{P}\omega] \to \mathcal{P}\omega$$ such that $\Lambda \circ \Gamma = \mathrm{id}$ but $\Gamma \circ \Lambda \neq \mathrm{id}$. Given $u, v \in \mathcal{P}\omega$, the application $u v$ is interpreted as $\Lambda(u)(v)$. Now take $u$ and $u'$ such that $u \neq u'$ but $\Lambda(u) = \Lambda(v)$ (these exist because $\Gamma \circ \Lambda \neq \mathrm{id}$). Then for all $v$ we have $u v = u v'$ yet $u \neq u'$. Extensionality is violated. In contrast, $[D_\infty \to D_\infty]$ is isomorphic to $D_\infty$, i.e., there are continuous maps $$\Lambda : D_\infty \to [D_\infty \to D_\infty]$$ and $$\Gamma : [D_\infty \to D_\infty] \to D_\infty$$ which are inverses of each other. So consider any $u, u' \in D_\infty$ and suppose that $u v = u' v$ for all $v \in D_\infty$. This means that $\Lambda(u)(v) = \Lambda(u')(v)$ for all $v \in D_\infty$, hence $\Lambda(u) = \Lambda(u')$ and so $u = \Gamma(\Lambda(u)) = \Gamma(\Lambda(u')) = u'$. Extensionality is established. We see that extensionality is a consequence of $\Gamma \circ \Lambda = \mathrm{id}$. What is the other equation $\Lambda \circ \Gamma = \mathrm{id}$ good for? For this we have to remember how $\lambda$-abstraction is interpreted: $$\lambda X. u(X) = \Gamma (v \mapsto u(v))$$ In words, an expression $u(X)$ with a variable $X$ may be interpreted as a map which takes $v$ to $u(v)$. Then the $\lambda$-abstraction $\lambda X . u(X)$ is interpreted as the $\Gamma$-image of that function. Now from $\Lambda \circ \Gamma = \mathrm{id}$ we get $$(\lambda X . u(X)) w = \Lambda (\Gamma (v \mapsto u(v))) (w) = (v \mapsto u(v))(w) = u(w)$$ which is just $\beta$-reduction. 

I refer you to Chapter 9 of the HoTT book. In particular, a category is defined in such a way that isomorphic objects are equal, see Definition 9.1.6. As Example 9.1.15 points out, there really isn't a reasonable notion of "skeletality" in HoTT. This is so because equality is so weak that it already means "isomorphic". Furthermore, Theorem 9.4.16 says 

While the extra stuff is not totally useless, in many applications we want to get rid of it and keep just . This can be accomplished if we use $\mathtt{Prop}$ to state "$k$ is ordered" and "$k$ is a permutation of $\ell$", but not "for all $\ell$ there is $k$". In general, a common way to extract code is to consider a statement of the form $\forall x : A \,.\, \exists y : B \,.\, \phi(x, y)$ where $x$ is input, $y$ is output, and $\phi(x,y)$ explains what it means for $y$ to be a correct output. (In the above example $A$ and $B$ are the types of lists and $\phi(\ell, k)$ is "$k$ is ordered and $k$ is a permutation of $\ell$.") If $\phi$ is in $\mathtt{Prop}$ then extraction gives a map $f : A \to B$ such that $\phi(x, f(x))$ holds for all $x \in A$. If $\phi$ is in $\mathtt{Set}$ then we also get a function $g$ such that $g(x)$ is the proof that $\phi(x, f(x))$ holds, for all $x \in A$. Often the proof is computationally useless and we prefer to get rid of it, especially when it is nested deeply inside some other statement. $\mathtt{Prop}$ gives us the possibility to do so. Added 2015-07-29: There is a question whether we could avoid $\mathsf{Prop}$ altogether by automatically optimizing away "useless extracted code". To some extent we can do that, for instance all code extracted from the negative fragment of logic (stuff built from the empty type, unit type, products) is useless as it just shuffles around the unit. But there are genuine design decisions one has to make when using $\mathsf{Prop}$. Here is a simpe example, where $\Sigma$ means that we are in $\mathsf{Type}$ and $\exists$ means we are in $\mathsf{Prop}$. If we extract from $$\Pi_{n : \mathbb{N}} \Sigma_{b : \{0,1\}} \Sigma_{k : \mathbb{N}} \; n = 2 \cdot k + b$$ we will get a program which decomposes $n$ into its lowest bit $b$ and the remaining bits $k$, i.e., it computes everything. If we extract from $$\Pi_{n : \mathbb{N}} \Sigma_{b : \{0,1\}} \exists_{k : \mathbb{N}} \; n = 2 \cdot k + b$$ then the program will only compute the lowest bit $b$. The machine cannot tell which is the correct one, the user has to tell it what he wants.