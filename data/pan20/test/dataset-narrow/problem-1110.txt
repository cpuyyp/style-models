The particular case of language universality (are all words accepted ?) is PSPACE-complete for regular expressions or NFAs. It answers your question: in general the problem stays PSPACE-complete even for fixed $E_1$, since language universality corresponds to $E_1=\Sigma^*$. It is indeed hard to find a modern readable PSPACE-hardness proof for regular expression universality, as it is now considered folklore. Here is a quick proof scheme that allows you to rebuild the proof: 

I am not sure it is in the spirit of your question, but here is a possible lead: a computer which acts as an "all-powerful mathematician", or for that matter, all powerful knowledge in general. This would be a computer with which we can dialogue, and ask it questions like "what is the answer of the Riemann hypothesis". The computer would give the answer and justify it by intuition-level arguments, that can be refined at the will of the questioner, all the way to formal proof if necessary. Same thing if the results are independent, or if the question does not make sense, the computer would be able to explain it to the questioner in the best possible way for him to get convinced of that. Any question could be allowed, as "What is the issue with dark matter? Can we design an experiment to settle the question?", and so on... This interactive device, all-knowing but communcating on a good level for our intuition, would be a good way to violate all that we know about the world. It is able to solve any problem humans can ask themselves, at least any problem for which there is a solution which can be displayed to us in a convincing way, and so in some sense it is the best possible "god-authentification". This is beyond your (presumable) limitation of a finite piece of data, but we can additionnally respect this condition with this fix: This device would only work for a finite time, say a year, during which many people (including experts in various fields) could come to question it. During this time, the inside of the machine is sealed and we cannot see the mechanism, it is a blackbox. After "expiration", the lock is opened, and we discover that the answers were hardcoded in the right order, separated by predefined time intervals, and the computer was just reading them. This is an absolute finite piece of data, that not only "knew" the answers to all the questions we could think of in one year, but additionally "knew" exactly what questions were going to be asked and when. The probability of chance for this can be neglected (such a probability will always exist anyway if the data needs to be finite). 

Each $C_i$ encodes a valid configuration of $M$ $C_0$ is initial, $C_n$ is accepting $u^R$ is the reverse of a word $u$ $\overline{u}$ is a copy of $u$ using pop letters $\#,\&,\$$ are special separation symbols not in the alphabet of $M$ $C_i\to C_{i+1}$ is always a valid transition of $M$ 

I want to define a notion of "closeness" between two regular languages of finite words in $\Sigma^*$ (and/or infinite words in $\Sigma^\omega$). The basic idea is that we want two languages to be close if they don't differ by many words. We could also use the edit distance in some way... I could not find good references on this issue. I don't call it a distance because I don't require all the distance axioms to be true (although it's not bad if they are). A first attempt is to define $$d(L,K)= \limsup_{n\to\infty} \frac{|L_n\Delta K_n|}{|L_n\cup K_n|}$$ where $L_n$ and $K_n$ are the restrictions of $L$ and $K$ to $\Sigma^n$, and $\Delta$ is the symmetric difference. Is this "distance" studied? Are there references on the subject (possibly with alternative choices for distance function)? Any help or pointer would be appreciated, thanks. 

I am trying to find references on algorithms for graphs of bounded bandwidth, in the same way as it is done with treewidth for instance. I could only find research related to computing the bandwidth, or properties of this measure, but not using it as assumption for better algorithms. Also, I am very interested in a generalization of bandwidth in higher dimensions. For instance this paper studies 2-dimensional bandwidth, but considering only the $L^1$ and $L^\infty$ norms on $\mathbb N\times \mathbb N$, whereas I am more interested in the euclidean norm $L^2$. It seems natural to consider graphs of $n$-dimensional bandwidth for euclidean norm. Formally, the $n$-dimensional bandwidth of a graph $G=(V,E)$ is defined as : $$\min_{\alpha} ~\max_{(x,y)\in E}||\alpha(x)-\alpha(y)||_2$$ where $\alpha$ ranges over injective functions $V\to \mathbb N^n$. This is pretty natural, for instance graphs coming from discretizations of real-life systems following differential equations would likely have bounded bandwidth. Indeed, if an edge takes you to the state of the system at the next time instant, it can not be too far from your current state if the time step is small enough and the system evolves continuously. It seems that this special structure could be used to design better algorithms (in particular for solving games on these graphs), but I could not find anything on this kind of graphs. 

It seems NP-complete even with weights in $\{0,1\}$. I reduce from the MINSAT problem: given a SAT instance, find an assignment that minimizes the number of satisfied clauses. More precisely, an instance is a CNF formula, and an integer $k$, and you have to say whether there is an assignment satisfying at most $k$ clauses. It is shown to be NP-complete in this paper. Start from a MINSAT instance with variables $x_1\dots x_n$ and clauses $C_1\dots C_m$, we build an instance of your problem. The weight vector has $m$ coordinates (the number of clauses). The first edge of the graph puts every coordinate to $1$. Then we traverse $n$ nodes where you have to choose the truth value of the variables $x_1\dots x_n$. For instance if you set $x_i$ to true, the corresponding edge vector contains a $0$ for each clause $C_j$ where $x_i$ appears positively and $1$ elsewhere. The idea is that a clause is set to $0$ if the assignment makes it true. Since you use the product to evaluate a path, $0$ is absorbing and corresponding to the wanted disjunction. Finally, you have a path from the source to the target with weight at least $m-k$ if and only if there is an instanciation of variables satisfying at most $k$ clauses. Reference: The Minimum Satisfiability Problem, Kohli, Krishnamurti, Mirchandani in Journal SIAM Journal on Discrete Mathematics 1994 

The complexity of deciding equality of regular languages (and many other problems on regular languages) varies a lot depending on the system of representation: 

It does not extend. Consider FO-LFP with just a binary predicate $<$, and the axioms for $<$ being a total order, with first and last positions, and every position has a successor. Moreover, we add an axiom saying that the last position can be reached from the first by iterating the successor function as a smallest fixpoint. This ensures that the universe is finite. Now for each $n$, we can build a formula $\varphi_n$ stating that the universe has at least $n$ positions. Let $\Gamma=\{\varphi_n:n\in\mathbb N\}$ Each finite subset of $\Gamma$ has a model, but $\Gamma$ does not, so the compactness theorem fails. 

This semantic is powerful enough to embed co-$NP$-complete problems. For instance, on an input graph $G$, you can design $\phi$ to say "the even elements according to $<$ do not form a clique". Then, under your semantic, $G\models^* \phi$ iff $G$ does not have a clique which is half the size of $G$. It is not hard to verify that this is a co-$NP$-complete problem, so unless $P=NP$, your logic is more powerful than $P$. 

What would be the nasty consequences of NP=PSPACE? I am surprised I did not found anything on this, given that these classes are among the most famous ones. In particular, would it have any consequences on the lower classes? 

Of course, as pointed out by Michael Wehar in the comments, for others $E_1$ the problem can become simpler. Classifying the complexity of this problem has been studied extensively in this paper [1] for equivalence, containment, and covering. You can see a summary of the results for the equivalence problem in this answer (there does exist NP-complete cases). As for your remark on squaring: allowing squaring in regular expressions make the inclusion and universality problem EXPSPACE-complete [2]. Remark that this can be seen in the proof scheme above, since $(\Sigma')^{p(n)}$ can now be expressed with a logarithmic-size expression in $p(n)$ using its binary decomposition, so we can go up to an exponential $p(n)$ while keeping the size of the expression polynomial. [1] On the equivalence, containment, and covering problems for the regular and context-free languages Harry B.Hunt, Daniel J.Rosenkrantz, Thomas G.Szymanski. Journal of Computer and System Sciences. Volume 12, Issue 2, April 1976, Pages 222-268 [2] The equivalence problem for regular expressions with squaring requires exponential space. Meyer, A.R. and L. Stockmeyer. 13th IEEE Symposium on Switching and Automata Theory, Oct 1972, pp.125â€“129. 

From a ITE formula $\phi$, you can compute polynomially a reduced assignment list to describe all valuations which makes it true. To do that, just look at your formula as a tree with nodes labeled by variables and leaves by $0$ and $1$. Left branches are the "then" part setting the variable to true and right branches are the "else" part setting it to false. Each branch leading to a leave $1$ will be labeled by a set of partial variables assignement, for instance $\{x,\overline{y},z\}$. Computing the list of all these sets from your formula is polynomial. You can then compute a normal form of this list by removing a set if it is contained in an other one, and merging sets that differ on a variable: if $\{x,\overline{y},z\}$ and $\{x,y,z\}$ are in your list, you remove them and add $\{x,z\}$, meaning that it works no matter the value of $y$. However, if you have $\{x,\overline{y},z,t\}$ and $\{x,y,z\}$, you cannot merge them and keep them like this. You apply these rules until you stabilize, once again this procedure is polynomial. Finally, choose an arbitrary ordering on variables $\{x_1,\dots,x_n\}$, and call $i$ the weight of $x_i$. The weight of a list is the sum of all weights appearing in it (with multiplicites). Apply "rotations" everytime it is possible, in order to minimize the total weight of your normal form. A rotation changes $\{\vec x,x_i,x_j\},\{\vec x,\overline{x_j}\}$ to $\{\vec x,x_i\},\{\vec x,\overline{x_i},\overline{x_j}\}$ with $i<j$ ($\vec x$ is a list, and $x_i$ and $x_j$ can also be negated variables). We can see that it makes the total weight decrease by $j-i$. Hopefully now the normal form is unique, I'll try a formal proof later. Then, two formulas are equivalent iff they have the same normal form list of assignments. So your problem seems to be in $P$. 

In ii), you say that $u$ being in $L$ can be deduced only by knowing $pref^k(u)$, $inf^k(u)$ and $suff^k(u)$. This mean that $L$ can be given by a set $E\subseteq (X^*\times 2^{X^*}\times X^*)$, namely $u\in L$ iff $(pref^k(u),inf^k(u),suff^k(u))\in E$. The reason why condition i) is stronger is because it forces $E$ to be of the form $P\times 2^I\times S$. An example of a language which is in ii) but not i) is therefore given by $E=\{ (a,X^*,a), a\in X\}$. This means that $L$ is just the language of words whose last letter is equal to the first. $L$ is locally testable with $k=1$ for condition ii), but it is not for any $k$ for condition i). 

For K=2, PARTITION reduces to this problem, so it is NP-hard. Take an instance of PARTITION: a list of nonnegative integers $x_1,\dots ,x_n$, and you ask if there is a subset $I\subseteq [1,n]$ such that $\sum_{i\in I} x_i=\sum_{i\notin I}x_i$. Let $S=\sum_{i\in[1,n]} x_i$, and $y_i=\exp(-\frac{x_i}S)$ for each $i$. Note that $y_i\in (0,1)$. You build a graph with $n+1$ nodes $p_1,\dots ,p_n,p_{n+1}$. You have two edges from $p_i$ to $p_{i+1}$: one with weight $(\frac{y_i}2,\frac12)$ and the other with weight $(\frac 12,\frac{y_i}2)$. The division by $2$ is there to ensure the additionnal constraint that the sum of coordinates is at most $1$. A path from $p_1$ to $p_{n+1}$ corresponds to a partition $I$: you end up with the vector $$\big(\dfrac{\exp(-\frac1S\sum_{i\in I} x_i)}{2^n}~,~ \dfrac{\exp(-\frac1S\sum_{i\notin I} x_i)}{2^n}\big).$$ Since the minimum of $e^{-x}+e^{-(1-x)}$ is reached for $x=1/2$, there exists a path of weight $\exp(-1/2)/2^{n-1}$ if and only if there was a balanced Partition of the initial integer list.