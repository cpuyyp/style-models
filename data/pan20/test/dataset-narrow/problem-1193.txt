For $\lambda > \mu$, consider independent random variables (i) $X \sim Pois(\mu)$ and (ii) $Y_i \sim Pois(\lambda),\;i\in{1,2}$. Question : Can we upper-bound the following? $$\mathbb{P}\big(X\geq\max(Y_1, Y_2)\big)$$ 

Consider a graph $G$ with max degree $\Delta_G$, min degree $\delta_G$ and average degree $d_G$. Is it possible to obtain a subgraph of $G$, say $G'$, such that $\Delta_{G'} = c_1d_{G}$, $\delta_{G'} = c_2d_{G}$ , where $c_1,c_2$ are constants EDIT 1: Also the size of the resultant subgraph $G'$ must be constant times the size of original graph $G$. My attempt : Let $X$ be the random variable which denotes the degree of any randomly chosen vertex. Therefore, $d_G = E[X]$. Using markovs's inequality, we have $$P(X > 3E[X]) < \frac{1}{3} $$ and $$P(X < \frac{E[X]}{3}) = P(\frac{1}{X} > \frac{3}{E[X]}) < \frac{E[\frac{1}{X}]*E[X]}{3} < \frac{1}{3}$$ Using union bound, we have $$P(\frac{E[X]}{3} < X < 3E[X]) > 1/3$$. Using the above equation, we can show that there exist $|V|/3$ vertices in $G$ whose degree is between $d_G/3$ and $3d_G$. Does the graph obtained by the above $|V|/3$ vertices solve the problem? If not, can we modify the technique to obtain a solution? Thanks in advance! 

This gives us the (polynomial) run time. Proof of correctness that for a properly setup lattice will give you the minimal factor of a reducible polynomial is a bit more involved, but please refer to theorem 14 of the same chapter to see the relation between the reduced basis and the minimal polynomial. By setting up the basis with dimension $n=k$ you can easily see the bound as roughly $O(k^5( \lg(||f(x)||_{\infty}^3) + \log n))$. Since, by assumption, you know the degree of $f_1(x)$ and $f_2(x)$, the lattice reduction algorithm only needs to be run once to find one of the two factors of $f(x)$. You can then use the discovered $f_j(x)$ to find the other by standard polynomial division. The original paper by Lenstra, Lenstra and Lovasz, "Factoring polynomials with rational coefficients", is also quite readable and I found it to be a good compliment to Yap's introduction. 

Perhaps I'm missing the motivation for your question but there are many examples of empirical results motivating research, algorithms and other results. MP3 use psychoacoustic to optimize the algorithm for human encoding. Plouffe gives an account of discovering the BBP spigot algorithm for the digits of $\pi$ where he recounts the use of whatever Integer Relation Algorithm Mathematica was using to discover the formula. Along the same line, Bailey and Borwein are big proponents of experimental mathematics. See "The Computer as Crucible: An Introduction to Experimental Mathematics", "Computational Excursions in Number Theory" amongst others. One might argue that this is more experimental Mathematics but I would argue that at this level the discussion the distinction is semantic. Phase transitions of NP-Complete problems are another area where empirical results are heavily used. See Monasson, Zecchina, Kirkpatrick, Selman and Troyansky and Gent and Walsh for starters, though there are many, many more (see here for a brief survey). Though not quite on the level of Theoretical Computer Science or Mathematics, there is a discussion here about how the unix utility grep's average case runtime beats optimized worst case algorithms because it relies on the fact that it's searching human readable text (grep does as bad or worst on files with random characters in them). Even Gauss used experimental evidence to give his hypothesis of the Prime Number Theorem. Data mining (Bellkor's solution to the Netflix Prize to make a better recommendation system) might be argued to be a theory completely based on empirical evidence. Artificial Intelligence (genetic algorithms, neural networks, etc.) relies heavily on experimentation. Cryptography is in a constant push and pull between code makers and code breakers. I've really only named a few and if you relax your definition of empirical, then you could cast an even wider net. My apologies for being so scattered in answering your question but I hope I've given at least a few examples that are helpful. 

For triangle-free (girth $\geq 4$) graph $G$. The following theorem holds true Theorem (Ajtai et al.): For a triangle-free graph $G$ with maximum degree $\Delta$, $$\alpha(G) \geq \frac{n(G)}{8d}\log_2d.$$ Where $n(G)$ is the vertex size of the graph, $d$ is the avg degree and $\alpha(G)$ is the size of maximum independent set. My Question : Are there extensions of above result for graphs with girth $\geq l$ ? 

Problem setting Consider a set $ S = \big\{ 1,2,\cdots,n \big\}$. Now consider $k$ equal-sized subsets $S_i \subset S$ s.t of size $\big|S_i\big|=n' \;\forall i$. Consider a $k\times k$ matrix $M$ s.t $\;M_{ij} = \big|S_i\cap S_j\big|\big/n'$, size of the intersection of the $i^{th}, j^{th}$ subset divided by $n'$. Question Does $M_{ij}$ lie in the polytope of zero-one matrices? Paraphrasing the question - Can we express every $M_{ij}$ as a convex combination of zero-one matrices? 

Consider a weighted graph $K_n$ and where the weights between vertices $i,j$ is $w_{ij}$. Consider a path, $\sigma$, passing through each vertex only once. Here $\sigma_i$ is the vertex in the $(i\%n)^{th}$ step of the path. (For example, $\sigma_{n+1} = \sigma_1$) Traveling salesman problem (TSP) minimizes the following objective : $$\sum_{i=1}^{n}w_{\sigma_i,\sigma_{i+1}}$$ A variant of TSP, 2-Fold TSP, will additionally consider the weights between the 1-skipped vertices on the path. The objective of a 2-Fold TSP is to minimize $$\sum_{i=1}^{n}w_{\sigma_i,\sigma_{i+1}}+w_{\sigma_i,\sigma_{i+2}}$$ and similarly the objective of K-fold TSP is to minimize $$\sum_{i=1}^{n}w_{\sigma_i,\sigma_{i+1}}+w_{\sigma_i,\sigma_{i+2}}+\cdots+w_{\sigma_i,\sigma_{i+k}}$$ Question 

Finally, getting to the original question you wanted answered, since we know that $\Pr(E_m) \propto \frac{1}{\sqrt{m}}$ we have: $$ \sum_{i<n} \Pr(E_i) \propto \sqrt{n} $$ And as numerical verification, below is a log-log plot of the sum, $S$, versus instance size, $n$. Each point represents the average of the sum of 100,000 instances. The function $x^{1/2}$ has been plotted for reference: 

If you're only concerned about finite permutation groups, I found the book "Fundamental Algorithms for Permutation Groups" by Gregory Butler very readable. It's only for finite permutation groups but was one of the only books that gave pseudo code and algorithmic descriptions that I could understand (for Schreirer-Sims, strong generating sets, etc.). The Seress book recommended by others is decent but for some reason he has an aversion to pseudo code so it was very difficult for me to understand. Personally, I used the Butler book for a concrete understanding of the algorithms and the Seress book as aid in understanding proofs of correctness. The Butler book is quite old by now but I still have yet to find a better introduction on finite permutation group algorithms. 

An Erdos-Renyi graph over $n$ vertices and average degree $d$ is not connected whp iff $d < \log n$. I was wondering for what the degree $d$ would a random regular graph of degree $d$ be connected? In particular will this be connected for some degree less than $\log n$? 

I dont have a complete solution. But for the case when the elements in the array are strictly increasing, one can find the solution in $\log(n)$ time. Solution Let $B[i] = A[i] - i$ Now search for element $0$ in $B$ using binary search. Proof : For the above algorithm to work, we need to prove that $B$ is also sorted. $$A[i] < A[i+1]\\ \text{thus we have } A[i] \leq A[i+1] - 1\\ A[i] - i \leq A[i+1] - (i + 1)\\ B[i] \leq B[i+1] $$ EDIT 1 This algorithm doesnt explicitly evaluate the matrix $B$. It uses the definition $B[i] = A[i] - i$ whenever required. EDIT 2 The restriction $A$ has to satisfy for the above case is $A[i+j] - A[i] \geq j \; \forall j > 0$. We could relax the restriction to the following $$ A[j+i] - A[i] \geq i \; \forall j > f(n) $$ where $f(n)$ is a sublinear function in $n$. The above restriction would ensure that $B[i+j] \geq B[j] \;\forall j > f(n)$. Now we can use a simple variant of binary search for obtain the solution in $O(f(n)*\log n)$ time. 

Fundamental Algorithms in Algorithmic Algebra by Chee Yap (available online here). This text covers (fast) integer multiplication, polynomial root finding, integer polynomial factorization, lattice reduction techniques (specifically LLL), elimination theory, Grobner bases and continued fractions, all from an algorithmic perspective. I found this text indispensable when learning about lattice reduction. 

While reading the article "Is it Time to Declare Victory in Counting Complexity?" over at the "Godel's Lost Letter and P=NP" blog, they mentioned the dichotomy for CSP's. After some link following, googling and wikipeding, I came across Ladner's Theorem: 

Here $\alpha_d$ is the value for the density transition and $\alpha_c$ is the critical threshold value ($\approx 4.2$ for 3-SAT). It'd be interesting to see if the locations of the different fractal regions reported by Ercsey-Ravasz and Toroczkai correspond to the different critical thresholds noticed in survey propagation (or if I'm completely wrong and the similarity really is superficial). 

In other words, the $(2^n)!$, which has an exponential number of bits, can potentially be represented efficiently. I have a few questions: 

Theorem: For any graph $G=(V,E)$, there is a polynomial time algorithm that finds a cut $S \subseteq V$ with conductance at most $\sqrt{2\big(1 âˆ’ \lambda(G)\big)}$. If I understand UGC correctly, the above result is tight for general graph under UGC. Question: Can we obtain a better approximation if we have the promise - $mincut(G) = O(\log n )$? 

Consider a universe $N$ containing $n$ elements, and a collection of sets $\mathcal{C}$, over $N$. The $k$-multiset multicover (MSMC) problem is to cover all elements of the universe $N$ at least $k$ number of times using minimum number of sets from $\mathcal{C}$. (When $k=1$, the problem reduces to min-set cover). Are there any heuristics out there with 'good' performance on 'real' data for $n=1000$ and $|\mathcal{C}| = 1000$? 

Can this be reduced to the original TSP? Is there any reference which deals with k-fold TSP? What is the name of this problem in the literature? Any heuristics/approximation algorithms? 

Consider a complete undirected graph with $n$ vertices, $K_n$. Let weight of an edge between vertices $i\; \& \;j$ be a random variable $E_{ij}$. Let $E_{ij} \sim exp(\lambda)$, where $exp(\lambda)$ is an exponential distribution. Problem What is the distribution of weight of the minimum spanning tree of the above graph? Note : If $ X_1 \sim exp(\lambda_1)$ and $X_2 \sim exp(\lambda_2)$, then $min(X_1, X_2) \sim exp(\lambda_1+\lambda_2)$ 

I'm not sure if this is what you're looking for but there's a sizable literature on the 3-SAT phase transition. Monasson, Zecchina, Kirkpatrcik, Selman and Troyansky had a paper in nature that talks about the phase transition of random k-SAT. They used a parameterization of the ratio of clauses to variables. For random 3-SAT, they found numerically that the transition point is around 4.3. Above this point random 3-SAT instances are over constrained and almost surely unsatsifiable and below this point problems are under constrained and satisfiable (with high probability). Mertens, Mezard and Zecchina use cavity method procedures to estimate the phase transition point to a higher degree of accuracy. Far away from the critical point, "dumb" algorithms work well for satisfiable instances (walk sat, etc.). From what I understand, deterministic solver run times grow exponentially at or near the phase transition (see here for more of a discussion?). A close cousin of belief propagation, Braunstein, Mezard and Zecchina have introduced survey propagation that is reported to solve satisfiable 3-SAT instances in millions of variables, even extremely close to the phase transition. Mezard has a lecture here on spin glasses (the theory of which he has used in analysis of random NP-Complete phase transitions) and Maneva has a lecture here on survey propagation. From the other direction, it still looks like our best solvers take exponential amount of time to prove unsatisfiability. See here, here and here for proofs/discussion of the exponential nature of some common methods in proving unsatisfiability (Davis-Putnam procedures and resolution methods). One has to be very careful about claims of 'easiness' or 'hardness' for random NP-Complete problems. Having an NP-Complete problem display a phase transition gives no guarantee as to where the hard problems are or whether there even are any. For example, the Hamiltoniain Cycle problem on Erdos-Renyi random graphs is provably easy even at or near the critical transition point. The Number Partition Problem doesn't seem to have any algorithms that solve it well into the probability 1 or 0 range, let alone near the critical threshold. From what I understand, random 3-SAT problems have algorithms that work well for satisfiable instances nearly at or below the critical threshold (survey propagation, walk sat, etc.) but no efficient algorithms above the critical threshold to prove unsatisfiability. This is just state of the art right now and could of course change in the future. 

Since every $3$-SAT instance with $n$ variables can be expressed as a degree-$3$ polynomial over $\mathbb{F}_2$ with $n$ unknowns, the NP-hardness of $3$-SAT directly translates to NP-hardness of solving(finding roots) $3$-degree polynomials. So my question is solving a single degree-$2$ polynomial over $\mathbb{F}_2$ with $n$ unknowns, NP-hard? 

Given points $x_1, x_2, \cdots, x_n \in \mathbb{R}^d$. What is the complexity of computing $$ argmin_{x}\left(\sum_{i=1}^n ||x_i-x||_2\right) $$ 

Consider a graph $G(V,E)$. For any two vertices $v_1 , v_2 \in V$, the subgraph induced by the neigbourhood of vertex $v_1$, denoted by $G_{v_1}$ be isomorphic to the subgraph induced by the neigbourhood of veretx $v_2$, denoted by $G_{v_2}$. Now suppose one can color $G_{v_1}$(and $G_{v_2}$) using $k$ colors. Can one upper-bound the chromatic number of the graph $G$ in terms of $k$ (and other graph EDIT 1: The motivation behind this question is the fact that the chromatic number is upper bounded by max degree of the graph. Therefore it might happen that if the neighbourhood satisfies certain properties (like densely connected?,lot of cycles of all lengths?), may be one can related its chromatic number of graph $G$ to $k$. Links to related literature will be helpful. Thanks in advance!