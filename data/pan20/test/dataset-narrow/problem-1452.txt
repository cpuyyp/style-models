The pixel shader returns a color based on light contribution. The result of the lightmap generation for this test mesh looks like this: 

Compose an array of edges in uv space. For each edge: a. Compute the cross product using the edge direction vector and a point that lies on the edge. The resulting vector is the edge's normal(It should face away from the triangle, perpendicular to the edge direction vector) b. Compute the edge center position in uv space. c. Translate the edge center position along the edge normal by a distance of a half pixel(or desired dilation amount in uv space...it should definitely be a value between 0 and 1). After all edges have been translated, calculate the intersection points between each edge to determine the new uv coordinates for the triangle. Adjust the triangle's position data. Each position should be dilated as well. The dilation of triangles with acute angles may cause too great a change in the uv coordinates. You should calculate an axis-aligned bounding box for the original triangle in uv space. Then dilate the AABB by the same amount as the triangle. When computing the lightmaps just make sure that the uv coordinates lie within the AABB, if not then discard the pixel. 

You'll need to compare the monitor handle returned to the list of screens found on the system. Screen.AllScreens is a list of all screens. As for the adapter mode comments above you should see the DirectX SDK and check out the DXUT classes, especially DXUTenum.cpp. This class is necessary for an application. It will enumerate all adapter display modes and build a collection of 'combinations' that can be used. Display Modes have specific capabilities. Certain modes cannot go fullscreen. Certain modes require a particular back buffer format for use with the adapter format. Certain depth/stencil buffer formats conflict with multisample types...and so on. Were you to try and create a device using improper settings the API will throw an exception...or return 'Invalid Call'. DXUT is very useful and is a great tool for avoiding conflicts. 

I would like for this code to be dynamic so as to reduce the instruction count. I understand that the problem is accessing the array in the loop. How can I rewrite this code to prevent unrolling during compilation? I am using ps 2.0 or 3.0. 

Can I change a rasterization state to allow pixels under certain conditions? EDIT: Lightmap and Deferred Shading Cube Pics 

UPDATE: The application appears to run faster when I use a pointer to the first back buffer like so: 

I am shadow mapping in Direct3D 9. I'm trying to avoid rendering depth to a 32-bit render target. So, I've created a depth/stencil texture( a texture w/usage Depth/Stencil ). When I render I do this: 

Take note of the first parameter of the D3DVERTEXELEMENT9 constructor...it is '0' for the mesh object and '1' for the transformation matrix. This is because you are going to instruct the graphics device to use 2 different vertex buffers. Also take note of the 'offset' parameters...they begin again at 0 for the 2nd vertex buffer. Before you can render though, you must also set the frequency of transformation matrices per instance...such that for every instance of grass the graphics device will use 1 transformation matrix. Before the draw call you will instruct the graphics device like this: 

You have to use StartCoroutine (probably not in the Update) in order to start its execution. Otherwise it's only a method call: 

This is the "guilty line" :) . The projected vertex position is offset by the projected normal calculated before by an amount proportional to (the size of the outline you specify by inspector) and the distance from the camera (). The idea behind is that if you don't multiply by the distance, the outline will become thinner depending on how fare you are from the camera. So basically it should guarantee that the outline should stay on the same (clip space) distance independently from camera distance. (Just comment the multiplication by o.pos.z and you will see). So basically in the second picture what seems a larger outline, is an outline of the same width when projected (de facto larger if you consider the width relative to the world size of the object). Note that the "outline" is simply the same model draw with front face culling: 

Player's code will be more clean and efficient. It's really simple to enable/disable the hit handling, simply removing the delegate associated with the event. If you have more classes interested to listen to the hit event, it's easy to broadcast this event to all listeners (es. audio manager that plays an effect on sword hit) 

Get a reference to the the specific instance you need of is attached to. Get a reference to the component attached to the Access the public field 

If you are asking how to reference in a a prefab is supposed to be instantiated and not destroyed in a , in then you can't. The object instance is only available when a particular scene will be loaded (at runtime or in the editor for editing) 

Polling code looks ugly Performance: you are doing a lot of unuseful polling checks at every frame, in order to catch an event that is some way occasional (sword hit enemy) 

There are several references on the web suggesting using unity_4LightPosX0 uniform values. I don't know, maybe they work on different rendering paths. For what concern the forward base pass the uniforms above should work correctly. I found out that 2 good ways to understand how rendering pipeline works are: 

Two other way of doing it (probably not suited for your specific case, but useful in more complex scenarios): 

I'm experimenting with and colliders. Unfortunately I still don't have version and I can't use the profiler. Consider the following situation: 

If I do the same thing with animated models, are created of the wrong dimension. For example if attach the script above to penelopeFBX model of the standard asset, is created smaller than the mesh itself. How can I solve this? 

You need and Android license to target those platforms. AFAIK you can use a plugin to play game in your browser without a specific license (for the one you have to pay) 

The problem is that the depth/stencil texture is a D24SX format...How do I sample from a texture of this format? My original attempt which of course will not work: 

I'm programming a managed Direct3D 11 application with SlimDX. I want to use Intel Graphics Monitor to capture draw calls for a single frame. When I try to set a depth stencil state my application crashes...any ideas? 

The light for this scene is floating in the center of the room... The problem is that the lightmap has 'cracks' due to the rasterization of polygons by the GPU. It appears as though that for a given face lightmap pixels are not included during rasterization because their pixel centers do not fall within the bounds of the face's UV coordinates despite the fact that the face overlaps those pixels. As a result a black( unset ) pixel is rendered and effectively blackens the diffuse color of the mesh during texture modulation. Here is a screenshot: 

code to convert world space position into normalized device coordinates for uv lookup of item buffer: 

Screen.FromHandle(): Retrieves a Screen for the display that contains the largest portion of the object referred to by the specified handle. (From MSDN) Also, the Direct3D9 object has a function that returns the handle(IntPtr) of the adapter monitor. I haven't worked with multiple monitors yet so I couldn't say that this method will work well but here is code for SlimDX: 

I'm trying to do lighting calculations for an array of point lights in HLSL. I simply want to pass light direction vectors from the vertex shader to the pixel shader. Here is sample code: 

I'm working on a radiosity processor in DirectX 9. The process requires that the camera be placed at the center of a mesh face and a 'screenshot' be taken facing 5 different directions...forward...up...down...left...right... ...The problem is that when the mesh face is facing up( look vector: 0, 1, 0 )...a view matrix cannot be determined using standard trigonometry functions: 

I'm trying to parse a .x file using SlimDX. I can create the XFile object and register templates but I'm having problems with the enumeration object. The enumeration object has a child count of 0 for a file I know to have valid data. Here is code to create file, enumeration, and data objects: 

This thread directly concerns lightmap generation; however, indirectly, the rasterization of polygons by the GPU. I am currently generating lightmaps using a pixel shader. To the shader I send 3 lightmap UV coordinates per mesh face. Those UV coordinates are directly rendered onto a lightmap texture( by setting the lightmap as the render target ). The vertex shader looks like this: 

The problem was due to the nature of controls found in Windows Forms. From MSDN: A control can be selected and receive input focus if all the following are true: the Selectable value of ControlStyles is set to true, it is contained in another control, and all its parent controls are both visible and enabled. The device window in my application belongs to a parent window and the parent window becomes nonvisible once fullscreen is enabled. Its possible that a conflict arose due to the 'focus rules' above. To test the theory I examined the return value from DeviceWindow.Focus()(derives from Control.Focus())...which returned false. My solution was to create a form used for the sole purpose of fullscreen mode changes. Now, when I want to go fullscreen I reset the device with the handle to the new device window. All problems solved... 

You can use Physics.SphereCast instead of RayCast. This allow you to perform queries of the intersection of a sphere sweeped along a given direction instead of single ray, allowing a more tolerant collision detection. Assign at least two different layers to the plane and the under it, in order to exclude the plane from the query. 

I'm looking for a graph library to be used inside script. I'm not looking for pathfinding libraries (I know there are good one available). I could consider using a path finding library only if it gives me direct access to underlying graph classes (I need nodes and edges, and classic graph algorithms) The only product I've seen that seems intersting is QuickGraph. I have the following question: 

If you extend AssetPostprocessor you can receive a callback(OnPostProcessTexture) when a texture import is completed. You can use that entry point to automatically create a new material and assign the relative texture to it. 

The first simple approach is to use a rigidbody with a collider attached to the player (let's say it could be even a shere collider) and use a collider for each object in the scene (coins, obstacles, bonuses,...) . AFAIK, using hundreds of colliders could have a serious impact on performances,specially on mobile devices, am I right? So here's some questions: 

For more details on coroutines have a look here. EDIT Sorry for the mistake. StartCoroutine isn't a GameObject method but belongs to MonoBehavior. So for what concern your question on extension methods: in order to use StartCoroutine method you need a reference to a MonoBehavior. I don't think use an extension method is a particularly good idea here, btw you can't add an extension method to GameObject because it's not a behavior itself. If you want to extend MonoBehavior: 

Groups the objects on a per-room basis. Each room has a root that you should enable only when you enter in it (or are next to it), and disable the room you were coming from. Maybe it's easier method, but you will load in memory all the room even if only the active one is rendered (if you haven't too much rooms it should be acceptable). Use occlusion culling to limit the rendering to non-occludee objects. You still have all objects load into memory, but unity takes care to decide what to render and what not, based on its visibility. Use a different scene for each room, and load(load additive)/unload scene(rooms) when you no longer need them. This generally should reduce the memory footprint, but can create a bit of garbage to be collected, so it may be a little more tricky do handle properly. 

You still need to cast at some point (either on Start or during a SerializationCallback). Hope this help 

Is it possible to use inside Unity3d? If yes. Is this a good idea? Does it have any drawbacks? Is it a quite fast and well written/supported library? Does anyone has ever used it? Are available other graph library that can be easily integrated in ? 

What you'll wind up doing David is creating a vertex buffer to hold the different transformation matrices for each instance of grass. You will need a vertex declaration that has your standard 'grass' vertex components( pos, norm, uv...etc ), and in that same declaration 4 additional 4-component floats to hold the 4x4 transformation matrix...the declaration will look like this: 

The desktop bounds, or 'WorkingArea' of the adapter can be found using the Screen(System.Windows.Forms.Screen) class. First you must have the handle of the device window(System.Windows.Forms.Form) displayed on the adapter. Then you can get the working area like this: 

Here is a screenshot of an auxiliary window which shows both the lightmap and a selected mesh face. This is generated by rendering the UV coordinates of the mesh face over a screen quad of the lightmap: 

Needless to say, time complexity is an issue here. What is the most efficient method for generating adjacency when comparing position data using an epsilon? 

The above example is simple, the constant buffer only stores two 4 component colors. I want to set the constant buffer before binding the pixel shader. I do not want to use the ID3DXEffect interface. The IDirect3D9Device interface only provides methods for setting primitive types...I want to set the entire struct at one time. Is this possible? 

I'm using directx 9 and vertex shaders to rasterize triangles...I have vertex shader input structs like this: 

Or, how do I convert the color returned from the sampler code above to a single floating point value? The above code will return a 4-component vector but depth should be one value for comparison. EDIT: Below is the vertex shader for the shadow map pass...I do not compile a pixel shader for the shadow map pass because color is not written...only depth. 

...There are no exceptions thrown by this function...the child count is 0 so the conditional loop breaks right away, the file objects are disposed of and the function returns... Here is .x file...a simple cube: 

I have a list of indexed triangles for which I need to generate adjacency data. I've already written a brute force algorithm that creates 3 edge data structures for each triangle and then compares the edge structures with those of other triangles like so: 

As you can see above, t0 is the Pos2 coordinates that i use to sample the texture...they are well above 1 ... the vertex they belong to is visible so this pixel should have valid normalized device coordinates. Are the coordinates being altered after leaving the vertex shader and arriving at the pixel shader? 

Here is my implementation of Zehelvion's suggestion. An octree wasn't necessary but his suggestion helped to formulate the following method: 

It will be up to you to manage these variables. Build a class to hold the variables, then you can access the key and mouse states at will. 

When I set the depth stencil and render targets all at one time then nothing is rendered to the screen. When I set only the render targets everything renders normally...Why might this occur?