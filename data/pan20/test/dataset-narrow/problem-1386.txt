The default operator& overload for _com_ptr_t and Microsoft::WRL::ComPtr assume you are using the pattern like in so it Releases the object and sets the pointer to null before returning the address of the contained pointer. This avoids a leak. Note the older ATL CComPtr's operator& did not Release and instead asserted the pointer to be null. 

Remember that Direct3D is actually drawing everything in 2D as it's just pixels on the screen. The pipeline is sophisticated enough to handle 3D projection, but you don't have to use it to that. Direct2D is best if you are drawing traditional vector-graphics like arcs, circles, styled-lines, etc. If you are just manipulating bitmaps (aka 2D sprites), then use in the DirectX Tool Kit for Direct3D 11. It's shared source so you can dig into what it's doing. 

The warning is a protection mechanism in the compiler when linking static libraries made with one version of the VC compiler with code built by another version of the VC compiler. This only matters for some specific headers, notably STL, but can also get pulled in by some other headers in older versions of the compiler (such as stdint.h). This does not affect import libraries for DLLs, just static libraries that contain code. I'm guessing you are using a static library of Effects 11 that was built by the book author, since we never shipped a static library of it just the source in the legacy DirectX SDK. The solution here is really simple: Build Effects 11 yourself with your current compiler. The latest version of Effects 11 is on CodePlex. Note that the book you are using likely has some other deprecated D3DX11 stuff as well. See this blog post for some modern replacements. Also be aware that since you are apparently using Visual Studio 2013 (the MSCVER 1800 compiler), but the book was using Visual Studio 2010 (the MSCVER 1600 compiler), the setup for projects that use legacy DirectX SDK must change since VS 2012 and VS 2013 have the Windows 8.x SDK. See MSDN and this blog post. 

Note that if your game is actually using something that the legacy DirectX REDIST installs, you should take a look at using the April 2011 update of those files--the files were not changed, just the DXSETUP files. See Not So Direct Setup, XAudio2 and Windows 8, XINPUT and Windows 8, HLSL, FXC, and D3DCompile 

First, Effects 11 is deprecated, or rather the HLSL profile you need to use it () is deprecated. You can use still it with the Windows 8.x SDK copy of D3DCompile, particularly if you are using the GitHub open source version of the FX11 library as long as you are comfortable with this caveat. You don't 'need' to use it, but some people have found it useful and there are many older books that make use of it. The main value in the Effects library (FX9, FX10, FX11) is allowing you describe in the file the combination of shader programs you want to use in a grouping (aka technique) along with some associated state. Without Effects, you just need to coordinate between your HLSL shaders, your content, and your C/C++ code that does the rendering. The problem is that the FX solution doesn't really scale well, and it's generally better in large games and applications to have your own bespoke material and state management anyhow. If you are using DirectX Tool Kit, you can get a long way just using the existing 'canned' shaders in et al, perhaps adding some custom pixel shader or vertex shader where the stock stuff doesn't do what you want. It's certainly enough to get you going while you learn all the other aspects of Direct3D 11 programming as well. See the DirectX Tool Kit tutorial Writing custom shaders. You could also try using the built-in VS DGSL shader visual editor which DirectX Tool Kit supports with . It's kind of 'toy' as well, but you can experiment with it and use it to learn HLSL by example. See DirectX Tool Kit tutorial Creating custom shaders with DGSL 

This particular code is loading images (maybe DDS files or maybe general bitmap files) into a CPU staging resource doing a format conversion and resize. Presumably you are going to do something else with the array that actually creates the resource you are going to render with. This is a lot of runtime processing, so the best option is to do that offline and just create a .DDS file with whatever your final resource should be. Then you have a simple case of using the DDSTextureLoader functions in DirectX Tool Kit to do the load with complex file parsing, format conversion, or resizing. If you don't control your resource files (i.e. they come from the user or the web), or you are doing some kind of application where you really are doing a lot of processing a part of the application itself, then you should use DirectXTex instead. See the source to for full details. You'll end up calling: 

which is derived from the classic quaternion paper: Shoemake, Ken. "Animating Rotation with Quaternion Curves", Compute Graphics (SIGGRAPH 1985), Volume 19, Number 3, 1985. You should read Jonathan Blow's The Inner Product, April 2004 article on slerp: Understanding Slerp, Then Not Using It. Basically, for most applications you shouldn't use . Instead use 'nlerp' which is implemented in DirectXMath as: 

Create an overloaded new for the class A that uses __aligned_malloc(,16); Create a global new overload that does this (which is not recommended) Just use XMFLOAT4 or it's kin and explicitly use XMLoadFloat4/XMStoreFloat4 

Here's a function that converts samples to milliseconds (which avoids the need to use floating point) 

There are a number of different techniques for organizing the data, and many games use a mix of them. For static geometry, it's best to have fewer individual IBs and VBs. Traditionally games are 'level' based which means the assets for a section of play are loaded and then the game play begins. To minimize load-times, the information is ideally organized to support this (i.e. load everything for the level as fast as possible without seeking around on the media/disk), possibly replicating information between levels. In this approach, one scheme is to have a large VB and IB for a model or a series of models, and then submit subsets from that to draw. For the Xbox 360 / PS 3 generation, the amount of RAM was quite small relative to the size of the games, so engines became 'streaming' oriented which means they load content dynamically as the player moves through them. This is also called an 'open-world' approach. In this approach, the challenge is 'chunking' the geometry into bits you can load based on spatial hints. Another challenge particularly for 32-bit platforms is ensuring that memory doesn't become fragmented (or even virtual address space fragmentation) over a long period of time--level-based games often reset memory between levels, something streaming engines can't do as easily. Therefore, packing into a fixed size or set of fixed sizes for the IBs/VBs which were allocated and reused as a pool is helpful. For the Xbox One / PS 4 generation, there's a lot of RAM to work with relative to earlier consoles, and a lot of extra cores, so many games are aggressively compressing their assets and then using "extra" CPU cores to decompress them in the background. With 64-bit virtual address space, there is less concern about virtual address space fragmentation. This approach keeps load times low, packs assets well for digital download, and supports ‘open-world’ rendering. Here the pool approach to managing IBs/VBs is used. There is also dynamic geometry submission which is often used for terrains, deformable/destructible models, etc. It is not an efficient in terms of GPU bus bandwidth, so games often have a mix of both static and dynamic geometry. In this case, the Direct3D Map DISCARD update pattern typically means you are only using a single IB/VB (or for multithreaded rendering scenarios, dual IB/VB which you swap filling/rendering each frame). 

As noted already, you cannot create a TextureArray with different formats or sizes. They all must have the same for both. That said, the binding limit for simultaneous textures with Direct3D 11 and Feature Level 10.0 is 128, so you could just bind up to 128 individual SRVs in a single pass. TextureArrays already require Feature Level 10.0, and Feature Level 9.x can only bind up to 8 textures at a time. 

Direct3D 9 and prior optimization is quite challenging. You have to handle the 'sea of caps' where specific hardware and drivers can remove almost any caps bit and expect apps to handle it when in fact few do. This really complicates the 'feature fallback' problem. With Direct3D 10 or later, the 'sea of caps' problem is greatly reduced by the Direct3D hardware feature level where each new feature level is a superset of the older ones. You pick a minimum feature level for your game, perhaps scale up to a specific higher feature level or two, and not worry that individual hardware caps will disappear at these higher levels. With all versions of Direct3D, you still have to scale based on performance. A Feature Level 11.1 device is required to support hardware tessellation, DirectCompute, and a whole slew of other features including everything a Feature Level 11.0 device supports. This says nothing with how fast the hardware is at doing any of this. For example, the WARP software device supports Feature Level 11.1 but is much slower than dedicated video hardware. The typical solution here is to have some basic assumption of 'good enough' settings and allowing users to tweak settings as desired. Ideally you can do a benchmark to make the initial settings more accurate, but it's still a pretty open ended problem. Developers use display resolution scaling, level-of-detail artwork, turn on and off individual features, etc. to try to provide this flexibly. This is the main way that consoles are easier to target than PC because you the developer can do all the tuning in development and know the user's machine is basically the same. This process on PCs is complicated by aggressive power management and heterogeneous GPUs (i.e. the laptop/tablet has an integrated part, but if you dock it or plug it in it can use a dedicated GPU). The device id ( / or / ) is typically only used to generate a warning--like I do in Anatomy of Direct3D 11 Create Device--or as a workaround for a specific driver bug. It's not a safe way to handle feature detection or to do performance scaling.