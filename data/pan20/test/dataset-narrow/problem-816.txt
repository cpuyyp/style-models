The displays the actual memory available on the column. Linux uses unused memory for caching disk I/O. 

I typically use SAMBA's native functionality for permissions and groups management on shares. For example.. 

I'm a huge QMAIL fan. It hasn't had a security issue ever. The toaster makes it easier to throw a box up if you're less familiar with it. 

I'd probably write a quick script and run it with . Without nohup, your loss of connection would cause the script to quit running due to bash's SIGHUP on exit. will make the script immune to sighups. 

The Practice of Systems and Network Administration is one of the most fundamental books for the field. 

Linux defaults to pretty high on the kernel level these days, so you likely won't have to tune outside of SQUID for the FD. If you provide log output, chances are it will indicate the exact issue, and we could provide more detailed recommendations. 

That's right, you can use CIDR notation too! Generally speaking, the best default policy is for all chains. Every chain has a default policy, which is specified by the flag. Even if you have your policy set to default , it is still advised to have the final entry in a chain to be a as well. For example, to change the policy to for the INPUT, FORWARD, and OUTPUT chains: 

I like Nagios and Cacti, which I use for both Windows and Linux. There's a ton of tools out there. Some of which are better suited for special purposes too, such as NMIS for types of network monitoring. Check out the comparison of monitoring software, which is a rather comprehensive list. There's a variety of methods of monitoring that can be applied to the particular application or service. It can be as simple as opening a TCP socket to verify that Apache is up or as complicated as a script that was written to connect to the socket and verify a specific function. Really, the options are only limited to your imagination. Notification methods are numerous as well. e-Mail and SMS to page a phone are common solutions these days. Ultimately, this is a large topic and your question is quite ambiguous. If you clarify, we may be able to provide additional recommendations. 

That's one of the standard ways to specify the umask for Apache in CentOS. If your init script (/etc/rc.d/init.d/httpd) sources the /etc/sysconfig/httpd file, either the umask is not specified or something is overriding it. How are the files being created? 

If these tools are in place properly, you will have an audit trail. Otherwise, you're going to have to perform a full penetration test. First step would be to audit all access and change all passwords. Focus on external access and potential entry points-- this is where your time is best spent. If the external footprint is not justified, eliminate it or shrink it. This will allow you time to focus on more of the details internally. Be aware of all outbound traffic as well, as programmatic solutions could be transferring restricted data externally. Ultimately, being a systems and network administrator will allow full access to most if not all things. With this, comes a high degree of responsibility. Hiring with this level of responsibility should not be taken lightly and steps should be taken to minimize risk from the start. If a professional is hired, even leaving on bad terms, they would not take actions that would be unprofessional or illegal. There are many detailed posts on Server Fault that cover proper system auditing for security as well as what to do in case of someone's termination. This situation is not unique from those. 

Say you have three subnets and a server on one of them, but want to see what rules are open to the other two. I run a nmap scan against the other two from the server. I typically use this line: 

If you have enabled, following the instructions below. However, if this was not already in use, your schema will need to be recreated in full for the space to be freed. With InnoDB, you need to the table. Newer versions of MySQL also perform the same function with as well. Be careful with large tables, as these commands lock the table. 

I am assuming an operational replication configuration with your MySQL servers. First, you create the database on the master. On the slaves, you update your cnf specifying for the new databases. is configured in either the cnf or as a flag () and cannot be changed dynamically as a variable.td From that point, you can populate the schema and master on the data and replicate down. You can also create and populate the database on the master and all slaves then enable . The key is making sure that the data matches before enabling replication on the slaves. 

djb as in Daniel J. Bernstein? He has a limited set of software that he has written, you are not going to replace many FreeBSD "utilities" with his software. I am not confident that you understand what you're asking. I use his software regularly and greatly appreciate his approach to secure software development. However, his lack of consideration of standard UNIX conventions such as the Filesystem Hierarchy can be frustrating. Last I heard, Theo removed djb's software from OpenBSD ports due to his licensing and conflict over the filesystem hierarchy. You could replace your MTA with QMAIL. You could replace your DNS with djbdns. You could run a static content Web server with Publicfile. You could run a combination of tcpserver and daemontools instead of a more common superserver like *inetd. daemontools is very useful to keep software running in case of crashing, but you have to run in the foreground. 

If not groking the flatfiles, I typically use the commands or . If you have the system configured to use LDAP or NIS/YP system-wide, any command-line utility should share this functionality. Ultimately, for your solution to be infallible, you will likely have to write more complicated logic into your script. This is a good example of why IT departments often try to prevent too many technology variances. 

Create a new home directory, such as /chroothome. Have all users home directories live within that chroothome. chroot adminuser to /chroothome. For everything else, just use filesystem permissions. As far as your "bonus question," it isn't possible using native functionality. The inability for the chroot user to write to the root directory is a security mechanism by design. Of course, you can always modify the source code. Nevertheless, I suspect you could specify the user's home directory as /user1 and have the working directory at login be the one they could write to. 

As Chris identified, the default shell option for non-interactive shells is to not expand aliases. Here's a solution I've found to work. Write a script, enable the shell option, and source your aliases. Be particularly aware that is sourced at execution, which is why it has to be sourced again after enabling expand_aliases. My apologies for the initially incorrect recommendation. This was more obscure than I initially expected it to be. Script: 

Yes. Shadow password files were introduced later. I once had to upgrade Slackware Linux systems to support shadow passwords. I have a hard time recalling what version. However, I'd guess around 2.0. There's a Linux HOWTO1 with more details. Edit I misread initially. Passwords were never stored cleartext in Linux's /etc/passwd. Shadow password files were not always used in Linux, as stated earlier. 

These recommendations are off of the top of my head and not intended to be comprehensive. Check out Bastille, it's a series of scripts that implements best practices in Linux. Don't send authentication data over plaintext protocols. For example, disable FTP. If you send authentication data via Apache, use SSL. Disable and remove any unnecessary software including the GUI interface. Audit any files with the SUID bit set and remove. (This will severely limit non-root abilities. Understand the implications for each individual change.) Audit public writable directories and remove the writable bit. (Leave /tmp alone.) Avoid running any daemon as root. Research all multi-user software that listens on sockets in detail for security best practices. Avoiding adding users to the system is one of the best approaches. Multi-user systems require greater attention to detail. Enforce password standards. For example: minimum 10 characters, non-alphanumeric characters, using letters and numbers. This is to make brute forcing more difficult in case of password file compromise. Enforce this via the system. Lock out users after 5 failed authentication attempts with a minimum of 10 minute lockout. Maintain a password history so users can't use the past 5 passwords. If you have a larger environment, using network segregation with multiple subnets to isolate risk is an absolute requirement. If a smaller environment, running a firewall on the local system to limit exposure is recommended. For example, only allowing SSH to your IP. tcpwrappers can be used too for an extra layer. (/etc/hosts.allow, /etc/hosts.deny) And, of course, keeping all software up to date. Especially public facing daemons. With SSH: 

Edit Check out /usr/src/linux/kernel/Documentation/kbuild/kconfig.txt (or appropriate path). You can use some of their recommendations to script a solution. I would use a combination of scripting and textutils to accomplish what you describe. Edit 2 As an additional note, this is a bad idea. What if optional hardware support unique to your environment changes but isn't default? What if a negatively impacting changes occurs? This really is something that should be interactive. You can make the config and automate the rest. "make silentoldconfig" is a little less verbose, which might be helpful. It is still interactive. 

You can add to the but the performance will differ from a redirect. Edit Since you want to redirect and you don't need advanced functionality, it seems like using should suffice for you. You would put the under a VirtualHost directive. A client side solution would be to use a tag. 

FTP is unencrypted. SSH is encrypted. SSH allows remote shell access as well as file transfer, whereas FTP only allows file transfer. Any data transferred via an unencrypted protocol has an unusual risk for eavesdropping, which could compromise both access to your system and the data being transferred. One of the primary applications of FTP at present time would be for a publicly accessible anonymous file server. I would attribute this partially due to the commonality and simplicity of the protocol. Moreover, an unencrypted transfer has less overhead than an encrypted transfer, which enables quicker transfers. FTP for user authentication is depreciated and ill-advised, as it risks the authentication data for your system. 

In the Windows world, "mirrors" are typically accomplished utilizing Windows Server Update Services (WSUS). However, you may run into licensing issues if you want to provide that for free as part of your ISP services. 

If you want consistent IE compatibility for your SSL connection without errors, you will need to have multiple IPs. If you are positive that you are going to stick with the list of hostnames you identified for at least a year, I would go with UCC because it is cheaper. If you anticipate a need to throw up a bunch more SSL vhosts later on hostnames under the same domain, the ROI is with the wildcard cert as you would not have to buy a new certificate. Both UCC and wildcard will be implemented the same way and maintenance will not be variable. 

You would think more people would remember multi-user systems and how it's often acceptable to run software from your home directory. Nevertheless, you should confirm it is okay with your host. If the system does not have the dependencies to compile from source and your administrator will not install them, your best options are as follows: 

If your chain is incorrect, the most likely scenario is that people who do not otherwise have the full root cert chain for your CA's issuing certificate will receive errors. EV certificates are fairly new. Even Thawte only introduced their full EV chain to more recent versions of browsers. For example, Firefox 2 and IE7 would throw a verification error unless the root certificates were updated. IE6 and Firefox2 will not display the green bar even if the certificate verifies without error, as the browser does not have support for displaying a green bar. There are various workarounds that including adding the full chain on your servers and client-side JavaScript "magic" that the CA will provide, which will update the client certs. 

postmaster is among the standard aliases that all SMTP servers should have available. Microsoft often ignores established Internet standards with their software. Point being, it is rarely safe to assume that the Microsoft approach is the right way. From RFC822: 

Groups and SGID. would have group membership in and you would set everything group writable under . Set user1's home directory to . You would also want to set the SGID on and all directories under it, which would cause permissions to be inherited. (g+s) Be aware, user1 would have access to all Web content. You could use a different group to limit the scope of the access. SSH (SFTP/scp) is recommended for user authentication as opposed to FTP, as the authentication credentials will be transmitted in plaintext with FTP. 

If you want to restrict to host and do not want to specify based on a subnet or wildcard using , that's the only way to do it. More details are available in the MySQL documentation. I am still trying to find ways to eliminate overhead when managing authentication to large MySQL installations and have yet to find a perfect solution. 

Note, removes all created chains. flushes all rules. There are native tools to save and restore the rules. Particularly, and . Most modern Linux distributions have and functions within an iptables init file provided with the system. There are other firewall best practices, such as dropping malformed packets and other type of undesirable traffic. This is one advantage of using a front end utility such as Shorewall, as it will implement many of these polices by default. Nevertheless, I agree with your approach and prefer to maintain my own rules directly as well, and these same best practices can be implemented without a front end. 

Prefix the command with to keep it from terminating. To resume the program, run the program within a session. 

While Richard's answer is the common solution, check your log. It's possible MySQL is running out of memory and restarting. I've also had this recently happen with failing hardware. 

The manual is published on the Internet. Two methods are suitable for connecting to the switch. The switch should come with a RJ45 to DB9 connector, which you can use any standard DB9 to USB adapter if you only have USB. This is the preferred method. Also, the switch will acquire an IP address from DHCP or Bootp servers by default. Once a lease is acquired, you can connect to the switch's IP via either telnet or a Web browser.