Buttons (controlls) and graphics handle on browser. With javascript, there is lot of drawing libraries, well, even game libraries (craftyjs, gameQuery ...). State a current game has will be on server in a database. 

Physics Engine takes care of positions and sizes. Game Logic Engine takes care of interpreting what Physics Engine changed (he could obstruct some waypoints ...), what goals characters have and what behaviour they should be doing, he runs scheduled scripts (this think function). Drawing Engine draws what objects are visible, and he knows what objects are visible because Quake engines kind of cheat here (see Draw section). My advice to You is to rather study how simulations are done rather that game engines. There is a huge pop-culture relating game development and game engines are made in imperative languages (because of tradition&speed); so it was more enlightening to me to get good textbooks (rather theory) and THEN look at engines (practice) rather than look at engines and puzzle for hours how they did it. Physics Whole notion of iterate all entities and do {think, draw} will probably lead to problems. There will be conflicts and so on. I belive Valve have Havok and I guess Havok takes care of enough-correct physics. Think Think function is run when a time in a game equals time in nextthink. It works this way in Quake engine, and Quake engine is basis for Half Life engines. It is NOT run every time. Internally it should be a simple iterating through a list of entities and checking if time has passed to call think function. Time complexity will be O(N), where N is number of entities. If there is a very large number of entities You should measure how much it will improve the fps. Note, that because of Amdahl's law it is potentially invisible speedup. I mean, You just iterate trough all items and decrease&check one number. I would speed it up by sorting entities by nextthink (create list of pointers to entities and sort it each time; not array of entities, because entities might change their nextthink anytime, so rearanging them in array takes O(N) instead of O(1) in list). You should also look at O(1) scheduler in Linux. Draw Engine draws what is approximately visible from area at which is camera. Game level is partition into a tree, and a area is leaf of that tree. I won't bother You with details about it... So if an entity is visible it is put into a set of visible entities and they are drawn. They store what areas are potentially visible areas. It is called "potentialy visible set", PVS for short. There is visualisation of PVS, green capsule is player and around him is rendered what his PVS contains. 

I am developing 2d platformer and I've faced with a very strange triggers behaviour in Unity. I have made the enemy that can throw objects into main player. So I have made two empty GameObjects with Circle2D colliders on them and attached them into the enemy GameObject. The first trigger ensures that when enemy hand will pass through it, it will spawn an object that will be thrown in future, and the second trigger is responsible for the throw that object into player. The first trigger ensures that when the enemy's hand will pass through it, it will spawn an object that will be thrown in future, and the second trigger is responsible for throwing an object into main player. Every trigger has a Rigidbody2D component attached to it. The hands of the enemy have tags "right hand" and "left hand" and I am checking the in the OnTriggerEnter2D method. This method is calling and I have log messages and this method is detecting that left or right hand are entering trigger. But the problem is in that this method is calling when the hand has already passed through trigger and get out of its bounds. Can anyone help me and explain why this is happening? I have attached a picture where I draw a scheme and described my problem. 

I want to know what options (or shaders) to set so that my OpenGL game looks like Playstation 1 game. I know it probably can not be achieved 100 % because PSX used television and television renders differently that monitor. Thanks. :) 

These steps You mention are most likely done in separate engines. It is just that simple game engines usually have them in one pass. Your sequence 

Like in physics. Only at the moment You press and character is on the ground add upwards velocity (it is called impulse), but make character fall by gravity all the time. If You do not want character to be jumping every time it hits the ground - because You are holding - add variable which You clear after is released and set after. Pseudocode: 

There is article about deriving collision detection with math on Flipcode. It has circle-cirle. There is how to detect precisely the point of collision and check if there is a collision at all. 

You can also store it in relational database, althought it looks like it is not necessary, if You want to make this game in big You might need to make one. You then have to parse these strings/things. Or You can use some scripting language like Python or LUA or language like LISP, they all can parse and execute it for You. :) How to use these events in game loop (2) You will need these two data structures: 

This gives you the damage value of 26 that your character would take Edit: having read the comments of the Op. There will have to be a hard cap on the percentage avoidance if he wants to avoid 100%. The other way to do this would have a maximum avoidance for each type of armor that does not add up to 100%. As it is also not described how these armor prices come to be. If they are pre determined values then it would be trivial to make sure they don't add up to 100%. If they are randomly generated simply put a cap on the maximum for each type. 

As you can see I've temporarily commented out the line which uses the texture color for shading and tried to replace it with vertex color. I've also highlighted in the code which lines i've changed to attempt to use vertex coloring. At the moment this only produces grey shaded models. I know there is vertex data on the models because i can use MonoGame's built in BasicEffect to see the coloring. What am i doing wrong? How can i modify the existing shader to use vertex color instead of texture color? Edit: Additional information I've tried using the BasicEffect in monogame to draw my objects and the vertex colors are coming through fine. It seems that i should be able to see the colors with my shader but i am not. With the BasicEffect 

You start these objects when they are demanded to start in action queue. these object can be used for other things such as some other timers. In Quake these entities are used for whole game logic, I recommend You to read some material about it. 

Do not allow click() handler to cause movement until some time passes Basically do not allow clicking faster than some value and allow it only once at the same time. :) There is how You can do it: Create global variable: 

In the game You find id and try to match id and the condition. You need to model the conditions and actions. By objects, function pointers, XML ... Good dialogue editor will be handy too. 

Map is a grid. Grid is a graph. A* works on graph, it is a graphs searching algorithm. A* should search few nodes of graph. As has been mentioned they can use navigation mesh. But the A* (or something similar) will be on top of that mesh anyway, because polygons of this mesh are just nodes of a graph; A* will then search for path from one polygon to another polygon. Not sure about Warcraft or commercial games, but there is also technique called Collaborative Diffusion and it is very simple; it is usually done on grid. There is also technique called Potential Fields, which is very similar to previous one if not the same. You might also try: 

This script is attached to the prefab of the object that will be thrown into main character by the enemy. This script is working, but in this case the object that was thrown will follow by main character all the time, because of this line of code: transform.position = Vector2.MoveTowards(transform.position, TargetPlayer.transform.position, 15 * Time.deltaTime); To my mind this is not good, because i want to give my player the opportunity to escape from the object that was thrown at him. For example run away. When the object reaches the player position (and the player is on the new position) - he will simply fall onto the ground. I did this, but this wasn't looking nice, because when the object was reaching his position, he was hanging in the air. Can anyone give me an advice how to make this process more good-looking? Edit: I need to make good-looking movement of the object, that was thrown by the enemy into main character. Every frame i am moving the instantiated object to the current player position. So the player can't escape from that object, because he always knows current player position. I think that this is not good idea, and i want to give to player an opportunity to run away from that object. In this case i am saving the position of the player into variable, and then every frame i am moving the instantiated object to that position. So when the player run away, the object, that was thrown doesn't know anything about new position of my player. But this is looking not good, because when the object is reaches its destination position he hangs in the air(( Edit # 2: I was thinking about destroying that object anyway, but to my mind this will not look good: the object is moving and suddenly disappears from screen(. May there is some ways how to make him smoothly fall onto the ground? The problem is in that this instantiated object has no Rigidbody2d component attached to it, so it will never fall down by itself. 

Each has its own pros/cons. You seem to me to be quite new/unexperienced to programming. I would recommend You to do some more excercises in general programming. Data structures and algorithms. Quite nice book about programming is C Programming Language, the language it is for -C- is similar to Flash. You should also try searching stackexchange for recomendations on beginners book/tutorials on programming. 

I present simplistic solution. It can be extended of course. I think simple list of (verb, object1, object2) would solve it: 

and it means that "jumping superhigh" is obtained after You have "running fast" and "antigravity's child" talents. Other solution I have not played Diablo recently but it might be, that it had only: 

The way around it is to have/create a memory where You store information WHAT should happen and WHEN it should happen. Then memory should be checked whether time has elapsed (in WHEN) and if it did, then do that WHAT should happen. You can acomplish this in several ways: 

You have to figure out rules of communication (communication protocol). Also there is a chance, that some of javascript game libraries has methods to help You handle communication. 

Compute bounds of Your shape (one You want to place into grid) which are consistent with the sorted set. If You are lucky Your shape would be small enought to be enclosed by one in the sorted set. Finding which one it is is O(log N) for binary search. Also note, that if You know what sort of shapes are going to be there You can precompute more. 

Total reduction = 35% Then for example if your character is hit for 40 points of damage you would do the following: 

I should mention that I'm pretty new to Matrices and will probably need a layman's answer to my question. I have a 4D matrix which represents the rotation of an object in 3D space. I have a normalized 2D vector which represents the direction i want the object to be facing by rotating the Y axis. I need to be able to change the Y axis rotation of the object only, by applying some sort of calculation to the XZ vector i have. What do i need to do to make this work? And if possible, can any answers come with an explanation of the process so that i can do it again on my own in the future! 

Edit: Additional Information Here is the code in the draw method i am using. The un-commented part is using my shader, while the commented part is the BasicEffect that is set up when the model is loaded. 

I'm trying to render a generated mesh using libGDX which acts as a java wrapper for openGL. The issue i'm having can be seen in the screenshot below. The faces of the mesh that should be hidden by closer faces are being drawn on top of the closer faces. There is probably something really obvious that i'm missing but i cant quite work out what it is. How do i get the draw order/culling to be correct. 

You can smooth or create some fractal details on it (usually when dimensions of array are small). Don't do collisions by hand, You might run into problems with speed, penetrations ... Use Box2D convex polygons for sidescrollers (Scorched Earth). For topdown RPG like games ODE, Havok, Newton, Bullet ... seem to have support for heightmaps, sometimes even natively. 

This way You can have talent A unlocking B, C and D ((A, B), (A,C),(A,D)) and talent Y unlocked by X,Z and W ((X,Y),(Z,Y), (W,Y)). In imperative/procedural/object-oriented language You would do it as list/array of pairs like there: 

Data is key to programming. If You desing Your data good, algorithm usually emerge from them (if You don't count some numerical algorithms, like computing determinant). 

Use Event Calculus. Then make some preconditions and actions which are applied after preconditions are met: 

It is same as waypoint pathfinding, only instead of way-points you have way-polygons and You can infer few things about navimesh from it: 

You can optimize Brute force search: For each point in plane compute how big disk (for example, can be arbitrary bounds) can be placed without colision. 

One way: You might look at Box2D source code, or collison source code in Java. Other way: I understood logic behind collisions from article about collision detection on Flipcode. I took a piece of paper, wrote down and derived what he wrote about. Then I was able to code it. Math helped me, it might do for You too. (I believe that Youry rectangular 4way is on the beginning) 

I need to combine both camera that follows the player and the camera shake effect in the same moment. The problem is in that, if I make the shake effect for the camera, then the camera doesn't follow the player and if I make the camera follow the player, then the shake effect doesn't appear. The basic idea of my script is next:` 

I have trouble with Animator in Unity2d. I have a main character for my game. The character has his own animation clip for fighting. When the player touches the screen, i am starting animation. When the player touches the screen slowly (every second) - everything is working fine, but when the player touches the screen fast, the animation clip is playing about 10 times, and then nothing happens (the clip isn't playing). I've checked - the touch event is triggered normaly, may the problem is with animator. Does anyone have ideas how to fix this issue? 

Does anyone have ideas how to combine these two things (camera shake effect and camera that follows the player) at the same moment? 

May be this is because of that at the end of my animation i have an animation event which calls the method, that stops animation. 

I have two character in my game: enemy and main character. Enemy can throw different objects into the main character. For this moment i am doing this action in such way: