Now we would like to alter the velocity each frame so that we can add gravity. According to the exact same source . Therefore we can apply the exact same principle: 

I am really just throwing ideas around here. Assuming you have (at the very least) the position and position; for each frame. You would need two separate broad phases, followed by your narrow phase: 

Limit the value of the angle between them (remember your trig functions probably work with radians, so try 0.1 as the turning rate). 

The problem is that XNA on Windows Phone doesn't have custom shader support - so you can't write a vertex shader or pixel shader. However, you can use a trick described by Catalin Zima that deforms a vertex grid to achieve the same effect. If you are not targetting Windows Phone 7, you can use a trick that I described on my blog. Copying the relevant bits in: These distortions require 2 images. Firstly you need the entire scene as a render target (i.e. Texture2D) as well as the distortion render target. Typically you would use a particle system to fill the distortion render target; using special distortion sprites (example below). Each color component in the distortion target (and distortion sprites) represents the following: 

Sure, but even though it is hidden, everything applies. Flash for example has a loop for code execution, and you cannot specifically edit the main loop, you however can use different events to trigger code, or have code on the timeline which flash executes when it hits it. 

No it will not create performance issues as long as the quantity of checks per frame are not too much for the engine to handle. For a physics engine on a modern computer I don't think there would be any problems with anything less than 1000 collision tests a frame, depending on your physics engine you can have many more tests per frame. 

As you said, the only ones I have found are either betas or alphas with none seeming to be ready for release. At this point in time it is probably better to roll your own: 

Now when you need to fill the buffer all you need to do is go over each triangle (in order) and append it to your vertex buffer. You don't need to worry about the indicies as those are constant. This is very similar to how sprite particle system works (except the indicies are not constant). You can also skip filling the vertex buffer each frame by additionally passing in the , and into the vertex buffer. You can then have your vertex shader animate each individual vertex. 

Getting a value from that list would merely involve choose a random index (given the count) and indexing the list directly (). 

Try using a 32bit index buffer instead of a 16bit one - it looks like you are running out of indicies. What you could look into is an engine with scene graph support. A scene graph is essentially a tree of nodes - where each node is attached to a parent via some matrix transform/translation (sound familiar?). If you are not allowed to use middleware a scene graph is somewhat trivial to implement; and there is a lot of reference code out there (e.g. CodePlex). 

That kind of modeling is strange, and can produce weird illogical results. Especially if the starting planets speed is really slow. Model the ships with a thrust power. When the ships are on their last orbit on the starting planet, accelerate with full thrust. When the ship gets within a certain distance use reverse thrust to slow the ship down to the target planet's orbit speed. Edit: Do the entire simulation at once when a node is about to leave the orbit. either send all the data, or send just a few of movement vectors at intervals, and interpolate between them. 

Take pop culture item, draw it with cute colorful cartoon art, advertise the hell out of it, offer a free demo, and make it a super Casual game with shiny things and little "ding" sounds going off all the time. There, the secret is out. 

Frameworks like SignalR deal with all this complexity for you (really, SignalR is just pure awesomeness). Combining the Two In terms of your question as a whole here is how I would deal with things. A throbber would be anything, possibly make the building/whatever transparent or display a spinner over it. It basically tells the player - "if you close your browser now these things might never happen". 

Typically if you are connecting from a separate country you can expect latencies of up to 400ms, or 600ms if your connection is bad (and even over 1s if you are using TCP and the packet loss is high enough - which it probably will be). Anything over 30ms can be perceived from the average user's perspective - so you are fighting a losing battle. To further compound the issue latency can vary/change (and as the average latency get higher so does the variance) - for example at 180ms I often get about 20ms variance on a premium priority account: this means that a packet takes between 170ms and 190ms to travel from South Africa to Europe on the most stable bandwidth available here. (This is also called 'jitter'). Jitter and latency are two defining characteristics when talking about lag. Most people see them as the same thing; when in actuality they have different outcomes: latency delays the outcomes of your commands, jitter makes things move forwards and backwards or erratically. We compensate for this using two strategies at the same time: client prediction (solves average latency) and interpolation (solved latency variance). Both of these are described in depth on a large amount of websites, so I will only briefly touch over them here. Client Prediction Essentially what the client does here is it anticipates what the server might be sending it at some point in the future. You basically need to resolve the difference in time between the server and the client: in 180ms I will receive a packet from the server telling me where this unit is, but in reality it's actually sending that packet right now - so I will chance a guess and move the unit to where I think the server will say it will be given its velocity, acceleration and sometime even information about the controller (mouse, keyboard, game pad) of the person controlling that unit. Interpolation This is when the client says, "OK, I am getting irregular updates from the server even though it is sending them at regular intervals". What we do here is instead of updating the unit to where the server says it is each time: introduce delays between updates from the server and let the client figure out where the unit is in between those delays. To do this we use a very simple function called 'lerp'. Fine Art The fine art comes in when you need to trick the user and make them believe that things are happening as they do them (where in reality that signal takes time to reach the server). For example in the case of the 'move command' above what we could do instead is: 

with each frame of animation inside. It will be much more efficient on video memory usage, as you are only passing each frame of animation when the video card needs it, instead of loading everything in at once when you at most will be displaying one frame at a time. Save all the animation as a png sequence inside a folder of the same name. (bigBG/bigBG0001,bigBG/bigBG0002.....) Create a method that all you have to pass is the name of the folder, and have it make a sprite and add it to a 

I think adding the solution to each new project is the best and easiest way to accomplish what you want. You can open two projects up at once, and drag the solution from one to another, it takes seconds, and it stays very organized. 

My math might be a bit wrong, so I have wikied the answer. I assume you want to do the continually homing scenario - where the missile P1 travelling at a velocity V1 constantly tries to turn toward the player P2; but at a limited turning rate. 

Zacharmarz briefly touched on it in his comment; however, it's less about performance and more about configuration. In the first example the sampler state is left uninitialized and works just like any other parameter (e.g. your ) - this would allow your game to change the sampler at runtime. Conversely your shader won't work if you don't initialize the sampler. Most often you will see this syntax in conjunction with custom shaders as they would allow the to provide crucial configuration. In the second example the sampler state is 'hardcoded' into the shader. This means that once the shader is compiled it's set in stone - your game can't change it if it needs to. Both techniques are just as viable as the other - it all depends on how you intend to use the shader. If you need the sampler configurable use the first, if you require that the sampler is always in a predictable state use the second. It is much more likely that you will be using the second method. 

No. Every electronic game thats some sort of updates in real time use a game loop. The Only kind of game that wouldn't really use a game loop would be txt based game that reacts to user input only. 

No, Test Driven Development is not suited for Game Development. Sure you can write tests for some parts you do want to test, but the Game Development process is completely different from Test Driven Development which requires having exact specifications before progress is started. Games rarely have exact specifications when started. And if they do, they always change and evolve during the development process. Game design is an art, you can't have specific tests to know when art is good or complete. 

You don't want to find the closest point. You want to find the point on the lines where the distance is equal to the combined radii of both spheres. 

You have the completely right idea by starting with something simple. However, minesweeper is a trivial program for most developers - you might try something even simpler. Maybe even start with programming something other than a game - maybe "Hello World" or such. Try something even simpler, maybe a text adventure. This might give you the mind-set you need to make a minesweeper. Off topic: People on any StackExchange website (StackOverflow included) don't take kindly at all to people asking for 'code'. Demonstrate your due diligence to us, and come with specific problems and we will be more than happy to help you out with any problems - but asking for an entire program will be met with a closed question and sometimes some hostility. 

Particles Use particles to simulate the water. During rendering using additive blending and then apply a multiplication function to the alpha channel to give the water crisp edges. Pros 

My main goal is avoid using an external program like SpriteSheetPacker. I would like to just use sequenced PNGs and have the sprite sheets be made, updated, and saved automatically when I build my game. Edit: The old answers I upvoted, but I updated the question and specifically asked how to do this automatically with the Content Pipeline. Please do not give an answer that involves using an external program. 

Put a cheats menu in the pause menu. Before you allow the cheats to be used, warn the user that his current game/score will be invalidated if he wants to continue and use the cheat, but only warn for the first time in a session if they are using a cheat, so if they use one they can use the others with impunity. Allow a user to unlock them somehow by playing through content of the game. If you want to give them the codes you can either have the cheat code number be reviled to them if they reach a certain part of the game or reach a certain score, or unlock a certain achievement. Alternatively you can have the user just unlock it from the menu when reaches whatever criteria you set for it. 

I would strongly recommend at least experimenting with a procedural approach to this. Essentially what you need to do is find the normal of each triangle face, and choose a extrusion distance (just a constant that you can tweak, most likely). Following that create a new set of vertices for each triangle offset by (they can likely inherit the UV coord of their original vertex). Finally wire them up in the index buffer - which you can keep as static data (so long as you retain the order of the triangles). This can be done when you load meshes that can explode; or as part of your build phase. Remember that shared vertices (arising due to index buffers or such) need to be duplicated. I would essentially store the data in something like the following structure: