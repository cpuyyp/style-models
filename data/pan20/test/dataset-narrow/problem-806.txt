You seem to have installed the NVIDIA proprietary graphics drivers on the host. If you mean to use this card on the guest, and you aren't using any other NVIDIA cards, try uninstalling this driver. 

This email came from outside your server, from the indicated IP address. Postfix is configured to pass it to Amavis for virus scanning, and when that is complete, Amavis passes it back to Postfix for delivery. This is why there are two localhost Received: lines. One is added by Amavis when it processes the message, and the other one when Postfix re-accepts it from Amavis for final delivery. 

Another issue you have which is probably causing you grief is that your block does not have a valid defined. This is one of the most common nginx misconfigurations. It should be something like: 

This is generally the first attribute I look at on a spinning rust disk. Anything other than a zero raw value is a potential problem, as it means parts of the disk surface have been marked as bad internally, and reserved space is now filling in for the bad sectors. With large numbers of reallocated sectors you'll see performance problems, and eventually, lost data. It will have to have a lot more bad sectors before SMART actually shows it as failing, but you can be sure that it is failing now, and should be replaced. 

Keep in mind that this will allow outgoing connections to anywhere. The secure fix is to write a local policy confining and allowing it to connect to port 5037, access USB devices, etc., but this is a lot of work... 

Delete at least one of the old kernels, as alexus said. Then: Edit and specify the limit of the number of kernel versions to keep. It's set to 5 by default, but your system seems to be capable of handling only two: 

HP provides support and warranty services for their own branded hardware. The same for Intel. That's it. So if you have an HP server, you use HP components to keep your warranty and support contracts valid. If you stick third party hardware in it, even if it works, you can't get support for it from HP. 

means that another process is already listening on port 80. Only one process can listen on a given port at a time. To find the process, run as root: 

Using the flag writes your changes to the persistent configuration, but not the running configuration. Run the same command again without the flag to have it take effect immediately. Beginning with RHEL 7.1 and current versions of Fedora, you can also copy the running configuration to the permanent configuration with: 

But this has to be done server-side, based on specific conditions. You can't do it from the client side. 

If you're using raw image files then the only way to get a consistent snapshot is to suspend or shut down the VM. You can take a snapshot using qcow2 image files without suspending the VM, but the snapshot becomes part of that file. This may or may not be appropriate, depending on your situation. You would have more options if you were using a CentOS 7 or current Fedora hypervisor, such as snapshottable LVM volumes or ZFS zvols. On these modern systems you would the guest, take the snapshot, the guest, and then backup the snapshot. This requires the qemu-guest-agent running in the guest. 

Don't bother with this proposed kludge. Just set the VM to have a fixed MAC address. Edit the VM settings in vSphere Client and set the MAC address to Manual (then specify an address). 

When you run as root, you are not prompted for the old password. As any other user, you are prompted for the old password. 

You can't do anything with the system time inside an OpenVZ container. If the host refuses to fix the clock, go take your business elsewhere. They obviously don't want your money badly enough. 

You also need to install the RPM to provide compatibility with system packages that were built against a lower version of MySQL. The current filename is which you can find at any mirror site. If this fails to resolve the issue, report a bug to MariaDB. 

Alternately, you can forget all that, and create a new virtual network which is isolated, and give each VM a second virtual NIC which is connected to the isolated network. The VMs can then communicate via this network. 

It decided to kill the child with pid 20977, a shell script that was spawned by the process. If you want Linux to always kill the task which caused the out of memory condition, set the sysctl to 1. 

Don't reinvent the wheel. Use logstash to get your logs off your systems. Have logstash send the logs to elasticsearch. Use the kibana front end for analytics. This combination is so common it's known as the ELK stack. And it's all open source. 

Later you should look at doing caching within your web app; if it writes generated HTML files to the disk, you could then have nginx serve those files directly out of its cache. 

First you need to move to the right, so that the unallocated space is before it instead of after it. Then you should be able to resize . 

Depending on the program, they may also need various options passed to them. Contact the program author if you have trouble. 

The second problem is that you specified a different hostname in the field than you are using in your web browser. While Apache is expecting , you are using . Since Apache doesn't know what to do with those, it punts, and you get your default virtual host. To resolve the issue: 

If you're just sending email on behalf of an end-user, who originates the email within your application, use authenticated SMTP to port 587. You can send mail to some servers via the SMTPS port 465, if the remote MTA is SSL/TLS-enabled and listening on that port, but don't count on it. Otherwise, advise the user that they need a business-class ISP. 

This change takes effect when you shutdown all VMs using the network, stop the network (), restart the network (), and restart all VMs using the network. You will then also have to insert your own masquerading rules, if you want the virtual machines to access the Internet. For example, in the nat table section of : 

First, tell the security department to stay out of things they know nothing about. Second, nginx in EPEL is clearly getting regular updates. Finally, if you really need to keep up to date on nginx (and I do recommend it) then just use nginx's own stable repository. It's always up to date and should make security happy. Or at least less mad. 

The nginx documentation clearly says that if you want to change the response code, you use . For example: 

Using with any timestamp suffixed by requires systemd 228 or later. This functionality was added in systemd 228. From the systemd changelog: 

Before you continue, it would be a good idea to fix your Internet connectivity issues. Anyway, is provided by the package. Install that RPM (and any of its dependencies). 

None of those obsolete options you placed in have any effect anymore. And Google will prevent your IP from being spoofed; you don't have to worry about it. 

You're missing a rule to accept traffic based on existing traffic (the rule that makes iptables stateful). This should be your very first rule: 

Your directive is not valid. This setting controls which IP address ranges Postfix will allow relaying from. It should consist only of your internal servers and networks. It reads: 

On Debian derived systems, is already present. On Red Hat derived systems, it is absent, but a sample file is located at ; just copy it to . 

You didn't set reverse DNS (PTR record) for your IP address correctly. Set a PTR record for your IP address which resolves to a valid hostname, whose A record resolves to the same IP address. 

If you want to use a wildcard address (listen on all IP addresses) in a , you need your directive to be listening on all IP addresses. 

I recommend you bring your production (and your development!) server up to date if you need this functionality. nginx 1.0.5 is very old at this point. 

I have often heard it recommended that a user account should be disabled by setting its shell to . But, on my existing Linux systems, I see that a great number of existing accounts (all of them service accounts) have a shell of instead. I see from the man page that prints a message to the user saying the account is disabled, and then exits. Presumably would not print anything. I also see that is listed in , while is not. The man page says that FTP will disable access for users with a shell not listed in and implies that other programs may do the same. Does that mean that somebody could FTP in with an account that has as its shell? What is the difference here? Which one of these should I use to disable a user account, and in what circumstances? What other effects does a listing in have? 

is redundant. When any other options are in use, it can be omitted. It only exists to fill the relevant column in . And since is already a default, it too is redundant. 

"Couldn't resolve host name" for something well-known that should be working, is a pretty obvious indicator that something is wrong with your DNS servers. Check and change them if necessary. 

If you shut down MySQL by killing it directly, then when systemd tries to run the script to stop MySQL, it returns failure because MySQL wasn't running. You can ignore this, but in normal circumstances you would never kill the MySQL process. You also would not use on a systemd-managed service. Use systemd to start and stop it instead. 

The security context for your home directory is wrong. I'm not sure why setroubleshoot didn't catch that, but the simple fix is to fix the security context. 

You need to make sure you have the RHEL optional channel enabled. Many packages from EPEL require it. The process to do this on EC2 differs from the normal process. Do it the easy way with : 

Unfortunately wget cannot parse JavaScript, so spidering such a site is quite difficult. The good news is, search engines don't generally parse it either, so they are most likely feeding slightly different content to search engines (which is a bad idea for other reasons) so that they can get their pages indexed. They have to feed search engines pages which are reachable without JavaScript if they want to actually be indexed. If this is the case, you can work around it by spoofing Googlebot with wget, such as: 

This is meant to help prevent erroneous or malicious SPF records from contributing to a DNS-based denial of service attack. In your case, the problematic part seems to be: 

If you've updated your puppetmaster to 3.0.1, you should update all your puppet agents as well. Or vice-versa. 

Yes, you are up to date, and not vulnerable to these particular vulnerabilities. To resolve this, you need to look up each CVE at Red Hat and note the status of the package. In some cases, a backported fix will be available. In others, the package won't be vulnerable because of various factors (for instance, the vulnerable functionality may not be present in the vendor's build). In the case of backported fixes, if you have the same or a newer package as that noted in the advisory, you are fine. You simply note that your package contains a backported fix and use the information from Red Hat as evidence that the fix has been applied. For packages listed by the vendor as not vulnerable, just provide the information given. In this particular case, the CVEs are: