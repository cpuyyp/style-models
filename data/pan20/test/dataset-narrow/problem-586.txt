You can override to perform the same function as in your code. Then, you could override to get the quantitative part and append the unit name. For the purposes of outputting your measures to text, and for debugging with e.g. Firebug, that would be a plus. As for factoring, it would be more flexible if you kept units of length separate from units of time. 

No, not in terms of complexity. Other reviewers have offered good, proven ways to optimize by reducing the constant term of the running time, but reducing the complexity is impossible given the nature of the problem. By definition, a long-addition operates on some fixed size of data at a time - in your case, base 10 digits with values 0-9. You can pick the idea apart in a lot of ways; reduce the number of digits by expressing your number in hexadecimal or base 64, for instance. No matter what digit you choose, there is a number that will not fit in it, for which you will need multiple digits, so adding two numbers with digits can always produce a number with digits. Even in the case of BigNums, which can be thought of as strings of digits in base 4 billion+, if you're adding one fixed quantity of data at a time, you must touch on each datum once, which makes your complexity O(N). 

Each of your subclasses has a different set of erroneous and valid inputs, but you can easily define the behavior of those three states independently: 

Notice that in that example, I have expanded your set of subclasses considerably and even added a level of hierarchy (the two types of ), and the manager can handle them without writing any additional code. Alternatively, if you want to keep your existing queries as shortcuts, you should still write the template method shown above, but you can make it private, then invoke it from the non-template query functions. That would still require you to add a method every time you add a subclass, but it would be very easy to write and maintain those methods. 

It seems a bit inconsistent to use the term "decimal" for an in system representation. It would just be confusing, if not for the problematic differences in function signatures between each of the functions. If it was more uniform, you could: 

just screams "I am extracting a single bit from the number and printing it!" to me, whereas with and , it seems like you might be calculating something at first glance. And, if you really like brevity: 

Now, your tests for all of your classes are reduced to the task of generating the input test cases and expected states they will generate. For the , that could be easily expressed in two arrays; you might want something different for your more complicated rules, since the criteria are presumably individualized per object for those subclasses. I might go with something like a generator. The concept of a class is helpful for BDD when you have specific class invariants, but with javascript you are by no means limited to a one-to-one correspondence between a class (constructor/prototype) and its defined behaviors. Like anything else in software design, you can tell your unit test is wrong as soon as you type the same thing 2 or 3 times. Usually, you can fix the repetition by making the object of your suite (parameter to ) something more applicable than the name of the constructor. 

Assuming the constraints are that you must have classes defined in a single block, you must be able to create objects by providing a string instead of a reference to the constructor, and you must use JavaScript: 

I am going to assume your table rows are for a real table, i.e. they're full of data itemized to present to the user. If this is not the case, do not use tables. Only use tables for layout if you are a real cretin that wants to exclude visually impaired persons with screen readers from using your product. I would look over all of your s and see if there's a more sound tag for them. implies a logical division with no semantic significance, so if you're using them just to divide your page visually, there is probably a better element to represent the content that can be visually blocked the way you want with CSS. The reason I suspect this to be the case is that your HTML contains only , , and table-related elements. Unless the web app is truly something the HTML standards committee has just never thought of, either the tables, s, or both are being used inappropriately for layout. Previous reviewers have mentioned replacing some of your IDs with classes and/or changing the names that include "body", as well as unwrapping some more meaningful elements from their enclosing s. These are all good ideas. I'm not certain that the rationale has been stated, though. attributes are a good idea in the broadest semantic sense when the element serves a role that is logically necessarily unique among all elements. They are additionally necessary to target anchors and elements. Long long ago, they were the most logical way to make an element accessible from JS, but preemptively ing almost every element in case it's needed in JS creates a maintenance hazard that can now be avoided. If it's conceivable that there could be more than one (there are two sides after all) in some future revision, for example, adding it will involve more work and possible catastrophic name collisions if you're identifying everything with IDs. You'll basically start defining what a sidebar is and should look like from scratch in the page's CSS and JS. Then you have to maintain that code, too. The attribute allows you to assign similar styles and behaviors to the elements that share them. If two elements share any stylistic or functional aspect, they should share a . Unwrapping elements from their parent is an extension of using more appropriate tags and abandoning the "everything needs an id" approach because there are many s which do literally nothing but possess an and contain a more meaningful element. If the element inside needs to be identified, give it an or attribute as appropriate. The wrapping it just makes it harder to revise or transplant without breaking CSS rules and layout. 

As an exercise, I think your evaluation is fair - by all means, carry on. I think it's worth mentioning, though, that in terms of production, the factors you've enumerated aren't all weighted equally. At the end of the day, if your code is totally DRY, you can go home happy. DRY (don't repeat yourself) implies that every datum about how your system works is located in exactly one place in your source. You can't make readable, DRY code difficult to extend - there's only one place to make a change. The "code inertia" as I like to call it, as measured in keystrokes per behavior difference, is at its minimum. Beyond that point, any addition of complexity should be driven by necessity only. If the system outside of your adders and swappers evolves such that the simpler design cannot logically suffice, that's when you can think about picking apart the simplest thing that could possibly work. If your simpler design is DRY, there is minimal risk in leaving it alone. Complexity, on the other hand, is always a cost - it's work expanding to fill available time, and it's more time you have to spend training someone when you get promoted before they can test/maintain/extend your code. Since I don't see egregious repetition in either design, I would therefore prefer the simpler one. 

UPDATE Using a function as a property key, while it may work as expected in whatever environments you've tested, is a risky proposition. According to the ES5 standard, all property keys are strings. Even array indexes are required to behave as if they were first coerced to strings. Any non-string used as a property key to a plain object is implicitly coerced to a string by calling its method - you can verify this either by reading the standard or by adding at the top of the function and observing the error. is defined by the standard as returning "an implementation-dependent representation of the function..." that "...has the syntax of a FunctionDeclaration". According to the definition of "FunctionDeclaration", it is permissible for an implementation to return for all functions, i.e. you have no guarantee that the key will involve the function's given name, the function's given formal parameters, or the given function body verbatim, or at all. Some fairly common patterns are particularly potentially brittle: 

I apologize for my lack of GCC fluency in advance - I have only used MASM and RosAsm for x86, but I will try to translate. This review will be in top-to-bottom order, not in order of importance. The first thing I would do is evaluate whether you really need to use cdecl calling convention. If you're only calling your function from asm, it makes sense to pass the source and destination in and , respectively, rather than putting them on the stack and then loading them. Next, instead of , I would do: 

will get the job done. Not particularly clean, though. Other than that, the particulars of the conversions are good. Stuff like constants for strike a good balance between efficiency and readability. 

That would be a really tough thing to change, and ultimately a matter of documentation more than quality, so let's move on. The fact that your involves a by value that doesn't have an accompanying buffer of elements is somewhat of a misuse of the structure. I can see where it looks like it might be necessary in order to have and take and/or return a , but you can make those functions and the structure simpler and clearer by eliminating the from . Instead: 

ing a register with itself is such a common idiom that some processors use it as an optimization hint. All it does is set the register to zero, with a smaller opcode & operand. The after the makes the register all 1 bits no matter how many bits your register actually has. Some day when all of our GPRs are 128 bits, some poor sap that is updating assembly code will thank you for that =D. Alternatively, you can forget about being a limit altogether. No matter what arbitrary limit you set on the size of the string, it will either (1) not be big enough for someone someday, or (2) be small enough that an access violation (or worse: no access violation) will occur before you actually reach that limit. Either way, that is really only a nominal protection of data integrity. Now, the string. There seem to be some inconsistencies in how you're treating its terminating null character. You're using to find four bytes of 0, then using to only copy/advance by 1. Normally, strings are only guaranteed to be terminated by a number of null bytes equal to the character size, although in practice there are probably at least 2-3 to get the next datum to be dword-aligned. What that means for you is that your code will fail to detect the end of ~3/4 of normal, null-terminated, ascii strings, and keep copying until it finally causes an access violation. But that's not all. Notice that you're fetching a dword at with the instruction, and that advancing that pointer by 1 at every iteration will make the pointer not dword-aligned 3/4 of the time. Loading non-aligned data takes two fetches instead of one, so for every 4 bytes of string, your instruction alone needs 7 fetches from memory. Furthermore, after fetching the data and discarding it with , you fetch it again with , a total of 11 memory loads per dword of data. To reduce that number, you should load the data into a register, do your test for the null terminator on that register, then store the data to the destination. I see that someone else has pointed you to the bit-hack that will let you test all 4 bytes of the dword at once, so if you can follow that, do so, but here's a less efficient way that demonstrates my point very clearly: 

I am begging you to reconsider. If your students ever work with real world programmers, they won't be able to read each other's code. If you want them to learn OO, teach it in an OO language. Really, if they aren't ready for the idea of a prototype the way JS supports it already, they probably aren't ready for JS.