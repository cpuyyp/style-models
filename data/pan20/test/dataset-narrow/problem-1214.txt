I have read a lot over the last couple of years about the early history (circa 1977) of TeX, and a lot of what Knuth has written. My conclusion is that the moment we speak about “TeX (as a programming language)”, something is wrong already. If we look at the early “design documents” for TeX written before (see and , published in Digital Typography), it is clear that Knuth was designing a system primarily intended for typesetting The Art of Computer Programming (he has said (e.g. here) that the main users he had in mind were himself and his secretary), with the idea that, suitably modified, it may be useful more generally. To save typing, for things one repeatedly had to do (e.g. every time TAOCP needed to include a quotation from an author, you'd want to move vertically by a certain amount, set a certain lineskip, pick up a certain font, typeset the quote right-aligned, pick up another font, typeset the author's name…), there were macros. You can guess the rest. What we have in TeX is a case of “accidentally Turing-complete” (more), except that it happened in the midst of a community (computer scientists and mathematicians, and DEK himself is to “blame” too) who were (unfortunately) too clever to ignore this. (Legend has it that Michael Spivak had never programmed before he encountered TeX, but he was so taken with it that he ended up writing AMS-TeX, at the time one of the most complicated set of macros in existence.) Because TeX was written to be portable across a large number of systems (which was a big deal at the time), there was always a temptation to do everything in TeX. Besides, because of his compiler-writing experience, Knuth wrote TeX like a compiler, and occasionally described it as one, and if the program that works on your input is a “compiler”, then surely you're programming, right? You can read a bit more about how Knuth didn't intend for any programming to be done in TeX, and how he “put in many of TeX's programming features only after kicking and screaming”, in this answer. Whatever his intentions were, as I said, people did start to figure out ways to (ab)use the TeX macro system to accomplish surprising feats of programming. Knuth found this fascinating and (in addition to adding some features into TeX itself) included a few of these in Appendix D “Dirty Tricks” of The TeXbook, but it turns out, despite the name, that “nine out of ten examples therein are used in the implementation of LaTeX”. Let me put it another way: LaTeX, the macro system that Leslie Lamport wrote on top of TeX, as an idea, is a great one. Authoring documents in a semantic, structured, human-oriented way, rather than (Knuth) TeX's page-oriented way, (or as Lamport called it, logical rather than visual) is a great one. But implementing something as complicated as LaTeX using TeX macros rather than in a “proper” programming language is, in my view and at least if it were done today, somewhere between a giant mistake and an act of wanton perversity. Even Knuth is shocked that people don't just extend the TeX program instead of doing everything in TeX macros. Today there are much better ways to do “programming”; you can use an external program in any of the many languages widely available on most people's computers, or you can use LuaTeX and program in Lua (and do a better job than you ever could with TeX macros alone, because you can manipulate internal structures and algorithms at the right level). And if you do it right, you could have programs that work better or faster than those implemented in TeX macros. The task of making programs in TeX faster is almost amusing when seen in this light, and reminiscent to me of the final words of the paper describing another “accidentally Turing complete” programming “language”: Tom Wildenhain's lovely “On the Turing Completeness of MS PowerPoint (video) from last year: 

I have a graph $G=(V,E)$, with positive weights $w_e, e\in E$ on the edges, and I would like to randomly perturb the weights of the edges so that for each pair of distinct vertices $(u,v)$ such that there is a path from $u$ to $v$, there is, after perturbation, a unique shortest path from $u$ to $v$, and this shortest path is one of the "original" shortest paths, that is, one of the shortest paths before the perturbation. It seems to me that the perturbation can only be additive and at most equal to the minimum difference between two edge weights divided by the maximum number of vertices in a shortest paths between pair of vertices in $G$ (let this number be $\Delta$). That is, the perturbation that I add to the edge $e\in E$ should be some $$ \varepsilon_e \in\left[0, \frac{\min_{\ell,r\in E}|w_\ell-w_r|}{\Delta}\right] $$ and distributed according to some distribution (is uniform sufficient?) on the interval. Possibly, I would also like the "perturbed" shortest path to be chosen uniformly at random from the set of original shortest paths. Is this possible? Any reference or hint is appreciated. Thanks. 

Given a set $I$ of $n$ items, and a collection $D$ of $m<2^n$ subsets of $I$, a closed itemset is a subset $A$ of $I$ that is contained in strictly more elements of $D$ than any of its proper supersets. Closed itemsets are important in data mining because they provide a compact representation of the dataset. I'm trying to find some non-trivial upper bound to the number of closed itemsets. It seems a natural combinatorial question and I'm surprised I can't find anything non-trivial. Any suggestion/reference? Thank you. 

where both occurrences of 'TimeStamp' are not only in the proper form of a time stamp, but also make sense as times (i.e. the first time is after you send the program to the system while the second time is after the first and probably shortly before the time the system gave you the results). 

The book Perspectives in Computational Complexity: The Somenath Biswas Anniversary Volume published this summer (July 2014) largely agrees with the consensus that we reached here. On page 199, it says: 

No, it is not necessary for a set of gates universal for quantum computation to contain a two-qubit gate. A common example of a set of gates universal for quantum computation is $\{H, R_{\pi / 4}, \operatorname{CNOT}\}$, where $H = \frac{1}{\sqrt{2}} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix}$ is the (one-qubit) Hadamard gate, $R_{\pi / 4} = \begin{bmatrix} 1 & 0 \\ 0 & e^{\pi i / 4} \end{bmatrix}$ is the (one-qubit) $\frac{\pi}{8}$-gate, and $\operatorname{CNOT} = \begin{bmatrix} 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0 \end{bmatrix}$ is the (two-qubit) controlled NOT gate. To obtain a set of gates universal for quantum computation but without any two-qubit gates, we can simply replace the two-qubit gate $\operatorname{CNOT}$ with the three-qubit gate $\operatorname{CNOT} \otimes \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$. This three-qubit gate applies $\operatorname{CNOT}$ to the first two qubits and ignores the third qubit. The correct statement is: 

This is an answer to "[Fisher-Yates algorithm] isn't better than the naive algorithm. Am I missing something here?" which you asked in the question. In your "naive" algorithm which uses real numbers: how many bits of accuracy do you use? If you're counting bit complexity (as you seem to be doing for Fisher-Yates), and the algorithm uses k random bits for the real numbers, then its running time would be Ω(kn log n), since comparing two k-bit real numbers takes Ω(k) time. But k needs to be at least Ω(log n) to prevent two elements being mapped to the same real number, which means that the algorithm takes Ω(n log2 n) time, which is slower than the Fisher-Yates shuffle by a factor of log n. If you're just counting the number of arithmetic and comparison operations and ignoring their bit complexity, then Fisher-Yates is Θ(n) and your algorithm is Θ(n log n), still a factor of log n apart. 

(With apologies for a long answer that goes in a direction different from the scope of the site: frankly I was surprised to see the question here in the first place….) 

So fine, (if I've convinced you) TeX was not intended as a programming language and does not work like real ones, there is no formal semantics, and there are better ways to program today — but all this does not help with your actual question/problem, which is that in practice, many documents meant for processing by TeX do use complicated macros (like LaTeX and TikZ), stunning edifices of monstrous complexity built on top of each other. How can we make it faster and devise “optimization passes”? You will not get there with formal semantics IMO. I have thought recently about this, and the following are some preliminary thoughts. My impression is that Knuth was one of the experienced compiler-writers in the 1960s (that's why he got asked to write the compilers book that turned into The Art of Computer Programming), and TeX is (in many ways) written the way compilers were written in the 1970s, say. Compiler techniques and design have improved since then, and so can the TeX program be. Here are some things that can be done, by way of speeding things up: 

Boaz Barak addressed this in a blog post My takeaway from his post (roughly speaking) is that we only know how to design cryptographic primitives using computational problems that have some amount of structure, which we exploit. With no structure, we don't know what to do. With too much structure, the problem becomes efficiently computable (thus useless for cryptographic purposes). It seems that the amount of structure has to be just right. 

Yes. At one point in (1), the complex-weighted counting graph homomorphism dichotomy theorem for any finite domain size, Cai, Chen, and Lu only prove the existence of a polynomial-time reduction between two counting problems via polynomial interpolation. I don't know of any practical value for such an algorithm. See Section 4 of the arXiv version. The lemma in question is Lemma 4.1, called the "First Pinning Lemma". One way to make this proof constructive is to prove the complex-weighted version of a result of Lovasz, namely: For all $G$, $Z_H(G, w, i) = Z_H(G, w, j)$ iff there exists an automorphism $f$ of $G$ such that $f(i) = j$. Here, $w$ is a vertex in $H$, $i$ and $j$ are vertices in $G$, and $Z_H(G, w, i)$ is the sum over all complex-weighted graph homomorphisms from $G$ to $H$ with the added restriction that $i$ must be mapped to $w$. (1) Jin-Yi Cai, Xi Chen and Pinyan Lu, Graph Homomorphisms with Complex Values: A Dichotomy Theorem (arXiv) (ICALP 2010) 

In CLRS, $s_k$ is defined to be "the minimum possible size of any node of degree $k$ in any Fibonacci heap." Assuming your example data structure is a valid Fibonacci heap, your Fibonacci heap has a node of degree 2 with size 8 and a node of degree 3 with size 6. Thus, these are possible sizes that nodes of degree 2 and 3 can have but not lower bounds on their sizes. Using Lemma 19.1 (as in the proof of Lemma 19.4), $s_2 = 3$ and $s_3 = 5$, monotonically increasing as CLRS claim. 

I have a domain $X$ and a set system $R$ on $X$, such that the sets in $R$ are one included in the other, that is, for any $A,B\in R$, either $A\subseteq B$ or $B\subseteq A$. The sets are not all equal: there is at least a pair of sets $A,B\in R$ such that $A\subsetneq B$ The VC-dimension for this set is therefore 1. I seem to recall that the usual random sampling theorem to obtain an $(\varepsilon,\delta)$ approximation of the sizes of all the sets in $R$ can be used only if the range space has VC-dimension at least 2, but now I cannot find this explicitly stated anywhere. Could anyone please tell me whether I am just remembering it wrong and the theorem can be used for range spaces of any VC-dimension? If not, are there other techniques I can use or do I have to resort to Chernoff+union bounds? 

I have a range space $(X,R)$, were $R$ is a collection of subsets of $R$ and I have an upper bound $d$ to the VC-dimension of $(X,R)$. Suppose for simplicity that $X$ is finite. Given $\delta\in(0,1)$ and an integer $m>1$, I know that if I have a random sample $S$ from X of size $|S|=m$, then for $\varepsilon=\sqrt{\frac{d+\log(1/\delta)}{m}}$, we have $\Pr\left(\exists r\in R ~:~ \left|\frac{|r|}{|X|}-\frac{|r\cap S|}{|S|}\right|>\varepsilon \right)<\delta$. Notice how $\varepsilon$ does not depend on the sizes of the members of $R$. I was wondering whether I can get a smaller $\varepsilon$ if I know that all members of $R$ have a specific size, or better, if I know that there is a $\phi\in(0,1)$ sucht that $\frac{|r|}{|X|}=\phi$ for all $r\in R$. Thanks. 

Background The $\mathcal{H}$-factor problem (a.k.a. the degree prescribed factor problem, or the degree prescribed subgraph problem) is defined as follows: Given a graph $G=(V,E)$ and a set $H_v \subseteq \mathbb{N}$ for each vertex $v \in V$, does $G$ contain a spanning subgraph $F$ such that $\operatorname{deg}_F(v) \in H_v$ for all $v \in V$? (I would also say that $H_v \in \mathcal{H}$ for all $v \in V$, but I have never seen it stated this way. Thus, the $\mathcal{H}$-factor problem is defined by $\mathcal{H}$ and the input is a graph $G=(V,E)$ and a mapping $f : V \to \mathcal{H}; v \mapsto H_v$.) A spanning subgraph is also known as a factor, hence the name. This framework of problems captures many classic problems. For example, when $H_v = \{1\}$ for all $v \in V$, the problem is to determine if $G$ contains a perfect matching, also called a 1-factor. Question What is currently known about the complexity of this problem for different $\mathcal{H}$? What about the special case when $\mathcal{H}$ is a singleton set (so $H_v$ is the same for all $v \in V$)? Strongest Results I Know Tractability: If each set in $\mathcal{H}$ does not contain two consecutive gaps, then the $\mathcal{H}$-factor problem is in P (Cornuejols 1988). A integer $h$ is a gap in $H \subseteq \mathbb{N}$ if $h \not\in H$ but $H$ contains an element less than $h$ and an element greater than $h$. Hardness: There exist some $\mathcal{H}$ such that the $\mathcal{H}$-factor problem is NP-hard (Lovasz 1972). See (Szabo 2004) for a modern reference that cites these two results.