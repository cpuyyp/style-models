Running a quick query against this view will confirm we have partition elimination working (as you don't see any lookups occurring against the new table we've created): 

First to answer your question, yes that looks like it will work. However, this approach opens up permissions a bit more than you probably want. While it's accurate that ALTER permissions are required to Truncate a table, ALTER permissions also grant the following: 

The quickest way I've found to get the value to search for is to paste the query in question into a Query Window and then Display the Estimated Execution Plan. Read the XML output and look for the attribute in the element and this should give you what you need. Plug the QueryHash value into the query above and hopefully you should have what you're looking for. Here's some screenshots showing how to quickly get the value in case I'm explaining it poorly. Display Estimated Execution Plan 

Does anyone have any tricks they care to share that will help better identify disabled elements within SSIS packages? Ideally there's some manner to adjust the text color to red or or something along those lines, but the default behavior seems significantly lacking in my mind. I've dug through a number of options, but nothing seems to impact the display of only the disabled elements. Here's an example image where 4 of the 6 elements are disabled: 

There are a number of ways around having to do this after every failover, but the way I prefer in this scenario is to backup a SMK from the current primary node in your Availability Group (AG), and restore that to all other Instances in said AG so your SMKs match throughout. Once this is done, you may need to run the above statement against each db that's not sitting in a read-only state on any Secondary Replicas so that any encrypted data will be readable after any future listener failover events. The whole point of having an AG is the ability to perform a quick and transparent failover, so a shared SMK shouldn't be considered a risk in my opinion. This article goes over this and walks you through things in much more detail, but take some time to set this up so you can take full advantage of Availability Groups. 

The database engine thinks you're trying to perform a piecemeal restore using the UI. This is the formal name of restoring individual filegroups. Sadly, it requires you restore the entire database to maintain transactional consistency (which I don't think you want to do in your scenario) and since you're not overwriting the database (as identified by Pinal Dave's answer), you're getting this error. If you're only trying to restore that one table, you've got a couple of options available, as follows: 

If you only require this process to truncate a table, I suggest you create a Stored Procedure that utilizes elevated rights via Impersonation to perform the truncate so you keep your SSIS account at a minimal level of security. First, you need to create a stored procedure that provides your Truncate Table functionality, as follows: 

Depending on what your end-goal is, you can adjust the ordering on this to your liking. Once you identify a query that you want to dig into further, then pull up it's execution plan via: 

I think this will do it, but confirmation from others would be nice. This code basically does the following: 

Why don't you just use an actual which was introduced to SQL Server with 2012? The following approach overloads the value where the leading 10 digits represent the server IP address after being converted to a (via the method outlined in this blog post by SQLDenis) and the right-most 10 digits represent the CustomerID local to the instance. A can have up to a maximum of 19 digits, but because the leftmost digit will never be higher than to start the sequence this allows for far more customer numbers than the max value of an allows for (the comments in the code explain it in a little more detail). The only requirement for this approach is that this solution only be deployed to, at most, one instance per server (because IP won't be unique across instances hosted on the same server). As stated above, this approach still allows up to the maximum of 2,147,483,647 customers per instance in your solution. Because the column in the tables is defined as a in your question, I'm assuming this is acceptable. It's still about as fast of an approach as you'll find anywhere else. 

Since you don't delete rows, no, rebuilding the index will provide no real value outside of updating the statistics for said index, as they are implicitly updated with a rebuild operation. A more efficient approach is to just run an statement instead. Per Benjamin Nevarez: 

Because I've not seen either of the following approaches listed yet, I figured I'd include them. If you're running SQL 2016 or later, take a look at the STRING_SPLIT function. If you're running SQL 2014 or earlier, you can utilize some XML trickery to split up the string into a table. Both approaches are as follows: 

If you're using IIS manager for application pools to configure identity for your application and your servers are Windows 2012 or later, you can look into using either a Managed Service Account or a Group Managed Service Account to run your app. Either approach will eliminate the need to deal with passwords yet maintain a secure application login. The comment provided by sepupic above is spot on though in that you should manage user permissions directly against the database separately, and how that's done will heavily depend upon what level of permissions are needed. Hopefully this provides an approach to your situation though. 

This will provide a workaround that effectively equates a in one column to a in another. So to work that into your Merge, it would be as follows: 

To further expand on my comment, the table is stored, by default, in the SYSTEM tablespace. When the SYSTEM tablespace fills, your database halts. There are a few options available to you to manage this, but these will depend on what version of 10g you have installed. As of the 10.2.0.5 patch, a new package, DBMS_AUDIT_MGMT was included that allows you to move the table to a user Tablespace. If you are at this patch-level, move the audit table, plain-and-simple. Filling a user tablespace makes write operations against said user tablespace halt, but it won't bring everything else down like the SYSTEM tablespace filling will. This functionality was backported, but not to all 10.2 versions. You can check Doc ID 731908.1 on support.oracle.com to get all the details. If you don't have the ability to upgrade to 10.2.0.5, you will need to regularly purge the table by some other means so that it doesn't continue to grow and consume space. If it gets too unruly and you find you do need to "shrink" the table, you will likely need to TRUNCATE it to release the white space back to the tablespace. I've tried shrinking this file using the typical trick of enabling row movement and shrinking the table, but because records are often appended to the end of the table and are added regularly, it often doesn't shrink much, if at all, which is why a TRUNCATE operation is often the most effective method here to free up some space. Finally, your last option is to just disable the Audit. If it's not needed, this is probably the easiest option available to you. 

This is an entirely different area of threat. SQL Injection has nothing to do with the data being encrypted or not and more to do with how you pass client-side SQL to the server. I'm not going to get into this topic as many others (i.e. Microsoft, Erland Sommarskog, Aaron Bertrand) have done a much better job talking about it than I can here. 

I've got to believe there's a reason for this, but for the life of me I cannot figure it out. It looks like ordering of Server Names within any Central Management Server is Case SENSITIVE, regardless the collation of the server acting as the CMS, itself. Attached is an example of a CMS hosted on my local machine, which is configured with a server collation of SQL_Latin1_General_CP1_CI_AS. CI meaning Case Insensitive. When selecting from the system table holding the CMS objects, the proper order is returned, however as you can see in this screenshot, the way the servers are listed in the UI, the order is obviously being treated in a Case Sensitive manner. 

If someone has a script readily available, I'd be grateful if you could post it, otherwise I'll post something after I code it up. Thanks! 

I find it easier to transfer logins via dbatools.io Copy-SQLLogin cmdlet if PowerShell is an option or sp_help_revlogin if not. The Copy-SQLLogin cmdlet is a much easier approach and that link even has a video to help you step through the process, but again, if PowerShell isn't an option and you need to go the sp_help_revlogin route, make sure you execute that stored procedure (after you create via the linked article) on ServerA, copy the login statements over to ServerB and run the statement(s) there. If you get an error, you may need to drop the existing user from ServerB first so that you can sync up the SIDs. Finally, if you're running SQL 2012 or later, you may be able to configure your database to be a partially contained database instead. This will short-circuit things so the security is transferred with the backup as security is handled at the database level and not at the instance level. There are limitations to using partially contained databases, so review those first if you feel like this may be the approach you wish to take instead. 

Using the , , or methods (as demonstrated in Max's answer above, you can remove access to any encrypted data by explicitly permissions on the symmetric key, asymmetric key, or certificate to any account (or database role) that you see fit. This will allow you to limit who has access to what within the database itself. Using the method however doesn't prevent users from sharing a passphrase among st themselves or others without your knowledge, so I would hesitate recommending this approach for anything truly sensitive. Always Encrypted allows you to choose who has access to the decrypted data and who doesn't. Again, another reason to try it in your situation. 

Since it doesn't seem to be server-level related, I assume it's client tools related, but there is no where within the tools that I can identify a collation level (or even case sensitivity setting) that would affect this. Obviously there is nothing critical about this question, but if someone does know how to force the UI to be case insensitive, I'd appreciate it as I like to Camel Case my server names which is throwing off the ordering. 

Ok, so what does that really mean? It just means that you have an ordering mismatch between how the values are stored in the Index Tree and how they are stored on disk. Low Index fragmentation does NOT mean data is stored contiguously or even on the same drive within a drive array. How does Index Fragmentation hurt you? Really, through my investigation, the only downside to Index Fragmentation that I've been able to identify is that read-ahead operations are less efficient (e.g. more are performed) against an index that is fragmented (in regards to Seeks and Range Scans operations) as opposed to said index being absent of fragmentation. Read-Ahead operations only happen when you pull an index/table off of disk. If you are able to maximize the time that the index remains cached, you will see less and less read-aheads negatively affect performance because you won't constantly be going back to the disk. Additionally, Index Scan operations (as opposed to Index Seeks or Range Scans) are less troublesome because the entire index/table is coming off of disk any way. Why does most documentation attribute High Index Fragmentation with Poor Performance? The answer is that often times, High Index Fragmentation creates unnecessary white-space within an index due to page splits and other operations. This white-space is the real detriment to performance because it requires more pages be read into memory to get less data. More white space = More I/O requests = less performance. As Kendra's article alludes to, even the BOL article makes mention that setting FILLFACTOR too low will cause performance issues. This is because of the exact same reason. More reads for less data is less performant. Setting FILLFACTOR to anything other than 0 when necessary is forcefully adding whitespace to your indexes/tables. Let's do some basic math here and see why this isn't a good blanket-recommendation against your database. Let's say you have an index that is 100GB in a completely unfragmented state with the default FILLFACTOR set. You set FILLFACTOR to 90 and rebuild the index. The index will now become 111GB (100/90 * 100), which is an increase by 11%. This also means that you'll have to read 11% more pages to get the same amount of data off of disk. Apply this system-wide, and you've just increase read operations by 11% across the system. The other detriment to white space is that it is not only stored on disk, but it's also stored when the page resides in memory. That means you're reducing your memory footprint by 11% just to help "prevent" bad page splits. Really, are page-splits so bad that you need to reduce your memory footprint and increase the amount of read operations off of disk? This setting is a negative double-whammy. There are definitely scenarios where adjusting FILLFACTOR is needed and in the best interest of your database, but to set it across the board in a blanket fashion is not a good idea in my opinion. I'm not saying you shouldn't adjust FILLFACTOR, rather you should only adjust it when other options are less desirable. So, after my rambling, what I suggest you should be reviewing instead of index fragmentation is the avg_page_space_used_in_percent field in the sys.dm_db_index_physical_stats DMV. If you see that creep up past 10% or higher, a reorg/rebuild would be worthwhile because this is the only way to compress white space out of an index. Often times, I see that this percentage of white space hits when the index is significantly fragmented, generally at 60% or more. Also, because this value doesn't creep nearly as quickly as index fragmentation, this may allow you to reduce the frequency you perform index maintenance operations.