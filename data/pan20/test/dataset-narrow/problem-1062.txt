You're running Windows 10 Enterprise. This is relevant because the Spotlight Group Policy settings only work on Enterprise and Education editions, so it's possible you have a policy set that disables it. 

So, no, Windows 10 (and presumably Windows 8.1, 8.0, 7, etc) does not support AES-256 encryption in zip files - however the "ZipCrypto" mode in 7-Zip does seem to be supported. 

Observe how, for the top 3 processors, as the core-count increases, the CPU frequency decreases. While the L3 Cache increases - as it's shared between all cores it works out at 2.5MB/core. Most of my computing needs are not many-core optimized, such as games - I don't do things like video-encoding, rendering, or bitcoin-mining - which means whatever is in cache would be suited to however many cores are being utilized, so the larger L3 cache would definitely help (and so be effectively larger than 2.5MB/core). So my question is: if I got the i7-6850K, would the extra 600Mhz (300Mhz in turbo-boost) in single-threaded performance offset the smaller L3 cache compared to the i7-6950X? But contrarywise: would the 500Mhz turbo-boost in the 6950X be in-effect if I was running low-threaded programs and augment the larger L3 cache? To be sure for certain, I'd have to wait for the Broadwell-E benchmarks to come out - though ideally I'd like to get my pre-order in first. 

I don't know about Malwarebytes' HTTP filter specifically, but I assume it works in a similar way to Fiddler. Fiddler itself is a HTTP Proxy that handles requests. It works by running a HTTP server on port that accepts both HTTP and HTTPS connections. When you run Fiddler, it reconfigures Windows' systemwide Internet connection settings to set itself as a systemwide HTTP Proxy. You can see this if you look at Control Panel > Internet Options > Connections > LAN Settings > Proxy server > Advanced > HTTP: . When you close Fiddler it reverts the settings back to their previous values. These settings inside Internet Options are automatically used by any application that uses WinINet and WinHTTP (these are Windows components that handle HTTP requests for userland application software). Software that doesn't use WinINet or WinHTTP (such as Java and .NET programs which have their own HTTP client libraries) often respect the WinINet/WinHTTP system settings anyway (in most cases, anyway). Chrome also has its own HTTP client stack but also respects system settings too. I believe Firefox is the same. These HTTP proxies then receive the requests that would normally go directly to the intended website, they can then inspect the request and handle it (e.g. to reject it) or forward it on to the intended destination. HTTPS can be handled with a private X.509 certificate that is trusted and valid for all hosts - or by forwarding those requests on. Note that if your certificate is not truly private and specific to your machine then this is a massive security liability and you should remove the certificate immediately. Fiddler, and how it works, is described in this blog article: $URL$ Besides HTTP and HTTPS proxies, SOCKS proxies also provide an injection route - though they're an older approach not seen much thesedays (as SOCKS is for all TCP and UDP traffic, whereas HTTP proxies only handle HTTP specifically). Update: Windows Vista introduced a new extensibility point in Windows called the Windows Filtering Platform (WFP) which provides a nicer API than a manual HTTP/HTTP proxy configuration, and it allows software to filter more things than just HTTP traffic. It's also built right-in to the networking stack which means that it should be able to intercept all HTTP traffic, even from applications that don't respect the WinINet or WinHTTP configuration. This API was updated in successive versions of Windows so it's actively supported and it seems like it's built specifically for security products: 

The Issue Today, I had tried to log into a web application on my server, when I was greeted by the following error: 

I recently installed ZNC on a Fedora 22 VPS I'm renting for educational purposes to try to strengthen my Linux skills and knowledge. One thing I am trying to do is set up a small IRC bouncer on this VPS using ZNC. I want to use a specific subdomain for all of the ZNC-related parts of my server, but after reading through the documentation, I am still confused about how I would go about binding ZNC to a specific subdomain as compared to the root domain of the server (i.e. znc.example.com versus example.com). How would I go about doing this? I feel like the BindHosts option is related, but I am having difficulty understanding its purpose. 

About a month or so ago, I rented a dedicated machine from server hosting company OVH. I am currently using the SP2 plan, which you can read details on here. My server has two mirrored 120GB SSDs, and is running CentOS 6.4. 

I now realize that there are "caps" to the amount of data that I can hold in each directory. This was how the server was provided to me and by no means was this intentional, as it puts me in a significant quandary with how I manage my data. I was then given the following advice that I should reimage my drive to correct this issue and to avoid data loss. 

For the past few days, I have been trying to get my Fedora 22 desktop and laptop to connect to my university's 802.1x WiFi network. However, I have been running into an issue. Whenever I try using the NetworkManager GUI in GNOME to connect to the network, it will prompt me to authenticate using my credentials. I set the Authentication to PEAP, Inner Authentication to MSCHAPv2, and I tell it that a CA certificate is not required. I also type in my user account and password. After typing that information in, it will attempt to connect to the network, and then it will continually prompt me over and over in a popup window for my username and password (which are already filled in using the info I originally typed). I have double- and triple-checked that my account information is in fact correct. To troubleshoot this, I found this thread on the Ubuntu Forums regarding the same issue, and for some users, removing the line from the config file resolved their issue. I tried looking for configuration files in , but I did not have any files located there. Instead, I tried using to manually edit the setting, and I ran . However, that also did not work even after reloading the connection. Finally, I found a bug on the Red Hat Bugzilla about a similar issue in terms of a specific kernel release on Fedora 21; however, it seems like the issue has been resolved for most users now, but my issue remains. My kernel version is . Are there any suggestions or ideas about how to resolve this? If any additional information is required, I'd be happy to provide if asked. 

Original answer taken from AskFedora Original Comment Please try adding to kernel command line when booting (you should edit Fedora line in GRUB and add it to the end of linux/linux16/linuxefi line in the boot config, and then press F10), and then run when booted. Also, I'd like to know what do you see when you boot Fedora? The Fedora logo which is being filled with white color, or 3 simple bars at the bottom of screen? Update As can be seen in your last output after adding to kernel boot command line, your graphics driver has been loaded and is working successfully. Previously, it did not load at all and you were using a generic driver. However, this is actually a bug. Kernel should have been loading i915 driver automatically. Update 2 Update 2: To change kernel command line permanently, you can: 

These are the formulas I have right now, so I can compute fine, but I don't know how to compute or on a monthly basis because only lets me do criteria on a single column (in this case, the column, but I want to only sum rows for and for ): 

An alternative option is to cut the text into the clipboard, paste it into a plain-text TextEdit window, then paste it back. 

I'm using a computer, a Dell OptiPlex 9010, which comes with UEFI firmware, but does not support booting from PCI-Express NVMe devices. I've worked around this by using DUET to create an EFI boot partition on a USB stick, which has an NVMe driver which it loads, and then executes my OS's EFI boot program. The commands to do this are currently entered manually. Here is the process: 

Today I was contacted by GlobalSign with a much better explanation, which I think answers this question: 

I've been needing to sign PDFs lately - fortunately everyone's been fine with me using a self-signed certificate, however I feel it's unprofessional. I'm looking for a personal certificate I can use to sign PDFs and other documents (such as emails). I saw that GlobalSign.com offer "Digital Signatures for Microsoft Office" at a reasonable $90/year for their "PersonalSign 2 Pro" product, or even $30/year for their email-validation only "PersonalSign 1" product. They also offer a separate PDF-signing product which is two-factor and comes with a USB token, this product is considerably more expensive, at $370/year. I don't understand this - a certificate can be marked as trusted for document signing, but as far as I know there is no per-application restriction inherent in certificates that says "you can use this in Office but not Acrobat", indeed when I open Acrobat Pro it lets me use any certificate on my machine to sign a document. I spoke to their Live Chat support, asking if I can use an Office certificate for Acrobat and she replied, saying only the more expensive PDF signing product has a "key-usage" field set to allow PDF signing. I didn't want to debate this further as it looked like she was copy+pasting from their website, but I'm still not satisfied how this seemingly arbitrary restriction is implemented. If suppose if I had more free cash I might drop the $90 for the "PersonalSign 2 Pro" product and try it to see if it works, but I don't want to risk potentially having my refund request denied if Acrobat doesn't work with the certificate. Can anyone testify what certificates can be used for PDF signing? 

According to this MSDN thread The setting is in the Registry, under , the value-name is and has these possible values: 

I have a table in an Excel worksheet which logs my incoming invoices and outgoing expenses - and estimates the tax I owe the IRS. It looks like this: 

That's a lot of HDDs. My problem is that my job is in a country with a bit of a repressive regime and there is no uncertainty in my mind that any computers in my company-provided air-freight crate will have their HDDs examined, so I've decided to remove all HDDs from my computers before they go into shipping (except for my laptop, which will be in my carry-on). This leaves at least 8 3.5" drives, roughly 5TB of data, that I need to sneak into the country. I'm paranoid about my data because it's almost everything to me, including my personal diary, and I also frequent on sites like 4chan and Fark so I have a lot of "unsavoury" (but far from illegal!) content on my drives that I'd rather not part with. I think I also have stuff like The Anarchist Cookbook on my drives too - I'd rather not answer questions about those, of course. One possibility I thought of is consolidating as much data onto a single drive, for example I could mount my desktop computer's HDDs on my server and copy their contents onto a huge 2TB drive and leave only the System HDD (which contains no confidential or personal information). I could do the same with the server. I could wipe the DPM backup drive and leave it in the server, which means I'd only need to smuggle two 3.5" drives: my Exchange VM server's dedicated HDD, and "the drive with everything on it" - all of the drives left in shipping are just system disks. I could fit the 3.5" drives into fairly compact external HDD caddies that go with my laptop. Obviously I'd then make another backup of that "one drive" and leave it with a trusted friend at home. Does that sound like a sound strategy to everyone?