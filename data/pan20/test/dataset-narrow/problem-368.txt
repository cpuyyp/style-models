If your data has large variable-length columns, the result of reloading could be the storage of data and index info outside of your BTree Indexes and extra splitting of pages. See DYNAMIC and COMPRESSED Row Formats for more details on this. Many of the new InnoDB file format features are deprecated in MySQL 5.7 and will eventually disappear in future releases. SUGGESTION #1 Even though deprecated, you could set innodb_file_format to Antelope on the MySQL 5.7 server, restart MySQL, and reload the mysqldump. SUGGESTION #2 Use MySQL 5.5/5.6 as the Master instead of MySQL 5.7. Restart MySQL on the Master, and reload mysqldump into the Master. SUGGESTION #3 Run on all the MySQL 5.7 InnoDB tables. GIVE IT A TRY !!! 

Your DELETE will calculate against every row in the table. This new DELETE stops short when comparing ti_time against a time value (now() - interval 2 hour) instead of computing timestampdiff on every row. Make sure ti_time is indexed. If not, do this: 

If you only see the .frm files, then there is a strong likelihood that the storage engine in use was InnoDB and innodb_file_per_table must have been off by default. If you transferred everything from datadir on the crashed server onto another disk on another machine, you may be able to startup mysql with that folder as is. For example, suppose ServerA is your crashed server and ServerB is where you want it placed. 

This will remove the specific two DB permissions. As I mentioned in my answer, the three permissions are very dangerous for test databases. Running this DELETE will neutralize those accounts for having full rights to test databases. 

The number 40101 indicates that this command will execute if and only if the version of MySQL is 4.1.1 or greater. These SQL directives are there for your protection if you load these mysqldumps into earlier versions. These directives allow full acceptance of certain commands. Please do not remove them. However, if you only work with MySQL 5.0+ and plan to dump your stored procedures separately, you can strip them using Perl or awk. Personally I would leave them be. 

No need to have the myenum in any indexes. Leave it to the MySQL Query Optimizer to search the correct partition should any SELECT query have a clause that includes . If you ever have to increase the number of unique values, you will have to increase the number of partitions. Give it a Try !!! UPDATE 2013-10-24 17:57 As I said in the comments, you should partition by the enum with the highest cardinality. What about the other enums? DO NOT INDEX THE ENUM BY THEMSELVES !!! If your SELECT queries include WHERE AND enum4=...`, you should think about making compound indexes of enums. For example, if you have enum2, enum3, and enum4, you could make compound indexes like these: 

Then, replication caught up. My advice would be to properly serialize your INSERTs on the Master because this bug-like situation is actually quite avoidable. 

Then do the mysqldump to /root/mydata.sql. Move the /root/mydata.sql from the master to the slave. Next, execute in the mysql client this command on the slave: 

Give it a Try !!! Caveat : I tried at least 7 ways to make timestamp work like this. NO GO !!! So, you must use DATETIME. 

Everything should be MyISAM. GIVE IT A TRY !!! UPDATE 2014-07-14 15:40 EDT Since you are using a shared service, I take it you want to work with your database. Suppose the database is mydb. Try the following: STEP #1 : mysqldump everything; convert the phrase to 

Sounds like MISSION: IMPOSSIBLE. Just kidding. I just cringe when I see MyISAM. I can tell you what the MySQL Documentation says. Please note what it says: 

If the Stored Procedures work, you can drop or keep it as a backup. If not, undo everything as follows: 

Step 03) Using vi or some other editor, edit the table's PRIMARY KEY to manually limit the PRIMARY KEY in such a way that the key does not exceed 1000 characters. Step 04) Load the schema 

You will need two things First, make sure mytable as a autoincrement column called ID Next, place this SQL in the SQL View of a Query and run it: 

Whenever an InnoDB table experiences DDL, DML, or being used in a Transaction, all four of these types of entries are either read or written. Meanwhile, if innodb_file_per_table is disabled, all these entry types live in ibdata1. If it is enabled, only the Table MetaData and the MVCC Data would reside in ibdata1 while the Table Data Pages and Index Data Pages would reside in the database subfolder as a .ibd file. That being considered, what would happen if ibdata1 were placed in another volume and symlinked ? For starters, how does MySQL represent a table regardless of the storage engine ? As a .frm file. Where do .frm files live ? In the datadir. What's wrong with that ? Here is an example: Using the default datadir of /var/lib/mysql, let's use an InnoDB table called mydb.mytable. With innodb_file_per_table disabled, everything would sit in ibdata1 (which you are proposing to symlink and send off to another data volume). For the table mydb.mytable, this is what you would have: 

Question 1 Does the DML operations committed by db2 during the replication process gets included in its own bin-log? Answer to Question 1 Yes it will, provided you have this in /etc/my.cnf on both db1 and db2 

PROLOGUE Someone asked the same thing of me in my organization because everyone was using MySQL 5.5. All DB servers was upgraded over the past 8 months to MySQL 5.6. Some client applications were being affected by change as well. ROOT CAUSE I just found out why what you did does not work and the workaround is very simple. According to MySQL 5.5 Documentation, sql_mode default is a blank sting. According to MySQL 5.6 Documentation, sql_mode is default is 

Circular Replication Circular Replication is nothing more than first setting up Master/Slave then performing the same steps using the Slave as the Master's Master and the Master as the Slave's Slave. It just entails 

You will still have to bite the bullet and run sometime downstream if the InnoDB table experiences high INSERTs, UPDATEs, and DELETEs. Otherwise, the MySQL Query Optimizer will take bad guesses at EXPLAIN plans. 

Instead of using the slow log (which are queries that have finished and logged), you may want to poll mysql for long running queries while they are still running. You may need to try using mk-query-digest or pt-query-digest and poll the processlist. I learned how to use mk-query-digest from this youtube video as a replacement for the slow log: $URL$ Here is the script I wrote to run the query digest program 

EPILOGOUE Suggestion #1 may be all you need. Suggestion #2 is an alternative means of deleting old rows. YOUR QUESTION If you have binary logging on the Slave and the Slave is not a Master, disable it. If you want to see which queries are expanding to rather than , use mysqlbinlog against the binary logs on the Master to see a text representation of all queries. The row-based ones will be a little obfuscated. The statement-based queries will appear as it was executed. 

There is current open bug report on this one. The bug report has a suggested work around at the bottom entry [22 Jan 2010 6:46]: 

Sorry, to tell you: Check Constraints are not implemented in MySQL. You are probably better off writing a , trigger that would check the count using something like 

A newly inserted row would go into the InnoDB Buffer Pool, double write buffer (inside ibdata1), and the redo log (ib_logfile0,ib_logfile1). For a table using the MEMORY storage engine, it would have to be no because the table's data and indexes reside in memory. 

Should any of these steps see the slightest intermittency, the RAID5 set enters a brief-but-annoying time warp. Multiply that by a huge number of writes and you will feel it in the database performance. Each of these steps could be a point of failure. Why? According to Wikipedia 

I cannot definitively say that the "Table is Full" broke your table or not. I just wanted to clarify with that error meant. OK, NOW FOR THE GORIER STUFF (is gorier a word ?)... Here is something you will find interesting. Run the following: 

When a Slave is read-only, it is not 100% shielded from the world. According to MySQL Documentation on 

I got responses 10-20 seconds. How? The client uses . I REPEAT : WHAT DO YOU DO NOW ??? Here is why I said "heartbreaking": You would have put all your InnoDB data back inside ibdata1. Would you like to know all the steps to do this ? Here we go... STEP #1 Add these to 

These are usually multiplied by max_connections. You can get mysqltuner.pl get downloading it as follows from the Linux command line: