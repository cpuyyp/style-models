This will require a "policy-based routing"-esque configuration, since you'll essentially be routing based on source address/subnet. This should be possible with WAN balancer if memory serves, but it's been a while so I recommend looking at it's requirements first. (i.e. requires separate cards for each WAN connection) 

The default view of the EIGRP topology table actually does not contain ALL paths to a network. You'll see a next-hop if it is either a successor, or a feasible successor. If a certain path doesn't qualify as either of those, then it doesn't go in the topology table. 

If the configuration for a FEX switchport doesn't match on both parent switches, it will place it into "inactive" state as you describe. 

This route-map will set the next hop for all permitted traffic, regardless of the routing table. (Use of the "default" keyword can get around this but doesn't sound like you need to) This means that your static route is probably not needed for this purpose, but you can leave it in there as a fallback in case BGP fails. FYI - the way I did this was to enter the entire configuration, live, during the day, but with no entries in the access list. Since nothing matches, obviously, all traffic behaves normally, following the routing table. This provides for a very easy, testable, reversible framework for switching internal subnets over, since all it takes from this point is just to add them to the ACL. 

They are quite different. What I'm about to write is in high level terms: Google and ETSI can help you with details. 

It's a reasonable thing to do, technically, but I don't believe it will help improve the users' experience, which is really the only thing that matters in mobile networks. And so, why bother? Consider that voice (rtp) is packetized into tiny lumps, 20 ms being typical. That translates into a lot of small packets, rather than a few large ones, that might benefit from the larger MTU. SIP, the signaling protocol, might do, because in IMS networks the messages are quite large, but that doesn't really contribute to the users perception of their experience. Data flows are the other case, eg video or email, but again, the video is is short packets and the email (which is typically really https) is not time and latency sensitive in a way that messing with the MTU would help. 

But: that's not much of a gain. The real promise of NFV is that you can spin up a function on demand, scale it up and down according to need, and generally be much more cloudy than traditional service providers have been. Now imagine that you have got to that state, so that you can, say spin up a call control core, or a application server, or a firewall in minutes not months. Now you can do service chaining In service chaining, you create new products by stringing together functions delivered by NFV. There are some subtleties here best explained by an example. Lets say you (as a service provider) want to sell some new phone product to the government? Ok, you'll need some call control, and a telephony app server. And a firewall or packet inspection engine. With function chaining you string the firewall and the call control/app server together so that the product is defined as the chain of all those things. The subtlety is that SFC can happen at the IP layer ("send traffic to the firewall, then the call control"). Or it can be a logical construct used by a product designer. Or it can be inherent to the elements being strung together (eg an IMS core using filter criteria to send calls to app servers). 

HOWEVER - you must repeat this configuration on the same port on the other control plane (other Nexus parent switch) because the configurations are not sync'd automatically by default. 

I would recommend that you look into First Hop Redundancy Protocols like HSRP or VRRP. Actually, having two gateways can be a very good network design, because if a router were to fail, the other router can take over somewhat seamlessly. However, as you're aware, it's not easy to make this transition if you have to make a manual reconfiguration of each client on a subnet. Protocols like HSRP (or VRRP if you have non-Cisco gear) allow you to have two (or more) routers (or L3 switches) on a subnet share a single IP address. You'll have your first router with an address of .2, the seond with an address of .3, and a "virtual IP address" of .1 that both routers are aware of through configuration. When the primary router fails, the secondary is able to detect this and take over the virtual IP address, meaning that your clients just need to have .1 configured as their gateway and you're good to go. In terms of routing design, that would largely depend on the current setup. It's possible that both gateways lead to the same internet edge, in which case you may not have a problem. Asymmetric routing can be bad, mainly because you risk packets being delivered in the wrong order, but again, depends greatly on the topology you're talking about. Lots of design principles implied in what I just said. I suggest you research both protocols, and determine what's best for your environment. If you're using Cisco gear, HSRP is a widely used and well understood method of solving this problem. 

WDS is by design intended for forward frames between the edge stations, repeater nodes and the base station (the thing that is connected to the wired Ethernet). It's not clear from your question whether what you call your core router is a WDS base station: if it is, it really ought not to be. Two reasons. If a frame is initiated from one WDS node, it is supposed to be forwarded to all the others. I believe (don't have the standard to hand) that it is not supposed to forward frames that it has already sent, to prevent loops. Broadcasts are one example where failure to do this can get out of hand very quickly. Now imagine that the WDS base station is also your "core" switch. Now it is spamming the wired network with frames too! That is bad. A better model would be to take steps to isolate your wired and wireless networks. This diminishes the scope for problems if a device goes nuts and --even more important-- gives you a place where you can ascribe security policies. Wireless is a common attack path and plugging it straight into your lan without filtering and policy is trouble waiting to happen. 

I look at this reductively. A base station is a giant radio receiver and transmitter serving a geographic area (cell). Connected to the base station and maybe considered part of it is the access networking piece, some software on some server-style unit that converts to IP and gets the traffic into/out of the carriers network. There is a fixed basic cost of transmitting even if no one is there: think of a radio tower in a rural location at night, say. When the first phone attaches, the base station has work to do to get them hooked up to the network. And then (depending on where you put the boundary) work to convert radio signaling from the phone to IP. The more phones, the more work. The more work, the more energy used. Now, given that the amount of work induced by one phone is very much smaller than the work required to power the tower, you might say that effectively the energy requirements are independent of the number of phones attached, but a very accurate accounting would definitely show a difference. 

To my knowledge, the ASA platform is only able to classify based on existing DSCP markings, not apply or change them. It does preserve existing markings, though. 

This is the subject of a large debate that's been going on for a while. When it comes down to it, using a /127 on a point-to-point link isn't really a terrible idea. RFC6164 illustrates that it actually may be a good idea to use a /127 - it identifies some of the big issues for moving to a /127 on a P2P link, and talks about the steps that have been taken to mitigate, if any. The fear of ping-pong attacks was mitigated in the most recent version of ICMP, and neighbor cache exhaustion attacks are actually eliminated on P2P links by using a /127 prefix. EUI-64 is generally preferable on user subnets, since SLAAC generally breaks if /64 subnets are not used. On P2P links where SLAAC is not used, it's not that big of a deal. In conclusion, I believe the general consensus is that using a /127 is not a big deal - in fact you may want to allocate a single /64 for all your P2P links. Your routing table may take a small hit since all of the P2P prefixes won't be easy to summarize, but it's unlikely to be a significant problem. Just keep the RFC I mentioned in mind, and make sure you follow the guidelines it provides. 

The picture you show is a logical diagram that shows functional elements. As such the functions within it may or may not be implemented as separate software processes, threads, daemons, etc. UNIX and its variants tend to implement the boxes in the picture as processes. Thus you have the netstat command to view the routing table and the route command to update it. You may also have a routing daemon (long running server process) to take care of updating the routing table without requiring manual intervention via the route command. In the vast majority of servers there is a limited number of routes needed so it is just as efficient to set up the routing table by hand and dispense with a routing daemon. But for those that do, they can run a daemon. The name of the daemon varies according to the routing update and distribution protocol that is in use. For example, routed for RIP, bgpd for BGP. 

It's the last point of significance in a service provider's network, relative to the consumers of that service, from the point of view of the service provider. For example, 

Yes, you are right. Although no one does this in the practical day to day world, it is easier to see this if you convert the subnet in question into binary digits and then remember that the broadcast address is simply the case with all 1s and the network address with all zeroes. 

NBMA networks require a special OSPF network type on the connected routers' interface. This setting affects quite a few things, including the need for a Designated Router, and the timers like hello timers and dead timers. I would recommend researching OSPF network types, as the question as you've stated is way too broad to be answered on this site. You should read the OSPF RFC, or even vendor-specific books. On this topic, Cisco Press has a few resources, namely Routing TCP/IP Volume 1. 

I don't have a lot of experience with Brocade, but I do know on the FC side that it's not uncommon (i.e. Cisco Nexus, MDS) for Fibre Channel switches to require a re-activation of the active zoneset when zoning changes are made. A will show a new zone, for instance, but will not until the zoneset being referenced is actually activated. It's one of the only cases I'm aware of (at least on Cisco gear) where the output isn't actually live and running on the system yet. Though I wouldn't know of any technical reason for one or the other (pertaining to TCAM or switch logic) I do know that this provides for a little better handle on the changes that are being made. It is an extra step but it allows you to make the changes, show the changes, but not apply them until you've reviewed and verified that they're good. Zoning from the SAN world being a rough analogy to ACLs in the IP world. 

Essentially because the dial up server has more than one POTS circuit associated with it. By contrast, a residential line has one circuit, so when A calls B who is on the phone, the circuit is already tied up. The dial up server would not have one phone line (circuit) but many, aggregated into an entity known as a trunk. Different size trunks are possible depending on anticipated traffic patterns. Of course, if you get it wrong, it's still possible for a trunk to fill up, and give you the busy signal. 

Things like the Cisco phone system and Windows servers are moot for your question insofar as they are immobile. So the real issue is how to make your mobile laptop clients' sessions persistent as your users move around the building. The best investment you can make here --and also the easiest one to sell to your user base -- would be an upgrade of your Wi-Fi infrastructure to permit seamless roaming on the same SSID. It requires no changes from the users, gives you a control point for policy, and does exactly what you need. 

Your question appears to be not, "are there any global networks other than the Internet" but "are there any global networks other than the Internet, and do any of those use a non-IP transport" and the answer here is yes. The global switched telephone network, aka the PSTN, was originally built on non-IP transports. About fifteen years ago telephone operators initiated a huge undertaking to move the PSTN from circuit-switched (TDM) to packet-switched (IP) but there are still huge chunks of the network that are non-IP. Another example is X.25. This was a WAN technology extensively used in global networking up until the 1980s and still survives in certain niche applications today (packet radio I'm told, and some credit card/ATM uses). If you were a multinational of that time, chances are that you connected your sites in a mesh using X.25 links. As a side note, TCP/IP is not a perfect protocol. There are some places where the cracks really start to show. Talking to satellites is one example (though there is work going in on this area, eg SCPS). I've learnt that just because protocol X is the winner in the market, doesn't mean it was technically the best...only that it was the easiest to get going and adapt. In 25 years' time we'll be running something else!