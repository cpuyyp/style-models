Because by default the SELinux policy doesn't allow the transition to manage the necessary signals. Really people should probably just use anyway. I normally hardlink to as a two-letter replacement for people who prefer to run out of a bad habit (like me!). 

To clarify, is 'john' the technophobe? If so then change the configuration and configuration to always ask for the users password (even if you are root) before switching users. If the users have thwarted the system and given themselves sudo, then theres a few problems here. NFSv3 and AUTH_SYS (the basic mechanism used for identifying users) is utterly broken when client machines are untrustworthy. You'll have to implement a stronger NFS authentication system such as to avoid the problem. 

Its extremely difficult to achieve what you want. I dont suggest reformatting as there is a means to salvage this. I'd drop completely by copying the entire contents of it into the mounted in . Something like this should work. I haven't tested it. 

This clears itself in the killed application after seconds. The best thing to do is fix your calling program to do the right thing though. 

Hardware RAID really depends on the card you get, but the more expensive cards shine when you have very many disks to use and will offer good monitoring and alerting to issues. They also offer hot swapping which can be very useful, but its usually the more costly of servers which offers this facility only. 

This will ammend the SELinux policy to be aware that haproxy is is listening on these ports. The strange label "commplex_port_t" is the type definition of port 5000 which (I assume) haproxy defaults to if you dont choose a port. In port 5000 claims is registered to the service, hence the name of the label being out of place. 

One way you can look to see if other processes are utilizing the disk(s) is to download from the main webpage here. Sysstat is of course available from the repo already but, unfortunately it does not include the command which is needed to check this out. EL5 kernels backported disk accounting into the kernel since EL5.4 without providing an interface to utilize it, but pidstat will work once you've done this. Then run the command to generate useful metrics for disk I/O, in particular what other processes are doing with the disk. You can also use to get a more realtime contention metric of the disk being used. 

Create a new directory called "localftpd" Place the content below into a file called "localftpd.te" inside of this new directory. Run 

Control Groups v1 cannot limit buffered IO which is the vast majority of IO on a system. Control Groups V2 can. If you are using a v2 compatible kernel (and if docker supports it, as I dont know if it does) you should use that instead. 

This is my preferred way to resolve these kind of issues. It is a simple, non-disruptive and trivial change. 

So I've ran last in a debugger which hopefully will give you at least some answers to your question. My feeling is the root cause is deeper though. Why does last -i show 0.0.0.0 for pts line entries The best way to explain this is what happens when you dont pass -i. The reason for this is in this code section of 

The following SELinux policy will be needed to set this up. NOTE: I assume here that the ajp_port_t type does not actually exist on the system currently. 

Make your program in cron check for the existence of some stamp file. If it exists, then the invoked cron program simply exits without doing more work. 

You create a veth pair, then fail to add one side of it into the new network namespace. One of the veths sides is not up. Specifying the broadcast address as as in your example cause a routing table lookup and the packet to be sent against the default route. Consequently you dont use to specify which interface you actually want to send down to. Note that this requires root privileges, which in many cases is not ideal. 

There is quite a lot of stuff happening here, but the pid 3734, a java process appears to be your culprit. You should find out what that is doing, what arguments were passed to it, what its parent pid is and a little about what it is meant to do. Over a 30 second period of 1 second samples java uses 1778.49 read kb/sec, there is also other java processes, pids 9677 and 19295 using 946.52 and 498.04 read kb/sec respectively. I'm in no position to tell you whether what they are doing is wrong or right, but you're high I/O is due to those java processes mainly. 

Why are these different? There are different classes of process schedulers on linux. The default one (CFQ) basically gives an equal amount of time slices to each process wanting to run and queues runnable tasks in such a way that everyone waits on average an equal amount of time for their turn. Some exceptions to this rule exist but thats the basic idea. Another class of scheduler is the realtime scheduler. Realtime is a little different, rather queue runnable tasks into a fair queuing scheme, the realtime process will get CPU time as soon as it is needed by the process, this evict a running process from the CPU in order to make room for the 'realtime' process. What values can they take? What 'priority' does is alter the niceness of procesess so that on login your main process starts at a certain niceness, any child processes you spawn also start at the same niceness. This has the effect of making it more likely to be scheduled in in favour of other competing processes and the user experience can be made to either be more responsive/interactive for the lower niceness values and less responsive/interactive if the niceness is raised. It may be important for normal login users to have a lower priority than serviceable daemons for example, or root to have a higher priority on login than everything else. As for realtime, contention is handled with the 'rtprio' field. If you have two realtime tasks both wanting to run then the 'rtprio' value is used to determine which of the processes to pick for priority first. A higher rtprio produces higher priority tasks. Setting this in the limits.conf permits realtime tasks to be set at a particular priority banding without needing root to set the value. This has no effect on tasks not set to run using a realtime scheduler. The 'nice' value should do the same as 'rtprio' but for standard CFQ scheduling. I've never tried it though. It sets the initial process spawned when PAM is setting these limits to that nice vaule, a normal user can then go to that nice level or higher without needing root to set them. If you dont renice explicitly it means all processes spawned from a shell from that login (for example) will inherit the nice value set in the limits.conf form the parent process that was initially created. What are the defaults? The 'default' limits -- technically are them all being set to what pid 1 is unless explicitly set, resource limits are inherited from the parent process, if no limits have been defined or overridden anywhere then the inheritance from is the default. Other Values 

The field is the kernels interpretation of 'when I go below this threshold, I will have to do drastic things to reclaim memory -- like OOM-killer'. Whats highly unusual about this field in your description is just how much is set as the min amount. This value typically floats at about 2% of your memory, in this case its 25% of the entire zone. Its no wonder you oom-kill so aggressively! Lo and behlod when reviewing your question output the reason for the problem lays here: 

Having dealt with support in the past I have asked the same questions. Sometimes I was right and they were not focusing their attention on my problem properly. Other times however, I was wrong and I was interpreting the data incorrectly, or failing to include other data which was important in my analysis. In any case, both of these situations were a net benefit to me, either I learnt something new I did not know before - or I have got their support teams to think harder about my problem to get a a decent root cause. If the support team are unable to provide you with a logical expansion of their argument to a basis you can be satisfied with (you need to have an open mind to compromise yourself, be reasonable to accept your interpretation of the data is wrong) then it should become very present in their response. Even in the worst case scenario you can use this as a basis for escalating the problem. 

Then I wait for you to update your webapp. Now what happens, is that the vulnerable script switches to . When it does this and runs it finds the program first, which in this case resets the root password, emails the attacker of the new root password, actually calls the real (to hide the fact anything has actually happened) and removes itself from the attack path. As root, you've got no idea what happened and the evidence is erased once the payload was delivered. 

When a process is initialized, it allocates some memory known as the 'data segment' when the process is copied into memory, this is where the space for globals, perhaps some other initialized data and memory allocated from the heap lives. The limit controls the maximum allocated amount that a process can take. Its unlikely you'll ever hit this limit because malloc() rarely over-uses the data segment to store data. 

Is very odd. The reason I say this is because on EL5, with the latest release of SSHD, that error message is impossible. Its not in the source. Anywhere. I grepped the entire source tree and the redhat patches for "ssh_selinux_setup_pty". Its not there. It does, however appear on Fedora 18. This leads me to think that the version of SSHD you are running is not the version it should be and it has been replaced. Either by yourself or by someone else. Update 1 SSHD at the critical section that does not work performs something akin to this (with python); I'm trusting the selinux contexts being used within sshd are as you mentioned. 

Assuming the order of the data unimportant, one way to do this -not so much of a faster way- but at least somewhat parallel would be to write a script that does the following. 

The reports standard SELinux permission issues, such as when the policy does not allow it, reports userspace AVC errors, such as dbus or systemd and reports errors with 'superpolicy', such as where the type is normally allowed, but the role is not allowed for the type -- or the role is allowed but the user is not allowed in that role. Roles and users are generally glossed over in SELinux as they are often not utilized, but there is a faint possibility that an issue could crop up because of them. So, if you feel the problem is SELinux related - this will help identify the problem. For the total avoidance of doubt (and where the system is insubstantial enough to warrant it) you can run to disable SELinux and retry to know for certain if the problem is SELinux related. You can when you have finished. But note, 'superpolicy' problems will still fail in this case as it is caused by runtime errors of the policy attempting to set labels that do not exist. 

If you want to make the labelling get honoured if you do a system relabel, you'd better update the local policy too!