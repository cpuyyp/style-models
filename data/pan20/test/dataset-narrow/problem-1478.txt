I am not a video pro, but I do enough studio work to recognize the technique. I use parts of this technique every week in live webcasts, albeit with additional hardware to overlay the graphic on the camera feed. Take a whiteboard, 

Another member of my webcast team is autistic to a higher degree than I am, but this kid (not old enough to drive) gets himself up every Sunday and rides his bike to church so he can do his part on the team as title artist. It suits him because he sits in a quiet corner away from the rest of the team and can focus on his artwork. He's started to earn respect from his peers because when he's not there they have to do that job. Modern software development requires a broad range of specializations - take advantage of it. 

An event is a data structure that contains what, where, and when, plus supporting data. For example keystroke from USB keyboard at 16:01:00.000, or packet received from network at ... . getNextEvent () simply pulls the next available event off of a queue. In the original macintosh I believe they used a circular queue implemented on an array of pointers. getNextEvent may actually call polling routines, or the event queue may be populated by asynchronously. dispatchEvent is a wrapper around a big "switch" statement. A typical form would be something like this: 

Look into demo instances for real products that run on various databases. I see more of sqlserver, oracle, and db2 in enterprise apps. Download some free demo instances of Openmaint, Maximo, redmine, or other apps that are backed by a serious database,. 

As requested by @heather, comment converted to answer: When my daughter was 6 I introduced her to Ruby and Postgresql because she wanted to know what i did at work. She soon lost interest, but the analogy I used for her was "cubbies" like she stored her stuff in at kindergarten. Cubbies come in blocks, which are assembled into larger installations. A database is just a very large wall of cubbies, and the DML side of SQL is about getting stuff into or out of the cubbies. DDL side of SQL is making the rules about what is allowed to be put into the cubbies 

Learning about references is important, but I don't feel that learning about pointers is that important for beginning Java students. Certainly intermediate students will need to understand them. When I started learning about pointers, I had a hard time grasping them at all until I learned assembly language. Once I learned assembly (for any processor), pointers made sense. It helped that I learned PDP-11 assembly at about the same time I learned C. Since C is essentially structured PDP-11 assembly language, I was easily able to see the relationship between the pointer structures and the compiled code. Java hides the concept of a pointer sufficiently deeply that I would be hard pressed to explain it with java. I can explain java structures in terms of pointers, but have difficulty expressing it the other way around. For teaching pointers and pointer concepts, I would probably use C (yep - plain old C, without the ++) and the x86 assembly language as a starting point. After that, it's easy to explain that the JVM is built in C, and java object references are implemented as pointers. 

The concept of a variable is not hard in and of itself, but it is the first conceptual hurdle for students. The problem is that in common usage we use the same symbol for comparison and immutable facts as we use for assignment. By the time we start kids with computer programming they are steeped in algebra where "=" means "is the same as". 

Yes. Programming languages that don't have variables still have conditional branching. The paradigm is called "functional programming". Here is a link to a list of programming languages that support functional programming: $URL$ A list of pure functional languages can be seen at this link: $URL$ Here is an example functional programming exercise in javascript that I found: $URL$ Here are some other links of interest: $URL$ $URL$ 

Speaking from an industry perspective, my team is scattered around the world. Source code is managed on a server in our rack in the USA. We use subversion because git and mercurial are a pain to work with. I can get to my team's checked in source code daily. While some of my team live close enough to each other to have face to face time, most work at a distance. Partner work is handled through online conferencing software. Everyone has their own accounts. Work is checked in to the version control system regularly (daily or more often if possible). Since everyone has their own account, we can use the subversion "blame" function to identify who checked in the code. A caution - operating the computer takes a certain amount of brain power, so the real work on the problem may be done by the partner who is not keyboarding. Detecting "freeloaders" based on counts or volume of checkins creates a false sense of security, and my be punitive to a team that has really worked out how pair programming works for them. I remember my final assignment for PDP-11 assembly class, which I worked on with a partner. With my prior experience, I was able to quickly solve the assigned problem in a way that earned all of the bonus points. For the curious, we built an desktop calculator in assembly. Bonus points were handling algebraic order, parentheses, square root, remainders, hexadecimal conversion, and smallest program. We got all of that into 120 bytes. My partner, who handled the keyboarding, looked at the finished program, had no idea of why it even worked and (wisely from a learning perspective) decided to try to solve the problem on his own without my help. Had he not made that decision, one could argue either that I was the freeloader because I had not keyboarded anything, or that he was the freeloader because he depended wholly on my experience. The instructor would have no way to tell who (if either) was the freeloader without knowing both of us very well. LOC and similar metrics from code and checkins are not useful for determining programmer productivity either in industry or in education. 

Make use of remote team management tools and practices. Today, in industry, many software project teams never meet in person. My own team includes people from all over the USA, Brazil, and India. On some of my most productive days I never actually leave my bedroom. Teamwork does not require face to face time. 

What you are looking for is "old style" macintosh like event driven programming. It's still there under the covers in Windows, but the high level libraries tend to hide the implementation. Your main event loop: 

Understand that part of learning to work in a group is learning when to leave the group unilaterally. In my daughter's case, she learned that sexual harassment is not an acceptable part of team work, and it is perfectly okay to walk away from a team where it is happening. Recognize that interpersonal conflicts that are irreconcilable do happen between high school students, they need to try to handle some things on their own, and you will not always know about those issues. Recognize that there is no cure-all solution. Setting an advanced student with good social skills (like my daughter) up as a team lead or teachers assistant can work well, but setting up and advanced student with no interest in socialization (like myself) in that role would precipitate a shutdown or walk out if you were lucky. Recognize that some tech companies are now specifically seeking programmers on the autism spectrum , precisely because they can solve certain classes of problems better than teams of neurotypical programmers. Being unable to work in a group is not necessarily a handicap. ($URL$ If your problem students share the characteristic of being hyperfocused and task-centric, put them together. They may go home and bring the task back completed for the first official meeting, but being similarly focused they are likely to strike a synergy and do it together (that would be me!). At the very least, they will have a chance to review each other's solutions and time to expand. Being task centered, they may not socialize much outside of the task, but they can develop a feedback loop of excitement as they expand and improve the solution. Don't treat students you don't understand as damaged goods. I have a gentleman on my webcast team whose teacher tries to meet him half-way by treating him like an infant. This kid (middle school) has earned sufficient respect as a camera tech (following directions) and a technical director (giving orders) during live webcasts that when he gives directions everyone on the team pays attention, including people twice his age or more. His teacher has nothing but frustration with him ... doh! Engage their interests with specialization. If I chose to do something in school, it was out of synergy with my own interest. I could do relativity physics in my head, but wouldn't do homework. In one class I got a final grade of 10%, because I scored 100% on the final exam that was worth 10% of the class grade. 

This reminds me very much of a similar discussion from the distant past. The Meat Human perception is colored by expectations. Transposed letters, misspellings, and wrong punctuation are all easy for a human reader to miss because our perception is geared to fill in for the unexpected. We are all aware of these internet memes that build on the understanding that any misspelled word is readable provided it starts and ends with the correct letter, and has all of the other letters that are required somewhere in the middle, regardless of order. Real time syntax highlighting and linting helps to expose those errors when they can be easily resolved, when the programmer is still thinking about the problem at hand. By preventing extra effort and distraction, it is a direct aid to understanding. Compile time linting is better than nothing, but I remember spending hours poring over lint print outs for C programs (yep - C, not C++, not even ANSI C) for hours, making one edit, then rerunning the lint to find the next error. It was better than nothing, but not by much. At one point in time. applications were written in a single language (COBOL, FORTRAN, PASCAL, etc). In a project of any scale today, you will use at least three programming languages (Example: SQL, Java, and Javascript). The programming language is a tool, not an end in and of itself. Each language expresses specific thought patterns more effectively than the others. In industry, it is not uncommon for me to pick up a language just enough to accomplish a particular task and never work with it again. Anything that reduces the time I need to spend learning the language is a benefit to me. Conversely, any language that I spend enough time in, I will learn in some depth. I would expect the same to apply to students, since in this field we are always students. The Long Stories - read at your own risk I think it was the 1980's (or early 1990's), the same question was asked about the use of debuggers. Conventional wisdom was that the debugger would interfere with the reasoning process and students would not learn the material. A few rebels in academia held that in industry solving the problem faster was what was paying the bills, so debuggers should be used in classes just like in industry. Ultimately, since this was a discussion in academic circles, someone (hey it's been a few decades, sorry no citation) did a controlled study where an entry level CS class was taught by a professor, half the lab classes were required to use the debugger, and half were required to NOT use the debugger. Much to everyone's surprise, not only did the use of the debugger not impede student grasp of the material, it actually gave them deeper insights into what the system was doing when they ran code. Fast forward three decades or so, there is a reason that we use syntax highlighting. I learned programming on teletype and monochrome terminals, and I'm usually oblivious to color, so when I ran into an issue where my syntax highlighting didn't work I figured "no problem, I'm olde schoole" and went to work. It took me about 2 minutes to realize that without the syntax highlighting, the code that was nicely formatted to the language manual was nearly unreadable. If I, having learned before syntax highlighting was an option and with decades of continuous industry experience, have trouble reading code without syntax highlighting, I pity the poor novice.