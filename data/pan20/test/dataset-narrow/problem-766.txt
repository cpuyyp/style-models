This role is not available in Windows Server Core. You must reinstall your server and choose the Desktop Experience version during the setup. 

Create the profile with the GUI on your computer Start a command prompt and use: to show all the available profiles (and hopefully your newly created profile will be listed). Use to export the profile (an XML file will be created) use on other computers to import the profile 

I recommend creating an Immediate Task via GPP to launch this command only once per computer, as SYSTEM account (for example). you can find more information about the videoconlock settings here: $URL$ (the KB says Windows 8 but the content is still relevant for Windows 10) 

You can safely delete logs in c:\windows\logs\CBS, but don't touch WinSxS, your server won't boot if you mess with the folder's content. You can try to follow the steps shown here to reclaim disk space and learn more about WinSxS: $URL$ 

Maybe the Hypervisor "forgot" to start automatically, you can try to use the following command in an elevated command prompt: 

Security groups are intended to assign permissions on resources (file share, ...), while distribution groups should only be used for mailing lists. The main difference, technically speaking, is that the Distribution Groups are NOT included in the security principal's token (a security principal is a computer, or a user for example), thus, you can't use a distribution group to secure a file share for example. Security groups => Assign permissions (=security related) more information here (for Windows 2000, but it's still valid): $URL$ 

You'll need to insure the '--with-suexec-userdir' compile time option is enabled in your Apache build. 

There is nothing to "compile" in Webmin. It is written in Perl, with some client-side JavaScript and Java. setup.sh is an install script that puts the files in the right places, enables the webmin service on boot, etc. There is an uninstall script generated when you run setup.sh, which will reside in the Webmin directory (wherever you told Webmin to install itself when you ran setup.sh), called "uninstall.sh". But, if the install hung very early in the process this script may not have been generated (it has to be generated because the locations are not known until you tell it where to put things, and it'd be annoying to have to know where you installed it when you want to uninstall it). I suspect such a script exists, though. There isn't a lot that can go wrong during the install; you've not given us any clues about when in the process it hung. I just haven't seen a Webmin install fail in years, except in cases of pathological server problems (failing memory, failing disks, no disk space, not enough memory, etc.). I would recommend you install Webmin using the apt repository Jamie provides at $URL$ or if you're also using Virtualmin or Cloudmin, use the repositories at $URL$ Using native packages just makes more sense, and provides many additional tools for keeping up with what is installed on your server, and makes removing stuff easier and cleaner. It also makes your install more predictable; if I sit down at a Debian system where Webmin has been installed from our package, I know Webmin lives in /usr/share/webmin. If I sit down at a system installed from the tarball, I have to guess where it lives, or go dig into the initscript to see where it points to. I agree with sybreon...you're trying to solve the wrong problem here. The problem is you don't know why Webmin failed to install. Installing it again will just keep failing until you understand why it's failing and resolve that problem. Anyway, to answer your question, if you don't have an uninstall.sh script in the Webmin directory: Remove the Webmin directory. This is whatever you told it to use. Maybe /usr/local/webmin, maybe /opt/webmin, maybe /usr/share/webmin. Probably the first of those. Disable the Webmin service on boot using the Debian update-rc.sh script (I think that's how it's done on Debian, anyway) Remove the Webmin initscript (/etc/init.d/webmin) Remove any Webmin cronjobs; or, if you're going to reinstall Webmin, you can just leave them and double check to be sure there aren't any extraneous ones using the crontab editor in Webmin. I think it will skip adding cronjobs if they already exist, even if it doesn't know it's an upgrade. That's pretty much it. Webmin isn't compiled, doesn't touch any system directories except creating the startup script, and doesn't leave stuff lying around at random on your system. 

I'm running Debian on a machine that has limited memory and no option to add swap space. The machine serves as a web and database server. The problem I'm seeing is that when multiple web requests come in, my database stops accepting connections and sometimes even crashes because the system has no more available RAM. Is it possible to tell Linux to kill specific processes (in my case, Apache) in case another process (in my case, Firebird) requests memory and there is not enough? If it is not possible to do natively, maybe there is some tool to help me achieve this? 

I have a haproxy server which gets limited to some 60k connections. I think it is because of ephemeral port limit as I have 1:1 connection mapping, so all my outgoing connections go to the same server. Here is what I think could help me: I can add a new network interface (eth1) with a new IP. I would then add a duplicate backend server definition and I believe the new destination will get a new ephemeral port limit as long as it uses a different interface. This should let my connection counts grow. However, I can't seem to find a way to force haproxy to use eth0 for one backend server definition and eth1 for another. Is it possible to do that, or are there other ways of achieving what I need? The system in question is running Debian and haproxy 1.4.8 (default on Debian). 

What are the permissions of /var/lib/bind and the hosts files within it? The likely problem is the files are owned by root:root, but need to be owned by bind:bind or named:named or similar. Check to see what user owns the BIND process, and make sure those files are owned by that user. BIND drops privileges after starting and claiming its ports, and so if the files are owned by root, it wouldn't be able to alter them. You can change file ownership with the command: 

Of course. SSL certificates are not really related to the OS or OS version, at all. The OS doesn't need to "accept" the SSL certificate. You would simply configure your new server with the SSL certificate in the places you're using it (presumable in Apache for web service, possibly in other services, like SMTP in Postfix or Sendmail or POP3S and IMAPS in Dovecot). There have been some changes to SSL that effect end users over the years, in terms of commonly used key sizes and the like, but it is a very slow-moving standard. Your certificates should be useful for years; we have some that have been in use unchanged for as much as five years. Oh, one other thing: If you were running a version of OpenSSL affected by the Heartbleed bug, you would need to get a new certificate, regardless of OS changes. If you use the standard package provided by CentOS 5, you will not be affected by this bug. It was introduced midway through the CentOS 6 lifecycle, and never appeared in a CentOS 5 OpenSSL version. 

The error you're talking about does not necessarily mean it's Applocker. Applocker can manage Universal Apps, it's called "Packaged app Rules" and you have to create at least the Default Rules in the "Packaged app Rules" node of your applocker policy. You can take a look at the AppLocker logs too: $URL$ 

You forgot to add "%" before and after ERRORLEVEL: IF %ERRORLEVEL%==1 GOTO OFFICE2007 etc... And you need to add in your OFFICE2010 section, otherwise you will execute both files. 

This probably means that you should suffix the user names with "-ada" (for example) if the user is an ADAdministrator, example: jdoe should be jdoe-ada if this account is an AD Admin. This allows you to see at a glance that it's a privileged account and that it must be used knowingly. 

is not a "root flag" (doesn't mean anything on Windows) but the Read accessâ€¦ a user can't change the permissions of files if he is not allowed to do that (i.e if the user is not the owner of the file, or if he doesn't have any rights to do so). 

The parameter you mention allows the Broker to know which collection the client is trying to connect to. Since a broker can manage multiple hosts and several collections, this setting is essential. Let's break this parameter in multiple parts: 

Yes, you can use SOFS, or Storage Spaces/Storage Spaces Direct. What do you mean by "a standard file server cluster"? Don't forget that the share must not go down when UPD are in use, and you must use a Windows Server-based share/cluster. $URL$ 

I am running several different Firebird versions (2.0, 2.1) on multiple entry level Windows-based servers with wildly varying hardware. The only matching thing between them is that they are running same home built application with the same database structure. Lately I've been seeing massive slowdowns on multiple servers. Turns out that database gets corrupted, so each time it breaks, I get to mend, backup and restore the database, and it all is fine for some time (1-2 weeks), and then it repeats once again. Thankfully, I haven't seen any data loss or damage... yet. The thing is that every such downtime results in lost productivity, and often quite some driving for me as some of the databases are in remote locations. I've been trying to find out what's causing the corruption, but I haven't been able to. The fact that it's running on different hardware hints that it should not be a hardware based problem. If we rule out hardware issues, I have a bad feeling that it's a bug in Firebird as I'm not doing anything fancy via SQL. Do you have any idea how to find out exactly what's causing the corruption and hopefully fix the problem? [edit] According to first reply: I get several different problems in firebird.log: 

I have always been wondering why Windows Installer only allows you to install one program at a time. It is very frustrating not to be able to launch multiple installations, especially when setting up a new installation of Windows. What is the reason for that? 

This doesn't make sense. Edit: Actually, looking at this, this is not even a PHP thing. This is a Webmin page. PHP isn't even involved in the request you're looking at. Where are you getting this data? It's not from the request to index.php. It's for a request to the Webmin init module where you were changing the state of the lighty initscript. My original reply didn't take into account that your data is simply not what you think it is. PHP and lighty are not involved in the request you're looking at, at all. 

Nothing is wrong with Postfix (or the Virtualmin install), as far as I can tell from the information provided. Your Postfix is being killed with SIGTERM; it doesn't look like it is crashing, it looks like it is being told to shut down. I would guess it is the OOM killer kicking it out because there's not enough memory on the system for everything you're trying to run. How much memory do you have? Is this system a VPS with so-called "burst RAM" and a much smaller amount of "guaranteed RAM". In a system with "burst RAM", it just means that you will never be able to count on your system to be stable...processes will be killed at random and there's nothing you can do about it, because processes and the kernel don't know what to do with RAM that suddenly disappears; but some hosts over-sell memory and advertise it this way. And, it may just be a VPS with oversold memory, without labeling it "burst RAM". You can usually find OOM errors (out of memory) errors in the kernel log (just run dmesg to see the recent kernel log entries). If you do find out of memory errors in the kernel log, you'd need to do one or more of the following: 

No, permissions are based on the SID (unique identifier assigned to every users, groups, etc... ) The newly created user will have a new SID. You should put your users into groups, and then give permissions on the group instead of users. 

In your screenshot, you are creating a network share (to create a file share and not to connect to it!) You should use the following GPP: User Configuration -> Preferences -> Drive Maps 

Use BitLocker, or any other hard drive encryption. It's the only reliable and truly secure way to achieve what you want. 

You can use the Remote Server Administration Tools (RSAT) to bring the management tools on your computer. You can download RSAT for Windows 10 here: $URL$ 

This is because the Networking node relies on SMB1, and SMB1 is deprecated on Windows 10. If you still want to see the computers in the "Network" node, you can try to follow these instructions, in "More Information" -> "Explorer Network Browsing" : $URL$ 

This behavior is expected, it works when you are in your intranet network/domain because the browser (Internet Explorer for example) can use the Integrated Windows Authentication (given that your domain is in the Windows' Intranet security zone) If you use a non-domain joined device, the browser "sees" two completely different domains and has no idea that they are related each other. Maybe, if you bring the iframe on the same domain that the parent frame you will see only one authentication request. 

Disclosure: I am a developer on Webmin, Usermin, Virtualmin and Cloudmin, and work for Virtualmin, Inc. 

I won't try to sell you on Webmin (I'm one of the developers), but I will point out that for web hosting management, Virtualmin is the project you want...not Webmin by itself. Webmin is a general purpose systems management GUI, and does very little to make web hosting tasks easier or quicker. Virtualmin is built on top of Webmin and is intended for virtual hosting, and makes a lot of tedious tasks very simple. So, if you've looked at Webmin for virtual hosting management, but not Virtualmin, you were looking at the wrong project, and it shouldn't be at all surprising that it wasn't what you wanted. 

Andrew Smith is correct, but has an unnecessary step in his suggestion. You don't actually need to login to ssh with a password for Webmin to work; ssh and Webmin are unrelated services. Simply set a password for your root, or sudo ALL capable user, and that will be the way you login to Webmin. 

We have a guide for reducing memory usage here: $URL$ Edit: Also, I'm not sure what to make of the error you had in your configuration after install. The last test install I did on CentOS didn't have this problem, but if it is reproducible, please file a bug with the steps to reproduce it, so I can get it fixed. It's possible (maybe even probable) that it is caused by the same problem with your system that is causing all the other problems. Installation is pretty demanding of memory, because so many packages get installed and started up at once.