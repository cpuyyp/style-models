While rendering with blending isn't the fastest possible rendering mode, it isn't exactly slow either. It doesn't go to each "thing" it has rendered before and blend with it. It's just blending with the destination color in the framebuffer. 

The purpose of "instanced" rendering is to make one draw call to draw all of the instances. You are making number of draw calls. So no, that's not instancing. Since each instance is completely separate from the other, sharing absolutely no data at all (the matrix is basically just a bulky way to encode the two endpoints of each line), you would gain nothing from instancing. Instead, you should build a vertex buffer that contains all of the lines (and their colors). If lines change, you change the buffer. This way, you draw all of them at once. 

The compilation model for OpenGL is described on the Wiki. But for your needs, I would suggest you simply use the fact that takes multiple strings. These strings effectively act as header files; the shader stitches them together and compiles them as a single unit. The "linking" model within a shader stage is not something I would... rely on. Not because of the specification, but because it's not widely used. And that means it's more likely to have driver bugs in it. Stick to the path most commonly used and just use multiple source strings. That way, your code is more likely to work. 

When doing game design, it's important to start out with a list of goals, what you expect the design to accomplish. That way, when you've created the design, you can analyze it against your list of goals to see if it actually does what you wanted it to. For example: 

Your question seems to confuse certain concepts, so let's take things from the top. This is the definition of the function : 

It isn't possible to create a program with geometry shaders that handle multiple primitive types. That being said, you don't have to do a whole lot of work to support multiple primitive types. Thanks to ARB_separate_shader_objects, you no longer have to link all of your shader stages together. You can have one vertex-only program, one fragment-only program, and 2-3 geometry-only programs that you mix-and-match together. As long as they use compatible interfaces, you'll be fine. 

If you used the extension function to create an object, then you must only use those extension functions to manipulate that object. So if you use to create it, then you must use to give it source strings, to compile it, to attach it to a program, and to delete it. Remember: the return type of is , which is a pointer, not a like the return value of . So they don't even use the same object type interface. The only functions that work with the ARB_shader_objects objects are those that explicitly say so. Which basically means those from that extension. Also, there is no guarantee that you can compile any GLSL versions other than 1.10. The extension only guarantees support for that version, no others. Basically, there is no reason to write code for this terrible 10+ year old extension. If you want to support hardware that has some shader functionality that isn't GL 2.0-capable, then use ARB_vertex/fragment_program. 

This doesn't make sense. Your stride is 12 bytes, so OpenGL will offset the current location for that attribute by 12 bytes for each vertex. But your data is interleaved. The first 3 floats are a position, and the next three are a normal. Your 12-byte stride means that the positions are tightly packed. So the positions for vertex 0 will be the first 3 floats, the postiions for vertex 1 will be the next three floats. You want it to be 6 floats from the first, not three. Your stride for both needs to be 24, not 12. 

You can write unsigned integers and use bit manipulation to pack data into them into half of those integers. You can use the ARB_shading_language_packing extension to help out in this process; it's pretty widely supported, even on older AMD HD3-5xxx cards (though I make no claim as to how well this actually works. They simply claim to support it). 

You're not going to find anything that user-friendly in the open-source world. Not full-fledged game engines. If you don't want to spend money on an engine, then you're going to have to accept one immutable law: you get what you pay for. Let's go through your points: 

Geometry shaders are geometry shaders, regardless of the API you use to access them. They are supported on the same class of hardware: DX10-class hardware. 

Do you currently modify your cubes on the CPU in order to do frustum culling? When you move the camera? If not (and I'm guessing not), then there's no need to do it for the GPU as well. If so... then you should probably stop doing that. Unless the positions within a given mesh are actually moving relative to one another, they should not be changing. They should be static. You should be transforming those cube chunks into different positions using matrices through OpenGL. The vertex positions you pass, whether in immediate mode or with buffer objects, should not be changing. Frustum culling should not be done against the actual cubes, but against the bounding volume of each chunk. That's what you should transform to do frustum culling. Yes you can, but I would strongly advise against it. See below. You can do whatever you want. But you shouldn't be deleting the actual buffer objects. Instead, you should be swapping data into and out of them. Allocate however much active buffer space you need initially, then upload different data into them as needed. More information on streaming to buffer objects exists. 

For a rigorous mathematical discussion of the issue: The 4D homogeneous representation of a 3D vector direction uses a W of 0. This is the root of your problem. 

Of course, texture swizzling can mess around with this too. But that's a discussion for another time. 

ASCII games are really nothing more than just tile-based games that use character glyphs instead of pictures of what they really represent. In general, height fields do not work well in tile-based games. Not unless it's in some kind of perspective view. Height fields generally are used for 3D terrain. When your palette of tiles is limited to whatever characters happens to be in the ASCII character set and the particular font to be displayed, you have to put forth some effort in comparing the different glyphs to see which ones look good "in front of" the others. In general, when it comes to ASCII art, the glyphs with less stuff in them are darker and can thus represent farther away terrain. Or you can just ditch the ASCII art and put together a real black-and-white tilemap. You're more likely to get good results and it really doesn't require that much more work than ASCII tilemaps. 

That will never actually draw anything. Triangles are made of 3 vertices and you told it to read 2. I doubt that's causing the seg-fault, but it might be. Just change the 2 to 3. Next: 

N' has a W of 0. N'' will also have a W of 0, unless M is a very ill-behaved matrix. And if it is, then you've got problems. 

That is a limited and limiting thought. I could give the spiel about different games having different UI needs, that some games do need resizeable windows and so forth. But there's a much bigger problem. Your kind of thinking leads to the Gratuitous Space Battles problem. If you've never played that game, it's a cheap, indie, and very GUI-heavy game. The actual gameplay is all done in the GUI (it's a "setup the units and watch them fight" kind of game). The problem? THE GUI CANNOT BE RESCALED! Oh, this is fine if you're using a normal monitor or have normal eyesight. But if you're me, for example, who runs a ridiculously huge monitor (one so big that you have Windows scale up the size of all text so you can actually read it), this is terrible. The text is microscopic. There's no way to change the font size. Granted, GSB is a GUI-based game, so it's absolutely inexcusable for them. A GUI-lite game can probably get away with it. Never assume that your user is looking at their game exactly as you are. To do so is folly. Having a GUI system that can rescale itself to the user's resolution, a truly resolution-independent GUI, requires layout to be part of the GUI system itself. If you're not going to provide that, then your text is going to appear tiny on someone's giant monitor. This is not a good thing. So I would say that your thinking on this subject is shortsighted. You do need that stuff. You need what retained GUIs provide. Oh, you may not need everything any particular GUI system provides. But you need some of it. The boilerplate work you need to do to get data to the system is a small price to pay next to having reasonable assurance that the user can interact with controls correctly and that it will resize itself to fit the player's needs. You might be able to get away with an immediate-mode GUI if you don't take much user input from the player. But that'd be about it. 

You are using Direct3D 11. So the only thing your mesh should be doing is setting up the Input Assembly stage and issuing some form of Draw call. So your mesh should only call , , , and , followed by one or more calls. Everything else should be handled by whatever code called the mesh's draw function. A mesh is just a dumb collection of the vertex state needed to draw. Any higher-level logic (what shaders to use, blend modes, etc) should be handled outside of the mesh. 

The following answer will assume that you are trying to do the following: There are certain tiles in your background which already have shadows baked into their images. You don't want your shadowing layer to affect them at all, but you do want your shadowing layer to affect everything else. There are several ways to accomplish this. Multitexture No "foreground layer" at all. Instead, have each tile tell whether it is shadowed or not. Render the non-shadowed tiles as normal. The shadowed tiles are rendered with two textures and two texture coordinates: one that picks from the background texture atlas (or however you're doing your rendering) and one that picks from the foreground atlas. You simply do the "layering" as part of your shader/texture environment. It's a simple multiplication, or perhaps an alpha blend, depending on how your shadowing works. The same goes for sprites. This method only works on a per-tile granularity. Stenciling You can employ a stencil buffer (if you do, make sure you also have a depth buffer. 24/8 depth/stencil in size). This brings layering back, but you still need to mark which background tiles need to be shadowed and which ones don't. At the beginning of the frame, clear the color, depth, and stencil buffers. The stencil buffer should be cleared to 0. Tiles that do not need shadows should be rendered with a stencil value of 0. Tiles and sprites that need them should be rendered with a stencil of 1. Make sure that your sprites use alpha tests/discards to cut out the area around them. The code for this would be (warning: untested):