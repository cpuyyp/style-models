Then when you need to start it you just call . Other than that please keep a consistent format, especially the indentation and brace style. It will vastly increase readability. Compare the listener I provided to your listener. Also the fixed layout of the components will do odd things when the user tries to resize the window, I suggest using a layout manager. 

Actually if there is any virtual function you should include a virtual destructor so proper cleanup can happen if you a and it happens to be a (otherwise the destructor of is never called). 

Your temp array is static, this immediately makes your function not thread-safe and non-reentrant. Instead add it to the parameter list. 

Besides that if you are using it for parsing then you will be popping and pushing nodes often. So it may be worth reducing allocation cost on that by keeping a linked list of previously allocated nodes: 

or simply preallocate result with SysAllocStringLen(&result, qstring.length()); and translate into that 

This assumes that the container holds raw pointer and it owns the pointers. it is a better idea to then let the container hold smart pointers. These will automatically clear the object they hold when they get destroyed (using by default). 

Admittedly it's a lot of lines, but they're very easy to understand. Also, the test method itself becomes dead simple. Since I'm on the topic of tooling, you might want to look into the TestDriven.NET Visual Studio plugin, which provides very nice "right-click -> run test" integration. 

It would be easier to figure out what's going on by separating those things out from each other. It might also make your life easier if you ever want to do anything more complex with this data than just dumping it to XML. So let's just do a little rewrite. To start with, let's create a class to hold each of those elements. (Honestly seems like a confusing name to me, it seems like maybe or might be more descriptive, but let's just stick with .) 

It's impossible to say what the problem is without knowing how the data is structured, how many rows are in each table, what the indexes are, and other information. Even then, the problem may not even be with this query but with some other query that causes problems for the database as a whole. Basically, your question is far too narrow. That said, you could try a few things: 

I think the major part of the slowdown will be applying the style. Otherwise you can pregen an array with the possible phases: 

Asserts are kinda useless in java, they only work when the jvm is started with the -ea flag (or you do some reflection). instead just test and throw the IllegalArgumentException in the public method and remove the obvious assertions that would throw anyway. 

Besides that you store a date as a string in the database, let dates be a dates. In fact the function itself is not necessary with how the code is used. Make OOP? well you could create a querryable object that will return the aforementioned array and keeps the object handle private. 

first check if the priority 1 are unequal and then return 1/-1 accordingly otherwise check priority 2 and repeat If you reach the end then all terms will be equal: 

First thing that is wrong is that you are reinventing a wheel. Second why not ditch the and do directly in the first runnable instead? 

Since your data is already sorted you definitely don't need to use a dictionary. You can just accumulate and then whenever the or rolls over you write them all out. That wouldn't be a huge change from what you've got. But honestly, what you've got is a bit confusing because you're trying to do several things at once. Namely: 

So now we have a nice, clean list of the data you need to output. Basically we've handled the first and second bullets from my list, so all that's left is turning that into XML. There's probably a cleaner way of doing this than using s directly, but let's just stick with it for the moment. But again, let's stick all the logic in a nice clean function. 

I would use NUnit rather than the Microsoft test tools. NUnit has a better assertions library (for example is quite useful). It also has easier data-driven testing that would let you remove all of the looping logic from your code. For example: 

Instead of using a raw array to store the children you can instead use a . This will better optimize the allocations that you do. Using a map will also remove all the for loops for searching a key in a layer. 

I would add the (currently global) VM state as a parameter to the function. This will make reentrant and allows multiple VMs working in parallel. I would prefer a switch for dispatch, it reads cleaner, and there is less chance of the jump table being messed up because you miscounted. Just a stack with only a view to the top 2 elements and 3 registers is very likely not enough. It's not Turing complete in its current form. You cannot sort an array with it for example. Add bounds checks for storing and loading the registers. Add bounds checks for stack over/undeflow as well. For a VM to be useful it needs to interact with the outside world, that means opcodes for input and output from peripherals/game engine. Stack implementation is fine (except for the bounds check) though using union to bitcast between types is Undefined Behavior in C++. You will need to use a memcpy to do the bitcast: 

Try running this with Explain Plan turned on. That should tell you what part of the query is taking the longest. Run and then your query. That will give you an idea if the I/O usage is high. If the above don't suggest improvement, check the overall DB for problems. Glenn Berry's SQL diagnostics queries are a good place to start. If you still can't figure it out, hire someone like Glenn to help you. Or start reading a lot of books on SQL Server optimization. 

That last function isn't really a thing of beauty either - it's got kind of a lot going on. But it's definitely better. I also added a statement around your , which is just a handy way of making sure that it gets d properly. By the way, I put up a DotNetFiddle of the whole thing. It doesn't work because I don't have a database to use, but it might be easier to read there. 

Now, let's write a function to parse the database records out into a list of objects. This is basically doing what I said earlier - tracking until we hit a new or . We're using C# iterators (that's the syntax) to make this a little bit cleaner. 

The way to solve this would be to not advance in the outer for loop so you can keep it pointing to z after the insertion. This also means that you can use the same insertion strategy in both cases 

You are using strings to store numbers and booleans, bad ideaâ„¢. Store them as the type they need to be and only convert when needed (JSON allows floating point and boolean values without the explicit conversion to string) I'm not a fan of hungarian notation. The prefix is unnecessary and just adds clutter to the names. A good ide will allow you to highlight field differently from local variables. You should add getters for the properties. You have 2 different key-to-field mappings. I suggest that there should only be one of them. You can convert to 3 different objects I suggest that there should also be a way to get a LocationInfo object from one of those (and make sure the round-trip is valid). add and 

As a more general suggestion there is a better method than reading the entire file doing some processing and then writing the output. Instead you can read only as far as you need to process a part of the data and then write the result out again. Whether you can depends on what you are actually doing with the data. This is only possible if you have a 1-pass transform. 

I'm not sure if you're interested in better algorithms, but if so here are some. In this particular implementation, I would consider changing how you handle substrings. You're currently doing a lot of string concatenation, which can be slow as a new object is allocated each time. Since you're just tracking substrings anyway, you could instead store the source string, start index and length of each match. That would save you potentially quite a bit of memory, and run faster as well. If you're really attached to having separate string objects, at the very least figure out the extent of the match and then do a single to extract it, rather than building up the substring one character at a time. 

Before even addressing the actual question, have you actually proven that database queries are harming your responsiveness? Since the queries are to local storage it's possible that they are fast enough to not require using asynchrony, particularly if they are simple queries or the database is small. Next, I notice you've assumed that the database itself is not threadsafe, i.e. that you must only allow access from one thread at a time. Are you sure that's actually true? Many (most?) database handle concurrency themselves, so you may be adding an unnecessary layer of synchronization. I looked around a bit, but could not find anything specifically documenting concurrent access to isolated storage databases. I would start by researching that, or possibly asking a question on StackOverflow. If the database does allow concurrent access then you just need to worry about update conflicts, which you could hopefully avoid in a single-user phone application. What I'm getting at here is that multi-threading and locking is hard. Don't do it unless you're sure you have a good reason to do it. If you really must to multi-threading, then the C# keyword is a good place to start. Unfortunately, your example probably will not work properly because each instance will have it's own lock object - so if you create more than one instance they could conflict with each other. You "Current Variant" actually gets this more right, because your is a static variable, so there is only a single instance of it across the system. However, as I understand it lets you use Linq statements against the database, which will not know anything about your lock and hence will not be synchronized. I think you'd have to create a separate application layer to wrap the and expose just the certain operations that your application needs. This is generally called the "Repository Pattern". Inside the repository you could create a single lock object, wrap a around all accesses to a , and use inside each of the repository methods to make them asynchronous. 

you have a O(n) time algorithm using O(n) space I don't see how much better this can be without using an external data store or a calling hasNext will advance the input several times which is not what you want. to fix test if next is already set: 

There's a minor race when the queue has just been emptied and the flag hasn't been reset yet. If a thread then adds an update it will not post the runnable to the EDT for running and the current invocation will just reset the flag and return. This can be fixed by checking the queue again after resetting the flag. 

You should put the lock statements before the . For example if the thread is interrupted before your interruptible acquire then will throw and the will try to a non-locked lock (which will throw a ). There is no need for the signalAll in the acquire methods, as nothing happens that may require a waiting thread to awake (all that were waiting will still need to wait). Similarly you only need a call in the to signal a single waiting thread to awake. Only the first issue is a true bug the other 2 are performance issues (and invalidate the fairness)