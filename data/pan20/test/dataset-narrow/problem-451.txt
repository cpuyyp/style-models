Adoption to your templates and other missing operators such as and const correctness are left as an exercise for the reader. 

because is automatically joined on destruction. My memory has failed me, if the thread isn't joined on destruction is called. Looking at here: 

Integer Overflow I'm not very confident with ruby but I'm assuming this is integer arithmetic (otherwise you could have a floating point index, which doesn't make sense): 

Thread Safety I'm not going to review thread safety as I'm not confident enough in the correct behaviour of the code. Addendum: Graceful Shutdown Requested in comments. To make a graceful shutdown when you may have other threads waiting on data on the queue you need two things: 

In addition to what has already been mentioned, the string representation of the name is a derived property of the registration number and as such I believe that it should be computed internally in the constructor. This saves you one argument to the constructor and avoids code duplication if you have multiple factories. Like this: 

The singleton pattern has all those properties with the benefit of automatic destruction when your application terminates by normal means. 

Work in logarithms You can simplify your determination of the correct suffix by using the logarithm of the file size. First of note that \$1024 = 2^{10}\$, \$1024*1024 = 2^{20}\$ and so forth. You're checking if \$x < 2^{10}\$ and then if \$x < 2^{20}\$ etc. It's much easier to take the two-logarithm of \$x\$ and then check \$\log_2(x) < 10\$, \$\log_2(x) < 20\$ etc... Now if you take \$k=floor(\log_2(x) / 10)\$ you will end up with \$k=0\$ for bytes, \$k=1\$ for KiB, \$k=2\$ for MiB etc. Which means that you can simply index into an array of the suffixes to get the right suffix, then upscale the result to get the correct number of digits. Like this: 

Why do you not want to use a virtual destructor? This would make all your headaches go away. Yes you need a v-table, yes it's an extra indirection to figure out the correct destructor to call. But unless this is in the 1% of code that is your inner-most time critical loop, it will rarely matter on PC platforms. 

Avoid unnecessary memory allocations. Memory allocations take time, significant time if you do them in your inner most loop. For starters, change: 

I don't do C# so pardon the syntax, but you should be able to reduce the amount of code by using a for loop over a string array with your column names. Again I don't do C# but in Java you could do something like this: 

Just a note for the curious. String comparisons are memory comparisons which are slow as you have to check all bytes in the source operands for a successful or near-successful match. But they can also exit early. So comparing one \$k\$ character string to \$n\$ strings of \$k\$ characters is anywhere between \$k\$ (match on first) and \$k\cdot n\$ character comparisons (all strings differ on last character). The JIT can optimize memory comparison to use native words instead of chars in loop unrolling. The array approach suffers from the same problem. Using a computes the hashes once for all \$n\$ strings as a pre-processing step. Then comparing one \$k\$ character string is equivalent to computing the hash for the string, which is \$\mathcal{O}(k)\$ character operations and then a lookup in the hash table is just an indexing operation, \$\mathcal{O}(1)\$. So ignoring the setup cost, the runtime improvement would be \$\mathcal{O}(nk) \rightarrow \mathcal{O}(k)\$ which seems like a good deal to me. 

where is an arbitrary constant, is a small value and is a value strictly smaller than i.e: . Your upper bound algorithm would pick i=0 first and then be unable to add any other items to the knapsack and the achieved value is: 

I was going to write this as a comment to @LokiAstari's answer but it turned out to be too long... What @LokiAstari points out in their answer is mostly correct. What you have implemented is essentially a but with one minor difference you preserve the insertion order when you later iterate over the set. While iterating over a is the same time complexity as iterating over your ; the set is implemented using a tree and when iterating a tree you will chase pointers possibly resulting in several cache misses on the way, while on the other hand your code is using a vector which is contiguous and fast to iterate over. Because of this iterating the will be faster in most cases. However you have double the memory usage of a . Note that and do not invalidate any iterators: Until C++17 

Do you care if the sequence is "seemingly random" instead of actually random? If the answer is "no" then there is a really fast, simple and cool trick you can use: "Fake shuffle" If you are shuffling between \$k\$ items. Pick any prime \$p>k\$ (use a sieve at program start, or hard-code a list of big primes). Finally pick any random starting index \$0\le i_0<k\$. Then the next index to visit is always \$i_j=(i_{j-1}+p) \mod k\$. This deceivingly simple algorithm will visit all the \$k\$ items in a seemingly random order without visiting any item twice (in any loop over all items). Example Don't believe me? Try this: \$k=8\$, \$p=11\$, 

Consider handling and inputs Currently your code will silently break if any of the inputs contain or . I would consider testing for these inputs and throwing if they are encountered. Return type of is weird As far as I can tell will return the input value or if the input value was not removed. To me this feels very strange, I would much rather it'd return true if the statistics changed and false otherwise. Change API to use instead of Currently your methods like first unbox the number into a then rebox it into a . So calling with a causes unnecessary boxing and unboxing. Further more calling with any of the primitive types (,, etc) causes first a boxing to , then an unboxing to then a re-boxing to (to use in ). This is a lot of unnecessary boxing and unboxing and will also generate a compiler warning on many systems. So I would change: 

I would recommend to go the OOP way and create a class which has all those fields as members. Then you do the initialization once and let the member functions just use the fields. This nicely avoids the code duplication and opens up opportunities for better design in general. Also the local variable doesn't seem to be used in is this correct? If you don't want to go the OOP way you can extract a function like this: 

then the value would still be wrong. To achieve a uniform distribution must only return values with the same exponent (i.e. only the mantissa differs). Otherwise you'd have many more numbers between [0, 0.01] than you would between [0.01, 1.0]. So for any return value of besides the addition of will truncate. However if returns 0.0 you will get the smallest value larger than 0.0 that is representable (5e-324) as your result. But then there will be a huge gap to the next number that you can get as a result, so your distribution will not be uniform any more. The following is also wrong: 

As is a class only used inside of it should be private or protected. Because it is protected or private and it is pretty much just a POD structure, you can just drop the accessors (get/set methods) which you weren't using anyway. Rule of thumb, if you're not using some parts of the code, remove them. The less code you have the better (generally). But don't skimp on the white space :) Your put method allows the use of -1 as a key, but your get method uses -1 to signal a 'no such element' condition. Either you need to throw a from or you need to use another way of signaling that there is no such entry. I would suggest throwing like this: 

Broken for more reasons Without even looking at the details, I can tell that the mutex is not safe. The compiler is allowed to re-order your instructions which means that your writes and reads may not occur in the order you have written them. The compiler may actually even omit them totally... Not to mention there is no guarantee on memory ordering semantics at all. Writing threading primitives correctly is VERY difficult, I do not recommend that you try to write your own unless you are very knowledgeable about the pitfalls. (And if you are, then you know you don't want to do this unless absolutely necesscary). 

Your code is not C++98 compliant Standards prior to C++11 only allows integer static member initialisation (see here). So unfortunately your code is not C++98 compliant and in fact does not compile. So technically your code is off-topic on this site. As it is not working as intended. Your code probably only compiles because you're using a compiler that has an extension to allow non integer const static members. To get around this typically you would define a static method that returns the value. In fact, this is why is a function instead of a static member value. However these cannot be evaluated in a constant expression context. You need C++11 for that afaik. General advice Some general advice. Template parameters are compile time constants by definition. Any sensible compiler should do any necessary casts during compile time so you will not get a run-time penalty for using higher precision. For this reason I advice that you use the largest types possible in your template to get the most precision at no additional cost. I.e. change to and to . You should consider wrapping the templates that are not intended for use by the user in a suitable namespace. Typically I use a nested namespace called . Also identifiers in are typically reserved for macros. So I advice against using this naming convention for your identifiers as it will confuse many readers. Better implementation If we restrict ourselves to the bits of the code that are C++98 compliant, then we can have a much easier implementation for the integer exponentiation. 

We have to be careful about the inequalities and off by ones here as any error adds a bias. Lets check: 

You're almost there. You rebuild the entire HashSet for each of the i-m sub arrays resulting in (i-m)*m worrk. Change the HashSet to a HashMap and then imagine the sub array as a sliding window. When the window moves one step to the right, count down number at the far left of the old window position in the HashMap and if it becomes zero, remove it. And then add the number to the far right of the new window position to the count of that number in the HashMap (or add the number with count one if it didn't exist), and at each window position take the size of the HashMap. This is (i-m)+m work which is much faster. 

This variable is never used outside of the constructor, in fact it is almost always shadowed by a method parameter. As such I would remove this member and the accessor which isn't used either. Variable shadowing is something I detest and find makes code much harder to read. I would recommend that you get into a habit of avoiding shadowing. Instead of having: 

I found myself in need of a fixed size queue and decided to implement one using a ring (cyclic) buffer. I have tried my best to match the API of with the addition of to test if the queue is full and unable to accept another element. The code compiles cleanly with: , it runs and all tests pass on clang 3.9.1. Unfortunately at least GCC 4.9.4 and below cannot compile the header file due to a bug where a specification can't refer to a member. All comments welcome. File: 

which reduces the expression of from 3 mult + 4 add to 2 mult + 2 add as the results from f1 can be re-used. The compiler should put the calculation of towards the end of the function and calculate while computes. There could be more of the same type of optimizations you can do by rearranging operations but unfortunately I don't have time to give a more thorough look. Disclaimer: The compiler may or may not do these optimizations depending on the FP precision setting. For example -ffast-math on GCC would probably do these, but only if -ffast-math as IEEE is not associative due to round off errors. There is an equivalent option for ICC but I don't know what it's called. But be advised this option can break stuff, like NAN handling/checking. 

And this is exactly the case you have, so I implemented Shaker Sort (which is simply Bubble sort but you bubble both ways) and compared it to your Local Heapsort: 

We have visited all indexes exactly once in 8 steps. What would the next index be? Well \$i_8 = (1+11) \mod 8 = 4\$ and the cycle would repeat. Want another cycle? Pick another \$p\$! Previous index Getting the previous index is a bit more difficult. Consider the modulus of a positive number: \$ R = a \mod b \$ then we have that \$\frac{a}{b}=Q+\frac{R}{b}\$ for some integer \$Q\$. In our case: \$R=i_j\$ and \$b=k\$ and we're interested in \$a=i_{j-1}+p\$. So solving the above gives: \$i_{j-1} = k\cdot Q+i_j-p\$. We then have \$0\le i_{j-1}<k\$ and there exists only one \$Q\$ for which this is true. Just assume \$Q=0\$ for starters, then \$i_j<k<p \Leftrightarrow i_j-p<0\$ then we have \$Q=\left\lceil\frac{i_j-p}{-k}\right\rceil\$. So finally: \$i_{j-1}=k\cdot \left\lfloor\frac{p-i_j+k-1}{k}\right\rfloor+i_j-p\$ Example reverse Here we go: \$i_6=6 \rightarrow i_5 = 8\cdot \left\lfloor\frac{11-6+8-1}{8}\right\rfloor+6-11=3 \$. The others are left as an exercise for the reader. :) Caveat If the number of items happens to be prime, then this will "shuffle" to just a plain reverse. You should detect prime sizes and then padd the size and just skip indicies outside of the range. Note: I don't remember the name of this algorithm, if some one can help me I'd be very happy! Edit Couldn't stop myself, here's an implementation. :)