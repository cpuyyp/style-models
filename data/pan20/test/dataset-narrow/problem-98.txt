To establish a TCP connection one end (the "server") listens and the other end (the "client") connects to it. Once the TCP connection is established either end can send data to the other end whenever it wants. In practice however your clients are likely to be behind firewalls or nats and that adds some complications. 

1500 bytes is the standard MTU for Ethernet. Lots of Ethernet hardware now supports larger limits but unfortunately there is no standard for handling segments with mixed MTUs on a single vlan. So increasing the MTU from the default of 1500 bytes means that you have to make sure every device on the vlan is both capable and configured to support the larger size. That is a massive PITA. For the most part the pain of running jumbo frames doesn't outweigh the gain. Some exceptions are networks that are used to carry tunnelled traffic and HPC/SAN networks but those kinds of specialist high performance networks don't tend to cross organisation boundaries. There is no reason two autonomous systems can't make an arrangement to exchange packets larger than 1500 bytes but few do because it's normally not worth the cost/hassle to allow exchange of larger packets with a small number of networks (there is something of a chicken and egg situation here too). 

Going from a multimode fiber or a lightsource designed for multimode fiber into single mode fiber will result in a very high loss. You need to replace your patch cords with single mode ones and your transcievers with LR ones. 

Most NAT implementations are not capable of handing that case at least not witout extra hacks (on linux for example I belive that to implement NAT with overlapping internal and external space you would need to NAT the traffic twice in two different network namespaces). You are of course free to ignore that paragraph and use the addresses anyway. RFCs are not laws. Using "shared address space" for your internal networks is certainly a lesser evil than using squat space. If you do choose to ignore it and your ISP changes your connection to CGN then there is the risk of an addressing conflicts. So like many things it comes down to a risk assessment. How badly do you need extra private address space? how likely is it that your internet connection will be put behind a CGN in the future? If you are thinking about using this block because you are short of regular private addresses it's probably time for a long hard look at your IP addressing policies. Do you really have millions of devices on your internal networks? Are you wasting IPs with oversized allocations? isn't it time you thought about IPv6? 

A tradtional router does not care about the source address, only the destination. So it would just forward the packet as-is. However in the modern world there are a number of complications which make it impossible to give a definitive answer without knowing both what the gateway is and how it is configured. 

The tag number used in VLAN tags to create virtual networks. The virtual Ethernet network created through the use of VLAN tags. 

In such a setup when an end-host chooses a source IP it is essentially making routing decisions but end-hosts are poorly placed to make routing decisions. Adding or removing IP prefixes is often difficult as IPs are stored in many places. There were proposed extensions to DNS to help with this but they added a load of complexity and fragility to the DNS system and were eventually abandoned as "historic". It doesn't really handle the case when connectivity to one provider unexpectedly goes down. Routers will need to make routing decisions based on the source IP. Some routers can do this but it's an advanced feature, not normal routing. 

The second option is more flexible and saves you buying a home/small buisness router but it requires you to know what you are doing with setting up those features on your server OS of choice whereas the home/small buisness router will work out of the box. 

Contary to what ron says I have not heard of any browsers changing the default to https per-se and a google search didn't turn anything up either. It's difficult to be sure without knowing the site in question but I expect you are seeing one of two things. The first is HSTS, if a website is in a browsers HSTS list then the browser will never make plain http requests to that site. This is intended to mitigate sslstrip type attacks. There are two ways a site can get into a browsers HSTS list. Firstly when a https connection is made to the site the site can send a HSTS header adding itself to the list. Secondly HSTS entries can be "preloaded" by the browser vendor, modern browser A second potential cause is address bar autocomplete. Firefox apparently now preffers https urls over http ones when autocompleting. A third potential cause is extensions. There are extensions like "https everywhere" that try and push as many requests as possible to https. 

The compressor assigns "connection numbers" to TCP/IP connections. The compressor and decompressor use these as indexes into a state table to construct the compressed headers and reconstruct the full headers. The compression operates at the level of individual point to point links, it sits below the IP layer but above the link level framing. When a packet comes in over a link using header compression it will reconstruct the full header before making any routing descisions. If the outgoing interface also uses header compression it will then attempt to recompress the header. Due to separate state tables a packet may be compressible on the incoming interface but not the outgoing interface or vice-versa. 

Ignoring the fact that your numbers are 6 orders of magnitude off from reality. If the two computers are directly connected or connected via dumb repeaters then they Must run at the same speed. To interconnect between different speeds a device that can deal with complete packets/frames must be used, that device must have a buffer that is at the very least able to handle one complete packet/frame but in practice is usually significantly bigger. 

Put these points together and you need both the "host" and the "network" parts of an address to be large. Certainly more than 32 bits each. 64-bits each was probably overkill but better overkill than running out. * The dream didn't really work out because the Internet is not a fixed hierarchy but this isn't about what actually happened in the 20 years or so since IPv6 was introduced, it's about what drove the design. 

A collision domain is an area of a network where collisions can happen and where only one packet may be successfully transmitted at a time. It passes through repeaters (hubs) but not through bridges (switches). All half duplex ethernet connections are part of a collision domain, that domain may be limited to a single physical layer connection (which may be either point to point or multipoint) or it may pass through repeaters. Full duplex connections must be point to point and can't connect to a repeater. In this case there is simply no possibility of collison and hence no collision domain. 

It rather depends on what exactly the "problems" are. If the problem is that the customers port doesn't support 10 Mbps (uncommon right now but may well get more common in the future) then a simple Ethernet switch will do the trick. On the other hand if the problem is that there is too much broadcast (or effectively broadcast) traffic for a 10Mbps device to cope then inserting another switch isn't going to help. You will need something that can allow the legitimat traffic to your device through while filtering out the unwanted broadcasts. Often a "home router" works well in this role with it's "lan side" facting your device and it's "wan side" facing the noisy network. 

No, that is not possible. Subnets must be a power of two size and their boundry must be a multiple of their size. So having made the allocation above the first palce you could put a /25 is 172.16.0.128/25 . You could also place them at 172.16.1.0/25 172.16.1.128/25 Which arrangement makes the most sense, again it depends on expected growth. If you expect one of the subnets may need to be expanded to a /24 then it would make sense to put that one at 172.16.1.0/25 and leave 172.16.1.128/25 free. 

In the real world packet too big notifications often simply do not arrive leading to connections that transmit small amounts of data ok but then mysteriously hang. For a connectionless protocol by the time the server gets the "packet too big" notification it's too late. The packet no longer exists so it can't just be sent out again. Instead the sever must cache the packet too big, then the client must time out and re-send the request. For small requests the extra latency of sending a packet, getting the packet too big error back may make up a significant percentage of total request time. 

To make a VM mobile you want to be able to move it's physical location without changing it's apparent network location. What that means is that we want to be able to put it on the same virtual Ethernet network regardless of which host machine it is sitting on. As long as a system is generating at least some broadcast traffic the Ethernet switches will quickly figure out it has moved and update their forwarding tables. In a very small setup we might just put all our VMs on one flat Ethernet network. In such a setup we can migrate the VMs trivially. Downside here is that there is no isolation, every VM can talk directly to every other VM, broadcast traffic flows to all VMs and so-on. A step up from that is VLANs. we can split our Ethernet network into a number of virtual Ethernet networks. If we can establish a link from any host box into any VLAN then again we can migrate our VM seamlessly. That works ok for moderate scales. Unfortunately at large scales VLANs start to break down as a solution for decoupling physical and logical topologies. There are less than 4096 usable VLAN tags (not sure offhand how many values are reserved) and Ethernet's Tree structure makes it difficult to build reliable high-bandwidth networks. It is difficult to serve a default gateway IP from multiple locations, so traffic may travel considerable distances in the network before reaching the default gateway (and quite possibly being sent back the way it came) Which is where VXLAN comes in, VXLAN lets you build virtual Ethernet overlay networks on top of an IP underlay network. It can either be used on it's own in a "learning" mode using IP multicast on the underlay network to carry broadcast unknown and multicast (BUM) traffic for the overlay network or it can be used in conjunction with MP-BGP with vxlan end points advertising MAC addresses and IP addresses for the VXLANs to each other over BGP and simulating a virtual default gateway at each endpoint. Other than needing to support slightly larger frames than normal (sometimes known as "baby jumbos") the underlay network is just a regular IP network. Furthermore VXLAN is designed to allow scaling of the underlay network using techniques such as link-aggregation and equal cost multipath. To communicate flow information from the underlay network to the overlay network the UDP source port of the outer packet is based on a hash of headers of the inner packet. VXLAN also allows over 16 million network IDs which should be more than enough even for very large datacenters.