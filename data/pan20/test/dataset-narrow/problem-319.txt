I'm after information on how to better understand the trade-offs involved in such situations as opposed to a simple 's best. Pointers to articles which may help me understand would also be welcome. Related SQL Fiddle: $URL$ 

You could create a database in your x86 SQL db which contains synonyms (or views if you only require read only access) pointing to the Sybase DB, then call those synonyms over your linked server from your x64 SQL db. Not sure how you'd go about accessing a linked server via a linked server directly though (i.e. without the use of some intermediary object). 

Running sp_who2 and following the BlkBy trail up to the root cause of blocking returns a SPID which has CPUTime and DiskIO values of 0; yet it's blocking 4 other SPIDs. I'm confused by how this is possible; the CPUTime in particular seems odd as in order to obtain a lock you'd have had to have spent some time requesting resources / requesting the lock itself. CPUTime is in milliseconds, so whilst it's possible that the requesting and locking of resources occurs fast enough to have a rounded down value here, that is a little surprising. Also, these SPIDS are sometimes a few minutes old; yet appear to have done nothing beyond cause blocking. Question How is it possible for a SPID to cause blocking whilst having zero CPU Time? I'm asking as I suspect something's lacking in my understanding of the CPU Time stat. If anyone can advise on sensible steps to aid in investigating such issues though that would also be useful. 

NB: this question is purely academic / to help improve my understanding of SQL Server performance. Given a master table which relates to one or more other tables, how would you determine the best approach to querying that master table for records, which include an indicator to the presence of records in the related tables? For example, say we have a Person table and wanted to get a list of all people along with an indicator of whether they have children (in this example Person can be reused as the related table): 

This record appears about 40 times one second, then there's a few seconds without anything being logged before the next batch of ~40. The events start appearing after I connect to a database hosted on the affected server from SSMS. I don't open a query window or do anything more than connect under my user account. Disconnecting in SSMS does not stop the events. Exiting SSMS does. Has anyone seen behavior like this before / any idea what may cause it? Thanks in advance. Version Info: 

10 Mio rows, table size ~2GB, index size 3,4GB The runtime was about 55 minutes (not complaining here). The amount of generated WAL files was unexpectedly huge. The aforementioned WAL archives are on a dedicated partition with has 100GB and at the point the query started, around 30GB were free. It was not enough as after 15-20 minutes disk space was <10GB and I started to delete "older" WAL archives. I had to do this constantly up to the point were I was pretty sure I already had to delete WAL archive files generated by this very statement. The tables in question were not used by any other process during that time but "normal" operations of other tables continued. 

I've marked the time where I started the query and where it ended. You can clearly see where I deleted the WAL archive files :-) To me, why so many are generated is a mystery and it currently is a problem because it's hardly foreseeable how much is needed and when operation strike which need one. What am I missing to better understand how much space is needed? Are these things avoidable? Am I doing something wrong? 

The issue with Query 1 .. unknown. It uses the index; if the index does not exist, it takes as long as 5s. The issue I see with Query 2: it does not use the index but the index. However, when I do the following changes, Query 2 uses the index: 

What else can I do to improve things without severely putting my data at risk? Ee.g. I don't want to . Although I can re-do this migration, this additional time would still be unwanted. Additional setting after Feedback 

In MySQL I could force certain queries to use specific, to my knowledge PostgreSQL does not provide such a think. Is it possible to speed up the queries with the current schema? 

I'm constantly caught by surprised how certain operations generate me huge amount of WAL files. I want these WAL files for point in time recovery (I also perform a nightly full dump in addition) so the basic functionality provided is wanted and I don't want to change that (i.e. I'm not searching for a way to turning WAL archives off, etc.) Using Postgres 9.5 with these settings: 

I'm using pgloader to perform a one-time migration from MySQL to Postgres. For that purpose, I want to temporarily configure Postgres specifically for that workload. 

I've around 5.000.000 entries with varying and I've two queries I regularly perform against this table. Think of usually having 200 to 500 chars. There are about 600 distinct in this table. Query 1: