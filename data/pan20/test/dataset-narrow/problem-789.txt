Config problems will not go away with a service going away. You will still have to setup you vpn correctly, now including breakout rules for external DNS traffic. 

When an application loads a dynamic link library or executeable without specifying a fully qualified path, Windows tries to locate the binary by searching a well-defined set of directories. This includes the local path, active path and the PATH variable (speaking of applications respecting that, like CMD). If an attacker gains control of one of the directories, like on a website path in IIS, they can force the application to load a malicious copy of the file instead of that it was expecting. These attacks are known as "preloading attacks" and are common to all operating systems that support dynamically loading and/or shared libraries and binaries. The effect of such attacks could be that an attacker can execute code in the context of the user (process) who is running the application. When the application pool is being run as Administrator, this could lead to a local elevation of privilege. This is why a lot of system processes do not use or no longer use the PATH contents to search for their binaries. More on this: Secure loading of libraries to prevent preloading attacks 

The problem is, my user(s) can edit and delete files like they have full access. Even if the 'effective permissions' show no right to edit, the still can. The script works fine and looks like this: 

I want to aggregate CoreOS logs to Papertrail service, which basically provides a syslog endpoint for aggregate logging. Common advice for this setup seems to be starting a service that does something like this: 

I am trying to use AWS autoscaling lifecycle hooks in a template that encapsulates the following things: 

I don't specify any access/secret keys in the command line. My instance role was manually created (by me) and definitely does NOT grant any permissions on resources. 

I want to forward TCP connections on a certain port of the machine A to another port on the machine B (which is actually the same that originated the connection to machine A) and simulate random or deterministic packet drops. How can I do it with iptables? 

Is it possible to buy an intermediate certificate to use it to sign subdomain certificates? It has to be recognised by browsers and I can't use a wildcard certificate. The search turned up nothing so far. Is anyone issuing such certificates? 

Within plain EC2 environment, managing access to other AWS resources is fairly straightforward with IAM roles and credentials (automatically fetched from instance metadata). Even easier with CloudFormation, where you can create roles on the fly when you assign a particular application role to an instance. If I wanted to migrate to Docker and have a kind of M-to-N deployment, where I have M machines, and N applications running on it, how should I go about restricting access to per-application AWS resources? Instance metadata is accessible by anyone on the host, so I'd have every application being able to see/modify data of every other application in the same deployment environment. What are the best practices for supplying security credentials to application containers running in such environment? 

VMware tools wouldn't have anything to do this. It's an optional package. You say it's not the firewall because you stopped it with . Still, I would try , which will flush all rules (until you reload the saved config). Here are some questions / things to try: 1 - Which machine are you pinging from? Is it also on the same ESXi host, or outside the ESXi's virtual switch? What happens when you ping it from another virtual machine on the same host? 2 - What happens when you try to ping something else from this VM? 3 - What does a traceroute show to/from the VM? 4 - Do you have any VLAN id's configured? 5 - Does the MAC address listed in match the adapter mentioned in VM -> Edit Settings? 6 - What Ethernet driver do you have configured for the VM? 7 - Have you tried installing a fresh VM? 

We're in the planning/development stage for our new platform and with everything separated out we'll need to setup between 9 to 16 servers, a load balancer, 2 or 3 hardware firewalls, and a VPN. During development we need to simulate all of this as cheaply as possible. Ideally I'd like to be able to setup a single machine with a lot of RAM and virtualize all of this to figure out what works and what doesn't. What are my better options as far as virtualization? VMWare? Other? How can I virtualize all the appliances as well? The appliances our data center offers: Cisco ASA 5510 (firewall), Foundry FCSLB8 Serveriron XL (load balancer) (We'll be running CentOS 6 64bit on our servers) Looking for something super easy. Something that will help me learn the real environment for later on. 

Any Ideas where to look for this? It is haunting me into my sleep :-( Updates: Surely I checked the local policies on the server(s). any changes would have surprised me - there are a lot of servers. Also checked the clients GPO, nothing. 

Insert another condition, like , before your RewriteCond. Or just use more conditional rewrites for HTTPS: 

Increase scheduling priority This policy setting determines which user accounts can increase the base priority class of a process. It is not a privileged operation to increase relative priority within a priority class. Specifically, this security setting determines which accounts can use a process with Write Property access to another process to increase the run priority that is assigned to the other process. A user with this privilege can still change the scheduling priority of a process through the Task Manager user interface. Or shorter: A User can do with his User Process whatever he wants. 

Your description read exactly like this KB: "Poor network performance on virtual machines on a Windows Server 2012 Hyper-V host if VMQ is enabled". VMQ must be disabled for your adapters. If that is not working, check the eventlog why. 

Thats right. Teaming distributes the TCP traffic over multiple interfaces (which do have multiple mac addresses), but that's done in the driver, not the IP-Stack. You application won't know about, like you vm doesn't. 

sendmoreinfo is right, watches for changes in file size. Sometimes this does not happen correctly on mac clients (especially when samba is involved). I ended my search in this phenomenon after two days, the mac smb client is just wired sometimes (ever tried to connect to shares with signature check twice?). 

I'm following this guide in setting up a nested ESXi 5 lab on a single box. It has you create 4 ports for each virtual ESXi box, 1 on VMNetwork and 3 on a Trunk port group. It says you need to do this to be able to create VLANs on the virtual ESXi boxes. How does this work exactly? Is the VM Network port any different than the Trunk ports? The virtual ESXi boxes don't show the same distinction. I'm having trouble wrapping my head around why/how this is necessary. 

How does this work with logging? Does each node write to the same place? What about configuring static ip addresses? If machine A writes to the disk, does machine B pick it up? When he says "web node" does he mean just the web server? I'm assuming this means the web application as well (PHP/Perl), correct? Is this even a good idea (with mostly using RAM)? Can this same thing be done with iSCISI? 

About six months ago we transitioned from an in-house Exchange 2003 server to a hosted Exchange 2010 service. For the most part this has worked well, but the providers OWA constantly times out. About 6/10 requests time out or more, and it's gotten to the point where OWA is just unusable. To give you an example: I'll login, read an email, choose reply and the window for replying gives me a request has timed out message. After a few attempts I'll get it to work and reply. After that I'll read another email and it'll timeout. I contacted the provider about this and they said it's a known issue with Exchange 2010, for all providers, they're working with Microsoft to correct the issue, and there is no ETA. To be clear this isn't a session issue. I don't have to login, it just says the request timed out and to try again. After a few attempts it does work. It's just extremely annoying. I've spent a litte time researching the problem and I can't find anything that would suggest it's a common issue. Exchange 2010 has been around for a while, so I would suspect that if it was a huge problem it would have been corrected by now. So is my provider full of crap, or is there really an issue that has yet to be corrected? If the issue does exist, is there any docs on it? 

There is no (easy) auditing itself (except audit logs), but you can use to check regularly (usage here). 

The command is used to mount NFS based network shares whereas "net use" is used for connecting/disconnecting from a SMB network resource or viewing connection information. Either to use "mount" command or "net use" command would totally depend upon the type of network share that you would be mounting and would not make any difference if the enviroment is load balanced or not. Since 2008, both are capable of mounting NFS shares. But until today cannot view, edit or do anything else with SMB logon-tokens than mount a ressource. 

This error occurs when a user-mode subsystem, such as WinLogon or the Client Server Run-Time Subsystem (CSRSS), has been fatally compromised and system security can no longer be guaranteed. In Short: Someone/Something is killing your LSA. This is less likely to happen, if the executing user has the priviledge of doing so (eg. doing thins right). What can cause this error? 

I would recommend a (Hard-)RAID0/1 on this for better performance and availability. But this configuration will be slow anyway - get all the cache and BB you can find on the controller (nearly all DL3xx are capable of BBWC/BBFC). 

Yes, thats the default behaviour. For any IP address - the 'name' field is dynamically filled by the client. 

Yes and no. Hyper-V virtual machines (VMs) need to connect to networking via a virtual switch or through Single-Root Input/Output (I/O) Virtualization (SR-IOV). Leveraging InfiniBand connectivity typically means using Remote Direct Memory Access (RDMA), which currently isn't supported via a virtual switch and therefore isn't available to VMs. The only currently supported use of InfiniBand is RDMA over InfiniBand for SMB traffic and user-mode RDMA over InfiniBand for HPC communications. Outside of these two scenarios, there is no InfiniBand support—which means no support for VMs. It seems that some network infrastructure vendors are heavily pushing their InfiniBand solutions and claiming to support Hyper-V over InfiniBand, even though Microsoft doesn't support it. In this scenario the IP over InfiniBand (IPoIB) miniport device is used by a Hyper-V virtual switch, to which VMs then connect. However, some organizations I work with have tried this method and have reported problems - sometimes very strange problems that were very hard to hunt down. It's important to remember that RDMA wouldn't be exposed to the VMs via the virtual switch with this method, nor does this approach use SR-IOV to directly map VMs to the InfiniBand card. The only benefit at this point is a very fast connection, which Windows Server 2012R2+ would be able to take advantage of using its virtual Receive Side Scaling (vRSS) feature. But until Microsoft tests and supports this approach, I would be very hesitant to use it. 

What would be the best way to pass sensitive data to EC2 instance (on boot or otherwise) that only root can access? 

It's single availability zone no backups not in a security group that's reachable from the outside world 

I cannot use UserData, because anyone can read it. I cannot use private S3 buckets for the same reason (metadata and hence credentials can be accessed by anyone on the box). I'd strongly prefer not to bake my own AMI, as it's quite a hassle. 

How come I can still read any CF metadata? I noticed that in the client code, the script goes to use instance credentials ( is True) 

with associated scale up/down policies, launch configuration, IAM role, etc. 2 of for EC2 launching/terminating events. (in a simplified example) where lifecycle notifications get posted. role for the autoscaling group to post notifications to the SQS queue. 

Basically what it ways on the tin, how can I create individual per-instance alarms inside an auto-scaling group created with a CloudFormation template? I can reference the ASG itself in an alarm and create ASG-level alarms, but cannot seem to specify dimensions to be "any EC2 instance belonging to this ASG". Is it possible or is my only option user-data script? 

For some reason the CPU usage is at 20% CPU while I'm doing absolutely nothing, exactly every 10 minutes spiking to 28-30%. I thought there was something wrong with the instance, so I've re-created it, same thing. What does this? Is this an RDS phenomenon in general or is this specific to the burst capable instance classes? 

Did you create records on your domain for your DKIM public key? If not, there's no way for Gmail to validate it. Do you have any records setup to validate that your server can send emails from the domain? Is it configured correctly? There are also tools on the internet that will help you troubleshoot issues. A search like "DKIM validator" should give you some tools to verify the DKIM record is visible. Also, what do the headers say? Sometimes email servers add headers to indicate the reason why a message was sent to spam. 

I have 3 ESXi hosts, each with 4 uplinks dedicated to a port group. I want to utilize each of these uplinks for incoming/outgoing traffic (load balancing). From what I understand I need to setup link aggregation and on my Force10 switches (stacked) and set IP Hash based load balancing. VMware KB article 1021492 shows how to do this with Force10. What isn't clear to me is, how many port channels do I need to setup? One per ESXi host, or one for the entire port group? Does it matter? 

I finally figured this out after working with physical switches, some trial and error, and further reading. This can be a very confusing because a "trunk" can mean different things with different vendors. It basically means a port that is "tagged" with 2 or more VLAN IDs, or with some vendors all VLAN IDs. With a vSwitch a "trunk" port is "All (4096)" which means all VLAN IDs. With VLANs there are "tagged" and "untagged" VLANs. A tagged VLAN adds extra information to the ethernet frame to indicate which VLAN a message belongs to. An untagged VLAN doesn't add this information, and strips VLAN tag information matching its VLAN ID. A "tagged" VLAN is useful for expanding a VLAN across more than one switch (physical or virtual). On a physical switch a switch port can only be attached to one untagged VLAN, but can be "tagged" with multiple "tagged" VLANs. A switch port is always associated with at least one untagged VLAN, with some vendors VLAN 1. The tagged VLANs take precedence. Devices plugged into a switch port with a tagged VLAN must understand what a tagged VLAN is and attach the correct VLAN id. If the recipient is plugged into an untagged VLAN of the same ID, this information is stripped before it receives it, so it doesn't have to understand what a VLAN is. With a nested ESXi environment, the master ESXi host acts as your physical switch. If you tag a port group on a nested ESXi host with, for example VLAN 100, the master ESXi host won't know what to do with the VLAN tag information. Because of this the master ESXi host needs to be on VLAN 100 OR (for other VLAN's to work) "All (4096)". In a real environment you may not want to trunk all VLAN IDs on an uplink. If you have a vSwitch that has port groups with multiple VLAN IDs, you have to at least tag these uplink ports with those VLAN IDs in order for a VM to communicate with another VM on another physical host. Otherwise only VM's on the same physical host will be able to communicate. The vSwitch really hides a lot of stuff you'd see on a physical switch.