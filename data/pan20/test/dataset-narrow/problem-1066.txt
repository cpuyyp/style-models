You can do this all on one disk by shuffling files utilizing the unallocated space. Essentially, begin by clearing the first partition(s) for a clean windows install to a new partition you create in the unallocated space. As a note, it is highly recommended you install windows before Linux if you have both on the same drive. Feel free to do a search for reasons why. Then, start extending the windows partition as needed and shuffle all of your windows files into the extended space. Once you are done shuffling the files forward and setting up the windows partitions, then you clear a space for your Linux install and do it all over again for your Linux files. Granted, my answer assumes you can search and find a way to mess with partitions. There are many free programs to use if you search for them. But logistically, that is the way I would shuffle things around. Backing up any data you can is definitely recommended. And get a live Linux CD made up (I use knoppix) before you do any of it so if you mess things up boot wise, you have a OS and a GUI to fix things and search the internet for reference and download programs and utilities to help you along the way. Good luck. 

As @davidschwartz pointed out in the comments, the "R" memory is registered which "means it has additional buffers". Sometimes registered memory is called buffered memory. To extrapolate, the "E" memory does not have the additional registers and is unbuffered. They both are ECC, but they both are NOT registered. You usually cannot mix them, but sometimes enterprise server boards can accept both; with "R" usually allowing more installable memory capacity I think. Further there was/is? a "U" which is unbuffered non-ECC. My work station circa 2011 takes ECC "E" (unbuffered at the time) and my server circa 2006 takes ECC "F" or fully buffered, which then for a time was labeled "R". It just depends on the times. I have read that registered memory was a crutch to quicken the pace of technology (more capacity/channels) at the time for the cost of performance and power consumption. I'm not sure its used as much now but now there appears to be a "P" ?!?! For further information you might look up registered memory, buffered memory, FB-DIMM, or fully buffered memory (they are all the same to my knowledge) 

I am assuming you can have more than one RAID array at the same time. Create a second RAID array using the (2) 2TB drives in RAID1. Then copy the data from the RAID0 to the RAID1. No matter what, make a backup first. 

We are using Microsoft Word 2003 documents for contracts. We are trying to link to a 2003 Excel file for the dynamic and redundant information listed in the contract like customer information, job information, etc. We insert the links via edit>paste special>as a RTF type and as a Link. The links are set to update automatically and Word is set to update links upon open. Word even asks to update links on open, which we say yes to, but the links do not get updated also, going into the links dialog via the edit menu and selecting all the links then clicking update does nothing either. But, right clicking a link and selecting "update link" will open the referenced excel file which brings up an excel dialog we have to answer, and then it closes excel with the link being updated. Why will the links update manually but not automatically? Any ideas? 

Answer to your first question. URE. Unrecoverable Read Error. The disk may be OK, but the data cannot be read preventing rebuild which is the same in the end as a failed disk in terms of a rebuild. I thought the article gave the proper insight on a basic level. Answer to your second question. Same is true for RAID 6 but for larger arrays. I think the point was if you are concerned about a URE for a 12TB array because a spec says you will have 1 URE for every 12TB, then you need an extra redundant disk for every additional 12TB in size to handle all the URE's you should expect to encounter. That is RAID 5 rebuild of 12TB has same chance of failure (per a 10^14 URE rate) as a RAID 6 24TB array. Again, this is extrapolating on the article. 

The product developers probably established they could sell more products and/or have less issues by supplying a dedicated power supply for their enclosure rather than relying on molex extension cables from a consumers computer which are not necessarily meant to be routed external of the computer. Could you imagine if an average consumer tried hooking up 4 or more drives to their 285 watt dell or HP power supply through molex extensions? It's messy and is asking for problems. Or the supplier can just include a couple dollar power supply and avert all power issues. As a general note, your question assumes nobody has done it. I personally have plans for a cheap mid-tower for drives, molex splitters and extensions for power, SFF-8088 external cables converted to SFF-8087 cables inside the case running from a used PCI-E HBA in our home/office server which would build exactly what you are describing giving room for 9-10+ drives depending on case, 3-6 Gbps per drive dedicated bandwidth to PCI-E slot, for only about $125-$150. But I have not met one person in real life that would do the same, they would (and do) just buy an enclosure much like you linked to. Interestingly enough, what you really seem to be asking is why the average consumer does not demand the product you describe which is not necessarily in the scope of a super user question; questions about consumer demand for products that is. 

Running a Facebook is obviously not a "light job". Webpages serve a function for both the page viewer AND the page owner. You require the page to be rendered, content from them to be cached, many requests to many other sites to processed to show the affiliate content, and videos to be ready and or playing, among other things. They (the site owner) require fetching and displaying advertisements, analytics to be performed, and probably a plethora of unbenounced to us functions. These are things that most of us don't pay any real attention to on the front end but can consume a considerable amount of resources for no "perceived" benefit. Point is the are many things independently happening to provide you with "the experience" and added up it requires alot of CPU and Memory rescources. 

For a RAID 10 the speed difference between the two should be negligible if their is any at all because their is no parity. If you run a RAID6 in the future, you might take a performance hit for full rate internal data transfers but not external (cloud) tranfers. Further, the HW raid does have the disadvantage of being proprietary and causing the headache of needing to replace your controller with a compatible controller if the controller fails. On our Dell Server, we setup the drives each as single drive RAID 0's exposing them to the host as raw devices, then we used MDRAID1 for the host and MDRAID10 for the data. Your controller might allow the drives to be "passed" through to the host, our controller would not allow that. Point is, I default to MDRAID for a combination of performance, reliability, robustness, and simplicity unless there is some odd configuration or performance mark that we are trying to work with. 

MAC address is suppose to be like a unique ID for a device where IP address is place to send data to with an ambiguous ID. Assigning a mac address allows you to ensure a device gets it's IP address reserved. Imagine a server @192.168.0.10 that shuts off, the IP address becomes available, a new devices uses it (192.168.0.10), then the server comes back on and is not allowed its address and either does not connect, or gets another address (say 192.168.0.11). But the other devices are still looking for 192.168.0.10 and they throw errors because the server isn't there. By reserving the IP address, you make the ID static (not ambiguous), and now the server can get its address back at all times. MAC filtering uses the theoretical unique ID to filter device access to the router. Problem is MAC address can be changed (spoofed) and a good hacker will be able to get around it even still. But it'll keep a bad hacker out :). 

You could use a 12VDC 4.5A adapter and split the outputs; you could possibly go down to 3.5A-4.0A given you do not need triple the available overhead of a single adapter. Also, drives use the bulk of their power on spin-up, when they are running, they use alot less power. You would wire the separate outputs in parallel. Also, different adapters react differently to load and voltages. Laptop type power supplies (electronic) put out a fairly even voltage up to max current then the voltage drops off sharply when overloaded. Wall wart (transformer, usually heavy) type adapters usually output a higher voltage under no load with the voltage dropping as load is increased. Point is, if you get a laptop type adapter, you are more likely to get the proper voltage. These can be found at a place like goodwill for fairly cheap. Just be sure to check the voltage under load (with all the drives on) with a multi-meter; drives can be sensitive to low voltage. 

This will open the file manager as a root user and then anything I open to edit from the file manager is opened as the root user. Or, if the file is easy to navigate to or name in the terminal such as "FSTAB" I just open my text editor with the named file such as 

In this situation, I have printed the PDFs using the Adobe PDF printer via a high resolution (1200 dpi+), high quality image(up any settings you can). Then, I OCR the image PDF leaving me with a searchable and workable PDF. When I have many PDFs to do over thousands of pages, I have opened multiple PDF windows at once to do this simultaneously using multiple cores for multiple PDFs. It is a PITA, but it works. Hopefully your files are small! I've done this to upwards of 10,000 pages once (building code books). Not fun. 

Either way I would contact the manufacturer to verify if their equipment will work at 208VAC if it is not printed in their documentation. With electronics it could go either way. Motors and light bulbs and such usually don't care 208 vs 220. Most systems like this have a neutral that would give you 120 volts hot to neutral meaning "normal" USA voltages. I would recommend you just use the neutral and one of the phases to run things at 120 volts. 

The copy you use, everyone using a computer has this copy. This copy is not a backup, it's the files you use, but it is one of the three. This is on your computers hard drive The Backup most people think of; the one where you do a full backup then incremental backups for a while. This backup is outdated the length of time between incrementals. This is on the first backup drive The backup most people forget about. Think about it, you do a full back up. Then you build on that full backup for some time, a week, a month, a year, what ever you feel comfortable with. IT guys many times do a week. But you hit a point where you need to do a full backup AGAIN so you can start building again on a fresh full backup, and you need to keep the last full backup during it so you are not without if something goes wrong during the backup process. This is on the second backup drive. 

I assume you are NOT talking about using all three phases (4 wires, 3 hot, 1 ground) and you are talking about using the voltage across two of the phases which is seen as single phase 208. If so you are NOT using three phase 208 for supply. 

So point is, you need enough space for 2 full backups on two separate mediums first before RAID. Then, after you have a minimum backup scheme, I would do a RAID for my active computer, NOT for the backups. Here's why. Think of a RAID as a single drive that gives you a chance to fix it while it is "BAD" (i.e. a drive fails). But it does not help with hardware, software, or user errors which are also highly probable if you add the chance of all three together. Two backups of different age on two drives drives in a non-RAID does help with ALL the errors. But a RAID will do great for the files you use actively every day in case of hard drive failure; that is you want to use the RAID for the drives you store things on everyday so you have a level of protection in between backups.This means you should centeralize your business files to a RAID; people should not store the business files on their personal drives. Email, project docs and contracts, contacts, programs, etc should be on a central server with RAID. You can even move my documents and user files to the server. Then you back up the central server as often as you can Usually 1-2 times a day. The more active the folders are, the more likely something will get missed in between backups, an the more they should be located on a RAID. Don't forget, the more diverse the storage media, the better (external drives are not good, internal drives are good, tape is better still, cloud (like amazon S3, not dropbox) is better than tape and internal drives for reliability, but not for speed) The farther backups are from the original data, the better. A NAS or other computer is good, a drive or tape written to then stored off site is better, cloud (amazon type) is best. A complete scenario includes different reliable mediums at diverse distances. Start with quality server with RAID 1 or 10; do not use RAID 5 or 6!. Then, backup (incremental style) to internal drive (or another RAID) daily or more often. Then copy that back up out at the end of the month to another drive, tape, or the cloud freeing up your internal drive for the next month of backups. A scenario like this is not that expensive and is near enterprise level reliability only hindered by consumer grade hardware, software, and consumer user. But START WITH BACKUPS, then RAID. Realize though that if you go with hardware RAID and you have a controller failure, you cannot just buy any other controller and get your array working again. With software RAID on the other hand, you can! Our setup is a Debian Linux box with 2 drives in a software RAID 10 for our server where all of our files are stored. Then we back up much like the scheme mentioned above backing up to another internal drive in the server, and second backup to another computer. Still working towards a seond medium and/or offsite backups probably to LTO Tapes a few generations old. Gotta start somewhere though. We only have about $500 invested in our server and drives. Our IT budget is low priority compared to the tools we are investing in everyday. 

Can you build a 2 disk degraded RAID 10 array on your controller at all? Can you build a 2 disk degraded RAID 10 array on your controller while running a separate degraded raid 5 array? 

Think of a VM in terms of hardware, essentially what you are asking is to change the size of a real HDD on the fly and have the OS dynamically adjust. This is not how things are setup. Changing a virtual disk size vs a real hardware disk size is no different to the OS. Just because it is virtual does not means they "integrate" in any way. 

Bits in a computer are simply a state of being. In memory and most electrical circuits, the bits are either "On" or "Off". Memory is like this. The 1's are parts of the memory that have power stored, the 0's are places where there is effectively no power. When you turn the power off, the stored power in the "1" bits leak and they become 0's instead; then all the bits in memory are "0". This leakage occurs very fast so it is considered that when power is lost, data is lost immediately, although it does actual take some time. Typically a fraction of a second. To put them in a stable non-zero state, you would have to change way the data is stored. In platter hard drives it is stored as a magnetic state. On a optical disc it is stored as a "pit" or a "land". So the answer is yes, you can keep the original state, but you have to change how the data is stored, or change the method in which the charge is stored. They are actually working on this, but the current RAM is extremely fast with low latency. Given the way RAM is used, they have not found a suitable alternative the has the speed and latency that is even comparable in cost given how cheap RAM is and how much the average person or server needs. They do make solid state RAM. I am sure there are caveats though.