Is that not working? Can you check and make sure the files are owned by the group, and that the second group of permissions is at least r-x? 

(Make sure the driver paths are right. Sometimes it's /usr/lib/odbc/) Then the python string should look like: 

Meaningless question without ram clock speed/ front side bus numbers. Extra meaningless because the "R" in raid is for "redundancy" and there is no need for redundancy in volatile memory. Pick the one that's faster. 

Doesn't sound good...You can try ripping the "rebuilding" drive out, on the chance that you just got a DOA drive, but chances are it was one of the others that failed. Rebuilding a failed drive is a common source of failure with raids...It's an intensive process. I once had a 20 drive array fail one drive after another as the array was being rebuilt; when the smoke cleared I'd replaced 18 drives because they warned of failure, and 2 others just because I didn't trust 'em (This is why you never buy 20 drives from the same production group). 

Well the address thing can be done simply with NAT but only for machines OUTSIDE of the NAT'd subnet. To make every machine have the same IP on the same subnet, just set them all to the same IP. Won't work, of course, but what do you expect? They all have the same IP. 

I myself probably wouldn't have split it so heavily; you're going to have issues if any particular partition fills up, and you've made it so that you've got ~6 that could fill up and cause problems, and it's a new system, so you really don't know for sure where space is going to get tight. Make sure you set up alerts for when available space gets low. 

Can they work with a service like dyndns.org? Not a static IP, but a url that points back to your current ip address. That's a common trick for beating the dynamic ip. Other than that, you're out of luck. I don't think LexisNexis has much experience dealing with people who can afford their service, but not a static IP. 

As far as I've ever been able to tell, this is designed behaviour. I've never been able to make it continue. I recommend springing for a better task scheduler (i.e. visualcron or similar) or setting your task up to run as a service. Task scheduler 2.0 is better, but I think it STILL dies if the job never succeeds...So if you tell it to retry 100 times, and it can't make it work, it won't try again the next time. 

This will copy the current file, then That being said, logrotate only "automatically" rotates files in specific places, unless configured otherwise. I imagine you're logging your script to /var/log/httpd, and that's why it's being automatically rotated. 

Red Hat is one of the most popular business Linux distros. Fedora is nice, but Fedora is bleeding edge. There are bugs and issues that you'll have to deal with there that you'd never have to deal with with RHEL. Enter CentOS, which attempts to achieve the stability of RHEL with the openness of Fedora. 

Well, yes and no. The Dyndns address is an external address: that's the whole point. It points to your external interface, the one out there on teh interwebs, not your internal one on your nice safe lan. So if something from your internal network is pointed at that address, it goes out, turns around, and comes back in. That's the only way it knows to get there, the only valid route attached to the url. The quick and dirty fix is to put an entry into your HOSTS file pointing the dyndns url to the local ip address of that machine. You'll have to do it for every local machine, and it'll absolutely break everything every time you leave the apartment, so you'll have to keep changing it. The more complex fix is to set up your own local DNS, and override the record locally. Then, if you connect via DHCP, and let the DNS be automatically assigned, you'll always have the correct address. 

I think you're making it too complicated. By default, AD DNS only does DNS queries within the AD domain, so all you need to do is tell it to automatically forward the remaining queries to your regular DNS server. You do this by going into the dnsmgmt tool, select your domain controller, right click on it, and select "properties" then go to the "Forwarders" tab. Make sure "DNS Domain" is set to "All other DNS domains" and then add your caching DNS server as a forwarder. Should be a lot easier than trying to configure it upstream. 

There is an msc that I'd really like to use: printmanager.msc. Specifically I want to be able to force certain OUs to use specific printers without having to push the entire directory. Now I've inherited a Win2k3 domain with a pdc and two secondaries, all patched and current. Unfortunately the printmanager and some other tools weren't installed originally, and I cannot for the life of me figure out how to install them now (If you tell me to do this I am going to mock you without mercy). Can't find a download link for a version that will work, and I can't figure out how to get the older version from the install disks to work either. Does anyone have any suggestions? I'm beginning to think I'm going to have to wipe one of the secondaries, and do a clean install. Edit: Since this has turned into a popular question, I'll add the answer: I had to upgrade everything to RC2 in order to install the msc. It was a problem due to my original disks being well below the patched level of my system, so I ended up making an upgraded install disk, and working from there. 

Each card will have it's own IP, but most webservers default to "all" addresses, and it's actually a bit of a pain to disable it for IIS. Inbound, connectivity depends on which address the remote machine is talking to. If you have 192.168.1.1, and 192.168.1.2, and 192.168.1.1 goes down, then traffic that is intended for 192.168.1.1 will not go through. Outbound, the server should use whichever interface it deems appropriate. You can type to see how it's set up, but it should automatically failover, unless you've crippled connectivity somehow on the second interface. 

Sounds like it's trying to auto-detect the monitor resolution. Is the account mobile, or is the user using a laptop? 

I agree with the above definitions, though I'd add that NAT and Proxies have a very different purpose. NAT is simply routing: there is no caching, and there is no real "oversight" for lack of a better word. Proxies are put in place for caching, monitoring, traffic shaping. They are very much about control. So NAT has very little overhead, but doesn't offer many options, while proxies have a much higher overhead (sometimes massively higher), but allow a lot of control. 

I like emacs, and I've used emacs for years, but if you're an admin you really need to know vi. Vi is going to be installed on every machine you log into and emacs is not. Never bothered with plugins with either, though. If I need an IDE I'll use Eclipse or Visual Studio or something. 

Yea, it's probably ACPI support. Chances are support is already compiled into your kernel. Look for /proc/acpi or /proc/sys/acpi. If you see them, skip to the "install ACPID" bit. Assuming you DON'T have a kernel that supports acpi, here's a little ACPI "How-To" for Fedora 8, which is admittedly not the same, but the process should be very similar. Here's another, more modern one. If your kernel already supports acpi, you might want to simply try using a package manager to install acpid which should fix the problem. 

You CAN store pictures in a database, but I highly recommend against it. I run a big image versioning/indexing system driven off a database, and the maintenance overhead is appalling. You'll be doing a lot of integrity checking. If you don't need to track version changes, I'd highly recommend putting the images in the filesystem, and only storing location information in the database. 

The usual problem with this change is that the background image is either the wrong format, or located in a non-shared location. 

It may be that it allocated around the bad sectors and "fixed" the problem. A certain amount of that is perfectly tolerable in a drive. 

...If you already know the source control system (MS Visual Source Save) then the only question is what machine to buy. Just call some vendor and see what they have, and see how that fits your budget. Not much of a question. 

Webmin is a good tool, but it's also another potential security hole...Make sure you lock it down so it can only be accessed from trusted hosts. It's basically a graphical front-end for a ton of command line stuff. It can't do anything that you can't do on a command line, but it makes some of those things a little more friendly...So if you already know how to secure a box, it'll help. If you don't know, however, it's not going to change anything. My advice is, unless you absolutely have to, do NOT store credit card details. Store the last four digits for verification, and pass the rest up to your merchant provider, and let them shoulder the burden. When you step into the world of hardened credit card handling machines, you have to understand that you need to keep on top of that machine constantly because every new vulnerability will get tried against it at some point. 

You can absolutely use .htaccess to restrict access, but I don't know of any way to avoid creating an equivalent .htpasswd file if you want to control access via users and passwords, rather than whitelisted IP addresses or similar. Now, you can create any number of .htpasswd files; so if you wanted a specific one for a specific directory, that would be easy to set up by creating the .htpasswd file using: