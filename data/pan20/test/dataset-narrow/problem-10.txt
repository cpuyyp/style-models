Since "deployment" to the IoT device, especially in bulk, will not be done using the CI system. Then the purpose of the CI system is mostly to make sure that it will work okay. This means that you mostly want to run some tests using the CI. Automated testing is definitely possible, both for unit tests and for integration tests. The most important thing for unit tests is usually very short runtime and a short feedback loop. For a large code base, if possible to compile parts of it using the native compiler of the host and run unit tests there - it is a great option. If you must, you can also cross-compile to the target platform and run the unit tests using some emulator to have the necessary speed. All of this can happen during a CI "build+test" job. Compiling for the target and running unit tests on the target will just be painfully slow if done properly, but can also be done - just make sure to only flash the smallest possible piece of code and have it report back via the Serial that it worked on the device. For integration tests, if possible to install your code on an actual device and the have some chatter with the device using the serial interface - you can ensure that the code actually works on a target device. If for some reason the code fails or works incorrectly, maybe draws too much power and/or restarts then the integration tests will catch that. You can also have another test device performing measurements and reporting via the Serial interface to the CI job. Can use an Arduino, or another ESP to maybe measure voltage and/or amperage during the execution of your code parts and checking that against known good values. You don't expect the device to pull 400mA when in a deep-sleep mode, for example, this is easy to test with a "test harness". All of these unit tests and integration tests can be triggered completely automatically on the CI server. Naturally, you will probably have this "server" running on-premises and not rely on a cloud solution that might or might not support your latest integration testing. With hardware, smoke tests are more "real", since you can actually hook-up the device and see the magic smoke come out. Usually, you don't even need to run code before it burns since the problem is often in the hardware. Since I mentioned testing, there is also integration testing which is done on the hardware level. If you have a good test harness that checks that the device works well by probing it, you can use the same test harness to do your QC cycle in the factory where they produce the devices later. There is quite a lot of information about making these testbeds. One example for this is here - $URL$ 

In an organization with a hundred developers, and several thousand salespeople using SalesForce to create their application. Given the restrictions of SalesForce environment and deployment options. What would be the process and which tools to use to reach a delivery pipeline where changes can be delivered to production many times per day? The basic flow is: 

This constraint, once found, is an important focusing mechanism for management of the system. So, how can you identify the constraint in an IT organization? And what to change about it to get the benefit of better flow? 

With 3200+ cookbooks available in Chef supermarket, often there is already a cookbook that covers the need I need to solve. Almost every time there is some change required to a template, or a variable, or a resource in an existing cookbook. What are the steps to override and/or improve existing cookbooks? Without forking their code, and retaining the ability to get version updates in the future. 

Agile software development is the methodology of choice for software shops today. But there are still organisations which are not practicing Agile in their software development, who might be interested in adopting DevOps. When I say Agile Software Development, I mean any offspring that came out of the Manifesto for Agile Software Development. Such as Extreme Programming, Scrum, Lean Software Development and others. Is Agile software development a mandatory prerequisite of adopting DevOps on an organisation level? 

The manufacturing world and Toyota Production System specifically have taught us that having small batches is much more beneficial than batching work items together. TPS even goes as far as to strive for single-piece-flow, where each work item is delivered to the next work center alone and not in a batch. Agile methodologies have taken a cue from TPS and also describe the benefits of having small-batches. These would be described as a "sprint" with a definite deployed deliverable at the end and striving to keep the sprints as short as possible. This allows to run short experiments and receive feedback regarding the value of the changes created as soon as it is possible to do something about them. Continuous Delivery is taking this even further by saying that any finished code, should be deployed to your systems as soon as it was auto-tested. And a release can happen at any time when someone decided to do so. And experiments can be validated as part of the development cycle. Moving the definition of "done" for a developer away from "I finished writing my code" and towards "I received feedback from customers that they received value". The shorter the feedback cycle is - minutes, seconds, etc... the better. And batching is a deterrent to short feedback. By having a button that by definition batches things together, would mean that risk of problems is higher. Learning from TPS, Agile and CD means that single-piece is far superior and has many benefits. 

The former is called Snowflake, while the latter is a practice that allows Phoenix and Immutable server types. Where Immutable states that no changes are made to an existing server once it was created, and Phoenix means that a server is destroyed completely and a new one is used to replace it during the change process. 

This means that under certain conditions, with the right architecture, the right technical practices, the right cultural norms, developer productivity can scale as the number of developers is increased. And DevOps is definitely in the middle of all this. 

The pros and cons of each such server are described in the articles. The main difference being in the way the server is managed. Servers exist to fulfill the role of a container for some application(s). Since applications change often, it is often required to change some attributes of the container - such as packages, configuration, etc. It is also sometimes required to change attributes of the container itself because of external reasons, such as security vulnerabilities that require patches to be installed. There are several ways to change an existing server: 

Sakichi Toyoda created an innovation to the Loom that would later become one of the pillars in the Toyota Production System (Lean). That pillar we now call Jidoka, sometimes called “smart automation with a human touch” or “autonomation.” In large part, Andon (stop at first defect) and Poka-Yoke (mistake proofing) are later developments that find their influence from the Loom. Removing Single-Point Weaknesses The term single-point weakness refers to the creation of redundancies in the system as an approach to improving system reliability. Redundancy is created by increasing the number of systems or individuals involved in the process. Having more backup systems or more checks (double, triple, or more) increases the probability that the process will proceed correctly. One great example for this is the "four-eyes principle," which means that "all business decisions and transactions need approval from the CEO and CFO. Since the CFO is not reporting to the CEO, there is an independent controlling mechanism in place". source: $URL$ Make Hazards Obvious If hazards are made obvious, or impossible to reach, humans cannot create mistakes. For example, color-coding is a common approach to making mistakes more obvious. Or if you think of various computer sockets that can only be inserted one way and not the other, etc. 

Why is an object useful? Because when you copy it around, for example from a dev environment to qa to production. You already know quite a lot (but not everything) regarding how it is going to behave. In many cases, the parts that are working will be consistent, and the parts that are broken are going to be consistent as well. Why are actions useful? Because when you want to change a state of some object, in many cases it is useful to only verify that the change has been applied and apply changes just in case it is required. For example, when a configuration item in a file is missing or has the wrong value, it is useful to add it just once or change it just once while applying the action multiple times. In many other cases, like log files, you don't want to have idempotent actions because you often do want to append another line each time some event happens. 

The way a cluster becomes aware of the EC2 instances associated to it, is a configuration file used by the ECS agent. You can modify this file, located at , and name a different cluster. Then restart the ECS agent. This will effectively "move" the EC2 instance to the other cluster. More information about in the documentation - $URL$ After the modification, it is possible to verify by sending an HTTP request to the ECS Agent metadata service and see the new cluster displayed. $URL$ The ECS cluster itself also needs to be notified. Can use the Register/Deregister API calls for this, for example using the AWS CLI: 

The new CircleCI 2.0 configuration allows to have a step of type which waits for user input. Is there some way to not just deploy code using manual stop, but also have a rollback to a previous version based on user input? 

When I write "Software Development" I actually mean the whole cycle that includes lead-time from the point where some customer need is discovered, to the point of customer value created and delivered. 

These also contribute to organisational performance overall. So it means that if your IT is doing great on these metrics, your bottom line gets more $$$. Continuous Delivery is enabled by these metrics, and has been described in depth in the book Continuous Delivery: Reliable Software Releases through Build, Test, and Deployment Automation by Jez Humble. In context of Continuous Delivery, there is an important distinction that differentiates it from Continuous Deployment. And that is the decision when to do a release of features (to customers). Keeping changes smaller in size, and deploying (copying code) half-baked features to production systems with a feature flag toggled off allows to shorten lead time for changes. When features are finally finished, doing a release is a decision left to the business. Maybe a release of a new feature needs to be aligned with some marketing, or a release in another part of the business like a feature in the mobile app. Features can be released using A/B experiements to only a part of the customer base, or to specific people, or even direct to general availability (GA). Although releasing to GA is often done only after there is enough certainty that the feature works as expected. One might argue that this in effect affects release frequency to be higher. This decoupling of release and deploy is almost impossible to achieve without feature flag toggles. Naturally when no deployment is required to toggle a feature off, then the time to restore service is lowered substantially. And by using feature flags that release features to a small slice of the customer base, the change fail rate metric can be improved significantly as well.