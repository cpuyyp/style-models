It's easy enough if you're doing 2D with a 3D API, and can draw textured polygons. Store a history of previous positions, use these to build a triangle strip along the bullet's path. Then texture it, and draw with additive blending (However, if the bullets make any sharp turns, or you need wide trails, it may get more interesting - you'll have problems creating clean geometry without unwanted overlaps) 

Are there any free/affordable systems/libraries out there for adding online features to a small PC game? (most likely, for a small primarily-Windows-based indie game) I'm not concerned about matchmaking or online multiplayer - but I'm interested in leaderboards, and maybe slightly more advanced features, such as the upload/download of user-created-content (e.g. replays or player-created levels). Maybe even automatic updates or downloadable content? Whilst it probably shouldn't be too hard to implement at least the very basics from scratch, it seems like a big wheel to reinvent, and a tried-and-tested system would be preferable, to reduce development time, and reduce the chance of gaping security holes. Is there anything in reach of low/no-budget indie developers? 

(Where positions are 2D vectors, rotations/scales are scalars, and 'rotate' rotates a position vector by a rotation angle) As you would with matrices, do a depth-first traversal of the hierarchy to update pos/rotation/scale of each node before rendering However, without matrices, I think you'll struggle to handle non-uniform scaling? 

You should be able to apply a 2D offset/scale after the projection. Just multiply the projection matrix by a suitable translation/scale matrix (where the translations are in the -1..1 range of viewport coordinates) 

Do your textures have mipmaps? Without mipmapping, texture sampling can be particularly expensive (loads of cache misses) 

A good example of 'true peer-to-peer' gameplay would be a real-time-strategy game such as Starcraft. In a game with hundreds of units/projectiles in motion, it's not practical to repeatedly send unit positions/states over the network to all other players, so one solution here is for all players to run the (exact same) simulation in sync. When one player performs an action, the command/order ('move zergling to X,Y') can be sent to all other players, to be executed by all instances of the simulation a fraction of a second later. In this situation, if any player disconnects, the game can continue - as there's no need for a server/host to be running the game, the remaining players can carry on. However, keeping the games in sync is non-trivial, you have to use a fixed timestep for the game logic updates, and must be very careful with use and seeding of random number generators, to ensure that the simulations will not diverge! 

60fps, if nicely vsynced? If you're looking for (un-vsynced) big numbers like '1000fps', stop thinking in framerates and start thinking in milliseconds-per-frame. The numbers are a lot more meaningful that way around (You won't panic when your first draw call halves your framerate...) 

World of Warcraft doesn't do collision detection between players/mobs. There may or may not be technical reasons behind this decision, but really, this has to be more of a game design decision than a technical decision: Imagine how exploitable it could be in player-vs-player situations. Or how hard it would be to use the bank/auction house/mailboxes if other (often idle) players blocked your movement! As for client vs server based collision detection - really, unless movement is very slow, it has to be primarily client-side, so it looks right to each client. Laggy/delayed collision response, and/or colliding with 'invisible' objects would be quite unpleasant. 

Another thing to watch out for with 2D scrolling games: Are you scrolling a nice constant number of pixels per frame? If you're scrolling 2 pixels one frame, then 3 the next, then 2, for example, that will add a bit of judder. If you're working with a 3D API, and scrolling some arbitrary speed, like 2.73 pixels per frame, that may add sub-pixel 'wobble' If you are able to target a fixed framerate, try to ensure that the character's walk/run speeds are a whole number of pixels-per-frame. 

So I wanted to switch to IDirect3DDevice9Ex, purely for the SetFrameLatency function, as fullscreen vsynced D3D seemed to produce noticable input lag. But then it tells me 'ha ha ha! now you can't use D3DPOOL_MANAGED!': Direct3D9: (ERROR) :D3DPOOL_MANAGED is not valid with IDirect3DDevice9Ex Is this really as unpleasant as it looks (when you're relying quite heavily on managed resources) - or is there a simple solution? If it really does mean manual management of everything (reloading all static textures, VBs, and IBs on a device reset), is it worth the hassle, will IDirect3DDevice9Ex bring enough benefit to make it worth writing a new resource manager? Starting to think I must be doing something wrong, due to this: Direct3D9: (ERROR) :Lock is not supported for textures allocated with POOL_DEFAULT unless they are marked D3DUSAGE_DYNAMIC. So if I put my (static) textures in POOL_DEFAULT, they need flagging as D3DUSAGE_DYNAMIC, just because I lock them once to load the data in? 

This is maybe a little worse than average, but not entirely unusual... The industry has always been unstable, but in the last couple of years it's gone from bad to near-meltdown. Not sure if new hardware is going to save it this time, or just make things worse... 

As a burned-out, bitter, and cynical programmer with >10 years in the industry, this would be my advice: Don't plan on games as a long-term career. Plan to do it for a few years, get it out of your system. But plan for a more sensible career longer-term, and don't leave it too late to make that change You might manage 5-10 years in the industry, then you'll realise that there's not much long term future in being made redundant every 1-2 years, and crunching like crazy to buy the higher-ups supercars whilst barely seeing any pay rises, let alone bonuses. Also, the industry changes at quite a pace. When I was at high school age, it was all about the Amiga, 16-bit consoles, and 2D games. By the time I came out of university, it was all about 3D and Playstations. These days, the 'big games' industry is in a worse state than ever, can't see it lasting many more years as things are. But we have a resurgence in bedroom coding/indie development, and new opportunities in mobile devices and web-based platforms. Change can be exciting, but generally change means layoffs. Layoffs force salaries down. Changing job means relocating... Most people can't keep doing it for all that long... 

If the game is based on a rectangular grid, then this grid defines your X/Y axes. And Z can be used for height. Collisions are then as more-or-less as easy as any 2D tile-based game. Then you just need to convert from the grid back to isometric screen coordinates for rendering. This is fairly straightforward - but you may need to think about calculating 'depth' values, for sorting purposes (rendering the isometric scene from back to front) 

This is what you're looking for: $URL$ Used by numerous games, from indies to AAA titles, to create bitmap fonts from TTFs Using this tool or something similar is probably the most common way to implement font rendering in a game. Other options do exist (e.g. rendering vector fonts directly with something like FreeType), but the simplicity and performance of bitmap fonts usually makes them the obvious choice (Note that Valve's distance-field stuff is super-sweet for extreme magnification of text, such as the examples of decals in an FPS, but of little or no benefit for UI text, which is often being scaled down from the source texture, or maybe scaled up just a little) 

I suspect that there must be a way to do this by using/abusing the z-buffer, too - but you probably want to z-test the 'hole polygons' using their real Z, then write a different Z. You could probably use multiple passes and the stencil buffer - drawing the hole 3 times with renderstate set up like this might work: