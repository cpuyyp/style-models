There is a lot of duplicated code in there. Most of the later parts of the blocks in fact. And there is a condition in common in both outer conditions: So lets pull that out first: 

This reduces the space needed during the merge portion. Though at the cost of modifying the array the user put in. 

Instead of starting a new thread you can instead create a executor which will take and reuse threads as needed. you can create a executor usign one of the ' static factories. This code relies on responding correctly to a thread interruption. Which you didn't include so I can't judge it. (A lot of IO functions don't respond to it by default). The catch-all when waiting on the result is not a great thing. You should instead catch only the specific exceptions you can get and only declare those you throw. 

There is no way for the producer to check if the queue is full. It will just overflow the buffer when asserts are disabled (which they will be in production). 

Failing to open a file is common enough to use an explicit and print an error message instead of ing (which won't do anything when compiled as a release version): 

Capturing groups can be handled my marking some states as starting or ending captures. During simulation you then have a list per NFA state of captured substring indices that you propagate along. If the current DFA state contains S1 with a capture with an outgoing connection with to S2 and it sees an then the new state of the DFA will contain S2 with those same captures. If 2 paths with captures lead to the same NFA state then you discard one of them based on a priority rule that is filled in based on the greedyness of the operator that led to the merge. 

That merge would be clearer as a , while bot arrays have elements to be merged in. And you can do 2 s for the remainder afterwards. 

Your code can benefit from RAII. For example by creating a small struct with a destructor to hold a single . Then you don't need to worry about calling in the correct places as the destructor will do it for you. 

you #define and but then don't use them in the nextFrame function. Also enum beats macro for a group of related constants. 

besides that your didn't. only one thread ever got out of the synchonized block in doWait, which means that deadlock would occur if more than one thread was waiting and the wrong thread got notified. 

There are multiple problems with this approach: You allocate new arrays but then don't them. This should be followed by a at the end of the function. You copy the elements repeatedly before they are finally stored in the node. If the assignment is non-trivial then this will be unnecessarily expensive. Instead you can use the fact that the index of the parent is equal to to hold the created nodes in an array: 

Patterns should be pre-compiled and held as a static field to avoid recompilation. Using reluctant qualifiers we can match only up until the first closing tag. 

To get a normal integer from a hex string you can use the built-in Integer.parseInt(String, int) which simplifies things to The actual parsing code can be simplified by knowing that this allows you to do away with the pow operation: 

This alone means it's O(n). Because stack has internally an array to hold all its elements that needs to grow as it holds more elements. Each reference to an element also takes up space. 

In pre-java 7 (without the try with resources) I find it easier to nest the try-finally in a try-catch: 

Every call of mergeBack will end up allocating 2 new buffers. You can avoid that by preallocating the secondary buffer and flip flopping between them but that is tricky to do in the recursive version. Which is why I prefer the iterative version that goes bottom up. 

Consider allowing (only) the move constructor and assignment. As is (with the unique_ptr) you can just remove the disabling declarations and it'll work, though I suggest implementing them yourself to null out the tail pointer in the moved-from object. 

Your code assumes that of the result list is thread safe for different indexes which may not be the case. You resizing will fail when someone uses the fixed-length to store the result. Instead create a second list to temporarily store the result (in a thread safe manner) and then fill the passed in using a list iterator: 

The code in and is nearly the exact same. This is a good hint that you can extract it into a single function. The switch can be simplified by letting the duplicate cases fall through: 

Thread safety is pretty poor. Instead of making threads I suggest you change the WorkerThreads into and make the do only a single and return the best move. Then you can submit it to a 's which will distribute the work over several cores automatically. (You can get a using ) This should be created and held by canvas to allow the executor and it threads to be reused as needed. 

You return what is effectively an enum as a double. Why? create the enum and return that it's much clearer that way wat the return value means: If you still want a single point of return (for whatever reason) then you can use an if-else chain: 

You assume all lines are shorter than 1000 chars. This is a mistake and you never check for buffer overflows. however you don't need to get the full line, just the 80 first characters and then if there is no newline then output the characters you have in the buffer and output all subsequent character you read until the next newline. 

you don't specify a destructor meaning every Chunk (and ) still loaded will leak when the manager gets destroyed. More about the efficiency: When the player is going back and forth at a chunk boundary the chunks at the edge will keep getting loaded and unloaded, you can fix this by making the unload distance 1 or 2 larger than the load distance. Also consider using a object pool where "deleted" chunks get copied to and can be re-purposed for another chunk. this will require changes in the chunk itself so they can get re-purposed. Either way I would suggest looking at the Chunk code and investigate why deleting one takes so long. 

Node can be a private nested class of RBTree. There is no need to access the nodes of the tree and allow the user of the code to invalidate the RB invariants. Color can be just a boolean with true being RED and false being BLACK. If you delete a node then you also delete all its children. 

After the first outer loop has run once you know that the largest element is at the back of the array. This means that you can shrink the number of iterations of the inner loop by 1 each time the outer loop completes 

I don't like using the object as a mutex and Condition variable. Doing that would let another programmer spin up a thread to lock and never release the . Instead you should either provide a and sync on that or use the java.util.concurrent.locks.ReentrantLock and its condition: 

Make the order of the fwrite parameters consistent first the sizeof and then the number of elements: