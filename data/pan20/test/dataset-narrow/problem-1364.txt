The description is somewhat misleading; even though the SDK link you've posted is for the June 2010 version of the SDK, the DirectX for Managed Code Update is from a much older version of the SDK (whenever they last updated MDX, which was years and years ago as MDX is a deprecated product). The latest SDK still contains the old MDX assemblies, but they are dead. Microsoft's "official" means of accessing DirectX through managed code is the Windows API code pack, which is somewhat of a bastard child and unlikely to get any more support or iteration than MDX ever did. XNA or SlimDX are better choices, depending on the level of abstraction you want (XNA for a high level view, SlimDX for a close, low-level mapping to the native D3D API). 

Probably not actually an advantage; probably either a wash, or a net loss. Rendering text via quads is really cheap. Rendering it via a bunch of lines or triangles converted from some likely vector-based description of glyphs? Not so much. 

Sort them based on their Y position and draw them. You are over-thinking it. Only worry about the performance if you implement it, it appears slow and you discover (via scientific profiling) that the sorting is the bottleneck. Fifty or sixty objects is pretty trivial, all things considered. It's very possible you could achieve reasonable performance using a bubble sort that way, depending on what else is going on (and the sorting algorithms supplied to you in the .NET standard library will be more efficient than bubble sort). 

An "entity system" should not directly handle rendering and physics anyway; at best it should just have references to objects that are part of the rendering or physics systems, whether or not you wrote those systems yourself. 

...and then use "../data" for your data paths, relative to the application location, or stick launch shims (shortcuts, aliases, batch files, whatever) in the root of that do , to specify the data path on the command line). You could also leverage the fact that, for native languages at least, you always know what architecture you're compiling for when you compile and it's generally a distinct project configuration. This means you can rename everything, and embed those names as appropriate: 

I would recommend the last approach. This way, you create one vertex buffer defining your sphere positions relative to the origin in model space. You can render this buffer many times, setting a different world transformation matrix (which is itself just a shader uniform) as well as a different appropriate color. The world transformation matrix is how you position each sphere in the world, and the color is obviously what controls the color value. This way you only have a single copy of the geometry (which itself does not contain a lot of redundant extra bytes to specify color data, unless you really need multi-colored spheres), you have support for uniquely coloring each node in your network, and you let the GPU do the transformation work it's designed to do rather than doing it yourself CPU-side. 

Mercury is a 2D particle engine, so you can't directly position/manipulate/simulate particles in 3D using it. While you could perhaps abuse it into looking 3D with a combination of a custom modifier on an emitter and some clever overloading of particle properties (or outboard storage of extra particle data), you're better off finding another solution. Mercury is open-source and released under a reasonably permissive license (MS-PL) so you could fork it and adopt its techniques to 3D rendering. You could also look for alternatives or hand-roll a solution. There are several examples you could use as a starting point: 

Similarly with your class, I'd do the same. Just pass the position; the itself need not know which player it belongs to, that can also be handled by an external, higher level interface. The basic idea I am advocating here is to keep individual interfaces as simple as possible, and compose the intended gameplay functionality by building up layers of increasingly higher-level interfaces that make use of lower-level ones. Like an onion, sort of. You may also find the SOLID principles of object oriented design an interesting collection of reading. 

Unfortunately, there isn't a good, legal solution for this except to make an installer, because your hands are tied by the distribution rights granted to you by the DirectX SDK, which provides the D3DX DLLs. Under the terms of the license agreement you are bound to by using the SDK (which is located in you are only permitted to redistribute the binary forms of certain subsets of the SDK, along with some of the sample and utility code. As of the June 2010 SDK, you allowed to redistribute anything in the "Redist" directory and when doing so you must include certain components (DSetup32.dll, DSetup.dll, DXSetup.exe, DXupdate.cab and dxdllreg_x86.cab). The Redist directory includes the .cab files for the D3DX DLLs, but not the DLLs themselves so you are out of luck. It isn't terribly hard to build an installer, fortunately, that just runs the appropriate D3DX web installer or whatnot that is something you redistribute. Simple .msi installers are just as easy for a user to use (double-clicking is generally all that's needed) and can be configured to allow installation into arbitrary directories, if you are concerned for some reason about "polluting" the Program Files directory with these small throw-away programs. The overhead in download size of an appropriately configured installer can be quite small, as well, so that shouldn't be too much of a problem. EDIT: Here is a good page about DX installation stuff. EDIT 2: Struck out the "web" bit in response to a correction in the comments. 

An advantage to this approach is a much higher isolation between the game and render logic; the disadvantage is the extra post-processing of the game objects into render descriptions. In practice, you can alleviate the algorithmic overhead of that second processing pass by pushing the creation/configuration of a render object for a given game object into the loop that iterates the game objects and updates them. This typically doesn't introduce that much coupling between the logic and render subsystems. If you are taking a component-focused approach that supports extensible aggregation of behavior into game objects, you can have the renderer publish a component that can be attached to each game object that configures its render object. This can allow for more extensible customization (via, for example, scripts -- which is probably overkill for this project). What I think you should not do is directly have game objects a "render myself" method, because I think this creates scalability problems in terms of reconfiguring rendering techniques and styles (it can be much harder to have different classes of object share render configuration code this way). Plus it tightly couples the two subsystems and creates additional responsibilities for the game object interface (interfaces should ideally have one responsibility). 

(An avatar may be invalid if the player doesn't have one. In that case you may want to fall back to using the gamer's profile picture, which is already available in an easy-to-use format you can turn into a texture.) Now that you have the avatar data, you can use it with the class by passing the avatar to the method of an : 

You will obviously have to change how you fill the vertex buffer (write into the data stream) as well to account for this, or you'll continue to get black screens / garbage because the buffer is misaligned relative to the declaration. Third, you're also specifying a FVF code to the vertex buffer when you create it; since you're using vertex declarations, you don't need to do that (especially since your FVF code does not match your declaration, either). Instead pass ; you already set the vertex declaration. Fourth, you specify a usage value of "points" but then try to render a triangle strip. For simplicity, you probably want to put your buffer in the managed pool so you don't have to recreate it when you lose the device. Your buffer creation code can look like this: 

You generally don't want to manipulate the vertices of the model objects to move them around in your world. Instead, you set the world transformation matrix (that you pass to Draw) accordingly, for example setting it to a translation matrix that moves the model by the desired amount. That said, if you really want to manipulate the vertices directly -- perhaps because you only need a subset to change, or infrequently, you can iterate the Parts collection of the Meshes collection of the model. Each mesh part has a vertex (and index) buffer object you can use to update the model. 

Consequently, we can conclude that your function is returning zero because the mouse is off the left edge of the client area when you run it. 

This tutorial from Ray covers preparation of the OpenGL render pipeline and the setup required to describe a square. It's about halfway down. Specifically, to draw a square you'll want to draw two triangles. Ray's code organizes them like this: 

That said, these are just canonical defaults. Since you are controlling the input data and the interpretation of that input data, you can place that data in any coordinate frame that is useful to you. For example, when faking 2D graphics in a 3D API it can be useful to simply place pixel coordinate input data into vertex buffers and have a very simple, almost no-op vertex shader. There are some aspects of the pipeline outside your programmable control though. For example, will always be offset screen space. The biggest thing to worry about it actually the output of the vertex shader stage. The rest of the pipeline will assume that output is in clip space, perform clipping, and perform the perspective division by . Consequently you may need to set accordingly (often to ) if you want to "avoid" this division. 

I think you are on the right track. Your proposed system of distance-based attenuation should work if you 

Nope. Clipping a triangle against a plane can result in a quadrilateral, which you will need to re-triangulate (unless you don't actually care about having triangles). In fact, it often results in a quad, since in most cases you get a quad on one side of the plane and a triangle on the other. You only get two triangles when the plane exactly intersects one vertex. Consider the triangle below, which exists in the XY plane (you're looking "down the Z axis"). The blue line represents a YZ plane the triangle is clipped against, resulting in a tetrahedral shape when we consider the left half-space of the plane to be the "inside" space we care about. The pink line represents one possible re-triangulation of the quadrilateral. 

3DS Max is a 3D modelling tool. There are several video tutorials available all over the internet (of varying quality). However, you can't make a game just using Max -- all it does is modelling and rendering. You'll need to use something else entirely, or at least something else in conjunction with Max, in order to make a game. Blender is a similar kind of modelling tool that does have a built-in game engine that can be used. It's also much cheaper than Max (because it's free). There's lots of documentation and educational material on Blender's website and elsewhere on the internet. You may also want to consider looking at Unity. There are several other game construction tools available as well. You could also teach yourself to program -- I'd recommend Python as a first language, if you choose to do this. This will give you a lot of control and flexibility in the games you create, but it will involve a much steeper learning curve (for example if you choose to go this route you'll likely be learning to develop very simple text-based games for some time before you are ready to tackle the complexity of 3D graphics and loading 3D models and scenes exported from Max). 

While this proposed implementation is workable, it's not very scalable -- and scalability should be one reason you consider using something MySQL. You don't need a "database" to store items and shop/vendor data for a game, especially not a simple single player game. Simply storing the data in flat files (text, or XML, or some binary format you invent) would work just as well and would likely be much easier to implement and maintain. You should not use a database like MySQL unless you need something a database offers that no other solution does. I don't believe you do. That said, some specific critiques: 

Your first concern, regarding size(*), is a non-issue. You can note in the source that just stores a matrix of an appropriate size to transform a homogeneous coordinate in the specified dimensionality (that is, a 4x4 matrix for a 3D transformation). This appears to be because is allowed to represent projections, rather than just translation/rotation/scale (which could be stored in few floats). Your second concern, about generating a new matrix every update, is also a non-issue. Construction of a matrix in general shouldn't be that slow. Plus, you usually want to do this because persisting your transformation data (position, orientation and scaling) in different forms usually makes them easier to access and manipulate. For example, it's a lot easier to interpolate position and orientation and vectors and quaternions, respectively, than it is to try an interpolate a transformation matrix representing the combined operation. Plus, due to floating point inaccuracies if you persist the transform as a matrix and constantly update into it, you can create rendering bugs as drift is introduced into what was originally (for example) a uniform scale portion of the matrix. appears to exist main as a way to simplify the creation and usage of a matrix for many typical transformations. As with any such simplification, yes, it forces certain conventions on you. If those conventions don't work for you, you shouldn't use the class and should instead operate with the underlying matrices directly (which sounds like what you want to do in this case). (*) Edit: I had assumed your reference to was a typo for , but when I went to confirm by browsing the source it turns out there is such a class. In this case, you are correct that the class will be smaller than a full matrix.