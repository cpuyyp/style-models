I have some data tables that where imported in from a flat file source so everything is except which is a that hold the row number the data came from in the flat file source (and is the primary key of the imported table.) The following query works perfectly 

So restrict says the row can only be deleted if the destination key does not exist, and since it is pointing at itself it will always exist, therefor it makes it so you can add and edit a row, but you can't delete it. 

(Plan XML here) I went to investigate more, but neither doing nor show the warning in their versions. SHOWPLAN_ALL: 

I assume sense the job only has two "Transact-SQL script" type steps and a "Replication Snapshot" type step it would be safe to call, is that correct? Does do anything extra that calling on the job would not do? If I want to write scripts that is safe to use on Sql2008 through Sql2016+ and up what would be the best approach to do? 

Update: I found a solution but it is very "hackish" IMHO, I really would still like a explanation of how to avoid things like this in the future and how to do this correctly. 

I am about to modify a large number of the stored procedures so it does not hit the table twice to something like the following 

I have a bit of a odd situation. I have two queries that produce the same result, according to SSMS and SQL Sentry Plan Explorer the first query should cost 95% and the 2nd query should cost 5%. However the first query completes in 132 ms and the second query completes in 8,531 ms. 

I don't know how db2 works, but I think this is making it so rows can never be deleted once added. from Wikipeda 

Is the index structure of my new table appropriate? The big thing on my mind is I am duplicating almost my entire table in that unique index. The other thought I had doing was to structure the table like the following 

And that is where temp db blows up in size. Both the source and destination tables have 1,770,373 rows in it (there is a 1=1 on ID relationship for the update). I tried running the database tuning advisor and it had me make a new index, but it did not help. The database I am inserting in to is just the middle step in a data migration and no queries other than other csv imports like one I am doing here and a bulk export at the end will be run against this database so it does not have any indexes or keys itself. Here is the create table statement for 

Is that pattern of including the search parameter on both joined tables still correct in modern versions of SQL Server? (Most interested in SQL Server 2008 R2 SP2 and newer) 

I never use in my program, it is only for merge replication. The most common query my application will be using this table for will be 

Let me start out that I do not need to reset the SA password, I know how to do that and there are plenty of resources on this site and elsewhere that give detailed step by step tutorials. We have SQL servers set up on site at clients premises, the problem I am having is 3rd party companies are logging in to the server using our own service logins and doing data mining and data pushing. We are trying to stop this behavior (I know this is a impossible goal, but I am trying to convince other people of this fact). We have figured out how they are getting our logins currently and will be fixing that, however what I would like to know is: Is there any known tool or process that can "extract" login passwords from a sql server instance (be it a offline attack or via intercepting and snooping a valid connection)? I think there is likely a way to do it but management would like proof that it can be done. Does anyone know of any set of tools or processes that it can be done with so I can demonstrate a proof of concept to management? 

I have a setup script that calls a few times to set up some system variables, it works fine but I have a few of the following statement 

Is there anything I can do to prevent those informational messages (which are useless to the script, I call from inside the script) from displaying in the messages window in MSSMS when a user runs the script? 

I was running the following query in SSMS and it showed me a warning in the "Include Execution Plan" window 

I am trying to do a bulk update of a column from a csv file, however when I do the actual update operation my balloons to over 20 GB in size (overtaking the entire size of the SSD the is running on). I load the csv file using a bulk copy in to a temporary table that has matching schema to the destination table, I then do the query 

I have a stored procedure that I need to both output the result set to the user and use a piece of information in the result set to possibly output other result sets. Here is a basic schema of what I have 

Right now I add all of those checks so I only trigger on the fields exposed by the view. Is there a better way to do this to dynamically get all of the fields exposed by the view? I am concerned about future maintainability where someone will update the view but not update the triggers. 

I get the exact number of rows I was expecting and everything is fine. However if I uncomment that last line so I only show the record from the data table who has it reports to me 

I am trying to start and stop the replication snapshot via t-sql. I found , and doing a trace while hitting the stop on the snapshot from inside SSMS I see it calls however I don't see any documentation at all on the procedure. Is this considered a "Undocumented procedure", I thought they all started with ? If this is a undocumented procedure is there a better way to stop the snapshot agent? I did look in to , the only thing that makes me hesitant to just use it is the remark in the documentation of 

How do I fix this? Can anyone explain what is happening so I can understand how to avoid this in the future? 

Things I have done recently to the database: I ran Database Engine Tuning Advisor and had it look at my plan cache (which had been building up for a few weeks) and added all of the statistics and indexes it recommended. After that I did a on both and with the option . After that I ran to clear out any old plans using the old statistics and indexes. I then ran the queries a few times to let the data get cached and any query plans that needed compiling let compile. After all that I ran the queries inside SQL Sentry Plan Explorer to get the numbers I have listed here. Why does SQL think the first one is so much more expensive and why is my 2nd query taking so much longer when similar re-writes I performed did so much better?