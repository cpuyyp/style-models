So I guess that your initial attempt is to iterate through all meshes in your scene, for each mesh, check all triangles if they intersect, right? The brute-force way. I'm not sure if there's a lightweight library for you to solve your problem, but the problem is quite a large discussing area. I would suggest using a bounding-volume structure, such as a KD-Tree used in 3 dimensions. Christer Ericsson suggests an implementation in his book "Realtime Collision Detection" which is cache-friendly and memory efficient. I've implemented his suggestion in a project and indeed it did turn out very well. The task of creating a KD-tree together with splitting your meshes into well-balanced tree's is covered in depth by Ingo Wald ($URL$ I suggest you read up on there. The Surface Area Heurestic (SAH) is considered (one of?) the best algorithms for KD-splitting, Ingo Wald covers it in one of his publications ($URL$ There are a variety of freeware KD-tree's out there, I haven't really looked into kdtree at google-code ($URL$ but it looks pretty decent. There's some interesting tutorials ($URL$ that you can read. Good luck! 

If the class is longer than roughly one page of your editor, refactor it. I don't think the order of methods or members matter much, as long as they're grouped somewhat logical together. 

I would say: Use neither, as long as you don't explicitly need instant-time feedback from the damage. The damage-taking entity/component/whatever should push the events to either a local event-queue or a system on an equal level that holds damage-events. There should then be an overlaying system with access to both entities that requests the events from entity a and passes it to entity b. By not creating a general event-system that anything can use from anywhere to pass an event to anything at any time, you create explicit data-flow which always makes code easier to debug, easier to measure performance, easier to understand and read and often leads to a more well-designed system in general. 

As you've, probably, noticed. For quads we have 4 outer tessellation levels and 2 inner. Because, surprisingly :-), we have 4 edges and 2 dimensions to subdivide inside quad. If you calculate tessellation levels dynamically (e.g. based on distance from camera) care should be taken to set correct index in gl_TessLevelOuter/Inner. Otherwise, your mesh might not be watertight. OpenGL uses next convention (which, by the way same as DirectX uses): 

For this you need to identity what mesh is currently being processed. If you need to draw many same meshes (say a lot of stones, or grass) you should look into Instancing (e.g.Efficiently Drawing Multiple Instances of Geometry) there you basically have one stream which has mesh data similar to all objects(vertices, tex coords etc.) and another which has per instance data (like object positions in the world). Both OpenGL and DX have support for instancing. OpenGL (since 4.3) also has very cool function glMultiDrawIndirect (or chapter 1.3 here) which allows to do what, I think, you want - draw several different objects using only one draw call. This is "more advanced" instancing, you pass array of structures describing how many instances to draw and where to get data for them in your buffers. See the description it is quite clear. However, you need to use same shader for all of the objects because you cannot pass "shaderid" in your per instance buffer. But you may write a generic shader and based on gl_DrawID (passed to your shader by OpenGL, has unique value for each instance) do stuff that you want. E.g., you may construct uniform array and index it based on gl_DrawID. You can do the same if you need different textures per instance. In this case you can create texture array and index it (note that in this case all textures have to have same size and format). You also may try to use bindless textures (OpenGL 4.4 :P). 

I would say that the singleton design itself isn't useful at all. Global variables can definetly be useful but I'd rather see them hidden behind a well-written interface so that you aren't aware of their existence. With singletons you are definetly aware of their existence. I often use global variables for things that need access all through out an engine. My performance tool is one good example which I use all over the engine to call. The calls are simple; ProbeRegister(), ProbeHit() and ProbeScoped(). Their real access is a little bit more tricky and uses global variables for some of their things. 

Mischief Mayhem Soap by Maciej is an awesome gamedev-blog: $URL$ He puts a lot of effort into explaining performance, caches, general issues that are commonly overlooked etc. I think it's a "must-read" if you're a game-dev. 

Bullet has a very well-working collision pipeline. They support various broadphases (sweep n prune, hashed broadphase, 3-axis sweep, etc) and have narrowphase with optimized bv-tree's. I've worked professionally with bullet for over a year and although their performance is not as good as havok(which I've worked with for over two years), it's free and the source code is maintained and enhanced often. It should be fairly easy to look into their source-code to figure out how to only use their collision detection. PhysX also has a collision-detection network but I haven't relly looked into it. Havok is a solution that costs a lot of money and I don't think anyone can afford retrieving their source-code unless you're a professional developer. They do have free-to-use libraries but then you can't modify it. 

When it comes to C++, I have tried and used the googletest framework, $URL$ It's simple to set up, easy to use and works great. 

Looks like you have some problems with references. Strictly saying, you cannot return local object as a reference, nor you can bind non-const reference to a temp object like this: 

Not sure if composition will solve all the problems. Maybe can partially help. But if what you want is to decouple classes I would look into more events driven logic. This way e.g. you'll have OnLoot function which needs to have player position and info about loots available to find the closest. Then function sends event to the looted item. Looted item in its event process cycle handles this event so item only needs to know how to update itself. OnLoot function can also update player inventory or item itself may send updateInventory/*OnLootSucess* event and player/inventory will handle it in its own process events cycle. Pros: you've decoupled some of your classes Cons: added events classes, maybe unneeded code overhead. Here is one of the possible ways of how it may look: 

If you have DYNAMIC buffer and map it with WRITE_DISCARD then both ways are pretty much identical. As soon as you issue map call, DirectX will provide you with brand new buffer, so there will be no CPU-GPU sync, that is the point. You cannot read data in this provided buffer, first because it is a completely new memory and does not contain your data, second - because returned memory is a writecombine memory and reading from it will cause big penalty. While in your case this will not be a problem, but mapping buffer with discard causes runtime to search available piece of memory, which sometimes may lead to hitches. More robust way would be to have several buffers (or just one bigger buffer) and map it with MAP_NO_OVERWRITE (only available for index/vertex buffers unless you are running Direct3D 11.1 on Win8), but you need to ensure that memory to which you are writing is not anymore used by GPU. One way to ensure it is to have as many buffers as you maximum frame latency, or issue queries and check that they are ready. You can read more about it here Hope this helps. 

I would say that that the "Hot position" when it comes to programmers is probably Lead Architect, Lead Engine, or any other name to the same job. Essentially the guy who gets to decide what to implement and how. It's often a person with very good knowledge regarding programming, someone who probably has one of the best overviews of the code in the company. I don't think that it's something that you often get recruited to externally, but instead most likely internally. It requires a lot of experience and often have a tendency to be the best "general" programmers that make it there. 

I have a home-made profiling system that consists of profile-probes that I've injected on a lot of none-inner-loop places in my code. The probes are initially disabled and I just enable the ones that I want to check up on. The system simply throws out the information to a .txt file (or a network stream) that I then use another language to parse the output from and present the data in a more user-friendly way. The probes are globally initialized upon creation and only when recording them creates any data. The benefits of this is: * While enabled (even in release builds), the system is light on cpu cycles and you'll most likely not notice any performance hit while all probes are disabled. * While disabled (final build), the system is reduced to 0 cost (like most home-brewn profile-systems). * It can measure time, hits, record callstacks, print variables, so it's flexible and can be used for most debugging that you'll need. * It's dynamic, you can get exactly the information that you want from it. On the negative side: It took nearly 2 days to implement so it's fairly complex. It'll likely make up for that time though. Examples for usage: * Timescoping * Memory allocations (sizes, names, etc). * Resource tracking * Debugging (conditional prints). 

Quad tessellation is similar to trianlges. The difference is that instead of barycentric coordinates gl_TessCoord.xyz which define point on a triangle (tcPosition) you have 2-component coordinate gl_TessCoord.xy (they also span in [0-1] range). Hull shader (or Tessellation Control Shader in OpenGL terminology) looks pretty straightforward: 

Almost, but only half of the pixel. Just subtract 0.5 from your quad vertices. E.g. you want 256x256 quad with same texture, here are your points: 

If you use same semantic for SemanticName, then you need to increase number for SemanticIndex. I also see that you are increasing InputSlot. This may be correct or not depending on how your data is layed out. If you really have 4 vertex streams (vertex buffers) then it's fine, but I assume that your instance transform is stored in one vertex buffer. Then you need to set same stream number to InputSlot in every instance binding. assume that: 

This is just one of the possible ways. Probably you don't need so many events. And I am sure you can do better knowing your data, this is only one of many ways. 

Probably after, you need this information to construct per instance data buffers. But there is no need to modify mesh data. I hope this was clear. 

In case of simple instancing (many same objects) you will need to update per instance data and amount of instances to be drawn according to results of your occlusion test. In case of glMultiDrawIndirect, however, you may update "count" parameter (set it to = 0 if object is not visible), but driver will, most probably, still issue an empty draw call. But you may as well update the whole array of structures containing the draw parameters. You might be interested in GPU based occlusion, like one described here starting at slide 35. 

Keep it simple. If you're not sure which way to go - just do whatever your game requires. Try to write small, basic libraries for stuff that you feel might be usable in the future. Look into data-driven software development. I suggest looking into component-based entity systems. Don't base the code around things that are unique such as a player. A player is just another object, just like anything else. An entity has components, perhaps a list of components. By writing small, contained libraries that interact with each other, you can go ahead and determine which ones to re-use for your next game. Personally I have things like a "container" library for data-storage types. I have a math-library for such things. There are several things like these that you can sort out and write as modules. Camera, effects, input, entity, movement, physics, rendering, resource-handling, threading, the list goes on. Writing small stand-alone components often increases readability and debugging possibilities of your code. Mike Acton and insomniac games (www.insomniacgames.com) have written a lot of topics and discussions regarding game development, in particular data-driven. Look them up and see what kind of information that is too complex and which you find interesting and understandable. They're great developers with a ton of experience. 

I would store all add/removes in separate lists and do those operations after I've iterated through the update-loop. 

When it comes to boost's pointers specifically, I think that they should be avoided as long as their implementation is not exactly what you need. They do come at a cost that is larger than anyone would initially expect. They provide an interface that allows you to skip vital and important parts of your memory and resourcement management. When it comes to any software development I think that it is important to think about your data. It is very important how your data is represented in memory. The reason for this is that CPU-speed has been increasing at a much greater rate than memory-access time. This often makes the memory-caches the main bottleneck of most modern computer games. By having your data aligned linearly in memory according to access order is much friendlier to the cache. This kind of solutions often lead to cleaner designs, simpler code and definetly code that is more easy to debug. Smart pointers easily lead to frequent dynamic memory allocations of resources, this causes them to be scattered all over the memory. This is not a premature optimization, it's a healthy decision that can and should be taken as early as possible. It's a question of architectural understanding of the hardware that your software will run on and it is important. Edit: There are a few things to consider regarding the performance of shared-pointers: 

You can, of course, interpolate in vertical direction first. tcPosition indices depend on your control points positions. I've provided case for the picture drawn above. I suggest, you to disable back face culling for the beginning to minimize frustration in case you suddenly generate triangles with winding different from stated. Hope this helps. You can also look up this link for more info. 

You can either work with pointers, but make sure that they were correctly allocated/destroyed. This way your Get and Remove method will be simpler. You can just return nullptr/NULL/0 instead of constructing and returning dummy object. If you do not want to use pointers than you can have dummy static object inside your scene class and return it. But you still need to make sure that your ordinary objects are not going out of scope. As an example, Get/Remove could look like this: 

I agree with petterson, but if you want to reduce amount of draw calls as well you need to use instancing. 

Basically, what Xnafan told is one of the possible ways to do it right. What (I assume) he wanted to say is: 

If you create it once and will not move a lot of stuff around each frame, there is nothing bad in it. It all depends on you usage. 

I wonder how did you get it to compile... If you want to remove references be sure that they are not destroyed (e.g. by goingout of scope). E.g. next code will not behave correctly: 

Orientation of quad vertices is clockwise. Note that zero vertex (u=0, v=0) is located in left bottom corner, that is different from DirectX, just in case you are porting code). Basically, your UV space looks like this: