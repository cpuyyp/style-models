I'd have to agree with JoeW further up, the question seems to be too specific, in that you state you want to solve the performance problem of lots of trees, but the question states only by partial updates and that leaves only to solutions based around that. What you don't seem to mention above is any form of LOD on the mesh, just mip-maps for the textures. When I've needed to make sure lots of tree's have to be drawn on screen I'd have at least two polygon mesh LOD's for them and in the distance have that go down to a simple forward facing sprite (we've used a bit of a hybrid solution where we also use SpeedTree which does pretty much the same thing). I guess it comes down again to where the bottleneck is and until you understand exactly what it is that's slowing it down the most you can't really optimize that area. Just in case by FBO you didn't mean 2D Imposters I've also thrown a link in for that. I've not shipped anything using them dynamically myself but I know titles have with success, it all depends how much video memory you have free on your target platform to implement. 

In addition to the other answer, you could speed up the per pixel solution using an octree to have a hierachical approach to being able to quickly reject completely transparent pixels (or regions). It would work best if there were large areas of non-collidable regions of pixels which could be quickly ignored. You could also have a hierachy of collision primitives, a basic encompassing circle around the whole object, which if colliding you could then drop down to the next level of primitives which could be a number of more accurately placed circles, etc, which more accurately follows the outline of the object. You could in theory allow this to recurse as much as possible, the hierarchy allowing for early outs if a collision isn't detected at a higher level. 

A quick Google threw this up here. A demo, description and code (in Flash) using Box2D to implement a simple rope. The rope collides with itself and the block at the top of the scene. 

I wouldn't expect any of the big players to talk about what they do to protect their games. The less people know about what they're doing, the harder it is for people to work around it. I think part of what Steam does is look for certain applications running that are on a black list. Personally I'd try and encrypt and obfuscate communication as much as possible between communicating machines, it might be worth reading up on the way https/ssl works to get some ideas. If the hosts were to generate a random public/private keys and only send the public part out to other clients then something wouldn't easily be able to intercept and change the contents of the packages being sent, although if you have access to the client machine then nothing is completely secure. You'll also need to ensure that the client exe isn't tampered with. 

As you're just curious about other stuff out there, I don't see any mention of Miles on here yet. I've not used it myself (although we did use it many years ago on a game), however these games use it. 

Depending on the scoring system in your game and the type you use you may never need to wrap. For example, an unsigned 64-bit integer can hold a maximum value of 9,223,372,036,854,775,807. Long before games get close to that most would start displaying problems rendering a number that long in the UI. It would also take an awfully long time to rack up a score that big so it's not really worth worrying about. Depending on how you implement a leaderboard (i.e. use a third-party system for online scoreboards) then the format of the score may already be decided for you on their servers. 

While annoying, it allows hardware manufacturers the flexibility to optimise the rendering process in numerous and transparent ways. For example, the PowerVR hardware (certainly used to back in the day, not used one for a long time) wait until the entire scene to be rendered was submitted, then perform automatic depth sorting using the painters algorithm and not actually need to generate a depth buffer. It would divide the screen up into tiles and render each one in turn. 

Is it a 64-bit application? I seem to recall there's a separate control panel for x86 and x64 applications in DirectX. It's been a long time since I messed with this stuff but you should be able to see it under the DirectX SDK menu options off the Start Menu, under DirectX utilities (should be one for 32 and 64 bit) 

It depends on the level of detail you go into and how you generate your data. From Will's post, deriving your layout from OSM does seem to be a way of doing this to an extent, however if you derive anything from any other source you'll need to carefully check their licences very carefully. There may be certain buildings or objects in real cities or locations that would require a specific licence to use (from past experience we've had to remove the odd distinct building that either didn't want to appear or had a ridiculously high licence fee), if you planned to try and actually use the real shops or corporate logo's of buildings you'd potentially have to obtain a licence for each one individually (this may vary depending on the country you're recreating). As an example, take the Hollywood sign, if you wanted to put that in a game you'd need to specifically obtain a licence for it here. As with all things legal, if in doubt, ask a lawyer who has some experience in this area. 

If you're seriously considering this I'd speak to Sony directly. Sales numbers are usually considered commercially sensitive, not only between competing game developers/publishers but between different platform holders. As a developer Sony would probably be prepared to provide you with generalisations on some of the numbers for what you could reasonably expect. 

With 3D textures you could use the 'w' component of the 3D texture co-ordinates to select a different texture to sample from. What are you trying to achieve? Are you making big savings by rendering all 3 with a single call? You could also use a texture page/atlas to have all 3 textures in one larger texture (maybe with a little wastage) and then have the 3 set's of UV's pick the correct texture out of the right part of the image. 

Without being able to see it running (or the rest of the code) it's hard to say, but are you sure it's actually what you think failing here? That value is only used in the lighting equation where it's contribution is based on the angle between the normal of the vertex and the lighting vector. It could be the normal value on the line vertex is such that it breaks. Have you tried just setting the output colour of the VS (Output.Col) to just be equal to "Colour" to rule out any other possibilities? That way the value will just be set directly and will validate it's this that's broken. With that set, also try setting a specific value in the code rather than pull the value out of the line structure to ensure that's valid. Other than that, there's any number of reasons it could be broken, e.g. the vertex layout might not exactly match the actual structure correctly, etc. I'm not sure what the state of PC shader debugging is like as I haven't had much call to use them (e.g. PIX, NVidia or ATI tools), but they might also be able to let you see better what's going on. 

Without a picture I'll have a rough guess on some of your problems. Normals: If this is a cube, I'd expect all the normal component values to be +/- 0.577350 in different combinations depending on the vertex. Where you have other values the normal is no longer being properly averaged from the three faces that share it and it'll be tending more in one direction. Because you're using shared vertices for the faces then despite it being a cube, it's trying to be lit as if it's a sphere. If you wanted it to look like an actual cube you'll need to duplicate up the vertices and have unique normals for them. "visible from inside": This sounds like a winding order issue. Graphics hardware tends to have Backface Culling enabled as a speed optimisation, depending on the order of the vertices given to the hardware it makes a decision as to whether it thinks a polygon faces towards or away from the viewer. It's possible you can fix this problem by changing the order of the vertices in your faces, so the first face would become "0 3 2" instead of "0 2 3". A picture of the output would help to be more specific, as would a more accurate description of what problems you actually have, for example, you say it's lit from below, is this a problem or was that just stating how it looks? Quick update: You can display the normals manually by drawing some simple lines, just use the vertex position as the start point, then add the normal value (scaled by some constant factor to ensure it's the length you want) and add this to the original vertex position to generate an end point.