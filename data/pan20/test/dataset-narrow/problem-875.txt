For those of you who still not tired of "XYZ for sysadmin" questions: This subject is bothering me for a long time. I had number of problems selecting notebook for job. For example: 

You didn't specified what kernel are you talking about. From BSD's point of view it's all explained in TCP/IP Illustrated, Volume 2: The Implementation By Gary R. Wright, W. Richard Stevens Short version follows: 

I think you trying to do something strange. You can easily sort messages in syslog depending on hostname they came from. See : 

You can probably workaround that problem by changing your docker's network settings (e.g. disable IPv6). Or if you have some time to spare you can try resolving to a LOC and try figuring out what could've caused GPF there. PS. Also you you probably haven't posted your first Oops here, since you already have and in your 

Basically most are related to physical memory failure. But in presence of virtualization it may also be a hypervizor bug. But I would suggest you first check . [1] $URL$ 

There is DHCP server in network (isc-dhcpd-server-3.0 on FreeBSD 7.2) than gives one IP per switch port to every user via Option 82 The problem appears when user disconnects one of his computers and connects another(i.e notebook with different MAC address) then DHCPD puts to log "...network net1: no free leases", because there is record in leases file that this IP is already owned by another MAC. That second computer will have his IP only after default-lease-time (that is IIRC minimum 10min, and after 3min he usually calling support) or after deletion of dhcpd.leases file and restart of dhcpd. Is there a way to turn leases off at all, because we have strict binding between switch-port-ip? 

Just a guess, but: Does php have access rights to ? PS. You also can try php-fpm instead of spawn_fcgi 

L7 solution: You can use nginx as a reverse proxy and redirect all requests from old IP to new with simple config like this: 

Caching is pretty new function in nginx (and not so well documented for now), but stable enough to be used in production. 

I'm not sure that I'll be heard this time but I'll try anyway: switching to is not as hard as you think it is. But I guess you still need some kind of explanation. I propose that if you'd have only 4G of memory then a would equal to ~850mb, for 16G it would be around ~750mb and for 64G it would be ~378mb. Let me cite Linux Torvalds: 

Another thing you can try that may help increase TCP throughput is to increase the size of the interface queue. To do this, do the following: 

Judging by your output raising and lowering both and may slightly help. I assumed you are using somewhat recent kernel e.g. . You can see 's source code here: $URL$ 

The line above tells to authorize user to run any commands as any user that is member of the group. The related sections from are: 

Your firewall rules seem correct. However, redirection of packets that enters the AP should be configured in the chain. Rules added into the chain affect locally-generated packets only. So, the following rule should be added: 

Note: I admit I am proposing a weird and possibly unsupported solution, which may get broken on future versions. Nonetheless, it will certainly work on a CentOS 7 server. I suggest you to directly add such port forwarding rule into the / stack. You can achieve that by using 's direct rules. For example: 

Postfix seems to use in one of its access restriction lists. I couldn't figure an exact cause of the issue. Please, could you add in the question: 

Add the argument to the command, which means "do not send any messages if the body is empty". Therefore, change the crontab line to: 

I suggest you to verify the DFS Replication health between the servers, by following this article: $URL$ : 

I would answer that you could install and run the script via the Shell Execute operator (). However, it will probably not work, because the system will certainly be unresponsible after a kernel oops and will not run the custom script. Because of that, I suggest you to run a script in another server when a kernel oops occurs. For example: 

According to the client log, the OpenVPN client did not add a static route to the OpenVPN server through the original default gateway (the one used before the connection establishes). This prevents OpenVPN client packets from reaching the server, because of the absence of a route to it. I suggest you to change the server config, replacing the line: 

I guess a modern mail transfer agent follows at least RFC2821 or RFC5321 procedures, so all three DNS setups provide failover capabilities. However, only the first setup may provide a better load balancing. If you give a try to the second or the third setup, you will have to make sure your DNS server delivers responses in a random order. Besides, DNS records may be cached either by MTA's themselves or by recursive DNS servers, so the randomness can't be guaranteed. I think will receive most of the messages. Another reason that directs my opinion against the second and third setups is the reference of multiple names to one IP address. Mail servers in the internet commonly rejects messages from hosts whose mapping doesn't match (as does the Postfix restriction reject_unknown_client_hostname), so you will have to take special care on setting PTR records. Clients that don't try MX records in a random order are already violating the RFC2821 and RFC5321 standards. So, I think there is no guarantee that these clients will also try the secondary IP address automatically. Because of that, I prefer the simplest DNS configuration: 

then ones a day/week/month you should run to update collection (not programs them selfs) After ports are extracted you can find one you want and install it: 

Bigger address space means that address has more bits that can be used as data storage. For example hop-count between two nodes then can be a function of their IPv6 addresses e.g.: IPv6 address can be in format so closer nodes will have more Most-Significant-Bits same. This is just an example, of course "closeness" metrics could be stored in some kind of external database like DNS records. There are some techniques of using address space of IPv6 for cryptographic purposes such as Cryptographically Generated Addresses (CGA) and SEND (SEcure Neighbor Discovery) When IPv6 is enabled all nodes in network have link-local IPv6 address(if not configured otherwise). So there is a chance that you can access even mis-configured node. You can get nodes' MAC addresses directly from link-local IPv6 address (if IPv6 privacy extensions are not configured) There is no way you can possibly use IPv4 in subnets with thousands of nodes - your network will be overloaded with broadcast traffic (e.g. ARP). You can query node for additional information using node information, e.g. in BSD you can query host for ICMPv6 Node Information Node Addresses: 

I'm backing it up at night with If I restore backup using on the same server then I'm getting not quite the same data, for example: 

Problem most probably cased by SAN malfunction. When FreeBSD looses disk there almost no way of leaving panic log entry. But in VM environment (and also in very few motherboards) there can be msgbuf () left after reboot. You may try to examine it. For debug you can try using instead of reboot after panic. PS. If you have system programmer at hand you can ask him to write something like Linux's for FreeBSD 

What you are doing is pretty strange: 1) You have same subnet reachable from different interfaces which will make your life a bit difficult for some types of server software 2) When you put 's interface down you should mangle routes: 

PS. Are you using apache? Check it's stats PPS. Try putting nginx before it. PPPS. Are you using accf_http kernel module? 

The problem is you don't have any files to build. Start with obtaining the kernel source codes. Then use link petre provided or use this one 

Solution 1: Hide untrusted PC under another router. This will solve arp-spoofing/mitm problem. Solution 2: Use any router with DD-WRT firmware. There you can setup different Wireless LANs and even put them in different VLANs. Too bad that ADSL modems aren't supported by it. 

To answer this question you should probably checkout changelog for you kernel package. This can be done for example via . But general recommendation is to always use latest kernel version provided by distrib's security team unless it introduces visible regressions for your workload. PS. To upgrade system packages under Ubuntu one should use PPS. Also as suggested in comments if you have more than one server it's usually a nice idea to use Chef/Puppet/Cfengine. 

In the server that eventually produces kernel oops, forward messages to a "monitor" server using the netconsole module. 

I could not find any documentation that explains the meaning of . I usually define the initial state to and let the election process to choose the master instance. I copied your configuration files to a lab environment and have found that a closing brace for is missing in Server2's keepalived.conf . However, the failover seemed to work well despite that character absence. Please, check using wether unrelated VRRP packets with are present. Or try to change the to another number. As VRRP packets are sent to the multicast address , each virtual IP in a network must use an unique . Also, if you intend to let Server1 take over the virtual IP, I suggest you to set in its . RFC5798 section 6.4.3. Master says that if Server1's IP address is greater than Server2's IP address and both servers have the same priority, Server1 wins the election and gets the virtual IP. However, seems to compare priorities only. 

If the mail server uses an invalid or self-signed certificate, you may need to set , and context options. I am not a PHPMailer user. I guess you may need to set attribute. Please, test this piece of code (reference): 

The custom script may restart the machine via the out-of-band management interface (iDRAC on Dell servers): 

I figured that CentOS's creates a chain in table for each active zone, which gets evaluated when packets that matches zone definitions arrive. So / rules can be added there. 

In [Case1], the socket that connects to the client during the file transfer doesn't belong to the process. Instead, it belongs to a process that is owned by root. So, the rule that sets the mark prevails. 

The RFC's that specify how a MTA should handle MX records are RFC974, RFC1123 section 5.3.4, RFC2821 section 5 and RFC5321 section 5. RFC974 status is now HISTORIC. According to it, MTA's are expected to query the list of MX records associated to a domain and are "encouraged" to try all (or a fixed number of) SMTP servers, in ascending order of preference. If there are multiple MX records with an equal preference value, MTA's must try to deliver the message to all SMTP servers until one succeeds. The order of attempts is a MTA's choice, that is, the RFC doesn't rule whether SMTP servers must be contacted at random or in the order given by the DNS server. In addition, the RFC doesn't rule how to handle a MX register that references multiple A records. 

RFC2821 status is PROPOSED STANDARD. This RFC obsoletes RFC974 and, in the scope of MX record handling, it slightly differs from RFC1123. While the former REQUIRES a random selection of a SMTP server among multiple MX records with an equal preference value, the latter just RECOMMENDS it. 

Question is fully answered about a three time by now, so I wanted just add some cents. Note that for quite a some time default ipfw config drops this kind packets: 

Setting to higher values is only needed on highloaded servers where new connection rate is so high/bursty that having 128 (50% more in BSD's: 128 + 64 ) not-yet-accepted connections is considered normal. Or when you need to delegate definition of "normal" to an applications itself. Some administrators use high to hide problems with their services, so from user's point of view process it'll look like a latency spike instead of connection interrupted/timeout (controlled by in Linux). manual says - acts only upper boundary for an application which is free to choose something smaller (usually set in app's config). Though some apps just use which means set backlog to the max value allowed by system. Real cause is either slow processing rate (e.g. a single threaded blocking server) or insufficient number of worker threads/processes (e.g. multi- process/threaded blocking software like /) PS. Sometimes it's preferable to fail fast and let the load-balancer to do it's job(retry) than to make user wait - for that purpose we set any value, and limit application backlog to e.g. and set to 1. PPS. Old versions of Linux kernel have nasty bug of truncating value to it's 16 lower bits (i.e. casting value to ), so raising that value to more than can even be dangerous. For more information see: $URL$ If you want to go into more details about all backlog internals in Linux, feel free to read: How TCP backlog works in Linux. 

One of pretty straightforward solutions for your problem is to use link aggregation technique. There is device with failover mode for that. There is config from my notebook which always stays on fastest available link: 

I think the best solution is to drop all IPv6 traffic via firewall. There is manual how to use ip6tables in Linux: ip6tables: IPv6 Firewall For Linux 

So actually workaround for your problem is to reduce amount of memory server has (physically or possibly via boot param but I have not checked). Also you can change kernel/userspace split via kernel config option. But really, switch to x86_64 is just easier, isn't it? =] PS. You can actually use x86 userland with x86_64 kernel. 

What you think is good notebook for sysadmin? May be you can list specific models; What hardware extensions(i.e. USB devices) you think should be added to "sysadmin must-have" list; 

Almost all of your memory is in LRU list. Memory sizes in table are in pages (which on your architecture most likely are 4kb) so they sum up to 14.8Gb, not 3.7. 

I guess that "server's control panel" software can be rewritten to be more efficient and not to degrade performance over time. NB! Do not copy/paste s from production servers - there could be some sensitive information inside that JSON e.g. logins/passwords/session/API-keys/etc.