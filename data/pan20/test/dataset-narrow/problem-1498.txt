The value of the command line can clearly be demonstrated by looking at a simple gui configuration task, which might take 5 or 10 screenshots, and still be ambiguous in comparison to 'open a shell and paste these 2 lines of text'. This doesn't encourage students to use the command line themselves, but starts to explain to them why it is valuable. You can draw parallels with using keyboard macro shortcuts in comparison to using a mouse - it's faster when it doesn't involve moving your hands as far (even if it requires learning the right set of shortcuts). Beginners won't want to start off by learning the short-cuts, but might become familiar with Ctrl-F for 'find' if they need to search for a few things. Of course, with a mobile device, the command line (or keyboard shortcuts) are not the most obvious step. However, there are plenty of things with a phone that can only be done using adb, or become easier to do (or script) once you have adb available. Shell commands, and shell scripting is just another tool. Trying to force students to use it too early is probably counterproductive - you need a scenario where they have to use it before they will be able to start to accept it. This doesn't mean you shouldn't yourself drop into using the command line when they can see you, but you're not explicitly teaching with your actions. 

You run the risk here of unduly penalising or discouraging students who have dyslexia or other issues which cause them to do badly with this type of trivial test. This sounds a little like the sort of tests that used to be used in job interviews, and are thought to be of little value now... 

My guess is that the gap in the learning comes from not recognising what variables are and the concepts we're familiar with for data storage. I can imagine that for maths/engineering students, the fluidity and connected nature of equations makes the problem worse. In circuit design for example, modules will be familiar. These are blocks that have interfaces, some inputs, some outputs, some power. The operation of the module is a continuous process, connections being made with wires. There are two connected parts that I think will be useful to show to your students about what a computer program is trying to represent (and the fact that it's an abstraction might be something to explain to them). Firstly, computers perform basic steps one at a time (or in blocks, or several at a time, but always in a limited scope). Think of buckets of water rather than a hose pipe. The second is the concept of doing the work on individual blocks of data. This data has to be stored somewhere. It could be the water in your buckets (which can be split up, coloured, mixed, etc). Computers don't do mixer taps, they have to take the items they're working on piece by piece and work on each element. If they know about integration using calculus, the difference between discrete and continuous items shouldn't be a problem. I think if you review the way you're teaching variables, also show that to process code, a computer (a general purpose machine) follows its instructions to operate in steps, it will be easier to show that the result of an operation always needs to be stored somewhere (not just for functions), so a program is different to a circuit. An electrical module is fixed at it's location in a circuit, but a software function can be called from different places. In a program, whenever a function is called, there is a place defined to put the result. This isn't 'in' the function, it's 'in' the code that calls the function. (of course, if it's not used, then the computer knows it doesn't actually need to bother with it). I'm not sure you need to have your students moving the data, but showing containers for data does help. The numbers in envelopes fits best if you use it to show how add, multiply etc. work - before you get to the functions. Playing out the operation of the machine requires a few more steps to make it complete, if you act it out, then you can avoid some of the details that they don't ask about... 

Its actually harder than just finding a modern user-interface which exposes a directory structure. The whole concept of a directory structure is just a convenience - there is nothing 'physical' which it relates to. Most of us started our interactions with computers at a point where directories were the first point of interaction, so it is hard to relate to the experience gained from modern interfaces where the 'workings' are abstracted and files are located by searching rather than through an index. I think it's now become important to teach storage structures as soon as you have a scenario which permits it. I think that a library is a good analogy - people are familiar with a large amount of structured content, and books containing different types of content. To discuss where a document (or book) might be stored, you have potentially quite a lot of layers: 

Start with a short message (in text) and round up to a multiple of 16 bytes, padding with spaces. Replace the final space with a non-space character Take the m5sum of the result, and look only at the last digit. If this is '1', you're done and have finished the block. If you're not done, go back to step 2, and modify your non-space trailing padding. After finishing a block, you can append a new message, pad again, and repeat the process of modifying the whole message to achieve the target hash. 

At some point in their lives, more so now than 40 years ago, these students will need to make decisions based on interactions with computers. When they do this, they will make better decisions if they understand what is going on inside a computer. They may also encounter situations where a problem they have could be easily solved by involving (an app, some automation, a bigger dataset, etc). Some example scenarios to discuss particularly in a 'imagine 20 years more innovation': 

Several of these scenarios I find hard to discuss with non-technical adults. Computers can be more consistent, access more data, do repetitive work without making mistakes. People struggle to understand some of the statistics and how to interpret risk though. People in a position to identify problems to be solved need to know what a computer can trivially do in order to innovate. The timetable planning example - a language teacher wanted to overlay a simple 2-week pattern (learning vocab/testing) and some other progress, with the ability to slip, insert and skip work. Didn't realise this was already 90% done 'off the shelf' (so didn't look), and didn't recognise how this off-the-shelf solution was a good fit. 

Maybe the easiest way to practice is to have an element of peer review. I find it's much easier as a reviewer to insist on good practice and make 'helpful' suggestions than to follow these rules myself. You might need to be careful to balance the level of reviewer and reviewee though. Justifying the time spent is probably harder. Some of these might work: 

They also link to this Computer Science for innovators and Makers curriculum which links the following: 

The scenario here doesn't really give much context for the evaluator's question. Most importantly, we have no information about what she did as a result of the opening question. It is perfectly possible that this opening was a hidden request for context - is the presenter actually familiar with the code or just doing the PR part of the project? By asking a 'harmless' question which has no right answer, it makes the rest of the questions much easier to pitch. There is nothing worse when doing an interview than asking an opening question which your student doesn't understand well enough even to be able to guess the answer. 

I will take a tip from one of the more experienced project managers that I work with. Some people like to plan everything in great detail, and will miss some of the things that practical experience will give them. These people need to be encouraged to take a break from planning much earlier than they feel happy with, and at a minimum start prototyping the bits they think they're happy with, or the bits they're worried about getting right. The other people, who jump straight in - give them time to start to make a mess, then help them to break what they have started with down into a plan. If they started perfectly, get them to rough out a plan of the bits they haven't thought about. Effectively, there are two decisions to make. Push/pull and which end to start from - both reacting to an individual's behaviour and comfort with the task. Assuming these 4 models are all valid to some extent, it is hard to drive the plan/implement cycle in a single way with a large group. You can however teach the process then guide people to find a way of delivering using it. 

The best encouragement is demonstrating how some simple changes can result in orders of magnitude improvements for a specific task. The best example I've seen took a synthetic benchmark, and between un-optimised 'C' and 10 lines or so of hand-crafted NEON assembler (together with a cheap re-arrangement of the base dataset), resulted in something like a 1:30,000 speedup. This video was one example I found quickly, it's aimed at showing how you can help the compiler when writing code. Once you've established the value of optimised code, then you can go on to address where optimisations make sense. Code that only runs once might be best written for reliability and readability, code like memcpy may well be hand-optimised down to the level of machine micro-architecture. Code written for portability might be optimised differently. When people try to optimise code by intuition, it is easy to make the wrong trade-offs. Most obviously when it comes to cache utilisation, but there are plenty of other micro-architectural traps which are less visible. Benchmarking is a critical part of optimisation (and this underpins the value message). There will be optimisation folklore which no longer holds with modern hardware and modern compilers - and sometimes hinders the compiler or readability. What you really need to focus on teaching (after you have set the scene for how optimal code is good), is simple, cleanly structured code. At most levels, letting the compiler do its job is the important thing. In the example of repeating a static calculation, the detail could equally be 'written like this, you seem to expect the size to be changing - is that what you meant to convey', rather than 'you do realise the compiler only needs to evaluate that once'. The opposite end of the scale is using a genuine resource constrained platform (as many of us learnt with), but these can be misleading with single level memory architectures and simple pipelines. In the MCU domain, interrupt latency is likely to be the limiting resource, rather than memory bandwidth (unless you're bit-banging a VGA output at the same time as running a 6502 emulator). 

I'll stick my head above the parapet, and offer that the people teaching these courses won't have been taught about version control as part of their degree courses. I certainly remember that the hassle of learning about how it worked (and some doubt/uncertainty) meant it wasn't something I adopted until I was forced to by work requirements. At the time it felt hard. Now, if I want someone to see some code, I give them a 'git clone' command line... There seems no real justification to avoid introducing version control in its simples form fairly early on. You can argue that it isn't needed, which may be true, so there is no need to go overboard on the detail. What is most important is to instill the understanding that version control makes life easier. It feels that GIT works more easily than RCS, although that might just be an effect of the concepts being more familiar to me now. 

There is a difference between having a clear convention for making identifier names (CamelCase, under_sep, abrev) and mandating that redundant information is provided in the code. There is also the challenge that what is good for beginners isn't necessarily what makes sense for an experienced developer, and maybe your preference changes depending on the language you're coding in. The critical aim is for intelligibility. Showing some examples is very useful, and even if Hungarian notation is not in vogue in general, it forms a good reference to practice with. By all means deduct marks for inconsistent, wrong (by context) or random naming, but be careful about enforcing a single style without good reason. You wouldn't want to turn out students programmed to antagonise the Linux kernel maintainer...