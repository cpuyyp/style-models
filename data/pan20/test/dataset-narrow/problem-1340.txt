Work iteravely. Break down your roadmap to completion into steps and start by offering smaller jobs to do. Ask for help on particular features, say you want to implement a foundation for an AI system that you can build on. It's less daunting than to say "I need someone to help me with these goals: to add a bunch of enemies, at least 10 story quests, and this many hours of gameplay". If you find someone that's interested in doing more the first time around, then consider yourself lucky, but you will more likely get responses from people that are okay with pitching in for a shorter time than going in it for the long haul. Target a problem that you are most willing to tackle first and go from there. Don't confuse this with bait-and-switching people by making them do more than they initially offered to do, unless they're interested. 

I am trying to port a XNA project to MonoGame which involves a DLL game library that I created. This library uses the IGameComponent, IUpdateable and IDrawable interfaces to load one of my library classes as a GameComponent. The compiler gives errors related to these interfaces, saying, for example: The type 'Microsoft.Xna.Framework.IUpdateable' is defined in an assembly that is not referenced. You must add a reference to assembly 'Microsoft.Xna.Framework.Game'... This would require me to add Microsoft.Xna.Framework.Game to my reference list, which defeats the point of porting to MonoGame. Is there any way these interfaces can be made compatible with MonoGame 

Maya creates objects in a proprietary file format, and the approach to convert these objects in a way that can be read in C++ is very open-ended and left for the user to decide. Since you don't give much detail, I think using the ASSIMP library is the most straightforward solution. Maya supports export to OBJ (and I think 3DS, I'm not sure though), which this library can use. 

NextIndex is the number of vertices and indices allocated to the buffers (always 1 index per vertex). Am I making too many buffers? It crashes despite the GC showing only about 12 MB of usage so I guess memory fragmentation is a problem when creating lots of buffers in a short time? Should I use a smaller amount of buffers that store more data and have several chunks share them? EDIT: I estimate roughly 0.75 to 1 GB of memory used in the vertex buffers. My graphics card has 2GB of VRAM. Though I also know sometimes not all the vertex data may be stored in VRAM at one time. 

The Game State Management sample that deals with screen transitions can be found here. (The MSDN site recently updated their App Hub url's so I'm guessing a lot of links will be broken for a while) Personally I find some of the code to be too complex for beginners, with the constant use of events to be fired when menu items are clicked, and layering of state machines, etc. However I can explain the idea behind all of this. Each scene has a transition delta time variable, which doesn't change when it's not transitioning. During transitions you increment it each frame. When the delta time reaches a threshold (like 1 or 0) the screen should update itself from "exiting" to "exited". You should pass this variable to functions responsible for drawing the screens. Maybe you don't want the actual transition behavior coded in the screen object, but it should have some set of parameters to tell the Draw method how it should transition. That way Draw can still take care of the visuals, from position to alpha and anything else you want to add. I am in the process of making "menu skins" for my menu system, adapted from the XNA sample. As you would expect, the skin determines the menu's appearance but also where it should be placed, and how it should transition in/out. This works as a struct of parameters passed on to the Draw method. Next time the main Update loop runs, the Screen Manager will check through the screens to see which ones have exited and it will remove those from the list. This way you can have two or more screens at once, so one function can tell Screen A to leave and the other one to enter. Both of them will be "passing through" and don't need to know about each other to know when to finish their transitions. 

In many action games with a third person view, joystick controls typically map the left joystick for player movement and the right joystick for camera movement (or more precisely camera's direction towards the character). With first-person games, mapping to mouse/keyboard is easy because the camera is directly influenced by the player's movement. The player has to be able to look at any direction to point where he should go. Here is where the mouse comes in to provide this movement. But the challenge I see is having separate camera and player controls with this setup. With a mouse/keyboard setup, it seems like I have to settle with a compromise, because the mouse is usually the only source for analog-like movement, whereas modern game pads have two sources, as separate joysticks. One control scheme I had in mind is using A and D to change the player's heading as he travels through the world, leaving W and S to move forward/backward and the mouse free to move the camera. This still has a disadvantage, because you lack some degree to control how fast to change heading with the keyboard, unless you momentarily punch at the keys instead of holding them. Is it possible to map the mouse and keyboard controls more intuitively for independent third person player and camera control? 

Most of those flashy 2D games are hardware-accelerated, which allows the developer to take full advantage of the graphics hardware, and apply nicer-looking effects without impacting performance that much. Geometry Wars was most likely made with 2D polygonal lines or sprites, with several shaders for effects. Shaders can be thought of as special programs that run in the GPU of the video card, that do additional stuff with pixels and vertices that would be much faster than doing it on the CPU. To get an idea of what shaders could do, here are a few examples. The explanations are very trivial and I think are pretty good for a total noob to start playing around with them. With some basic math and shader programming it's possible to get those "warp" or "glowing" effects you see in the background. Object transformations are usually done with matrix-vector operations, or sometimes using linear algebra. However, the graphics in that game are also simple to the point that a lot of those objects can be also created as sprites, and then it's a simple matter of blending sprites appropriately to create those effects. If you can reproduce the same visual effects from an artist's point of view, it's usually easier and faster to work that way. I don't know of any good mobile frameworks, not having programmed for mobile platforms before. However I know that cocos2d is a good one, usually used for iOS games and it's based on OpenGL so it's hardware accelerated. 

Tiles have the benefit of being stored in less memory, taking advantage of re-using the same graphics for all the areas in the map that need them. I will describe why it's not a good idea to use large images. Drawing large images in place of tiles is inefficient also for the workflow. You'll have to recreate an new image from scratch every time a change in the map design is needed, and plus you'll have an arbitrarily large amount of images for any maps, they will barely be reusable. Another caveat is managing collision detection- I mean, it's going to be more than a pretty backdrop in that you will want to interact with it. Handling collisions is much easier on a tile-based level since tiles can contain collision logic or vice versa, and their collision boxes are "locked in" with the tile area itself. With large static images, there will be a tendency to lose the spatial connection between the visuals and collidable areas, and you'll have to take extra care in not letting collision boxes become misaligned with the visuals. This will just lead to more unpredictable, buggy results. Even in 2D games where the level design looks very "freeform" (see Aquaria) there is usually still a copy-paste philosophy behind it. The editors may not use tiles that snap to specific areas, but you're still using reusable bits and pieces for making maps and levels that can be scaled, moved and rotated which may take some interactive properties along, collision boxes being among them. 

You've got the right idea of setting triggers in your game and game maps to fire off events (note, I don't necessarily mean the events in the C# language). Scripts are optional, but they can be a more flexible way to add these triggers to your game, and re-load new ones if a change in the storyline requests it. Whether you'd be using scripts or not, generally, it would be good to have some "event loader" that can pass a new group of events or triggers to the game maps whenever it needs it. With scripts, it will be considered a script loader and that will be responsible for populating the game world with new events at specific locations, including events that can load another script. For example, at the start of the game the first script (or event loader object) will be called automaticaly, and fill the game with event triggers. One of those events may be triggered after beating the first boss, and this event in turn will load another script that replaces some or all of the event triggers in the game. Now you have a new set of interactions or objectives you can explore. This adds a layer of flexibility for branching paths in quests and story, but with this also remember to plan out the branching paths of your storyline well, so you know all your events make sense within the story. 

One way that hasn't been mentioned here is treating the vectors as complex numbers. They don't require trigonometry and can be pretty intuitive for adding, multiplying or rounding rotations, especially since you're already have your headings represented as pairs of numbers. In case you're not familiar with them, the directions are expressed in the form of a + b(i) with a being the real component and b(i) is the imaginary. If you imagine the cartesian plane with the X being real and Y being imaginary, 1 would be east (right), i would be north. Here is the key part: The 8 cardinal directions are represented exclusively with the numbers 1, -1 or 0 for their real and imaginary components. So all you have to do is reduce your X, Y coordinates as a ratio and round both to the closest whole number to get the direction. 

The added benefit to using multiple render targets, as in deferred rendering like Josh mentioned, is that you send the scene's geometry to the vertex shader only once and apply it to different pixel shader outputs, instead of re-sending the geometry for every output you need. This saves a lot of computation time for the GPU. The trade-off for faster GPU performance is higher consumption of frame buffer memory. 

Model.Draw is an XNA function so we can rule that out as the problem and more likely it's in one of the matrix arguments you're passing. Try pointing the camera at the origin and centering the model by setting the world matrix to Matrix.Identity. Then you can start from there to see if your model is still rendering or not. If you still don't see anything, it could be several things, either face culling is in the wrong direction, AspectRatio being zero, or a bad depth setup in your viewport (less likely). 

Rounding both components of what was originally (10, -2) gives you 1 + 0(i) or 1. So the closest direction is east. The above doesn't actually require the use of a complex number structure, but thinking of them as such makes it quicker to find the 8 cardinal directions. You can do vector math the usual way if you want to get the net heading of two or more vectors. (As complex numbers, you don't add, but multiply for the result) 

I see that some XNA resources implement ICloneable (namely the Effect class) but textures don't. I have encountered a situation where I need to make a complete copy of a RenderTarget2D texture and use it as inputs for two separate rendering effects. One effect will change the contents of the RenderTarget2D so I can't pass it to the other effect, which is why I need two copies. Can you "clone" or deep copy a RenderTarget2D in an easy way? My current work around is that I wrote a copy function that sets a new render target, uses a simple effect to just re-draw the contents of the target to be copied to into a quad and return the new render target. But seems like a lot of work around simply to create a copy. 

This animation is likely a bunch of different colored sprites moving or fading in to follow the path of the trail. Look up particle systems. They let you control many sprites/objects at once easily with a set of rules to define their movement. For this example, you can start with a white circle moving in pre-defined path. Using trigonometric functions is a good way to easily make some curved paths, and you can use bezier curves or splines, although they are more complex to define mathematically. You can also just make it follow the mouse cursor. Either way you choose, once you have the moving circle, you make a list of sprites to store them in different sizes and colors depending on their order in the structure. You pass on the location to the other sprites in the list the on each frame to create a motion lag, which makes the trail. This tutorial does a great job at showing how to make particles with this kind of behavior in XNA (MonoGame follows almost the same syntax). 

I noticed a few programmers setting time-sensitive challenges for themselves, usually in the area of "write game of type X in Y amount of time" or "write X number of games giving only Y time for each". What are the tangible benefits for setting your workflow in this manner to speed-code for a while? It feels like you have to trade off efficient code to get something done quick. And I suppose adding a final layer of polish isn't a big priority in these challenges, so it's okay to use programmer. I've made some simple 2D scrolling shooters and puzzle games a few years ago and out of stupidity I deleted most of my code. So now I'm curious about using the speed-coding approach to get a couple simple things done again, and get myself more into game logic.