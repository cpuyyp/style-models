As a consequence, every problem has a trivial, constant time solution (output Maybe). We can now shift our attention to deriving a procedure that does not always produce Maybe. To return to the questions above, a solution that works for some problem instances is one that returns Maybe on problems it cannot solve. Moreover, Maybe is an approximation of Yes and No because we are not certain what the answer is. This idea is not restricted to decision problems. Consider these problems concerning programs. 

In all these situations, we can move from an exact solution to an approximate one by considering solutions that have some uncertainty. 

The modal formula $\Box p \implies p$ is true in a frame if and only if the frame is reflexive. The formula $\Box p \implies \Box \Box p$ is true in a frame if and only if the frame is transitive. 

There is much more. I am not an expert. I believe the third paper was an important position statement. The work of Xavier Leroy and Sorin Lerner would give you pointers to two different but very current approaches. 

The three notions of expressiveness are to ask (i) what languages (of finite or infinite words) each logic can define, (ii) what first-order structures these logics define, and (iii) what the complexity of defining a given language (or first-order structure) in each logic is. A more refined vocabulary for comparing expressiveness is provided by the notion of hierarchies, which are briefly mentioned at the bottom. First-Order Structures definable by temporal languages Kamp in 1968 studied an until modality that is slightly different from the notion commonly used in computer science today. I will write it as $\mathit{Until}_+$ for because a formula $p ~Until_+~ q$ is true at time instant i if $q$ is true at some $j > i$ and if $p$ holds at all $i < j' < j$. Note that the orders are strict. The temporal-dual is the modality $Since_+$. Kamp compared temporal logics to the Monadic First-Order Logic of Order (MLO, sometimes MFLO or FMLO). MLO formulae contain unary predicate symbols and a relation $<$ and are interpreted over linear orders. Kamp's theorem shows that a logic with only $Until_+$ and $Since_+$ modalities is expressively equivalent to MLO when both logics are interpreted over the naturals or over the non-negative reals. In fact, Kamp's theorem applies to a family of structures called Dedekind-complete chains (which notably does not include the non-negative rationals). Stavi's theorem shows that a temporal logic with standard since and until and a special since and until modality is expressively-equivalent to the first-order monadic logic of order over every linear order. The notion of expressiveness in these results is "definability of first-order structures". Gabbay, Pnueli, Shelah and Stavi considered a family of MLO formulae called future formulae, which intuitively only refer to future points in time. They showed that on a family of models called discrete, complete orders, which includes the naturals, future MLO formulae have the same expressive power as temporal logic with the $Until_+$ modality, a next and previously modality. So these results relate certain temporal and first-order logics on certain structures. Relating languages to first-order logic, McNaughton and Papert showed that first-order definable languages are star-free and regular, which in conjunction with Kamp's theorem shows that all the logics above only define subsets of regular languages. Adding the next and previous modalities does not change what you can define and a proof that the third logic above still defines only the star-free regular languages is due to Zuck and Pnueli, I believe. Comparative expressive power of temporal languages Kamp was also one of the first to study how the properties one can express changes with the modalities in a temporal logic. He showed that the $Until_+$ modality cannot be expressed in a logic with the Eventually, Next and more modalities. This difference in expressive power led him to study the $Until_+$ and $Since_+$ modalities. Gabbay, Pnueli, Shelah and Stavi proved what is called a separation theorem. They showed that a formula that involves $Until_+$ and $Since_+$ can be written as a Boolean combination of formulae that involve either only $Until_+$ or only $Since_+$. (The story goes that when Kamp heard of a form of this separation theorem from Gabbay, he went out and bought Gabbay a cake.) This paper and separation result is sometimes cited as the reason for not including past modalities in temporal logics. It follows from their results that for a formula with $Until_+$ and $Since_+$, there exists a formula involving only $Until_+$ such that at time instant $0$, either both are true or both or false. It follows from this result that a temporal logic with the standard $Next$, $Until$, $Since$ and $Prev$ modalities, when interpreted over time indexed by the natural numbers (the standard semantics in computer science) has the same expressive power as LTL with only $Next$ and $Until$. Unfortunately the only algorithm known to compute the separation above non-elementary complexity. Moreover, not every temporal logic has the separation property. In particular, if you only have an eventually and previously modality, separation does not hold. Lichtenstein, Pnueli and Zuck did show that every formula in LTL with past modalities is equivalent to a formula with the form below. 

Efficient Interpolant Generation in Satisfiability Modulo Theory, Alessandro Cimatti, Alberto Griggio, Roberto Sebastiani, ACM TOCL, 2010. Covers interpolation for linear rational arithmetic, rational and integer difference logic, and Unit Two Variables Per Inequality logic (UTVPI). Efficient Interpolant Generation in Satisfiability Modulo Linear Integer Arithmetic, Alberto Griggio, Thi Thieu Hoa Le, and Roberto Sebastiani. 2010. A Combination Method for Generating Interpolants, Greta Yorsh and Madanlal Musuvathi. 2005. Shows how to generate interpolants in the presence of Nelson-Oppen theory combination. Ground interpolation for the theory of equality, Alexander Fuchs, Amit Goel, Jim Grundy, Sava Krstic, Cesare Tinelli. 2011. Complete Instantiation-Based Interpolation, Nishant Totla and Thomas Wies. 2012. Interpolants as Classifiers, Rahul Sharma, Aditya V. Nori, and Alex Aiken, 2012. 

History and basic features of the critical-pair/completion procedure, Bruno Buchberger, 1987 Canonical Reduction Systems in Symbolic Mathematics, Franz Winkler. Springer Link 

A lattice is thus a mathematical structure which can be approached from the algebraic or the approximation perspective. The shortcoming here is that the elements of a lattice themselves do not possess a type structure that is factored into the approximation relationship. Meaning, we cannot compare elements based on the notion of having more or less structure. In the context of your problem, you can think of categories as a natural generalisation of preorders that capture both the notion of approximation (in the morphisms) and type structure in an algebraic setting. The setting of category theory allows us to dispense with various unnecessary distinctions and focus on the structure of entities you care about and approximation of that structure. Universal properties and adjunctions give you a very powerful vocabulary and tools to understand the landscape of structures you are interested in and enables a rigorous mathematical treatment of even intuitive notions like different levels of abstraction. Regarding my comment about abstract deltoids, it appears that what you want is a category. The abstract deltoid is a specific category analogous to the category of sets. There are other categories you are considering. I initially thought you were defining a deltoid that in the sense of category theory would be a terminal (or final) object. You are studying the kind of questions that category theory provides a very satisfying answers for. I hope you will be able to come to that conclusion yourself. References 

There are algorithms for checking if a given $\omega$-regular language is star-free. Unfortunately these are usually couched inside the proofs of theorems. 

For the bounded quantifier alternation case, I do not know of better results than those of Reddy and Loveland but maybe an expert can point you in the right direction. 

So the types of relations you are asking for can be viewed as being defined by a finite set of modal formulae. These formulae can in turn be viewed as the axioms of a logic, so your question is directly related to the study of modal logics. You can look up material on the model theory of modal logic for more details. 

Topology is such a mature discipline with varied subfields including geometric, algebraic, metric, point-set and (the self deprecating) pointless topology. Computer science is also fairly broad and has many mathematical sub-areas, so I would expect much applications of topological ideas in CS. Marshall Stone said "always topologize," and computer scientists with the requisite background often have. Enough blah. A few examples. These examples are not just of hard CS problems solved by topology. Sometimes a topological notion transfers very well into a CS setting or gives the basis for a sub area of CS. 

A lot of those papers are not relevant for this discussion, but there are quite a few which contain relevant discussions, so I prefer to let you choose. 

Languages of Infinite Words The connection to LTL and the necessicity of modelling infinite behaviour led to an intense study of $\omega$-languages, which are languages in which words are defined as functions from natural numbers to a finite alphabet. The community has studied properties of regular languages over infinite words and developed several results analogous to the finite-word case. There are several surprises that show up, so we cannot just lift the finite-word results to the infinite-word case. Some of my favourite results are the characterisiation of $\omega$-regular languages in terms of regular languages and analogues of the Myhill-Nerode theorems. Staiger showed that you do not just get infinite word automata from an appropriately defined equivalence relation. This holds only for a specific sub-family of $\omega$-regular languages. Alpern and Schneider formalised the intuitive notions of safety and liveness of computer programs in terms of prefix-closed and limit-closed sets of $\omega$-words. Moreover, using elementary topology, they showed that every linear-time property can be expressed as the intersection of a safety and a liveness property. This result has significant practical consequences because it means that rather than build complex property checkers, it suffices to build a safety and a liveness checker. A further reduction shows that it is enough to build an invariance checker and a termination checker. The safety-liveness characterisation was extended to trees by Manolios and Trefler and more recently to sets of traces, in the hyperproperties framework, by Clarkson and Schneider. 

I am trying to trace back the origins of transition system semantics for imperative programs. I am assuming a transition system is a tuple $(\mathit{States}, \mathit{Trans})$ consisting of a set of states and a (binary) transition relation over states. By transition system semantics, I mean that there should be a mapping from programs to transition systems. The presentation need not be exactly as I describe above and the mapping from programs to transition systems need not be completely explicit. For example, I would consider Plotkin's Structural Operational Semantics as providing transition system semantics to a formal language. Other early references I know of are due to Cousot & Cousot, and even earlier, due to Robert Keller in Formal Verification of Parallel Programs. There is earlier work by Richard Karp and Raymond Miller on reasoning about parallel programs, but their model is closer to Petri Nets and I am unsure about whether to read their paper as giving transition system semantics to programs. Does anyone know of references from the early 80s or earlier where transition system semantics are provided for programs? Please add a few lines about the semantics and whether it is used today, and in what form.