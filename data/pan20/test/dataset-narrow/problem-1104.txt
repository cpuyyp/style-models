Update (12 May 2014): I realized that the way I originally explained the conjecture was not strictly speaking correct, since the recurrence for $NF$ actually counts lambda terms which are ordered and not merely linear. (For example, both $\lambda x.\lambda y.x\ y$ and $\lambda x.\lambda y.y\ x$ are linear lambda terms in normal form, but only $\lambda x.\lambda y.x\ y$ is ordered. Up to normalization, the two ordered linear lambda terms of length 4 are $\lambda x.\lambda y.x\ y$ and $\lambda x.x\ (\lambda y.y)$.) I am still looking for a proof of this conjecture. 

You might also have a look at Andrej Bauer's talk on The Role of the Interval Domain in Modern Exact Real Arithmetic, which surveys some of the different approaches to specifying computation over the real numbers both in theory and practice. 

Update: fixed the accidentally dualized terminology in the original description (thanks Yann Hamdaoui!). 

Again I'm not exactly sure what you are looking for because there are potentially many "similar" systems, but for recent work that I think is very related you can read Part II ("Mixing Derivability and Admissibility") of Dan Licata's thesis, as well as Constructive provability logic by Rob Simmons and Bernardo Toninho. 

The following category theory inspired analysis (adapted from Plotkin's A Note on Inductive Generalization) explains a sense in which unification and anti-unification are dual concepts. As notation, let's write $$t \underset{\sigma}{\Longrightarrow} u$$ for two terms $t$ and $u$ and a substitution $\sigma$ whenever $t\sigma = u$. The existence of such a subsitution $\sigma$ implies that $t$ is a generalization of $u$, and that $u$ is a specialization of $t$. Suppose given two terms $t_1,t_2$. A unifier of $t_1$ and $t_2$ is a term $u$ together with a pair of substitutions $\sigma_1$ and $\sigma_2$ such that $$ t_1 \underset{\sigma_1}{\Longrightarrow} u \underset{\sigma_2}{\Longleftarrow} t_2 $$ It is a most general unifier if it is a generalization of any other unifier, that is, if for any other unifier $$ t_1 \underset{\sigma_1'}{\Longrightarrow} u' \underset{\sigma_2'}{\Longleftarrow} t_2 $$ there is some $\sigma'$ such that $$ u \underset{\sigma'}{\Longrightarrow} u' $$ In other words, a most general unifier is precisely a coproduct in the category $\mathcal{C}$ whose objects are terms and where there is a morphism $t \to u$ just in case $t \underset{\sigma}{\Longrightarrow} u$ for some $\sigma$. To define anti-unification we just reverse all the arrows! Which is to say that... An anti-unifier of $t_1$ and $t_2$ is a term $u$ together with a pair of substitutions $\sigma_1$ and $\sigma_2$ such that $$ t_1 \underset{\sigma_1}{\Longleftarrow} u \underset{\sigma_2}{\Longrightarrow} t_2 $$ It is a least general anti-unifier if it is a specialization of any other anti-unifier, that is, if for any other anti-unifier $$ t_1 \underset{\sigma_1'}{\Longleftarrow} u' \underset{\sigma_2'}{\Longrightarrow} t_2 $$ there is some $\sigma'$ such that $$ u' \underset{\sigma'}{\Longrightarrow} u $$ This means that a least general anti-unifier is precisely a product in the category $\mathcal{C}$ defined above. 

Consider the following recurrence in two parameters $n$ and $k$: \begin{aligned} NF(0,k) &= 0 \\ NF(n,k) &= Neu(n,k) + NF(n-1,k+1) \\ Neu(n,k) &= [n=1 \wedge k=1] + \sum_{l=1}^{n-1}\sum_{i=0}^k Neu(l,i) \cdot NF(n-l,k-i) \end{aligned} The expression $NF(n,k)$ counts the number of (untyped) ordered lambda terms in normal form of length $n$ with $k$ free variables. Recall that lambda terms are either variables, lambda abstractions or applications \begin{aligned} t &::= x \mid \lambda x.t \mid t\ u \end{aligned} that a term is ordered if every free or bound variable occurs exactly once and in the order it was introduced, and that a term is normal if it contains no subterms of the form $(\lambda x.t)\ u$. I take the length of a lambda term to be defined by \begin{aligned} |x| &= 1 \\ |\lambda x.t| &= 1 + |t| \\ |t\ u| &= |t| + |u| \end{aligned} The recurrence for $NF(n,k)$ is derived from a standard inductive characterization of normal lambda terms (in a mutual induction with "neutral" terms -- for background see these notes, or slide 9 of this talk). $NF(n,0)$ thus counts the number of closed normal ordered lambda terms of length $n$. I computed $NF(n,0)$ for $n=0..14$, and derived this sequence: $$ 0,0,1,0,2,0,9,0,54,0,378,0,2916,0,24057 $$ Now, dropping all of the 0s and plugging the result into the OEIS, I landed on A000168, whose first few terms are $$ 1, 2, 9, 54, 378, 2916, 24057, 208494 $$ and which user Don Knuth says corresponds to the $$\text{Number of rooted planar maps with }n\text{ edges.}$$ A nice explanation (with illustrative pictures) of planar maps is given in these slides (and also this paper); in particular, a planar map is defined as a proper embedding of a connected graph in the plane (considered up to homeomorphisms of the plane), and it is rooted if one root edge is marked on the infinite face and oriented in counterclockwise direction. Conjecture: for all $n$, we have \begin{aligned} NF(2n,0) &= \#\text{ of rooted planar maps with }n\text{ edges} \\ NF(2n+1,0) &= 0 \end{aligned} Questions: Is the conjecture true? Can you prove it by exhibiting a simple bijection between ordered lambda terms and rooted planar maps? 

The closest I've seen to an answer to this question is the first picture in the Gallery of Doctor Melliès, 

You could have a look at McDowell and Miller's Cut-Elimination for a Logic with Definitions and Induction, which shows how to adopt Tait's method to a first-order intuitionistic sequent calculus with an inductively-defined natural numbers predicate. 

Design of the Programming Language Forsythe by John C. Reynolds Intersection Types and Computational Effects by Rowan Davies and Frank Pfenning Practical Refinement-Type Checking by Rowan Davies (dissertation) Tridirectional Typechecking by Joshua Dunfield and Frank Pfenning 

What you are asking about in the first question is sometimes called a "verifying compiler", and a few years ago Tony Hoare offered it as a grand challenge for computing research. To some extent this already exists and is in active use in tools such as the Coq theorem prover, which organize the problem by way of type theory and the propositions-as-types principle ("Curry-Howard"). EDIT: just wanted to add emphasis on "to some extent". This is far from a solved problem, but the success of Coq gives hope that it is not a pipe dream. 

Statman defines an essentially isomorphic collection of combinators which he calls "HOT", for "hereditarily of order two". The tech report actually shows that the word problem (i.e., $\beta$-equality) for HOT is still undecidable, despite the fact that it is not combinatorially complete. Statman later wrote a short self-contained paper with the proof that HOT is not combinatorially complete in: 

for the result that deciding formulas of HOQBF requires nonelementary time. I checked that paper, and unless I'm overlooking something it doesn't contain a direct proof of this result. I'm not 100% sure it contains a statement of it either...what looks most relevant is the theorem on page 4, which cites a list of results that various decision problems are nonelementary, including "7. The theory of pure finite types [M. Fischer and Meyer, FM75]". Naturally, the bibliography includes the line 

Re: "why encodings for binding-introducing constructs are considered third-order", the conventions are a bit arbitrary, and I've usually heard these encodings described as "second-order". For example, although in these notes by Gilles Dowek, the order $o(T)$ of a simple type $T$ (Definition 2.3) is defined as \begin{align} o(p) &= 1 \tag{$p$ atomic} \\ o(S \to T) &= \max(1+o(S),o(T)) \end{align} on the other hand in these notes by Herman Geuvers, the order $h(T)$ of a simple type $T$ (Definition 22/Exercise 7) is defined as \begin{align} h(p) &= 0 \tag{$p$ atomic} \\ h(S \to T) &= \max(1+h(S),h(T)) \end{align} I'm not sure why Pfenning & Elliott chose the 1-indexed numbering scheme, but I suppose it might be the influence of the literature on higher-order matching/unification. 

In particular, the author says that the problem of recognizing that a knot diagram represents the unknot is in $\mathbf{NP} \cap \mathbf{coNP}$, by combining a result of Hass-Lagarias-Pippenger (that unknottedness is in NP) with independent results of Agol and Kuperberg (that knottedness is in NP, the latter proving this under assumption of the generalized Riemann hypothesis). The Agol result seems to be unpublished, but the other references are: 

Dave Clarke's answer basically says it all: this is the standard convention in classical and constructive mathematics. Nonetheless, your objection is the source of a century-old subdiscipline of philosophical logic called "relevance logic", which can be seen as rejecting the axiom p → (q → p) -- or in terms of natural deduction, rejecting precisely this ability to use a hypothesis zero times, or equivalently in terms of sequent calculus, rejecting the structural rule of weakening. Reconsidering other structural rules/axioms leads more generally to substructural logics, which have found applications in linguistics and theoretical computer science. (One important example, linear logic, is mentioned in the appendix to Proofs and Types.) 

A bit of "folklore" in lambda calculus is the idea of characterizing the class of $\beta$-normal terms inductively as a syntactic category ($R$) defined in mutual induction with an auxiliary syntactic category of "neutral" terms ($B$): $R$ ::= $\lambda x.R \mid B$ $B$ ::= $x \mid B(R)$ This division shows up in many places, such as in bidirectional type checking, normalization-by-evaluation, and in proofs by logical relations. I was recently surprised to see this grammar clearly displayed in an old essay by Don Knuth, "Examples of Formal Semantics" (albeit followed by a word of warning!): 

and I can't find much evidence that such a paper ever surfaced. I do believe the claim that deciding HOQBF requires nonelementary time, and moreover Mairson's paper also gives a separate encoding of Turing machines in simply typed lambda calculus, which computes the result of running the machine for any tower of exponential steps — so I suppose it might be possible to complete the circle and try to reduce the problem of deciding $\beta\eta$-equality of simply typed lambda terms back to HOQBF. Still, it would be nice to know if there is a classical reference for this result. Question: Is there a reference for the result that deciding HOQBF requires nonelementary time? (Side question: Is there a standard name for HOQBF?) 

What is known about the class of languages recognized by finite automata having the same initial and accepting state? This is a proper subset of the regular languages (since every such language contains the empty string), but how weak is it? Is there a simple algebraic characterization? Ditto for languages recognized by non-deterministic automata having the same set of initial and accepting states. 

These kind of logics are considered in linguistics: you can have a look at Michael Moortgat's article, Categorial Type Logic. 

you should have a look at $URL$ As the nLab article says, in its common usage there is no precise definition of forgetful functor, though there are some typical examples (such as a functor $U : Alg \to Set$ forgetting some kind of algebraic structure, which will typically have a left adjoint $F : Set \to Alg$ corresponding to the construction of free algebras). And in another (useful) sense, every functor may be regarded as a forgetful functor, and classified according to how much it forgets. There is no requirement that a functor be unfaithful for it to be called "forgetful", and many common examples of forgetful functors are faithful (such as the forgetful functor $Grp \to Set$ from groups to their underlying sets), while others are not (such as in general the functor $cod : C^\to \to C$ from the arrow category of $C$, forgetting everything about an arrow except its codomain). 

Schaeffer describes how to efficiently generate (rooted) Eulerian planar maps uniformly at random using a bijection with a certain family of trees. In turn, Eulerian maps have a simple bijection with bi(partite-)cubic maps: see the second bullet point on slide 5 of this talk by Éric Fusy. (Generating a uniformly random rooted planar bicubic map and then throwing away the rooting + embedding would give you a non-uniform distribution on planar bicubic graphs, but depending on what you have in mind that might be okay?) 

Would you be satisfied with generating planar cubic bipartite maps (i.e., such graphs equipped with a planar embedding specified by a cyclic ordering on half-edges)? That problem was addressed in: 

One reference: Automating Proofs in Category Theory by Dexter Kozen, Christoph Kreitz, and Eva Richter. 

illustrating the map $$\neg\neg A \otimes \neg\neg B \longrightarrow \neg\neg(A \otimes B)$$ which exists in any dialogue category (i.e., a monoidal category with closures into a fixed object). Note that the left-to-right CPS transform of general binary functions reduces to applying this map and then composing with the functorial action of the double-negation monad. The illustration basically follows the standard conventions of string diagrams (modulo the polarizations of the wires, which are meant to indicate the flow of control). In particular, the map is constructed in three steps: twice applying the strength ($\kappa\wedge$) of the monad induced from the negation self-adjunction, and then applying the counit of the adjunction ($\epsilon$). At this level of abstraction, the derivation is generic for any adjunction giving rise to a strong monad, and you could then ask for a more abstract characterization of such adjunctions, which Melliès has also written about. 

I am not very familiar with the area, but there is some recent work from the programming languages community that might interest you, based on the idea of restricting to a language of type isomorphisms. In particular, you could have a look at 

Update (June 17): So I finally went ahead and looked at Statman's original paper, and it seems that Mairson got his citation from there! Statman begins by defining these formulas, which he calls "$\Omega$-sentences", then states the result that deciding whether they are true is non-elementary. This is listed as "Proposition 1 (Fischer and Meyer, Statman)", stated without proof, but with a citation to the Meyer survey paper (conference version) and the specific item "7" of the theorem I had in mind (which cites the [FM75] paper I have been unable to locate). Since Meyer is actually listed as the handling editor for Statman's paper, I'm beginning to suspect that there may not exist a more canonical reference for this... 

Mairson showed that the problem of computing the $\beta$-normal form of a linear lambda term (or equivalently, computing its principal type) is complete for polynomial time. 

I also found another related paper by Agol, Hass, and Bill Thurston, where they show that the more general problem of determining whether a knot [in an arbitrary closed 3-manifold] has genus at most $g$ is NP-complete: 

In "Multi-Prover Interactive Proofs: How to Remove Intractability Assumptions" by Ben-Or, Goldwasser, Kilian, and Wigderson, the authors introduce a bit commitment protocol as a subroutine to their Theorem 1 that every language in NP has a perfect zero-knowledge protocol in the two-prover model. The protocol is presented as a bit commitment scheme, which generalizes to a commitment scheme for arbitrary data by the well-known fact that all we are is 0s and 1s. My question is about the existence of more "direct" generalizations. Specifically, it seems to me that the protocol is based on some simple facts about the finite fields ${\bf Z}_2$ and ${\bf Z}_3$, and I was wondering whether anyone has worked out how to abstract away these facts and generalize the commitment scheme to values over larger finite fields?