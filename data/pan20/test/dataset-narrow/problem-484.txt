There's also a question mark I have: â€“ that works in Python 3, but not Python 2, because . Since your code seemed to work for you, I assume you are on Python 3. I'm not sure if Python 3 people think making it portable with a dot/cast is a good idea or not (i.e. ). There's always the explicit if you can't decide. 

Python 3 introduced a new cleaner format for the common case when you want to step up from the current class and pass (the first argument): 

Again, you are creating lists which takes time. This whole thing you iterate over could be a constant nested tuple that's only allocated once at the top (or even outside the function). 

By choosing block size close to , you only need to keep about \$\sqrt x\$ items in memory at a time. 

Depending on your application and the number of users it is possible that both, the latter or neither is insecure. 

You should define the lower level method instead. will use that to define and that way you are sure to get efficient testing. Speaking of which: 

On Python 3 you can encode the letters into bytes and avoid inside the loop, for similar performance. You might still make it about 1.5x as fast if you replaced the -> algorithm with something faster ( and depth first search?), but that's about it. 

ansi function usage. such as CreateProcessA this is very bad. windows is unicode (utf-8) system. almost all api implemented as unicode. the ansi (A) api - is shell over unicode (W) api. the A shell convert input ansi strings to unicode, call W api and finally convert out unicode strings to ansi. this is very not efficient. more bad that use ansi strings simply wrong by design. ansi code page is not invariant. it different on different systems. if you hardcode some ansi string in code, which use characters > 0x80 - you got different unicode strings after convert, on different systems. finally not any unicode string can be converted to the current ansi code page. use ansi code page for cmd is wrong. cmd use for pipe input/output not ansi but oem code page. this is different code pages. when cmd read multi-byte string from stdin file - he convert it to unicode via with . and when he output something to stdout file - he translate unicode string to multi-byte via with . so until he output characters in range you not view different. but if will be say "not english" file name in output, or you pass some command with "not english" file name - will be error - because you and cmd use different code pages for translation. you pass him ansi but he wait oem. he pass to you oem strings, but you wait ansi. also note about inherited handles - begin from vista better use also with for restrict list of handles to be inherited by the child process - not all inheritable handles, but only one pipe handle. yes one but not two as you use. 

At this point you can probably guess that I'll recommend doing away with the list. A generator should work. If on Python 2, is probably better than as well. (Note, I didn't mention . That could be changed into invocations if you are on Python 2, but you seem to be on Python 3.) 

If "large input" is only up to a couple of GB, there's not much you can do. As long as all the data comfortably fits in memory, the built-in sort is about as good as you can get. If, OTOH, your dataset is large enough to cause swapping and/or not load at all, you could: 

I was able to shave some milliseconds off by moving the call inside the calls, which let me get rid of the explicit loop: 

My recommendation (echoing well known advice) is to use the 32-byte random string directly as an ID (converted to base64 if needed). That gives such a small chance of collisions that you can do away with the loop as well. (It's likelier e.g. that the CPU fails to loop due to cosmic rays than that you see a collision.) 

Two ways to rewrite it: When you know which version of the method you want to call you can name it directly, but in that case need to pass self as an argument: 

interface of course also must be absolute another. here faster need export class with virtual functions. class implement cmd exec and write commands to it. virtual callbacks with read data from cmd. you inherit own class from this base interface class, implement your own on read data handler and cmd exit (disconect). some basic implementation of class: 

here - in/out parameter, but in only - if you reallocate user buffer - you must return new buffer size to user. may be next signature: 

in this case and out only parameters. and you need say to caller - which api need use for free returned buffer. 

then reallocate caller supplied buffer - this is very bad idea. for reallocate you need exactly know how caller allocate buffer. you must add to interface contract - how caller must allocate initial buffer and free final. which concrete routine use. say for example caller must allocate initial buffer with and free with . but nobody do this. usual used 2 ways: 

again bad and wrong. for what you create 2 pipe pairs ?? when 1 pipe pair only need. one pipe handle in you process and one connected pipe end in cmd. pipe must be duplex. what you write to this pipe end in self process - will be read in cmd. what cmd write to self handle - you read via handle in self process. so not need additional pipe pair. next - always need use asynchronous pipes and io here. synchronous is not efficient and can deadlock. 

The actual hashing is done in and OpenSSL. Those pretty much cannot be reduced, so at best it could be made ~3 times as fast. 

Read the input in blocks, which you sort and save into files. Merge the files while iterating by always choosing the extremal item. 

First, the obligatory pointer to PEP 8. In particular, your class names and some docstrings do not follow it. Variable names and line lengths arguably as well. Next, a couple of specific cases where you could make the code clearer or more efficient: 

Is it an improvement? On the original: I think so. Nested logic is generally more difficult to follow. On the --? Not really, but that's the price to pay for caching the intermediary values. 

Nothing else really. The s at the start of all your strings are a bit ugly, and some people prefer using empty print statements to indicate extra empty lines. 

In python 2 you can remove the invocation. That alone saves a few seconds. A set is faster for testing, so that's also an easy fix. Take advantage of 's and by noticing the length stays constant and you are at 2x the speed: 

another way - use for buffer. windows let reserve memory space. we can reserve tens of megabytes how minimum. this operation not allocate any memory but simply mark memory region as reserved. then we can already commit memory to region begin. when, after read, will be not enough committed memory - we commit more and so on. advantage - we from begin will be have contiguous memory - we never will be need copy/move/reallocate memory with this way. this solution is better when we assume big enough final data. example: 

then look for (full nightmare) ; you all time read to to buffer begin () and never change . so what sense try reallocate buffer if you any way try read only bytes. then you all time read to buffer begin - so new read overwrite previous data. you use wrong and senseless , , instead of . for what you use before ? when you try reallocate buffer after every read ? even if still exist free space in current buffer ? on which size you try realloc buffer ? on 1 byte ?? and every time anyway try read constant to begin ?? for dynamic buffer buffer usually used 2 strategy: allocate memory chunk (usually 0x1000..0x10000 size). read to this chunk until exist free space in it (of course not all time to the begin of chunk but to the begin of free space inside chunk). when no more free space in current chunk - allocate new chunk (not reallocate existing !!) and so on. but not copy anything. when read will be completed - once allocate new buffer and once copy content of chunks to this buffer. for example. 

By default pickle uses an ASCII format, so you shouldn't really open the file in binary mode, although nothing should break if no one touches the file. You could leave out the s from both calls or use binary pickling by passing to . 

Again, I do not think relying on this is a good idea, but it does not seem insecure either. Personally, I would rather make the number of iterations a smoother function of time, i.e. round after the multiply. You still get different iteration counts for different passwords, but you also avoid the abrupt stepping up every two years. Also, you lack any code to upgrade the iteration count of password hashes as time goes by. That should probably happen somewhere in the class, e.g. if the iteration count is less than some fraction of the current. 

You are saving some data that you never use. , never used after this. The whole parameter is unused if you remove the assignment. already is. If you remove from here, you can also remove from . 

Here you could avoid the list creation by using a generator (by changing the to ) or you could use . Probably no difference performance-wise, but the latter is less code. 

but main question - are you need Contiguous Memory buffer at all ? for what you need cmd output ? for send it to remote system, display it in interface ? for this not need. after you read some data from cmd in fixed size buffer - just display this chunk in interface or send to remote system. and begin read new data chunk. of course you need absolute another interface for this. for parsing cmd output ? for this yes - need Contiguous Memory buffer.. but we never need parse cmd output. for what ?! if say we want list files/folders - we need do this yourself but not run dir command 

you not need handle this at all. return number of bytes read. and you need use it. no any difference what bytes you read. 

if buffer not big enough - error is returned - (in case no valid data in buffer at all) or - in case exist some valid data in buffer, but need large buffer anyway. anyway you need here additional out parameter allocate buffer yourself 

SetCommTimeouts again - senseless code. this api simply send control code to device on which file open. usually only serial controller driver handle this ioctl. the npfs.sys, which implement pipes - not understand and not support this ioctl. driver return to you ( mapped to win32 error) but you not check for errors here.