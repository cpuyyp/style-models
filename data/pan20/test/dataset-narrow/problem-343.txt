According to a post in the MSDN forums, SQL Server 2005 (and probably earlier) contained a flaw that results in the error. This was reported by "A Fellows" in his problem resolution back in 2010. $URL$ In part he says: "Well microsoft looked into it and with SQL2008 it works properly, with SQL2005 it doesn't ... (but) ... SQL2008 full text has been rewritten and works as it should." If you are still on SQL Server 2005 and still stuck with the problem, then he also offers a workaround of sorts for SQL Server 2005. 

From at least SQL Server 2008 R2 SQL Server comes with an understanding of HTML. $URL$ says: " SQL Server installs its own XML and HTML filters. In addition, any filters for Microsoft proprietary formats (.doc, .xdoc, .ppt and so on) that are already installed on the operating system are also loaded by SQL Server." You mention umlauts, but not what you want to do with them. Umlauts and other characters that may seem unusual to English readers, can be managed by choosing the proper collation for the Index. Also the chosen Word Breaker (Neutral, English, French, etc) will affect your results. 

Resetting the collation of the SQL Server, as you did, should have changed the system databases ,, , and . See the instructions at: Rebuild System Databases However, your error indicates that you are still using the collation. If you expected that changing the system collation would change the user database collations, then that is likely your problem. The system collation change does not automatically cascade into user databases. (Which is reasonable for an environment handling many collations.) Set or Change the Database Collation offers you a detail that may have been overlooked. 

However, if the designer glitched you would then use the snapshot to revert the database back to the point in time of the CREATE...SNAPSHOT. 

Use index-based access method that produces ordered output Use on 1st non-constant table Put join result into a temporary table and use on it 

The Mail Server has failed. And likely this will be harder to troubleshoot if Exchange is your mail server. Somebody has changed the configuration. For example, changing the SMTP Authentication setting. There is a network/firewall/etc. problem that is interfering. 

Since linked servers are used to communicate with another server, in this case a newer version, it will all probably work for you. However, you should check that you are not depending on an object (of any type) that has been modified and is no longer compatible. (E.g. in the database becomes .) 

A transaction log contains transaction details for many parallel both transactions that are (a) completed or (b) still processing. A transaction log backup is intended to harden the log file with all data needed to restore the database to the point in time that includes the last completed transaction. This also includes all the transactions still in process, even though they have no known state until they either commit or rollback. Therefore, the FirstLSN of a log backup needs to include the oldest incomplete transaction so as to be able to cover all cases of committed or rolled back transactions. Note: That also explains why a long running open transaction may make the database log file grow excessively. The log file must continue to maintain all of the LSNs that contain transactions back to the oldest still open transaction. 

There is a tool to help you test your queries: $URL$ You can use the to test your full text results. For example, three similar searches using this function. 

The Distributor is the server that contains the distribution database. Configure Distribution at $URL$ says: 

Well, that is interesting. I created your 3 databases using different collations for each database. I tried starting from different databases to see the results. Naturally I do not know which collations you used on each database, but apparently the SQL Server is (in fact) aware of this. 

I do not believe that is a supported feature of SQL Server full text searching. That would require a wildcard resolution to words and then a thesaurus lookup of each matching word to gather the thesaurus terms. This basically maps to a pretty complex query: some one of a group of prefixed words is very near to some one of another group of prefixed words which all then go through a thesaurus lookup to provide even more words. Based on previous experience, that is just not supported. (I see online that you have asked this elsewhere in the last few months, but without any answers, so I hope that this helps.) I believe that you can create something useful for your query, but it probably requires externalizing the thesaurus entries by doing something like the following: 

The answer is It Depends on exactly how much load your are putting on SQL Server, IIS, and so forth. (SSIS? SSRS?) All of these things add up. Jonathan Keheyias has a general formula that works pretty good for me: "Reserve 1 GB of RAM for the OS, 1 GB for each 4 GB of RAM installed from 4–16 GB, and then 1 GB for every 8 GB RAM installed above 16 GB RAM." $URL$ So this formula would say to limit SQL Server to about 5 GB and let the other code on the server also have some memory to use. (Or add more memory and recalculate.) You will need to experiment with the memory settings until you find your balance. Note: If you get your memory use balanced correctly, most of the memory will still be in use, but better shared across your applications. 

A default instance running under Local System should run under NT Service\MSSQLServer, then NT Authority\System has role to the “master” database. A named instance running under Local System should run under NT Service\MSSQLServer or NT Service\MSSQL$ServerXInstanceX, then ONLY NT Authority\System has role to the “master” database. If running under Domain or Local user account the instance should run under Mydomain\MyUser, then Mydomain\MyUser has “db_datareader” role to the “master” database 

The poster also noted that that he was using asynchronous replication and noted that it was extra work to tear down and recreate the affected referential integrity. Nonetheless, that apparently got his replication running again. 

I am sorry to say that this does not look like a good implementation of dbo.Eval. Since this script uses xp_cmdshell and osql, it means that for every call the xp_cmdshell command shells out to the operating system, executes the OSQL command line utility (which has been replaced by the newer SQLCMD command line utility) and inserts the answer into the dbo.Eval table where you then select it out for your use. That is a lot of overhead for a simple calculation. Likewise, there is nothing in the stored procedure to prevent multiple uses of the EVAL function from running simultaneously. Which would mean that you could easily get the wrong answer from a basic select due to the concurrency issue. You might look into using dynamic SQL as Uday Kothari suggested using sp_executesql in his response to that post. That certainly has less overhead. Note: Mikael Eriksson also mentioned the concurrency issue. Other problems exist as well. 

This is actually quite a viable design, since in some parts of the world they may not define locations as you describe. (There are a lot of unique decisions made around the planet.) Of course you can generate an artificial name or description for your tracking purpose should that be necessary. For example: There is no named locality, you could create a Locality like: "Island NW of Salty Creek" If you intend for each Locality to belong to a single Country then you might benefit from a small change to add a CountryLocality table: Locality