This is kind of a nonsensical question based on a poor understanding of how Facebook apps work. Facebook doesn't really have anything to do with what technology exactly you are using; they simply embed your app as an iframe on their site. You build your app using whatever technology you want on your own server, and then simply tell Facebook what URL to point to. So basically anything that can be done in a web browser can by done as a Facebook app. Now there are certain technologies that get used more often for Facebook apps, but those trends are due to reasons that have little to do with Facebook, like the fact that most browsers have the Flash plugin. Also, while you can build your app with pretty much any web technology, you will need to work with PHP or JavaScript (does Facebook provide an API for any other languages?) if you need to interface with their API (eg. to retrieve the player's friends list). That doesn't mean you actually have to build the entire app using PHP or JavaScript, but that you need to have at least a small script acting as the middle-man between your app and Facebook's API. (I'm not criticizing you btw; until recently I didn't understand how Facebook apps work either, and thought they were hosted on Facebook's servers or something.) 

There are multiple ways to handle this issue, it depends on your game and what will work best. For example, on our game Tyrant Unleashed we simply made wide maps with unimportant detailing on the sides, so that it's okay to cut off the sides on narrower devices. However other games might be better with an approach where you actually shift buttons around or something to fit the screen better. (also part of our approach is also keeping a consistent height on all devices, only varying the width. This certainly makes life easier for us, but again this may or may not be any good for your specific game. It doesn't matter in our art style if the images are scaled a bit on different screens, whereas this might matter for something like pixel art. Basically, this is the "let Unity handle it" approach) 

I happen to have a list of such links on my website: $URL$ The most helpful resource for someone in your position (ie. interested in but has no idea what video game designers do) is the first one on the list: $URL$ 

I was confused by your use of the term "interface", since that is a keyword that C# responds to. However, when you described a "callback interface" I realized you're talking about something different: a way for the Java code to call functions in Unity (rather than only the other way around). This is done using the command UnityPlayer.UnitySendMessage (imported into Java by including Unity's classes.jar file). This command will invoke methods on a named object. So for example, would call MethodName() on the object GameObjectName, and pass the message to that method. To ensure that my custom plugins have an object to send messages to, I usually have my plugin scripts create an object named something like MyPlugin_instance and use DontDestroyOnLoad() to make sure that object is never removed from the scene. That code looks like: 

The coroutine itself will pause, but the code that called StartCoroutine() will keep going. So in this case, WaitTime() will pause but OnTriggerEnter2D() will keep going. What you probably want instead is for the entire button logic to go in the coroutine. Then it won't matter that OnTriggerEnter2D() keeps going, since starting the coroutine is all it does. At that point you should call the coroutine function something other than WaitTime() since it's doing a lot more than just waiting eg. WaitThenRespondToButton() 

Corona is a very good tool for developing 2D mobile games; you can develop for Android on Windows and then compile to iOS on a Mac. 

Mipmaps won't help you. Instead, you need to load different assets based on something like iPhoneGeneration. And even then, you would need to make sure your assets are in Resources and not actually part of the scene, because everything in a scene is loaded immediately when that scene loads. In other words, swapping a texture in a scene wouldn't prevent that texture from loading in the first place. 

The three essential methods an event system needs is an addListener() method, a removeListener() method, and a method to dispatchEvent(). That is, a method objects use to register for an event, a method objects use to un-register, and a method to actually broadcast an event to all the listeners. Everything else is gravy. As you note, you will certainly need some sort of data structure to keep track of registered listeners. The simplest approach would be an associative array (Dictionary, or an Object in JavaScript) that associates a vector (or simply an Array depending on the language) with an event. That vector is a list of all the registered listeners; add listeners to the list or remove them in the add/removeListener() methods. To broadcast an event in dispatchEvent() it can be as simple as looping through the vector. You could add more complexity to dispatching by sorting the priority of events or whatever, but don't worry about that until you need it. In many cases you won't need it. There is a little nuance to dispatchEvent() when you consider what data to pass along with the event. At the most basic level you might not pass any additional data; all the listener has to know is that an event happened. However most events have additional data that go with them (eg. where the event happened) to you'll want to have dispatchEvent() accepting and passing along some parameters. 

Collision events parameters for the objects involved in a collision. The parameters are named "other" or "other1" depending how how exactly you setup the collision event listener. Here's the documentation: $URL$ To have control which objects actually collide use collision masking: $URL$ 

I am not familiar with the book Head First C# (or any programming book really, which should communicate to you how I feel about the necessity of reading programming books) but I'm pretty certain it's a bad choice for learning how to develop in Unity. That said, it may be a great resource for learning C# generally, so perhaps it would be worthwhile for you to learn C# outside of Unity for a bit before diving into Unity. I mean, I wouldn't recommend that approach, but perhaps Head First C# could be useful in that way. I never read any books to get up to speed with Unity, and I'm the main client side developer on a Unity game (I was already extremely proficient at ActionScript 3 however, a language very similar to C# in the sense that both mostly copy their language design from Java). Personally I would recommend diving into projects and learning by doing, with the one caveat that as your learning projects get more complex you should really concentrate on object oriented development. My path to getting proficient at game programming involved a year and a half at a job where I started with little experience in game programming. Because of that I wasn't being paid a ton, but the amount I learned made it one of the most worthwhile jobs I've had. While the whole approach of "get an entry level job in order to learn the process" may not be feasible if you have literally no previous experience at all (I was hired to develop web games, and I had already used Flash for a bunch of personal projects at that point), you could certainly replicate the aspects of that job which were so useful for learning. Specifically, that job pretty much amounted to a string of small two-week projects, and that is precisely how you should approach learning Unity, with a string of small learning projects (as opposed to trying to tackle something large right out of the gate). 

The command to load a level is Application.LoadLevel(). Call that from an "On Collision" function on the cube. 

Yes. I have three versions of Unity installed right now. If you don't rename the folder it will replace it, so just make sure to rename the install location. btw "tk2d" code is referring to 2D Toolkit, and that is not an open-source library. 

One approach is to set ignoreListenerPause on the AudioSource for your music and then set a mute on the overall game using AudioListener.pause. Now AudioListener.pause will mute everything except your music, while you can still mute that audio source directly. I take that approach in the audio chapter of my book (see my profile). 

To share persistent state between clients (that could be multiple players, or just multiple platforms for a single player) you need data being stored on a server. Since you will need to host your game on a server anyway for a Facebook app, presumably you can also create a database of player states on that server. 

We're using JSONObject from the Unify wiki. Not sure how this compares to other options people have brought up. 

Put a script on the camera, get a reference to the 'player' gameobject, then move the camera vertically to match the player when the player is higher than the camera: 

Just store it in JSON. Storing it in the colors of a bitmap seems like you're being tricky for no real reason. 

You should use raycasting to check for visibility. Each raycast is expensive, so stagger the visibility checks for different enemies (they don't all have to see the player on the same frame) 

A cross-platform development tool that is so new I don't necessarily recommend it is $URL$ It hits every platform you mentioned. While it is too new to really judge, it has a great pedigree: it's creator previously made Blitz3D and BlitzMax, which were great development tools for indie game developers. 

It sounds like the job title you should be shooting for is environment artist. Those are artist who specialize in scenery and props. There is generally a bigger demand for environment artists than character artists; if you think about all the open-world games coming out these days it's pretty obvious why. 

I would create a separate InputMapping class that simply correlates different Unity input names with my own input names. Then other parts of the game (eg. a keyboard settings popup) can change these mappings (eg. what InputMapping.Forward maps to). Now change the FPS movement script to use the settings from InputMapping instead of referring to Unity inputs directly. 

How exactly this is best handled depends on the exact use case. The two main use cases are: 1. You want to access a shared background object that persists throughout the game. 2. You want to access a specific object within the scene. For situation 1, you could use one of the code patterns like Service Locator or singleton (justin's suggestion is basically a Unity flavored singleton). Alternatively you could use FindObjectOfType() to reference an existing object in the scene. For situation 2, you can simply drag the object onto a variable in the Inspector. In other words, create a serialized variable at the top of the script (eg. public Example2 otherScript) and then that variable will appear in the Inspector so that you can drag in an object in the scene. Now you can call any public methods of that object. (incidentally, as zee points out the AddComponent command does exactly what it says, it adds a new component, not give you access to an existing component. If you don't want a new component added, then use a different command like GetComponent) 

You can't really make the game overall appear faster than it is, but you can make slow parts look faster (or at any rate less noticeable) by de-coupling them from everything else so that everything else can run faster. Indeed, this is precisely why network commands are done asynchronously. Similar things can be done locally, whenever one part of the game is slower than other parts. For example, physics updates are often run asynchronously from the rendering loop. Perhaps character animations are updated on a separate thread from background graphics, etc. 

The simplest 3D game engine to use for getting an animated model from Blender onto iPhone is Unity, but that's not free: $URL$ The best free option is probably Oolong: $URL$ 

at the top of your script. Now the variable 'object' will show up in the Inspector within Unity's editor, and you can drag objects onto that variable. 

I would suspect there is a way to setup the normals within your animation tool so that you don't have to mess with them in Unity, but it turns out there's a simple setting when you import the model. Go to the Inspector and look in the Model tab, and set the Normals property to Calculate (it defaults to Import). (There is also a code command to calculate normals, but that's exactly the same as doing it through the import settings.) 

Unless I am misunderstanding the situation you are asking about, this seems like premature optimization to me. I would say implement whatever technique is most straightforward for you. You can optimize it later if you start having performance issues, but for such a simple game I wouldn't expect to have a bottleneck with the creation of random objects. 

The "normalized direction vector" is how this task is usually approached, and how I often do it, but lately I've simply been clamping the resulting movement vector. It usually achieves the same end result and the code is a lot simpler: 

Eyes are just balls. There's nothing expressive about a ball. What's expressive are the muscles around the eye, which not many games model. For example, think about the squint of anger, or the relaxed eyelids when you're bored. 

In my book I summarized them this way: One of the most central parts of game design is crafting game mechanics; these are individual actions (or systems of actions) within a game. The mechanics in a game are often set up by its rules, whereas the challenges in a game generally come from applying the mechanics to specific situations. For example, walking around the game is a mechanic, whereas a maze is a kind of challenge based on that mechanic. 

Collision detection is not applied when you Translate() a transform directly. In order to apply collision detection while moving, you must Move() a Rigidbody or CharacterController. 

First off, do you know about having a Resources folder? Assets put in there can be loaded in code by name, instead of needing to reference them within the scene. Putting dynamically loaded assets in a folder called "Resources" makes dynamically loading assets a lot more flexible. The assets that you load from Resources don't have to be prefabs, although you usually want them to be in order to already have their various components and whatnot already setup. However if making everything a prefab is onerous for some reason then you could load the obj mesh (or whatever) and then AddComponent 

I can't give exact code because I've not done this myself yet (may make a good exercise with the new 2D functionality) but I can see the outlines of how you would implement this. First off, detect which sprite was clicked either using good ol' OnMouseDown. Use Input.mousePosition along with the sprite's transform to determine where the cursor is on the sprite. With that, use properties of the sprite to figure out the exact pixel; I'm not sure off the top of my head which ones you'd use, but the script reference for Sprite mentions stuff like 'rect' and 'textureRectOffset' Finally get the Texture2D with the sprite's 'texture' property and call GetPixel() 

Think of it this way: pick a point at random in your level, and then think about how much work it'll take to figure out everything within a 1000 pixel radius of that point. If you can do that quickly because everything is organized by location in a 2D array, then you don't need a quadtree. If however you would have to loop through everything and check each object's distance individually, then you could make the search much more efficient by using a quadtree. 

You didn't specify the platform in your question, but since you are leaning toward Game Maker that clearly means you are developing a Windows game. There are of course many many tools you can use to make PC games, with lots of different pros and cons. Using XNA is an option I would strongly consider, but another great looking tool I recently learned of is: $URL$ It uses Lua for doing the programming, and I have fallen in love with that language because I'm using Corona to develop an iPhone game. 

Just don't use the First-Person controller that Unity comes with. It's simply a pre-written script attached to a Character Controller; you could easily just write your own movement script (that's what I do, and it's the second chapter of the book I'm writing). Since the movement is simply a batch of code within a script you wrote, then any time you don't want to move the object simply don't run that code. Just wrap all the movement code with and then set when you want to player to freeze. (incidentally, if you're making a 2D side-scroller then why are you using a first-person controller? forgive me making the obvious point, but er your game isn't first-person) 

No, that's not true. It does cost that much for full professional access, but you can program and sell a game with the base free feature-set: License comparison