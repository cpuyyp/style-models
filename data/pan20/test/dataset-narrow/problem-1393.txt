As the adage goes, you get what you pay for. Sure, you can find free assets to probably technically fill most of your needs (and with the embedded Unity Asset Store it's even easier, but without the breadth of content that TurboSquid provides). But you're not going to have a consistent look. Quality is going to be all over the place. And you might not find a particular kind of building you're looking for. And depending on what kind of assets you find it might be pretty hard to get a set of things that fit together in some kind of city generation scheme. You'd be much better off just having a single static level you throw together manually. 

I think there's a fake dichotomy here. It's possible to make simple, yet powerful tools. The key is how you present them to the users, and what frame of mind you're going in to when designing them. This also depends on what, exactly, type of tools you're talking about here. Do you mean that users would be editing levels a la Atmosphir or Little Big Planet, or is it more all inclusive like Second Life? If you're talking about the former, you can make everything work within your system and do some things to prevent mistakes and issues with authoring content. For example, you can implement a visual scripting system a la Kismet and have it be very powerful but still safe for users to use. When users are authoring content, find out what issues there are with the content being generated and try to prevent it from happening in the first place. If you set up some kind of system that has triggers and effects, don't let players save the level that doesn't have everything that needs to be hooked up, hooked up. If the game is a platformer, have some logic that determines that maximum distant/height people can jump and warn the user if they have made something that's physically impossible to complete. That kind of thing. One other thing to keep in mind is the amount of investment you expect people to have in the game. It may be harder to author content in Second Life, but then again you can sell your creations. If your game doesn't have some mechanism to empower users to do something meaningful with their content, then you need to keep it simple. 

I don't know about gamesalad in particular, but the general way you solve this problem is the following: 

Doing a quick google search on your PC model number led me to this page: $URL$ The important bit is this: 

One of the common definitions these days is that low-poly is the model as in the game. High poly is the source model that's used to bake down normal maps. 

There are a lot of approaches for 2D animation. The most common that I've seen is traditional frame-based animation where you draw multiple frames and just swap between them. Any art tool that you're comfortable with you can use (photoshop, illustrator, corel draw, whatever). A slight variant I've seen of that is modeling/animating a character in a 3D studio package (like max or maya) and then just rendering out frames. You can get some interesting effects that way. One of the games I've shipped, Splode did that. Another technique I've seen is to do 2D skeletal animations where you have mostly rigid body parts bind those to bones in a skeleton and animate that. It gives you a different look but has lots of benefits (at the cost of being a lot more complicated than just drawing a different image). A good example of that done in an iPhone game can be found here: $URL$ Sometimes that's done with a combination of the frame-based animation (e.g. the head will have different frames for different expressions). 

In my experience (mostly mobile titles), the audio quality should be as low as as possible without overt negative side effects so that you have more in memory for other things. Keep in mind that just because there's compression involved doesn't necessarily mean that your quality is too low. Your audience isn't going to be doing side by side comparisons with the base sounds like you are, so if they're missing something through the lossy compression, they're generally not going to know about it. For example, you have to ask yourself if there's any reason to use stereo sounds or music. Is the effect it gives you worth nearly twice the overhead? For music, depending on how it's authored, the answer might be yes. Some engines don't even support stereo sources for sound effects. That kind of thing. Where that line is is very subjective, of course. There are other answers that go into more specific rules of thumb. The important thing is to have standards, set them early, and try to stick to it. If you're authoring music for a game and have to half its bitrate to fit into memory, then you're going to be much worse off than if you set a low quality level in the first place. 

Other than the high level discussion points that Joe brought up, there are a few other things you should be aware of. 

If you have two components that need to talk to each other, hiding the types or not letting them communicate to each other directly isn't really going to do anything other than hide the coupling that already exists. I'd get rid of the generic "receive" method and instead just make it so you can get a component by type and call methods on it directly. Unity does this with its method, which in your case might look something like this (untested, and using C++11 for loops for brevity): 

It depends on the studio. There are two fundamental camps. The terms are ones I've used, but probably aren't common elsewhere. "Dallas-style" level designers typically do everything, typically using some kind of engine that has heavy brush editing (i.e. quake based). Usually from layout, texturing, placing props, lighting, NPC placement, scripting, etc. "Environment artist" isn't really a position that exists. Usually the art department are involved with making textures, ancillary props, skyboxes, and occasionally some integrated hero props (that are usually first roughed out with brushes and then exported into a format where the artist can make something over top of it in something like Max). You'll occasionally do things like paintovers from concept artists to give the LDs some artistic inspiration for the final art passes. The LD is primarily the one responsible for maintaining performance. A lot time this is with older engines that require a bit more care and technical knowledge because these engines are portal based. "California-style" level designers mostly do layout and scripting only. This is more common with engines that are based around art tools (i.e. the LDs are also using Max). After gameplay is proved out, the environment artists go in and do the rest. Texturing, props, particles, sometimes lighting, and pretty much anything that isn't gameplay specific is done by the artists. They usually work pretty close with the concept artists. The artists have a good amount of responsibility with performance in this mode as well, usually in the form of "keep this number in the green" for a given scene. Fortunately, "Dallas style" level designing seems to be going away. Splitting up responsibilities means that you aren't putting as much on the shoulders of the LDs. Plus you have a higher theoretical artistic bar if your artists are the ones doing the "arting up". Why is "Dallas style" still popular at all? Mainly due to the engines being used. Artists generally are averse to learning LD tools. They can be very comfortable with Max/Maya, but trying to get a not-very-technical artist to use something like Radiant can be a bit of a disaster. Some studios have solved this as a culture issue. 

CrazyBump $URL$ Creates normal maps, spec maps, ambient occlusion data, etc. from flat textures. Windows $299 per seat for commercial use (volume discounts available) Commercial, has demo available CrazyBump is the de-facto way of creating normal maps given just straight materials. Has a lot of adjustment sliders that you can tweak in real time. The video on the web site gives a good impression of its capabilities. 

Usually contracts like that are work for hire. The person doing the work has no rights to what they create for you since it's yours. 

I can't think of any game that has bullet time in single player that transitioned it successfully to multiplayer in any meaningful way. There might be a few of them that solved it by speeding up the player using it, but that kind of defeats the point. Bullet time exists because you want to make the player feel like a badass. You're giving the player a seemingly unfair advantage through simulating higher level perception. The end result of this is that players can aim while doing cool things like jumping out from cover and so forth. If you just sped up the player while they have bullet time enabled then you give them less time to react, which is the opposite of what you want. In a synchronous multiplayer environment, there really isn't any solution for user-activated "time slows down" that simulates the feeling that comes from using it in a single player environment. If time itself were slowed, then everybody's perception goes up. Especially in a PC game where mouse aiming is generally instantly, everybody would get the benefit of slower moving targets. Now if you were dead set on this, my suggestion would be to, instead of making it a player-activated feature, make it sort of an encounter "state". Think like a John Woo movie where it's the good guy vs the bad guy and everything seems to slow down as they're shooting at each other. So when an "encounter" starts, turn on slo-mo and you can get some interesting effects. Guys jumping around and stuff ricocheting from missed bullet hits floating in mid air, and all that stuff. Of course, this would only really work for a 1 on 1 game. You wouldn't get the one-sided benefit of the bullet time like in a single player game, but it might be an interesting play experience. 

Let me preface this entire answer with the fact that this is my personal philosophy on coding practices and how I run my teams, and that there are different people with different priorities. My answer to this is absolutely not, but that's because speed of code execution isn't as important as shipping the game. The reason those higher level features exist is so that you can write code a little more abstractly. And by doing that you can theoretically get more done in less time (or fewer lines of code). Usually there is a speed tradeoff. For example, virtual functions and RTTI have a speed hit. Is it worth the speed hit? In my eyes, the answer is yes. Anyway, for all the computationally heavy stuff (i.e. pathfinding), it's more about the algorithm anyway. If you have sections of code that are speed critical (not all code is speed critical), then maybe you want to take one of your more advanced guys and optimize that carefully. Each individual particle structure probably shouldn't have a vtable, for example. But part of being a good technical director is realizing where those heavy bottlenecks are and paying special attention to them. Besides, in my experience, your real performance gains come from things like how your code manages the GPU. Draw calls, occlusion, that kind of thing. Specifically speaking of your Carmack reference, read the section on "code lineage" from this article (it's at the bottom). The Doom Resurrection code base I worked on went heavy on boost/stl/delgates/etc, the levels themselves used LUA as a scripting language, and there were a bunch of things that were not ideal at all in terms of performance. I'm not going to say the code was perfect at all. Even with my lax feeling about code performance there were things I didn't like. But we shipped the game quickly with a few number of people. And you can read Carmack's own impressions on it there.