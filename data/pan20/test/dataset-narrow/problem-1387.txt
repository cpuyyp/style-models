Basically the same as JasonD's answer, except using bitwise operations instead of absolute value function. This is assuming you have 16-bit short integers! 

But in order to retain flexibility in situations where multiple handlers may need to observe the event, "Bubbling" can be applied so that all handlers get to see the event: 

(although, I think maybe you wanted this one that accounts for gravity but can be used to calculate any possible jump) 

One way to circumvent the accumulation of rounding errors is to re-normalize your vector when you calculate . This might look like such: 

And for good measure, here's the tool I wrote to generate those images. Using SDL and plain C, I called it "hbm2tnm.c" (Height Bump Map to Tangent Normal Map) 

Which is our answer, notice that time is still unknown in this system. This means there are infinite trajectories that will land on the purple rectangle. You have to decide how long it should take. 

You're right on track with using the context only from a single thread. You can only use an OpenGL context from one thread at a time, but you can do everything else in another thread. 

I have obtained an implicit solution, and although it looks like it could maybe be solved by the W function in closed form, we would then need to implement the W function in C++, so I have not investigated that. Instead, I have taken the approach of reformulating the problem as root-finding, and numerically approximating the soluiton using Newton's Method. This strategy has yielded the following fixed point iteration: 

This time the Adjusted Jump Speed is being forced non-negative; If the player is already rising faster than they should be able to jump, they would attain a negative adjusted speed, which allows them to use the "jump" action as brakes. (to slow down to the intended jump speed instantly!) Note: I believe your contact X and Y are already normalized as a pair. I included explicit detail for completeness sake though. 

There is no canonical "correct way" to approximate general functions. Sorry. With that said, the very source you linked to has suggested the Lafortune representation. This representation has been described as "...compact and works well for hardware rendering..." in chapter 18 of GPU Gems. Implementation details appear to be out of scope for this question. 

If multiple, independent agents can both use/modify the same data on the server, then it requires certain design principles to prevent problems. 

If the server environment is multi-threaded, then the access to the actual data on the server has to be protected with mutexes (or something similar like a multi-user database) so that changes to the data are atomic and no two threads or processes are ever trying to change the same piece of data at the same time and all data structures retain appropriate integrity no matter how many people are trying to change the same data at the same time. The client environment has to both know that any data it holds might be getting changed by another agent at any time and it has to be designed to handle that in its normal operation. There are a number of design strategies for handling that and which makes the most sense depends entirely upon the application. When the client wants to change data, it has to have a design strategy for how to handle the case where somebody else has already changed the data since you last saw it. The strategies can be as simple as "last writer wins" or much more involved requiring verification that the client knew the previous state of the data before changing it or even temporary locks while making a change. 

Your and variables are local variables so they only last the duration of the function they are declared in. Thus, when you try to call using them, the variables no longer exist. The way your code is currently structured, you need those variables to be global variables (declared outside any function) and not declared within a function. This will allow the variables to exist across your different function calls. Also, it does not make sense that you're using for the because you're just clearing the interval the first time it fires. Perhaps you should use instead and then you won't even have to clear it because just fires once. 

First off, you have to decide what performance characteristics are most important from a user experience point of view and then understand the technical issues involved in delivering that experience at scale/load. So, the operative question for your game may be something like: "At what delay does the experience for others start to deteriorate?". Some games would be basically ruined if the delay in update of other's moves was 1 second and other games could easily tolerate 5-10 seconds as it entirely depends upon the game and what the networked data you are transmitting means to the experience of the receiving player. So, in your specific game, you need to figure out what the goal is. Do you need to deliver updates to other players within 300ms, will the experience still work just fine at 2 seconds or is the info being sent periphery to the experience and even 10 seconds is OK? Then, whatever time delay you find still acceptable for a decent experience, you can build your client so that it collects points for about 2/3 that time minus whatever the usual transmission time is and then sends what it has when that timer fires. This will give you batching for the most efficient transmission at larger scale, but should deliver most packets in a fast enough time to deliver the user experience you want. A more advanced implementation would gauge the activity level and deliver a faster experience (shorter batching time period) when load is light and allow the batching time period to go update when the activity level is high. This assumes that batching more updates into a single packet is the more efficient way to deliver things from a network point of view and client/server processing point of view so you want to move that direction when load is high and move more to the low lag side of things when load is low. Let the desired experience drive your design goals, then figure out what technology solutions are needed to deliver that desired experience at load and design a self regulating backoff for very high loads. 

Then we also assert that the player's position after velocity is on the same line: With enough information to define the line now available, we can solve for the slope and intercept of the players line of motion to find: Applying the same technique to finding the slope and intercept of the wall yields: By solving the system formed by these two line equations, we find a (rather large) formula which directly computes the intersection, I've formatted this as code just in case you aren't familiar with maxima 

Sounds like you are asking for a convex hull, this is sortof like "gift wrapping" all your vertices. (Otherwise, if the shape can be concave you cannot imply it by the vertices alone) Wikipedia has a good list of techniques here: $URL$ And google code even has an implementation (I haven't tested this): $URL$ 

The fix is simple, integrate position in the middle of integrating velocity. (As in, add half of the force, update, then add the other half.) Here is a more in-depth explanation: $URL$ 

A less effective, but simpler, approach would be to use a fixed timestep. This can be achieved with a function like or . Be warned there are issues with these routes: might create a queue of frames to draw faster than they can be pushed. might leave you waiting too long for your next frame. With that said, here is another example jsfiddle 

I didn't check thoroughly, but one major problem I see here is that you aren't following the OpenGL manual: This line of code is never valid: 

Long answer: (pre-calculus required) Define your jump function which is a simple integral over time: 

I arrived at my assumptions because your offsetting code in the vertex shader seems to indicate that your variable is measured in pixels, not normalized: 

Variance shadow mapping, plainly put, just suffers from these light bleeding issues. I personally prefer to implement ESM (check out page 257 of ShaderX6) as the memory pressure is half of the VSM map and the artifacts are much less abrasive to me: (The very beginning of the shadow is a bit too bright.) With this said, here is a (rather old) PDF full of great techniques to get you thinking. (or just to show you the algorithm if you don't have ShaderX6) $URL$ In my current engine, I have a hybrid which is basically ESM, but uses the 2-moment (or higher) shadow map to compute the variance and reduce the ESM artifacts at the places where the occluder is too close to the receiver.