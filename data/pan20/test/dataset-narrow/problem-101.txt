In this configuration the port 4 will behave as a trunk port with native VLAN 30. Note that it's unclear if the port PVID will be set correctly with this configuration, there's PVID configuration command only within GVRP, so ??? Also note that D-Link use the term for both Link Aggregation and VLAN trunking which could be confusing. 

The easiest way to do this would be to use a linux machine with and OpenVSwitch give you a fine control over traffic forwarding and provide, among many other features: 

There's a standard to achieve this: 802.1X. Basically the switch request authentication from the computer, then contact an authentication server to validate the credentials and depending on the answer the switch will deny or allow access. There's further possible options, like placing the host in a guest vlan if not authenticated or placing the host in a specific VLAN depending of some of the user properties. Obviously your switch must support 802.1X and you need an authentication server (usually a radius server). In a windows environment, the Network Policy Server role can act as the authentication server. It is natively integrated with Active Directory. 

Some IOS based switches allow this configuration (with 2 destination ports), so if you have such switches with ports available you could do it. Obviously it increases the cost and number of ports required. 

Yes, what's important to the router is layer 3 interfaces. You can think of a layer 3 interface as a logical construct, which can be be tied to a VLAN, physical or tunnel interface. 

You just need to wait for the port to goes in forwarding mode. By default on Cisco switches (and it seems in packet tracer), when a port goes UP, the STP process block the port until it determines that the network is loop-free, by listening for BPDU on this port. To avoid this you can configure ports that are connected to hosts (I.E. not other switches) with the command. This will cause the port to goes in forwarding mode immediately upon connection, but still run STP discovery and block the port if a loop is detected. 

To get the best of the 2 approach you connect the 2 cables, aggregate them with LACP, set this bond as a trunk and configure QoS. You can further increase the redundancy and bandwidth by adding more link to the bond (most systems allow at least 4 links, 8 is also quite common). This way you have improved bandwidth and fault tolerance. 

It's likely that the subnet masks are throwing you off. As long as you keep in mind that the below rules no longer apply, you should be fine. Ultimately classful addressing came down to the most significant (or "leading") bits in the address. Nothing more, nothing less. 

The most common way is to segregate access based on group membership. Within ACS there is/should be an "Access Policies" menu - I won't go into every detail of configuring ACS here, because that's why there's a manual, but you can essentially define your policies of which groups members can log in (and which group members have access to run which commands) there. In addition, there's also a way to define hierarchy in your actual network devices themselves (via hostnames, "Locations", etc) that can provide further criteria on network device access. ACS is a decent product if you need point-and-click AAA, but there are far cheaper ways to do the same thing if you have staff that know what they're doing (see tac_plus or FreeRADIUS). Taking some care in defining and laying out elements in your Network Resources/Network Device Groups in ACS will make your life easier when it comes to defining new access policies and allowed command sets. 

All routers within an OSPF area keep a link state database (note that this is completely separate from the main routing table), where they're aware of all other routers and their links within the area. Each router within the area builds a topology tree of the area, with shortest paths to all other links/routers with itself as the root. This last part is important. When an area grows large, the link state database (the tree or topology) that each router must maintain also grows large. This means that it can become more and more intensive for the router to process link state (topology) changes as there are now a large number of entries in the link state database. The tree grows larger and is more difficult to "keep up" with as there become more and more branches/leaves of the tree. Something else to keep in mind is that as the area (network) grows larger, there is greater potential for link state changes, and thus a greater potential for recalculations of the link state database. While the details of which are somewhat "out of scope" of this answer, the OSPF link state update process is also relevant here. Ultimately, as a single area grows larger and larger, the SPF recalculations themselves will take longer to complete, and you have more risk of those SPF recalculations happening due to various reasons - the moral of the story is your routers' CPUs will be sad. The "advantage" of OSPF areas is that they provide a means to alleviate the demands placed on the routers if they were otherwise in a single area, by way of cutting down entries within the link state database and pushing responsibilities of the link state database maintenance to area border routers for their respective areas. It allows for a way to keep the tree size manageable. Thorough thought and planning is mandatory for designing/implementing multi-area OSPF - there are a number of situations where poor design in multi-area OSPF can bite someone. Using areas doesn't necessarily increase the "speed of communication" but it can have significant performance benefits (if done properly) to the routers in your OSPF network, especially if your network is very large, because their CPU's aren't having to work as hard. 

You may perform the test from a different client, and event a different operating system to determine if the issue is client side or server side... Regarding the network between the client and the server: 

This is likely that there's a IP network between the firewall and the SBS server different than the one use between the client computers and the SBS server. Also you must check that there's no Group Policy applied that would enforce some network settings on the client computers, such a proxy settings and Windows Software Update settings. If there's those kind of GPO you must remove them in a way that they will no more be applied on the computers (there's a Check box in the GPO settings that tell if the settings are still applied when the GPO is removed). 

I'm not sure I understand you question but the fact is you cannot aggregate in a single prefix 2 subnets from 2 different networks. If org2 need only a /24 network and org3 need a /23 (I.E. 510 hosts in a single network) the simpliest thing is to use 200.23.20.0/23 for org 3 and use the free 200.23.19.024/24 for another customer who also need a only a /24. Otherwise you can allocate two different /24 to org 3 but once again you cannot aggregate them. 

You may connect the client on another port / another switch, etc... Actually the idea is to look at each element of the chain and eliminate them one by one. 

When a client contact an htpp server on TCP port 80, this port is the port. The client use a random port with a number higher than 1024 as the port When the server reply the source and destination (for both IP and ports) are reversed. I.E. the request from the client to the server has those characteristics: 

EDITED Despite the extended usage of binary in computer world and power of two based units (Byte, 32-bits word etc...), network bandwidth is commonly expressed in power of ten units. So it is (or /50^3) 

You cannot get the website trough the IP address since behind a single IP there can be many web sites. What you need to do in order to get the web site is to inspect the content of http packets. Be aware that there may be strong legal issue about this, depending on the country. 

So the question is: Why can't I ping between 2960X and Nexus1 when I cut a link? Bonus: How to configure HSRP in this configuration? 

Not with a 4948-10GE I'm afraid. X2 transceivers can only go up to 10GB-ZR which will get you ~80km. Edit: dfex is right on the money as well - you'll need to get the path loss from your provider before you can make an informed decision on this. 2nd edit/suggestion - if the path loss still prohibits you from off-the-shelf optics, maybe ask your provider if they can give you a wavelength instead, at least until you decide if *WDM is a more viable option for your needs. 

I've been spending the last week or so troubleshooting some (maybe related, but probably not) issues with Quagga. I have a test router - 7204VXR-NPEG2 running 12.4(24)T6 - with a single BGP session to a Quagga host. The only BGP session on the 7204 is with the Quagga box. This is an eBGP session. There is literally zero policy configured on either side, yet I get this without fail in output: 

You're kind of thinking about it the wrong way, but I'll try to explain. When you purchase bandwidth from an ISP, this is called transit (colloquially in the industry). Assuming you've got yourself some PI space (1.0.0.0/8, for example), you're paying your ISP to get your bits from your network to other networks. So say your AS is 6500, and your ISP is 3356. Bits from any other ASN will also need to transit AS3356 to get to you. Let's say that there's another ASN (6501) that buys transit from a different ASN (7224). AS3356 and AS7224 are peers. Now, in order for bits to get from AS6501 to AS6500, the path goes like this: 

Step Two: Set up GNS3. Edit -> IOS images and hypervisors. Click the "External Hypervisors" tab. Add in the IP address info for your remote hypervisor (Most of the time you can leave all the fields besides IP address as the default). Once you've filled in the IP of your remote hypervisor, click "Save". 

Move the second ISP connection to one router on your side. Both you and the provider configure on each of your sessions - you don't have to use Lo0 if you don't want to, as long as you guys agree on which address to static-route to. Configure 2x /32 static routes to each others' loopbacks via the connected interfaces (or next-hop IP's) - this is how the load balancing works, as it's really just ECMP. Configure on each others' sessions (You want to keep this number as small as possible to avoid TCP session hijacking). 

There's no username for enable mode. From exec mode, you enter the command "enable" and the device ask for the password. You may also (depending on the IOS version and the actual configuration) type "login" and provide the username and password of a account configured on the switch (either locally or through radius or tacacs) that, upon successful login, will be put directly in privileged mode 

When talking about routers we consider IP networks (layer 3), while collisions occur at layer 2, so the two concepts are somewhat unrelated. If you have a single layer 2 network connected with hubs, you have a single collision domain. If you split this network in two with a router then you will reduce the collision domain BUT this imply to reconfigure all the hosts behind the router with new IP settings, so this is a totally different thing that simply breaking up the collision domain. So to keep it simple: 

Yes you can, by configuring the port that connect to the router in trunk mode and the other ports on the central switch in access mode , each in appropriate VLAN. However I strongly recommend that you go for 4 VLAN aware switches. The additional management capabilities and flexibility it will give you largely compensate the additional cost (which is not so much). 

Depending of the devices chosen, the price could be a pro or a con. Personally, I strongly prefer separate devices. 

When a tagged frame (it's Layer 2 we are talking about so we are dealing with frames, not packets) enter the switch, it will be verified against the authorized VLANs for the port. If the VLAN2 is not authorized on the port, the frame will be dropped. So yes, if properly configured, it's secure. Note that as a best practice, you shouldn't use VLAN1, and by default netgear use VLAN2 as the voice vlan (you can still use it but it may be easier to choose another one) Also the statement 

The setup you describe is possible and does not even surprise me for a SBS setup. I can only guess but I would say the SBS server act as DHCP server and Router. You can remove it and connect the firewall to the switch but you probably will have to reconfigure the firewall. You have to consider 

I don't understand what kind of answer you expect. You have to figure out how the cabling is done. There must be some kind of logic and you should be able to find it without testing all 400 cables. You have to use a tone generator and a probe to identify in which panel a few jacks are connected and how each patch panel is linked to the main patch in the networking room. Looking to the numbering at each side you should be able to guess the logic in the numbering... if there's any.