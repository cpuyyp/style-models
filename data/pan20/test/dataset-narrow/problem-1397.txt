In one of my voxel engines, the voxel block explosion was done by creating a defined amount of minature blocks at the explosion point, and applying physical properties to them, eg velocity and gravity. Then, set them at random directions, and draw them. So, the actual voxel model wasnt really being disintegrated, but the voxel particles gave that impression. That is one approach. Another approach is to actually break up the voxel model. To achieve that under testing, was to detach the smaller voxels from the model, and apply the same techique for the previously mentioned explosion. No new voxels were created. In relation to pixels, I would imagine it possible, yes. An approach might be to look at using a rendertarget for the sprite, and where the texture pixel coords match the explosion points, store those coloured pixels in a dictionary, with position and colour values. Then, the rendertarget would form the source of the sprite without those pixels present. Use finally some type of custom particle manager to explode the pixels from the dictionary, using a technique similar to the explosion of the voxel model that I mention in the second part of this response. Edit: As requested in the comment, here is an example of using a rendertarget to regenerate a sprite: 

PEP-0342 details coroutine implementation in Python. You can create your own scheduler and tasks which can simulate multithreading on a single thread. This is the same way that Javascript frameworks allow for multithreaded like processing even though Javascript is run on a single process. 

A good response should be fact based, and any subjective subjects like difficulty should be based on an explained experiences with the product. 

Unity is a very popular engine/WYSIWYG editor which allows programmers to expose easy to modify "components" which artists/designers can attach to entities to give functionality within the game. A bunch of components come standard which provide a lot of the basic functionality for games. From the Unity site: 

Sergio you might want to aim more toward a Game Development math book like Essential Mathematics for Games and Interactive Applications, Second Edition: A Programmer's Guide Instead of the classical Linear Algebra you would learn in college. Also like Ron Warholic said, stating what your math comfort level is would better help us taylor a specific book. 

For a game like you described you might consider going for a full Planner based solution. This allows you to describe simple transformations of the world state the AI can perform. Essentially the AI plans a number of moves ahead of time to reach its desired goal. This approach is computationally expensive but for a turn based game it's a great fit over classical min/max and alpha/beta pruning techniques. The issue you run into with the Rule Based System you described is having to constantly tweak conditionals and re-prioritize the list. When the list of rules grow larger they become nontrivial to fix small issues without affecting everything else. Utility systems have similar issues when a large number of utility functions constantly struggle between themselves. STRIPS is a well known planner algorithm that was used very effectively in F.E.A.R $URL$ Jeff Orkin's paper on his STRIPS implementation for F.E.A.R is a great starting place. A SDK to F.E.A.R is also available to take a look at some of the AI implementation details. $URL$ 

Here's how I would do this. First, make sure you have the object's UVs or world coords (which you can pass through from your vertex shader) available to you. If it's just a background, you could also just use fragment coords (). For instance, let's say we're using UV coords. A fragment shader with only: will look something like: 

When I hear game designer, I think of somebody who thinks up game mechanics, freedoms and constraints, level designs, balance etc. The may well have no part in actually programming the game. What you are is a game artist. That doesn't mean that you can't have more than one role in creating a game, and at the same time each role influences every other role significantly. At any rate, you are a game developer, as are programmers, testers, sound engineers, etc. 

However, you don't need to check for all of these. What you have is a decision tree; all you need to check are if the orange ones match your center tile. If they do, then you proceed to check the secondary ones. Here's a diagram that connects the orange tiles to their secondary tiles (notice how you only need to do four checks for the green matches and not 8 since the other 4 are the same): 

While doing a BS in CS at a California State University there was only one game development course which was group based where each group was to deliver a complete game from scratch in 10 weeks. Each group consisted of 4 programmers. This single game was worth 100% of the grade. It was straight C++ and OpenGL with weekly deliveries from all groups. One of the hardest classes I've ever had but at the same time we learned everything about how game engines really work. Rarely do students learn this anymore since most are spoiled with engines or frameworks that abstract all the "hard" stuff away. My professor published a paper about the class in 37th ASEE/IEEE Frontiers in Education Conference 2007 Student Teamwork: A Capstone Course in Game Programming The game my group created Images from my Portfolio Video of the game from another teammate 

So typically Havok works best with normal human sized objects with a gravity of 9.8m/s^2 and dealing with everything in meters. In my Game though there will be a large variety of scales from millimeter sized objects to meter sized objects. Typically this rules out running a standard Havok setup and dealing with things in a meter scale. Would it be best to increase everything by 10x or some scalar like this and increase gravity likewise? I understand this would also decrease how far objects can be away from the origin but for the sake of this question assume everything is relatively close to the origin, a hundred meters max. Issues of concern Object penetration - Havok usually allows some object penetration in the 2-3cm range in the meter scale. Floating point precision - Issues dealing with distances of objects etc, typically physics breaks down at the kilometer scale in Havok. Unseen - other unseen issues that may result with such large differences in scale. 

First of all, when you say "creating" a tileset, I presume you mean that you want all these tile transitions pre-baked into textures. I'd recommend against that as the number of transitions you need increases quadratically as your number of tile types increases, and isn't worth any extra efficiency usually. What you want to look into is Texture Splatting and do this all runtime. I can't think of anything in particular that would give you extra efficiency when it comes to cell types, except the usual voxel optimizations like storing voxels in an octree and optimizing that, occlusion culling, frustum culling, LOD, optimal mesh generation etc. On that last one, as the saying goes, premature optimization is the root of all evil, but if you end up having some extra FPS, you could try rendering your cells to look more "detailed" with algorithms like marching cubes / marching diamonds (think the 3D Worms games' destructible terrain). Edit: Here's a good read on voxel terrain meshing. 

Yes, step 1 and 2 are correct. Here's proof. Step 3 and 4 can be done in a couple of ways. Following your steps to the letter, you can convert the RGB color to HSV, modify the values, and convert back to RGB. The first conversion is unnecessary though, since the image is grayscale, so we know the only thing that is affected is the "V" in HSV. So you can use your image as V, and use those constant H and S values to get something similar to what you want. Subject to tweaking and experimentation of course. Converting back and forth between RGB and HSV isn't the best idea for something like this though; perhaps in this case - if all you want is a slight blue/cyan tint - then you could instead just slightly tweak the blue and green channels and get the same result.