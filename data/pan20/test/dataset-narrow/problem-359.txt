This shows that it is trying to read from a socket that has been closed. It's a networking problem. Ask your network administrator to raise the firewall connection timeout between the database host and the netbackup host. 

You'll need to open a new shell to see the changes take effect. That will modify the setting for just the current user. If you want to make the changes applicable to all users system-wide, put the above lines in or . 

There are two things wrong with it. Firstly, you need to specify maximum data lengths for the columns. Secondly, the column has to be the . The following DDL statement will work: 

RMAN only works at the block level & has no idea about the contents of a given block, and therefore cannot do this. You need to use with the parameter: 

You can set it to a non-zero value that is equal to or less than , so if you need to allocate more memory, just up and . eg: 

Oh, and also the affect the situation - I missed them because the question was formatted like someone had been sick on the screen. 

I'd advise against killing sessions unless you know that doing so will not cause problems on the application side (trying to use a session that's been killed, for example). It may be the case that you're looking at an incorrectly configured connection pool which creates hundreds of connections once the app starts up - the connection pool may be an order of magnitude bigger than it needs to be. I suggest reaching out to the developers/application support staff & taking a look at how the connection pool is configured. Having done a bit of research, w3wp.exe is the IIS Application Pool Process - you almost certainly want to talk to your IIS webserver admins to help get to the bottom of the connection pooling configuration. 

Then grant it back to certain users, plus all other internal Oracle users. The 2nd option is to look at the source for the view, drop it, then recreate an altered version that supports your needs. Another option that would trick casual users would be to create a table called ALL_USERS in each schema. Unless the logged in person explicitly qualified ALL_USERS (ie: SYS.ALL_USERS) they would get the resultset from the table in their own schema. This trick could also be done with a synonym pointing to a view that does: 

Note that tablespaces are simply the place the object is stored in, and have no bearing in DML queries. 

You'll see one process for each database that is up. For example , where is the instance name. You can also ask the listener which services it is serving connections for, with: 

... from the command prompt should just work. If not, edit your question with the full error messages you are seeing. Post-installation steps are summarized in this blog post. 

They're control file backups. The reason for the file size discrepencies is due to the fact that they're for different databases. Order the list by filename and it'll be more obvious. Just for your information, the first number after the prefix is the (database ID). 

returns the location of a match, not a string, so you don't want to use that. would be the one to use, but is simpler. 

Edition-Based Redefinition is perfect for this. You define schema changes in a new edition, along with procedures that are used to migrate the data between the base and new edition/schema. Switching between the two is seamless and can be done with zero downtime. There's a good demo on the Oracle Base blog. 

Either create the table manually beforehand, or specify the column names an NULLability in the CTAS statement: 

Basically, all of your calls in the subqueries were wrong. It always needs to be because you need the sid to join with . Note that you could condense it down to a single statement. I've tested this on 12c and it works: 

You can do this with , but you'll need double the space occupied by the table. If I read your question correctly, this should do it: 

Restart the listener with followed by . Create the reference to the external library & create the function to interface between PL/SQL and the C prog: 

It's a bug. See Metalink document 382576.1. The bug was fixed in Oracle 10.2.0.4, so upgrade to that release (preferably 10.2.0.5). There are workarounds, but I'm not sure if it's ok to reproduce Metalink documents on this site. 

If you omit the clauses when creating the user, the user will inherit the database default values. These can be queried as follows: 

When you create a new user, you can optionally specify the default tablespace and default temporary tablespace for any objects created by that user. For example: 

I don't understand why the current answers haven't questioned the requirements fully, so I'll ask and leave it as an answer. What are the business reasons? What data do you need to encrypt and why? If you're looking for PCI compliance, I could write an essay. Questions about your requirement: 

The reason is that it's not connected via TCP/IP, so there isn't a port. MySQL allows local clients to connect via a "socket file", which is located on the file system (, for example`). 

It can't be done because you're mixing and (happy to be proven incorrect, by the way). You also can't use in an , which was my first thought as a way around this. Anyway, this is a logical workaround for you: 

Now, I'll create an example of an FGA auditing policy that uses the above table. This will audit any SQL that contains a row with a value greater that 100 in its resultset. The parameters speak for themselves. 

You can create the database link using a full TNS connection descriptor, to workaround the requirement of needing tnsnames.ora entries on the DB box. For example: 

can't be changed from inside a session, however other settings can. You can't change the character set once a database connection has been established (ie: the 2nd part of ), but you can change the language with: 

It only allows access to data dictionary views, so the only security implication is that the users(s) would be able to see which objects existed in the other schemas. They would not, however, be able to actually view the data in the other schemas. I said there was only one security implication, but another is that they would be able to view the source of any stored procedures/functions in all schemas, by viewing etc. 

Qualify each column in the / and join clauses. So, for example I've qualified the column so that it's read from the table in the clause - it's ambiguous because it is in both the and tables. 

You can also do this using , but I find the above way to look cleaner. Example SQL Fiddle for you to mess around with. 

Now do a scandisks on the other node and check that everything is as it is on the first node (should be fine if you're using the same /dev device names). Now the disk is ready to be added to the group. List the groups: 

(Untested, but will test it when I have time - unsure if the end of the chain & job will again modify the .) I have tested the following, which works OK (but involves creating a new job): 

Runtime error, that won't get picked up as it doesn't analyse the actual values involved, and is unaware that the included string isn't a number: 

There are other way more complicated ways of achieving similar results, but the answer would be significantly longer! 

You're have AMM enabled, so Oracle will manage it for you automatically. will be set to a non-zero value, which means: 

You need to use SQL baselines to force the execution plan. This blog describes the steps involved. You'll need the for the statement and the of the old plan. 

For completeness, whilst Jack's answer is technically true, it is possible to use Data Cartridges to expand on vanilla Oracle offerings. In fact, a company called CopperEye released a new indexing method (patented, now not available) utilizing this functionality. See this old press release. The patent makes for fascinating reading. 

... to Be aware that it will impact connection performance. To increase the logging level to be more verbose, you can also use the and options for the parameter. 

If you don't know all locations there are hacky ways of doing it, but they're not pretty. This Oracle forum thread has (hacky) examples that can be used when the columns aren't known. 

It's not actually possible to specify a different tablespace when importing using the oracle utility. However, as a workaround, you can pre-create the tables by doing a import into the tablespace, then for each table to move them to the new tablespace, then do the import again with the parameter to ignore the table creation errors and import all of the data. If the data was exported using Data Pump (), (as an aside, everyone should be using this these days, rather than the old legacy / utilities) you can easily import into another tablespace using the parameter. eg: 

I like to use . Using a CTE to get the current maximum PK value, you can easily double-up your data. Example below. Test table: 

I can't do hard s, it's just one of those things that breaks my brain. You need @bluefeet for that. Anyway, you can do it the oldskool way with and if the number of groups per is finite (I'm assuming the names are unknown, and there's a finite number: 

MySQL will have silently done some mathematics with and got its knickers in a twist. It does warn you though: 

Consider using de-duplication if you have lots of identical XML - documentation link. I wrote a huge unit test, but it turns out that SecureFile LOBs are always stored in a Lob Segment outside the row! 

From a database (and client) point of view, you need to do a few things. The first thing you need to consider is that you have to use integers for everything and have a number of implied decimals for each currency (eg: $2.00 is actually 200 with 2 implied decimals. The $2.00 part is a client formatting issue and a database maths issue.). Floating point never comes into it - you don't want to go near the mathematical implications involved in using floating point. My advice: Have a table with the (PK), and fields. Any other table then just needs a and column to relate to the original table. Formatting is then just a join between the two. Maths between any tables with the same currency is then just straight integers. Maybe add a few more columns to the table for leading and trailing symbols (eg: '$' for prefix, '.' for decimal spacer) for formatting. 

Oracle 8.x.x has been out of support for some time. Apologies for the bad news, but your only option is to either recover the software from the dead disk, or ask Oracle (obviously with a valid support contract) for a copy of the software. Raise a ticket on My Oracle Support and they will help you. 

The Oracle documentation says that 512Mb of RAM is recommended to run Oracle XE, with 256Mb minimum required. In reality, with anything else running on the Linux box/VM, you're really going to struggle with just 256Mb. Make sure you've adhered to all of the pre-requisites in the documentation (kernel params, adding 2Gb of swap space) before you try and re-install. I've successfully had it running on a Digital Ocean VM with 512Mb of RAM - I just added a 4Gb swap file on the disk - and it ran like a dream. Well, a slow dream :-) 

I suspect you're missing the difference between and (otherwise known as CTAS). allows you to create a table from the resultset of a query. For example: 

Doing the initial part of this with a windowing function is trivial, it's adding the "missing" rows that I'm struggling with. 

Edit the generated pfile and remove the parameters, then recreate the spfile from the edited pfile. Bounce the database & all should be well. The database might need to be down when you recreate the spfile from the pfile. 

Yes, you can manually script it. This is covered in the documentation here. In essence, you copy the archive log files to the correct filesystem location on the logical standby host, then register them using the command. 

You're on the right track. You just need to catalog the files so that is aware of them. At a prompt: 

is what you're looking for. Skips the first N rows, so in your case you just want to skip the first. 

The official Oracle white paper Oracle Database Vault with Oracle Database 12c, provides a very good high-level overview of the functionality it provides. To be honest, you're not really going to find a better source of material. Start with that, then read all of the documentation that is linked from the product home page. There's a fair number of blogs that discuss initial installation and examples of use. Google is your friend. 

What you are asking is impossible, unless you brute-force the password hash for the user. How do you expect a system to be secure if passwords are stored in plain text? 

The code you have posted works OK, and is guaranteed to insert the same IDs. The other way of designing this is to have a separate table that stores the hierarchical relationships, but you don't really need to do so unless you have many:1 or many:many relationships. 

You have several choices. You can either create the tables without the constraints & add them afterwards, or create the tables with the foreign keys & them import the data with foreign key checks disabled - simply run in your session to temporarily disable them. For example: 

Ok, minimal test case that reproduces the error, showing it's the intermediate table PK that is the problem: 

It's simple. MySQL has a single daemon that runs the database server. Within the server you can create any number of databases - these databases have no direct mapping to users. Oracle has a single database. When you create a user in an Oracle database, it also creates a Schema with the same name as the user that created it. This is equivalent to a database in MySQL. Having seen the edit to your question, you really need to forget about mysql while you learn Oracle. DDL and RDBMS concepts are completely different. Start with the Oracle Server Concepts guide (link). The Oracle documentation home is here: $URL$ To create a user, the syntax would be: