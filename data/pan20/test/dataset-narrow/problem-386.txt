So here's the rub: every single developer logs in with the same user, so I can't really use . I don't want to open up blanket for every single user. This would allow a dev manager to pass in a username (i.e. jsmith) and kill that session, and would email us DBAs that this happened, so we can see if the devs are doing this a lot. Any thoughts as to why I'm seeing this: Errors for PROCEDURE KILL_DEV_SESSION: 

But hey, what is life without a challenge? I'll work on that, then perhaps post another question to the forum if I can't resolve the issue myself. Thanks for the help. 

Oracle specifically split out the sysaux from the system, and IMO this was a good choice by them. Essentially, without going deeply into the documentation which you can read for yourself, SYSAUX stores things like statistics history, non-essential performance views, and other pieces of metadata that may or may not be in-use in a particular database, depending on what that database is used for. It is sort of a "separation of duties", and allows for easier manipulation of these non-critical objects w/o SYSTEM level downtime (I'm generalizing here, 11g isn't 100% perfect in that regard). I'd break it down like this, as-if the database was the human body: SYSTEM is your nervous and cardiovascular system. You cannot live without it. SYSAUX is all of the other systems of your body - you can survive without them but for optimal performance it's best to keep them in good working order. 

First, let me state that I think that running anything as the non-oracle user on your filesystem may result in significant database issues! (I'll explain why in a minute) Aside from the pathing issue, which you solved, I think that Colin is correct. You (or your admin) does need to give read on the binary: 

I prefer to use the RMAN clone method. The overall method is to start with the PROD database, and then a DEV database that is in a NOMOUNT state with all datafiles/controlfiles/tempfiles/archivelogs removed: 

is probably the best starting place. In that view, you can pass in the view you're looking for in the field. If you want to see who has permissions to more than one view, you could always use a sub-select on the view to then see what the on that view are. However, depending on how your database was implemented, you may also need to look at role information. Using may only show you the roles that have select on the view(s), from there you'll have to use the series of views to determine which physical users have been assigned those roles. 

Don't get hung-up on "cloud" vs "local" - what you're doing is establishing a TNS network link between two databases. It is nothing more than that. In order to do this, you will need to have the appropriate tns entries configured in your tnsnames.ora (unless you are using LDAP or you pass in the entire connect string). If you don't know how to do this, the netca application will create one for you using a wizard. Once you have this tns entry, you can simply create the database link as you listed above, but replace the USING clause value you have with the tns entry alias. $URL$ 

First, let me say that you haven't listed the version of your RDBMS, so I'm going to assume you're running a version that utilizes the Cost-Based Optimizer (CBO), as opposed to the Rule-Based Optimizer. The CBO was introduced in the 10g series of databases, so I think this is a safe assumption. If you're still running a 9i or earlier version, my answer won't help you. So your question is "will inserts stop my RDB from using an index?". The easy answer here is no, they won't. Your database will continue to use the index it used before, as a_horse_with_no_name mentioned in the comments that the rows will be maintained automatically in the index without any extra effort from you. However, there is a chance that the volume of changes could impact the performance of using that index, which is something that you need to be aware of. How? Take the total row count of all rows that could be included in an index (remember we cannot index nulls). Then consider the number of inserts you've done - is this number >= 10% of the existing rows? If the answer is yes, then your statistics are now considered out-of-date. Luckily, by default Oracle's later versions installs an overnight job (usually running around 10pm local server time) that will automatically gather statistics on any table & indexes where it senses a 10% or greater change in the count of rows. But, if you are doing something outside of ordinary processing, say adding a significant amount of rows due to a one-time data load, you may very well need to gather stats yourself sooner than the automatic job. Also, in my experience, the automatic job only has a certain window of time in which to gather stats, so it's possible that it won't be able to gather stats on all objects if large amounts of data was manipulated across many objects. My point here is that changing data volumes significantly in a short period of time can lead to performance problems not because your indexes will be bad, but because in a Cost-Based world, the Optimizer will have bad information, and will make bad decisions. I bring this up because you seem focused on indexes, which are only one tool in a much larger toolkit to having a well performing database. HTH. 

However, without knowing more about the table, I don't know if the TIME column is simply an integer, or is a date/timestamp field. If it is date/timestamp, SUM won't really do what you need it to. One other word of caution, using rownum doesn't always return the same results between runs. Please take a look at $URL$ for a much more succinct explanation than I can provide. 

Here's how searching for any object works (this example assumes the user has appropriate permissions, and that you didn't make the call as "schema.table") 

I have been tasked with allowing developers to kill their own sessions in the Development database. I've written a procedure, but for some reason I'm getting when trying to call . Here's the proc, being compiled as . Running on an 11.2.0.4.3, 2 node RAC database: 

This will create a compacted index of only the rows with a 1 value. As long as you keep this 1 value at 1-5% by aging out rows, you'll see great performance. Not that partitioning won't work, but it does cost extra, while function based indexes do not. For reference, $URL$ (9i version), scroll down to "When to Use Function-Based Indexes". Again, I know you already accepted an answer, but I wanted to throw this out since you seem open-minded about possible options. 

Search the current schema for that object Search private synonyms for references to that object Search public synonyms for references to that object