For 10BASE-T and 100BASE-TX, the MDI side (NICs, routers) transmits on pairs 1-2 and receives on 3-6. On the MDI-X side (hubs, switches) the pairs are swapped. In general, concentrators use MDI-X pinout while edge devices (from the L2 segment perspective) use MDI pinout. Whether the link uses full or half duplex doesn't matter. Auto negotiation takes only care of speed and duplex settings. Automatic send/receive pair negotiation is called Auto MDI-X. Auto MDI-X is defined in IEEE 802.3 clause 40.4.4 and was added alongside 1000BASE-T in 802.3ab-1999. Auto MDI-X can almost be taken for granted today. Devices not implementing it are rare, especially with gigabit+ ports where it doesn't even require any additional hardware. 

Not exactly sure about any Junos specialties but with 'standard' regex, matches any two characters, repeating or not. If you'd need two of the same character it should be looking something like . matches two or three of any character (same or different). 

Bridging your LAN and the WAN link is a terrible idea to start with... You don't need a 2nd physical interface on your firewall but you do need a 2nd logical interface. 

When the gateway address for a route points to one of the host's interfaces it means "I'm the gateway, I'm able to transmit to this destination directly." 

As it seems, each node splits off two 位s from the fiber loop, each originating from one of the other nodes. Then it adds its data on (the same) two 位s to the remains on the fiber and passes on the loop. Each 位 addresses one of the other nodes as per the table. Follow each 位 from the transmitter to the receiver and you'll get the picture: 

Probably the baud rate is fixed to something you didn't try. If you can run a telnet or ssh session, you can check the serial console setting with . You can reset to default settings by 

DHCP has the benefit of central management and potential scripting. If you intended to split your network into /24 subnets it'd be very doable with DHCP. Additionally, you can very easily change options such as DNS servers, gateways, domains, NTP, ... 

Items 2. and 3. are more or less ugly hacks and may easily a become a source of trouble once you have to replace your switches, so the only real solution besides Q-in-Q tagging is renumbering your VLANs... 

Your network might just be severely congested or there's something wrong with the port configurations or the general design. 

It's a universal PSU - 12 A is for ca. 120 V and 6 A for 230 V AC. Note that this isn't what's pulled all the time, it's the peak current on startup, peak load etc. 

What you need is the distance to be covered and the speed of the signal. The distance of an arbitrary point on the globe to a point above the equator can be calculated by the cosine rule. The speed of the signal - well, you've probably got that. btw: geostationary orbit is 35,786 km above the equator, so it's more like ~36,000 km. 35 km is well within the atmosphere, much too low for a satellite (about 50% higher than the normal flight altitude of an SR-71 and somewhat below Baumgartner's and Eustace's stratosphere 'space' dives). 

Your rendezvous server requires some kind of coordination protocol (ICE?) - this could use a token, user name, or something similar to connect both sockets coming from different directions into a virtual session. Their originating port doesn't matter. However, this is no function of NAT and higher level protocols are off-topic here. 

I haven't seen a device supporting DLEP yet. LLDP is widely supported but only works on the link level, so it would discover only directly connected devices. LLDP messages from devices behind (802.1D compliant) switches will not reach you. However, given access to the discovered devices you could use SNMP to query their LLDP database and work your way through the network. What you're looking for may be ICMP Router Discovery Protocol for IPv4 and Neighbor Discovery Protocol for IPv6. 

Network classes are dead and buried since 1998, check RTF 2317. A router can use any free IP address of a subnet. The host parts with all zeroes or all ones are used for the network and the broadcast address respectively, of course. 14 hosts plus one router don't fit in a /28 subnet. In real life, you'd usually use a subnet mask of /24 with private addresses, so you'd have plenty of space for your small numbers. Public addresses are scarce nowadays, so you'd probably use IPv6 to start with. 

A NIC covers layers 1 and 2. Promiscuous mode is when the NIC ignores the destination MAC address which is part of layer 2. Normally, a NIC ignores all frames with a destination MAC other than their own or the broadcast address. Monitor mode only exists for wireless NICs - when they receive independent of their (logical) link status all the time - more or less a layer 1 thing. 

Mostly agreeing with the answer above, you're completely right in that this should work. My guess is that the receive level is a little too high and that the receiver fails to give a more meaningful reading in that domain. Physically, it's impossible to receive more power than has been transmitted, of course. 

When both ingress and egress interfaces are VLAN trunks the tag should keep the same VID. You could also say that the tag is removed on ingress and a new one inserted on egress however. Some dumb (802.1Q non-compliant) switches ignore 802.1Q tags and leave them on a frame. This can lead to various (more or less) strange effects and may cause bridge loops. You should never trunk to an unmanaged switch. 

Multiple public IPs: each server requires a different public IP that clients are forwarded from Single public IP, easy and ugly setup: run servers on different ports on the public IP address and forward accordingly Single public IP, more sophisticated setup: install reverse proxy that you forward clients to, separate servers on the application layer and forward from proxy to associated server (correctly speaking, this is not 'forwarding' but a new TCP connection); HTTPS needs to be terminated on the proxy. 

IEEE 802.11 wi-fi uses the same framing as Ethernet (with some additions) and usually that's Ethernet II. 802.11 frames can be somewhat larger (2304 bytes payload) than Ethernet's (1500 bytes payload) but very often both are bridged together and use Ethernet's MTU. 

It's not just an optimization library. DPDK is about controlling hardware functions through a framework with an Environment Abstraction Layer (EAL) that provides a general API for various device types, hiding the actual complexity. You can write your SDN device as an application using this framework. 

A successful ARP resolution is required for two IPv4 nodes to communicate on a common layer-2 segment (usually Ethernet). Incomplete ARP requests have two basic reasons. 

If DNS doesn't work, nothing relying on it will. Obviously, you're having a problem with 'routing' UDP packets (you more or less implemented a stateless NAT router). UDP uses a "pseudo IPv4 header" for the purpose of calculating the checksum. If you don't recalculate it as well the packets will get dropped. As Ron's pointed out, TCP uses the same concept and requires checksum recalculation inside the segment. 

There are various reasons when servers that should be in a single segment are geographically remote, including: 

In addition to the already present, good answers: The preamble is an essential function of the physical layer. Note that when you serialize data to a single bit or symbol stream you need to provide some form of synchronization - first to bits/symbols, then to words. The symbol pattern the preamble generates on the wire (it's really only 01010... with 10BASE-x Manchester code) allows the receiver to tune it's symbol clock to the exact speed of the transmitter. It will know how many symbols it has just received even if there's no change on the wire. (All physical layers provide means for intermediate synchronization as well, so it's a continuous process.) The SOF pattern behind the preamble marks the beginning of the first word (or octet/byte). The receiver activates its buffer and clocks the decoded bits into it, deserializing the bits coming out the decoder and transmitting it to the buffer word for word. It doesn't matter if it's a byte or a 32-bit word at a time, but it's important that the byte boundaries are correct. So, preamble and SOF are necessarily part of the physical transport mechanism, thus belong to the physical layer. From the layer 2 perspective, a frame doesn't require a start marker - it just starts with the first octet coming in. 

$URL$ This needs to be included in the startup procedure, it doesn't survive a reboot. To avoid any possible duplicates you should use a locally administered MAC (LAA) with the first octet's bit 1 set to 1, i.e. the first octet needs to be divisible by two but not by four (x2, x6, xa, xe). An alternative way to handle the problem is to use L2 broadcasting at all times - this is an ugly hack, so it should be done on a separate segment for these devices. On the source (or the router connecting these devices) set up a static ARP entry for each device with its IP address mapped to - this way, the switch is used like a hub and every packet is sent to every device. Each packet is received by every device but unless the destination IP matches it gets dropped again. On the devices, routing must be disabled to avoid them trying to forward non-local packets. 

When VLAN 10 is tagged on egress from switch A but unknown in switch B the frames will be sent on the link and dropped by switch B. When VLAN 10 is untagged on the egress port all frames enter the untagged VLAN on switch B. The same with your second question: the switch sends traffic for all allowed VLANs on the link, whatever the receiver chooses to do with them. 

As stated, you can actually run Ethernet over any two or four twisted pairs. The higher the speed and the distance, the better your cable needs to be. Any splice or tap will severly reduces cable quality and possible speed and distance. Gigabit (1000BASE-T) actually works on four-pair Cat.3 but only over a very short distance (a few meters). Fast Ethernet (100BASE-TX) requires only two pairs and is much more lenient, I used a 15+ m run of Cat.3 for a while without problems. 10 Mbit Ethernet (10BASE-T) runs over close to everything for a few dozen or even more than a hundred meters. Note that Ethernet ports don't automatically link at a lower speed when the cable is sub-standard, you need to configure the ports down. If you do so, do it on both sides or auto configuration will fail and may easily cause a duplex mismatch. Also note that you can't run a productive link over such a cable without very close monitoring of the error rate.