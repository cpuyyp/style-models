In this case the first query returns all the account and address records updated since a specific date (2015-07-01) and the second query returns all the accountshare changes updated since a specific date (2015-07-01) and I need because that table along with group match targets to territories. 

are parameters coming from PHP and that's my only problem. How do I pass a parameter to a view if it's possible? I am using MySQL 5.6 at the moment. 

But I don't know how to properly do the FROM clause and/or how to order the JOINS and if will be better to use LEFT or just JOIN. Also I am not sure if I can get every media for each row or I need to separate that into two queries. Can any help me to build this queries to get the expected output? 

I want to get the rows on between and meaning the rows between last sync_time and previous sync_time for a given . I was doing this: 

I am working in a player versus computer web application which is a version of "Rock-Paper-Scissors-Spock-Lizard". I should be able to provide some statistics like for example: 

Can any give me some help? EDIT Because has duplicates (a table with no restrictions at all - see image below) I need to clean up a bit the trigger before execute. 

Trigger won't work since it has a lot of issues and I am trying to fix them so, between lines and I should perform a query to and get current row based on because that already exists and then I should pass values on that to the statement just before comment, how I can achieve that? 

I'm running in CentOS 6.7 server. I'm trying to get queries logged and I'm doing by redirecting log to files as shown below: 

I need to delete each row in (fps from now on) table if has not relation (NOT IN) (fmmp from now on). Since my input will be an array of values (fps.id) as for example: 

That's the error you get when you restore the master database from a server with AlwaysOn Availability Groups configured, or try to restore additional user databases onto a server that had the master database from an AG replica restored. Don't restore the master database from an AG replica onto a different SQL Server as the master database. If you absolutely have to restore master to get user objects out of it, restore it as a different database (like master_old) and then transfer the objects you need. 

There's two things involved here: the version number of the file, and the compatibility level. When you attach a database to a newer major version (like from 2008 to 2008R2, or 2008R2 to 2012) the database version is changed permanently, and you can't attach that database to an older version again. The compatibility level is for parsing old-school deprecated T-SQL that used to work in older versions of SQL Server. It doesn't change how the data is stored on disk. To give the database to someone on an older version of SQL Server, you'll need to export the data and import it into another database. Tools like Red Gate's Data Compare are helpful for this. 

There are a few different questions in here. Do all drives safely flush data to disk when power is lost? No. Consumer-grade computers and drives often don't include their own battery backups or capacitors. If power is lost without warning, they can lose data that the OS thinks was safely flushed to disk, but is actually still living in cache. Does SQL Server work on those systems? Yes, but its ability to recover from a power failure is unpredictable. It's fine for things like development environments where you should be checking your work into source control anyway. Should SQL Server go in production on those systems? It depends on what you're using the data for, whether the data is recoverable (for example, TempDB is perfectly fine on drives like this, since it doesn't survive a restart anyway), whether the data center has its own redundant battery backups, etc. 

And I need to keep repeating the same queries all the time for get those types of statistics. Is there any other approach or a better way to achieve this? I am using MySQL 5.6. 

I have a file with a bunch of data which I am using for load all the data into a DB table. The file lacks the ID column (because that's is an internal column managed through our software and they don't care about it). To avoid issues with the data my "solution" was to move the column to a position where doesn't interfere with the data from the file and that's right after column or just at the end. Check the following image for a graphical representation of the table: Currently the is my first column and I haven't any problem but I am trying to move to the end because the issue I am having with the data but I got the following error: 

Right now I am running the same script (made in PHP) and changing all the time the slave database (in the figure db1, db2, db3 act as slaves) and I want to change that. I have the following query that returns data from table: 

But it's taking an eternity because the large size of the resultsets. I've tried to separate in two queries and then JOIN them but is the same takes to much time: 

Now, regarding performance, disk space savings, query savings and so on, how would you do that? What is your recommendation on this edge case? Note: for the moment I am using MariaDB 10.1.x but this will be in a MySQL instance, probably 5.x or so I am not sure at all since I didn't got those details yet 

Which make me ask: what value I should set for parentheses when I am defining a type. (I am using BIGINT because I don't know if INT can hold as many numbers as a phone could have - perhaps I am wrong too). Which is the right way to create|design a column in MariaDB/MySQL databases? Anyway I would like to know your opinion, experience and of course I would like to get an answer Note: I am using MySQL Workbench latest edition for create the ER diagram. I am using also MariaDB 10.0.x 

That code can fail. Long term, consider using GETUTCDATE() instead and storing dates with DATETIMEOFFSET - but that's a big code change that you can't really do quickly before changing the date on a server. 

If you want to create a stored procedure to restore a database, put that stored procedure in master itself (or in another database, but just not the one that's about to get restored, since you can't kill a connection while still running a query from it.) You won't need any "use database" commands in there at all. Finally, as long as we're talking about restoring databases, check out sp_DatabaseRestore in the open source First Responder Kit. If you're using Ola Hallengren's excellent maintenance scripts to take your backups, you can just point sp_DatabaseRestore at your backup folder, and it'll automatically restore the newest available backups of your database. (Disclaimer: I'm one of the contributors on the First Responder Kit repo.) 

It's way easier than it sounds. Then your stored procedure can have the business logic to check to make sure the database doesn't exist, plus you can put in more stuff like checking that there's enough drive space to safely restore the database, that they're putting it on the right drives, etc. I can imagine even coding in a max number of databases that can be restored - for example, once we've hit 50 restored databases, don't allow any more - it's time for the user to clean house. The stored proc would have input parameters for backup file, target database name, and folder path(s) for the restored files. You might find the logic in the MSSQLtips post on automatically generating restore scripts useful too - point it at a folder, and it gets the latest full, diff, and t-log backups and generates the restore statements. 

In theory, Azure Data Sync does this, but it's been in "preview" status for years, and there's a lot of gotchas. Read the documentation carefully to see if its limits can work for you, and just know that in a preview program, Microsoft can end up removing support for it later. A better solution would be something like SSIS jobs to keep the data in sync, but that's obviously not easy, either. As your tables change, you'll need to keep changing the ETL jobs. 

For row it means: Service1 will be available for users of type 1 and Service2 will be available for users of type 2,3 and 4 only so in register form for users of type 1 I should only show the Service1 option and for users of type 2,3 or 4 then Service2 will be showed, I need some help building a query for get that data or help to change my model with better solution to that problem, any? 

After each on I execute a trigger that update table by setting up the right based on relationship from . This is the code for the trigger: 

Table tbl_database contains ~194 074 records and they should continue to grow in large numbers, table tbl_cmdatabase contains ~45,742 records and similarly can increase but perhaps not so exaggerated as tbl_database but would increase and finally the table tbl_blacklist having ~92,038 records. I am developing an application where I need to verify that the number that I will insert into table tbl_database is not in tables tbl_blacklist and tbl_cmdatabase so I need to check for every row looking for the number (this queries are slow in this amount of records). What I need to do is to optimize some tables or change the structure or not because when I perform these queries the server tends to fall as the shared hosting does not support large queries, anyone can help me with this issue? Any suggestions? Edit: Added a file for test data 

What could be wrong here? Why logs are not being sent to those files? UPDATES @rick-james: I did check permissions by running: 

I am working in a PHP application and some "complex" queries are starting to appear in the code. Because of the complexity I am not able to use any ORM and the only resource I have is a plain SQL and PHP MySQL native functions which I don't like. Without more here is one of the queries I want to convert into a view: