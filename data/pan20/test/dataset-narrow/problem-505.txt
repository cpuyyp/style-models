The points you've specified in your question actually show that you (almost) see issues in your code yourselves, so thumbs up for that. I'll only expand on your points plus add a couple: 

I would call this method or similar, since the main action here is actually capturing a timely-limited resource. Result of the method specifies whether resource has been acquired or not. You may also call it to highlight the fact that acquisition may fail. As a side note - you can rewrite the code without locks in case if that's the only place you use the . It will be a bit more verbose though... 

So by caching you'll reduce the time consumption by 75%, and by caching both and you get a nice 33.5X performance boost :). 

The best way to answer this question is to measure the performance and see if it satisfies you. If not - then start thinking about caching results and refreshing them instead of calculating from scratch. 

You have a bug in your code: can return a new instance, and you ignore this instance when calling and . Also, I do not see the reason to iterate on simplification (), as it appears as each expression will only need one call to be simplified. class exposes 2 public fields, and . Exposing public fields is a bad practice, and I would assume there may be cases where expression can have 1 or more than 2 "parameters". Can you make use of Expression Trees available in .NET instead of developing your own framework? It seems like a good fit for your purpose. If not - I would still consider copying design patterns from it, like immutability of expressions and Visitor pattern for walking the expression tree. 

Update: I did miss the point of having just a single thread that does the heavy work... You're right about using , this is the best structure to be used here: 

And the usage will look like this (note that now all exceptions from third-party library will be passed through as if the code ran on the same thread) 

What you have done is usually called a Maybe Monad. There are several implementations of those for .NET (one, two), and usually they just use extension methods to apply operations to nullable object. Concerning your code: you don't need a hierarchy here, since most of the code is already in base class. 

Solution can be optimized even further in terms of readability, with the same level of performance as "manually create a HashSet and populate it with items": 

We can use the fact that in the ordered sequence of cards the cards that match your requirement will be located at the beginning of sequence, and their rank will match their position: 

Generally the most flexible solution (as I see it) would be to implement a repository and unit-of-work pattern (similar to in NHibernate or in Entity Framework). Basically it's better not to hide communication with 3rd-party but rather expose it in such a way that you have maximum control and flexibility. Primitive implementation may look like: 

Correct. See good article Await, SynchronizationContext, and Console Apps that describes in details the behavior of . 

Update In comments it was asked if you can extract interface for ColumnDataBuilder. Of course you can :), and the easiest way would be to use "Extract interface" refactoring from ReSharper :). If you still don't use it you'll have to do that manually (move the and declarations out of first): 

You should never generate dynamic SQL by concatenating incoming values into an SQL string that is executed later. This type of code leads to SQL injection vulnerability, and by using your service as it is now it's very easy to get access to any user account without knowing its password. If you plan to develop your service further take your time to learn one of the ORM frameworks (Entity Framework, NHibernate, or maybe one of the NoSQLs like MongoDB or RavenDB) and get rid of low-level DB management code from your service. Alternatively (if you prefer inventing a wheel :)) move DB-related code to separated class and name it "DB repository" so that your service doesn't have too many responsibilities (currently it has business logic responsibilities combined with DB access management). About exception handling - here is a good article that describes what you should and should not do. Basically you should only catch specific exceptions, and only if you know how to recover from that exception in a meaningful way, that doesn't leave your application in an inconsistent state. In case when WCF service has no way to return a meaningful response (e.g. when response is based on DB data and database is not available) you should pass exception to the client. And finally, store your connection strings in the configuration files rather than hardcoded. 

In a quick test this method was about 3 times slower than shuffling in-place using random element swapping (@Abbas solution). Note that strictly speaking it is not equivalent to other solutions since it creates a new enumerable rather than shuffling elements within existing list. 

I know it's not a direct answer to your question, but I'm trying to get to the roots of the problem rather than giving correct answer to issue caused by potential misuse... In your code what you are actually trying to do is to write a cache with time-based expiration of items. Even though is thread-safe, it's not quite appropriate structure for frequent element scans like you do. Moreover, in your code you remove items, then add them back in case when they have been updated in the middle. It causes side effects for other threads that may try to read the value in-between. Correct solution would be to use a proper data structure. If by any chance you are using .NET 4.0 or later .NET has already provided you with proper solution - class, otherwise I would recommend creating a lock-based class that maintains 2 indexes for entries - a for storing key-value pairs, and a for storing expiration timestamp-key mapping. In this case you'll always know upfront when the next expiration will happen so timer can be set to specific , and you don't have to scan through all cache entries to find expired ones. 

Your code is absolutely correct in case when you want to start workflows only when all of them are configured. But if you want to start each workflow once it's configured (independently from other workflows) then it might be a good idea to use continuations... In .NET 4.5 it would look like this: 

You're definitely going in a wrong direction. Instead of trying to synthesize some weird generic classes in attempt to find a common general pattern in "I send request and receive a reply, in each case requests and replies are different classes", you should start from designing the interface of your communication, so that other layers of your system are abstracted from technical implementation of COM/Web service/whatever protocol you have to deal with. Based on your comment: 

Since you've asked for suggestions to clean up the code, here is my list of what I would do with it: 

Note that it doesn't actually test the fact that allows only one thread at a time, it just ensures that nothing fails when multiple threads call this method. There is no way in current design to detect it. What I would suggest is to expose the fact of long process inside of by returning a that any thread can wait on: 

There are a number of naming issues here so it's quite hard to understand the code, I'll start from those: 

I'd rather use the and as primary keys, because your logic ensures them to be unique. In case of your current solution you would still require (unique) indexes on these fields (in order for lookups to be efficient) so there is no reason not to use them as primary keys. Given suggest optimization you don't need to check/insert an author record , just use the merge to insert/update the data in the table, and create a separate SP that will do the same job for Authors. 

Defining the shape drawn is a pretty simple trigonometric exercise: you have coordinates of your starting and ending circles (x1,y1 and x2,y2), and a bunch of similar right triangles. Here is the calculation of your points: 

Since we are talking about sets, it's probably better to use collection types that represent a set: and . Another improvement you can make is to keep track of the boxes you've added to current set at the last iteration (horizon of your expansion), and try to match candidate boxes only with them. Note that resulting solution doesn't use the knowledge about box matching logic, so it might be a good idea to extract the interface that defines the connection between elements (i.e. a method that checks for the presence of link between nodes). As a result I've got the following solution: 

You should introduce Dependency Injection so that receives the object of type rather than instantiates it itself. Once you've done that you can write tests by injecting stub of into . In your current code there is no need in creating mock for since it's the object under test, and you can instantiate it directly (you can use mock for object under test e.g. if you're testing abstract class). Also you may not need stub for object (it looks like a data object) if you can instantiate it with required configuration yourselves. Fixed code for your current implementation: 

is what you're looking for. Otherwise, if you do need to use , try using to run comments retrieval in parallel: 

In addition to Jeff's changes (I completely agree with all of them) here are my 2 cents: I assume this class may process large number of documents, so it's better to switch it to using streaming techniques where you are not required to keep all the data in memory. So, let's start with constructor... it's usually better to move time-consuming logic out of constructor, e.g. you may later want to introduce asynchronous implementation. So we get rid of constructor and move all the logic into method. By following "streaming" technique it should receive IEnumerable instead of pre-loaded array of documents. We will calculate all the stats for each document and then forget about it, so all the arrays that expected a known number of terms and documents should become lists (except as it have to be calculated later, when the total number of docs is known). Here is the resulting code for your class: 

We "walk" through the collection once to build a lookup table, and go through the list once to replace elements that match the item in . 

Not sure if you need interface, added it so that you don't loose the possibility to reference both types of entities in generic manner. Yes, you'll have to declare separate IntEntityRepository and GuidEntityRepository, but I don't think it's that hard given that you can extract common code to base class, and it's a one-time job. As to mappings - I don't use class hierarchy for them (declaring all the fields on the actual entity mapper), but you can do the same trick as with repositories. 

method (if applied to ) is O(N) operation, and it's a lazy operation so it will do the filtering while consumer reads the result. 

Your code is correct as long as you plan to validate business integrity using triggers. But I would question whether business validation in SQL Server is a right choice: 

Can I try to convince you that you don't actually need such a class at first place? How do you actually use the string value of this class? Do you show it to user? If yes, then what would you do when you need to make it multilingual? What I'm trying to say is that verbal interpretation of "success" or "failure" should actually be done on UI level, and class is not a UI. Also there is usually a single "success" case. You may say that you might want to differentiate several failure cases, but those are best described by a nice technology called exceptions. So, what do we have beside ? A boolean flag. That's what we probably want to return in case if we're interested whether something was successful or not... but wait. What usually happens when something goes wrong? Exception. And it would probably be more useful to let the business code process this exception, as the same exception may be treated differently in different situations. Now let's go back to your code. You class doesn't have a state, so let's make it static: 

It depends on the meaning of this constant. If the value has logical relation to (e.g. it means that it should go right before in some list) then just use there, but if it's just - then either define a new constant or just use as value, depending on situation. What I would suggest is to rename to more meaningful (descriptive) name unless it's a well-known acronym in your company. 

Even if your solution is (almost) correct, the actual problem is in a wrong formulation of the problem. The main issue in your question is the assumption of a certain order of records within a table. In reality SQL Server cannot guarantee original order of records when you do a statement without clause, even if you have a clustered index defined. In order to properly map 2 tables you must have a criteria for matching records. You provided a solution that won't generate consistent results. Imagine that you need to add another student/subject () and a mark for that. If you add one record to table and one record to table your data will be screwed up since record will be matched against 3rd record (). In order to fix the issue you must add a field or fields that allow unique reference of records, that is you must add both StudentId and SubjectId to table. Alternatively you can create a surrogate key in the table and use it as a reference in table. UPDATE. The main difference between original question and example in Edit section is that records can be ordered by unique key (primary key) in latter case, while in original question didn't guarantee specific order and produced inconsistent results. Your updated example is using mapping properly, according to (updated) requirements, and will produce consistent results as long as and are unique in corresponding tables