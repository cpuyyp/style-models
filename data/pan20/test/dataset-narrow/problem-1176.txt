This problem was studied in the following paper. Abdol-Hossein Esfahanian, S.Louis Hakimi, On computing a conditional edge-connectivity of a graph, Information Processing Letters, Volume 27, Issue 4, 1988, Pages 195-199, ISSN 0020-0190, $URL$ The idea is identical to Saeed's method, contract pairs of edges and find a min-cut. However, one can be more careful and show $O(m)$ pairs are sufficient. 

Let $y_i=\min\{b_k| i\in J_k\}$. Observe for any feasible solution, $x_i\leq y_i$. Claim: The system of $\max$ equations is feasible iff $x_i=y_i$ for $1\leq i\leq n$ is a solution. Proof. If $x_i=y_i$ is a solution, then the system of $\max$ equations is feasible Consider any solution, and $x_i < y_i$ for some $i$. We can increase $x_i$ to $y_i$ without violate any equation. Assume it violates the $k$th equation, namely $\max\{x_j|j,i\in J_k\}=b_k$, then it implies $y_i = \max\{x_j|j,i\in J_k\} > b_k$, but that's a contradiction because $$ b_k \geq \min\{b_j| i\in J_j\} = y_i = \max\{x_j|j,i\in J_k\} > b_k $$. The algorithm is just compute $y_i$s and check if it satisfies all the equations. This takes linear time. 

There is a randomized algorithm for computing Gomory-Hu tree in $\tilde{O}(|E||V|)$ time when all edges have capacity 1. Once you have the Gomory-Hu tree, you can process it so you can answer maximum flow queries between two vertices in constant time. 

We can reduce this problem to your problem: Split each vertex of $G$, so each vertex $v$ in $G$ become $v^-$ and $v^+$, and edge $uv$ become $u^+v^-$, also there are edges $v^-v^+$. Add one new vertex $u$, and edges $t_1^+u$ and $us_2^-$. Let this graph be $G'$. There exist a path from $s_1^-$ to $t_2^+$ in $G'$ that uses $u$ if and only if there exist a node disjoint path between $(s_1,t_1)$ and $(s_2,t_2)$ in $G$. 

Given $G$, $C$ and $M$, where $G$ is a graph with maximum degree $3$, $C$ is a hamiltonian cycle of $G$, and $M$ is a matching of $G$. Let $\mathcal{N}$ be the set of all matching of $C$ with size $|M|$. We want to pick a $N\in \mathcal{N}$, such that the number of cycles in $M\cup N$ is maximized. Here we also define edges in $M\cap N$ to be cycles. Is this problem NP-hard? A cool way to visualize the problem is consider $n$ points on a circle and some endpoint disjoint chords between the points. We want to connect adjacent points with disjoint arcs to maximize the number of cycles. 

There is the common dynamic programming algorithm taught in algorithm classes, which takes $O(n |X|)$ time. It takes $O(n^2)$ time for large input sets. It's not hard to devise and output sensitive version that takes $O(|X||S_n(X)|+n)$ time. It's possible to solve it in $O((n \log n)^\frac{3}{2})$ time by decompose the problem to $\sqrt{n\log n}$ ALL-SUBSET-SUMS with small output size, and we can combine the solutions through FFT. How fast can we solve this problem? There are subset sum algorithms using analytical number theory[1], but they have many technical conditions on the input. It can't be applied directly on ALL-SUBSET-SUMS. Reference: [1] M. Chaimovich , G. Freiman , Z. Galil, Solving dense subset-sum problems by using analytical number theory, Journal of Complexity, v.5 n.3, p.271-282, Sept. 1989 

My feeling on all of these after having though about it a bit is that an exponential increase in size is needed in most of the cases, or that the results must be nondeterministic. So the question is really: is anybody aware of a place where this kind of problems have been addressed? Has this variant of finite automata being studied before? 

The answer was buried in a small section of the same paper that I was citing. Adding past operators to TPTL, in contrast of what happens with LTL, causes a huge increase in complexity as the satisfiability problem becomes non-elementary. The fact is proven in the paper by showing how a mixture of future and past operators, combined with the freeze quantifier, can emulate an arbitrary first-order existential quantifier. 

Your argument proves that $\mathsf{NEXPTIME}\subseteq\mathsf{EXPSPACE}$, since if a TM terminates in (nondeterministic) exponential time it cannot write to more than an exponential number of tape cells. On the contrary, if a TM uses exponential space it can still run in doubly-exponential time, e.g. a TM that increments a binary counter of $2^n$ bits until wrapping uses exponential space but runs in $\mathcal{O}(2^{2^n})$ steps. So the problems that you’re looking for are those that require at most exponential space but whose running time cannot be bounded by an exponential (even though it can be bounded by a double exponential since $\mathsf{EXPSPACE} \subseteq 2 \mathsf{EXPTIME}$). I don’t have a specific example problem in mind though. 

Consider a kind of automata similar to common DFAs or NFAs where it is possible to represent succinctly linear chains of states. In other words, an automaton like this: 

Given two NSAs $\mathcal{A}$ and $\mathcal{B}$, is it possible to build the NSAs for $\mathcal{L}(\mathcal{A})\cup\mathcal{L}(\mathcal{B})$ and $\mathcal{L}(\mathcal{A})\cap\mathcal{L}(\mathcal{B})$, of size still polynomial in the size of $\mathcal{A}$ and $\mathcal{B}$ (i.e. without paying for the unrolling of the chains before computing the results)? Is it possible to compute those operations on DSAs (deterministic) guaranteeing that the resulting automata stay deterministic (and still polynomial size)? Is it possible to determinize an NSA with only a singly-exponential blowup (i.e. without paying for the unrolling of the chains before paying for the classic determinization)? 

This question is important in functional programming since usual representation of graphs are inelegant and inefficient to use in purely functional languages. A nice approach was presented at ICFP last year: "Algebraic Graphs with Class (Functional Pearl)", by Andrey Mokhov. I don't know if it fully answers your needs, but it can represent algebraically a wide range of different types of directed and undirected graphs. 

For a simple graph, the local edge connectivity of vertices $x,y$ where $x\neq y$ is $\lambda(x,y)$ and defined as the maximum number of edge disjoint paths from $x$ to $y$. One can find this by a maximum flow computation. Define that 

For a graph $G=(V,E)$ with $n$ vertices and $m$ edges, a subgraph of $O(kn)$ edges is an $r$-rooted-$k$-sparsifier if it preserves the local edge connectivity from $r$ to every other vertex up to $k$. Namely, it is a subgraph $G_k$, such that $\lambda(r,x,G_k)\geq \min(\lambda(r,x,G),k)$ for all $x\in V$. Here $\lambda(x,y,G)$ is the maximum number of edge disjoint paths from $x$ to $y$. For undirected graphs, Nagomochi and Ibaraki shows such graph exist and has an algorithm to find a $r$-rooted-$k$-sparsifier in $O(m)$ time. In fact, it finds a subgraph preserves all local edge and vertex connectivity. Are there similar results for directed graphs? Or are there a proof that a $r$-rooted-$k$-sparsifier cannot exist for some directed graph? 

Let $S(X) = \{\sum_{i\in Y} i | Y\subset X \}$, the set of subset sums of $X$. $S_n(X) = S(X)\cap \{1,\ldots,n\}$. Consider the following variant of subset sum. 

Let $d^+_G(x)$ be the in-degree of $x$ in graph $G$. Theorem (Lovász 1973): For a directed graph $G$ and a specified vertex $r$, there exist a subgraph $G'$ with the property that $d^+_{G'}(x) = \lambda(r,x,G') = \lambda(r,x,G)$. The desired sparse graph exists, as we can keep removing edges to reach a minimal graph with the desired connectivity property. 

Let $f$ be the running time of calling the oracles, and assume $f=\Omega(m+n)$, then one can find the sets in deterministic $O(f k \log n~\mathrm{polylog}(m))$ time. [1] Now we can reduce the finding witness problem to $1$-reconstruction problem. Here $S_1,\ldots,S_{2n}\subset \{1,\ldots,2n\}$ where $S_i = \{a|a+b = i, a\in A, b\in B\}$. Define the polynomials $\chi_Q(x) = \sum_{i \in Q} x^i$, $I_Q(x) = \sum_{i \in Q} i x^i$ The coefficient for $x^i$ in $\chi_Q\chi_B(x)$ is $|S_i\cap Q|$ and in $I_Q\chi_B(x)$ is $\sum_{s\in S_i\cap Q} s$. Hence the oracles take $O(n\log n)$ time per call. This gives us an $O(n~\mathrm{polylog}(n))$ time deterministic algorithm. [1] Yonatan Aumann, Moshe Lewenstein, Noa Lewenstein, Dekel Tsur: Finding witnesses by peeling. ACM Transactions on Algorithms 7(2): 24 (2011) [2] Noga Alon, Moni Naor: Derandomization, witnesses for Boolean matrix multiplication and construction of perfect hash functions. Algorithmica 16(4-5) (1996) 

Here is an example of a non-trivial good matrix. $$\left( \begin{array}{cc} \frac{1}{2} & -\frac{1}{2} \\ -\frac{1}{2} & -\frac{1}{2} \\ \end{array} \right)$$ 

To clarify, I'm looking for dictionaries with space requirement as a function of the size of the universe, and not the number of elements in the dictionary. 

I'm concerned with the validity problem for sentences of first-order logic over finite words, i.e. $FO[\le]$ interpreted over finite subsets of $\mathbb{N}$. AFAIK it should be nonelementary. However, I'm looking at the complexity of the levels of the alternation hierarchy, i.e., $\Sigma_n$ and $\Pi_n$ fragments of $FO[\le]$. For example, the satisfiability problem for Bernays-Schönfinkel formulae, those of the form $\exists^*\forall^*\phi$, a.k.a. $\Sigma_2$-formulae, is in general $\mathsf{NEXPTIME}$-complete, and this should hold also on words, is this correct? But then what is the complexity of satisfiability/validity for $\Sigma_n$-formulae for a fixed $n$? I've found a lot of papers and surveys about the expressibility problem for these fragments, that is, to decide whether a given language can be expressed in a given fragment, but nothing on the computational complexity of the validity/satisfiability problem. I'm feeling like I'm missing something very trivial or commonly known. Can you give me any reference? 

where the thick edge represent the chain of states, where each state is connected to the next by a single edge and all the edges are labeled in the same way, in this case by $a$. So this is not really a counter or anything fancy, it is just a succinct representation of a very limited special case. By succinct, I mean that by representing the $k$ parameter in binary, the second automaton can be represented in logarithmically less space than the first. Let's call this kind of automata the "succinct automata", SA, so say DSA and NSA for short for the deterministic and nondeterministic variants. Now, my question concerns the complexity of boolean operations over this kind of automata. In details: 

I'm learning a bit about algebraic logic and I was wondering how knowing the algebraic semantics of a given logic might help the study of the logic itself from a computational point of view. In particular, is there any example of a complexity (or decidability) result for the satisfiability problem for some logics that was obtained by reasoning about its algebraic semantics? For example, the semantics of propositional logic can be given in terms of boolean algebras. Is there any connection between them and the fact that SAT is decidable and $NP$-complete? 

It seems to me that the macro language employed by $\TeX$ can maybe be seen as some kind of term rewriting system or some kind of programming language with call-by-name scoping. Even modern implementations of the $\TeX$ engine (e.g. $\mathit{Xe}\TeX$) interpret code in a quite direct way and I'm not aware of any attempt at optimizing the execution (like modern optimizing interpreters can do). However, devising correct optimization passes for a language like $\TeX$ is going to be very difficult because of the "action at a distance" that macro redefinitions can have, and the ability of redefining macros by calling them by name. So implementing an hypothetical optimizing interpreter for $\TeX$ sounds a very difficult problem in practice but also a very useful one, since $\TeX$ is used all over math and science and slow compilation times are a known drawback of the system. Note that the majority of time is spent interpreting code, not computing the actual typesetting, especially when computationally heavy packages are used (such as ). Maybe a formal semantics for the language could be a start to address the problem. So has the semantics of the $\TeX$ programming language ever been formalized?