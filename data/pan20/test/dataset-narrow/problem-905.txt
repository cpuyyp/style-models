I don't specify any access/secret keys in the command line. My instance role was manually created (by me) and definitely does NOT grant any permissions on resources. 

What would be the best way to pass sensitive data to EC2 instance (on boot or otherwise) that only root can access? 

I know I can use IAM roles, but I found it's just too many moving parts, and complicates any scripts that have to use the access key/secret key (e.g. rewriting /etc/apt/* lines when it changes). Not to mention there is no way to attach roles to existing instances, which makes it even more pain. It's also not possible to simply restrict access by using VPC subnet, because S3 bucket access goes via public EC2 interface. 

Is there a way to let anonymous access to a certain S3 bucket only from my EC2 instances (all of them) within a single AWS account? 

So my question is, what is the best solution to make sure I keep the state of static NAT and stateful firewall rules (not ZBF) on both routers at the same time? Again, I want traffic to leave through ISP A and return through ISP B. Is it possible at all or do you think it would be better to purchase a pair of ASA 5500 series with Active/Active support and do NAT and inspection on them? 

I am new to powershell, but I've been reading manuals and practiced a little bit. My objective is to List all users in all Security Groups under specified path. I have found the way to do it: 

At my company we have a single Cisco 3925sec/k9 router running BGP with 2 ISPs. Now we want to purchase a redundant router of the same model to eliminate a single point of failure. I can set up BGP between routers and ISPs no problems. We plan to send out all traffic through ISP A and receive all traffic through ISP B (ISPs send us only default gateways and we can play around with as-prepends and local_pref attributes for that). 

Some guy configured a Cat 6500 Core Switch on my net to handle MPLS traffic (and it works). The MPLS line is also directly connected to the internet, so our edges and firewalls are bypassed actually. I also have a 2851 router (IOS 12.4) router on my edge and want it to handle the MPLS traffic, but I'm stuck with the config. To me it looks something is wrong with the tunneling. This is the working configuration of my 6500 Core Switch: (irrelevant configuration is omitted) 

Worked fine for me (in a Windows Server 2008 R2 domain, of course). Update: Right, this would only give access rights to domain users on local computer 

GoDaddy provides DNS hosting, so all you have to do is creating 2 A records, one for YOURDOMAINNAME.TLD and another one www.YOURDOMAINNAME.TLD, both pointing to your VPS's IP address 

But it glosses over the specifics of how these policies are combined and when the "fall through" happens to the next policy in the list, i.e. under what conditions each policy fails and moves on to the next policy in the list. For example, I have a policy list in my group and yet after scaling up and then down, the scaling group proceeded to terminate by newest (and healthy) instance (newer by a large margin), and I can't figure out why. Additionally, according to the same doc, default policy is actually itself a combination of policies, and includes and as two of its steps. If I have a list that includes , does it evaluate and twice? Lastly, does the termination consider load balancer? For example, if my new instance failed to initialise properly and is not in-service with the load balancer, and is in effect, will scale-down action kill the unhealthy instance first even though it's newer? 

You can also use if you want it in PowerShell. Substitute MSSQL$SQLEXPRESS with your SQL Server instance name. 

How are IP addresses mapped to Autonomous System Numbers (ASNs)? Is there a reference database for it? Then how are these Autonomous Systems geographically located? 

There isn't anything ready for Windows Azure, But you can create one, since Git can be used over http. You can use GitSharp or DotGit libraries. 

Not an issue for a small network, but becomes a pain when it grows. How can I track what ever happens to my network's hardware (repairs, upgrades, whatever) if I don't want to dig into loads of Excel and Access files? UPDATE: Looks like it's called inventory or asset management 

I've set up a Squid proxy which requires Windows Authentication. When Internet Explorer users try to use HTTPS websites, it just fails. FireFox users don't have this problem. I cannot imagine of any reason for this. 

Here I supply the list of IP addresses that are all alive, as you can see in previous command, but only 2 hosts out of 8 show up as alive. Can anyone explain this behavior of nmap and maybe tell the work around ? I want to use nmap in the shell script to quickly determine alive hosts. Previously I used 'fping -a' command, but nmap seems to be better at discovering hosts behind the firewall, so I would like to switch to it without modifying my script too much. Any help will be appreciated. 

I'm setting up a freebsd router and want certain IPs on my network to be forwarded to our local webserver if they make port 80 requests. An example would be - banned user tries to surf the web, but all his requests are forwarded to the web page which notifies him that he is banned. As I understand I can use IPFW for this and maybe NATD. I would be grateful if someone could show me a good example on how to do it. 

How can I tell (in ) if I'm running in interactive mode, or, say, executing a command over ssh. I want to avoid printing of ANSI escape sequences in if it's the latter. 

It's single availability zone no backups not in a security group that's reachable from the outside world 

When an ASG is launched, the queue ends up with two test notifications from the creation of lifecycle hooks, but no notifications for instance launch. And here is the race condition. object references (and hence depends on it). This dictates the order in which CloudFormation creates resources (the group is created first). The problem is that the group starts launching instances before the hook creation is complete (instance launch is not a part of the template, so it starts executing in parallel). By the time the hook is created, there are no more events to post as the instances were already created. Is there any way to work around it and catch launch events at stack launch time? 

But the problem is I do not see the group name. All I get is a bunch of users. It would be nice if someone could tell me how to display the group name before all the members of this group get listed. Thanks. 

at the end of dhcpd.networks file (which I include into shared-network 'clients' clause, see above), all my clients start getting ip addresses from 172.20.111.0 range, regardless if they have a class specified for their port. Is there a way to make dhcpd server first look at class declarations and then subnet ? 

I am a bit new to ASAs so far, so my question is "Is it possible to set up ASA 5515 to use 2 ISPs to have VPN connection with a remote site and in case of the main ISP's failure switch over to backup ISP automatically and then to return back to the main one when the link is reestablished ?" 

For some reason the CPU usage is at 20% CPU while I'm doing absolutely nothing, exactly every 10 minutes spiking to 28-30%. I thought there was something wrong with the instance, so I've re-created it, same thing. What does this? Is this an RDS phenomenon in general or is this specific to the burst capable instance classes? 

Is it possible to buy an intermediate certificate to use it to sign subdomain certificates? It has to be recognised by browsers and I can't use a wildcard certificate. The search turned up nothing so far. Is anyone issuing such certificates? 

I am trying to use AWS autoscaling lifecycle hooks in a template that encapsulates the following things: 

As I understand it, an instance needs to be granted access to resources in order to do anything with CloudFormation. But when I run this on a Beanstalk web server instance: 

Some hosts let you create/editing files, some others not, instead, they provide a file manager which lets you set the permissions. Though it's better to ask your host about it. 

Looks like there is something wrong with your server's dns settings or sendmail itself if it has separate dns settings. Make sure they are valid and alive. 

Since Exchange doesn't provide support for all calendar types in OWA, I need to create one, using Microsoft.Net's support of calendars, but where should I start? 

The same configuration was applied to the router, but it simply doesn't work. We want to connect our 2851's fastport 0/3 to WAN directly instead. Our topology: Router 2851 -> PIX 525 Firewall (It's a dinosaur? Yes I know that) -> 6500 Catalyst Core Switch Note: Our side of the MPLS is 10.24.17.254 

But it's not ideal, as it doesn't handle restarts and remote endpoint downtime very well, because it doesn't have anything like 's pooling, so I'll get duplicate logs and/or drop logs. Given that CoreOS has no package management, is there a conventional way to solve this painlessly? 

Within plain EC2 environment, managing access to other AWS resources is fairly straightforward with IAM roles and credentials (automatically fetched from instance metadata). Even easier with CloudFormation, where you can create roles on the fly when you assign a particular application role to an instance. If I wanted to migrate to Docker and have a kind of M-to-N deployment, where I have M machines, and N applications running on it, how should I go about restricting access to per-application AWS resources? Instance metadata is accessible by anyone on the host, so I'd have every application being able to see/modify data of every other application in the same deployment environment. What are the best practices for supplying security credentials to application containers running in such environment?