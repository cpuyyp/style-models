Due to the fact the company only has 10 employees and doesn't need anything drastic, I'd recommend Microsoft SBS 2011 (Microsoft Small Business Server 2011). This would easily be able to cope with your needs, it's easy to manage and can hold up to 75 users if you go for the "Standard" edition or 25 if you go for the "Essentials" edition. Regarding hardware, I'd personally say you only need one tower server to run all this. You could then have shares (if required), Active Directory and a lot more (however by what you've posted this is all that's required). A simple tower server (however the specification depends on their exact requirements, but custom builds are available) will easily be sufficient. Hope this helps. Please feel free to ask if you require any additional help or information. 

I've solved the problem. Here's what's going on. /etc/apache2/apache2.conf includes a call to any config files that have symlinks in /etc/apache2/sites-enabled. Since there was a symlink in that directory pointing to /etc/apache2/sites-available/000-default.conf, that latter config file was being loaded and it was over-riding the blocks and directives in my vhosts.conf file. Once I deleted that symlink, my vhosts.conf settings were able to take effect. The lesson for me was that any file that has a symlink in sites-enabled will be enabled. 

Is there some other step I'm not aware of? UPDATE Here are the firewall rules if I run the command "sudo iptables -L -n -v": 

I figured it out. The solution is to set "user = root" in the project's Supervisor configuration file. The documentation says, "If supervisord runs as root, this UNIX user account will be used as the account which runs the program." Thus, setting user this way is equivalent to my running the script manually using "sudo." 

You can configure User and Computer settings in Windows 2003 with Group Policy and Group Preferences, just as in Windows 2008. This may solve some of your configuration issues. Going into all of the details of Group Policy and Preferences is beyond the scope of a simple answer, but Google will be your friend here. Also, each version of the Windows client increases the capability of Group Policy, so you will need to be diligent in verifying that you can accomplish what you want in Windows XP. Group Policy alone won't necessarily solve your problems, at least not without extensive scripting. If you're having problems with programs being installed as a non-admin, you'll likely need to augment Group Policy with other tools. If the problem is people installing programs as local admins, then removing local admins permissions should be your priority before any of this work. As for games, are you talking about online, or installed? Again, Group Policy won't necessarily solve, say, Flash games. There are other network tools to prevent that. Depending on how much of a problem this is, you may need to step up to system management tools, such as Kace or Microsoft System Center. Again, beyond the scope of a simple answer, but this should get you started. 

I have a Django/Nginx/Gunicorn web server ("web02") and an Nginx file server ("fs02") that is used to store user images. When a user uploads images through the web site, they are saved to the file server via a directory that is cross-mounted from the file server via NFS. I build my servers using an Ansible playbook that provisions each server and then configures the file server first and the web server second. When I initially build my servers, NFS works perfectly. However, if I rebuild and reconfigure just the file server (for example, if it crashes and I need to rebuild and restore it), NFS doesn't work. In that situation my web server is unable to see the exported directory on the file server. I have confirmed this two ways: 

I have an Nginx/Gunicorn/Django web server and PostgreSQL database server that I only want to access using SSL. I've purchased, installed, and configured a certificate on my web server from a certificate authority and so now my users can only access my website via HTTPS and it's working fine. Now I'd like to implement secure two-way communications between my web server and database server over SSL. Since the only machine talking to my database server will be my web server, will it be OK from a security standpoint to generate my own private key and certificate using the openssl command ("self-signing") or should I get a free ones from somewhere like letsencrypt.org? 

I thought that EMC kept all of the documentation behind a login wall unless you are a customer, but it turns out that's not true. So I was able to download the manual and check it out myself. Turns out you can take the Data Domain backup to tape. In Networker lingo, this is a backup clone. This will lose the Data Domain's deduplication, but the clone should be readable by Networker in a disaster recovery situation without the Data Domain hardware. That's what I see from the manuals, anyway. Still wouldn't mind getting a sanity check from someone who has actually used Networker, but I may have what I need. 

Short answer to "do you need DNS pointing to Domain Controller for GPO to work" is yes. spacenomyous has the answer up there. I'm guessing that if you're new to AD and DNS, you may also be new to DHCP, which will dynamically grant IP addresses and associated settings to clients. You can add that role to the DC (or other server), and then point your clients to use DHCP to update the network settings, including DNS entries to have them all point to internal DNS. If you absolutely must set them on each computer, then you should be learning some Powershell scripting to automate. If you can do a .vbs script, then you can look at the following link to figure out how to update the clients: $URL$ 

If I turn off the firewall on my file server and rerun both of the above commands, they run successfully and I can mount the file system. But if I re-enable the firewall, both commands fail again. What is baffling is that the firewall rules that I enabled when I rebuild the file server are identical to the rules that are enabled when the file server is initially built since the rules file is built by my Ansible playbook. Here are those rules: 

This message repeats every five minutes. I suspect this is the IP address of an earlier build of the file server since I can see it's a linode.com address if I run "whois" on it. But what's more interesting is that if I to a "grep -Rn 45.79.65.48 /etc" I see this address in the /etc/mtab file. I see now that this is the previous file server's IP address since I neglected to unmount the file server's directory before I destroyed and rebuilt the file server. I did "sudo umount -l /var/www/mysite.com" to unmount it. I then did "sudo mount -a" on the web server and now I can see that the file server directory is mounted onto the web server. However, if I re-run "sudo rpcinfo -u fs02 mountd" command on the web server, I still get the "Connection refused" message. I don't see how I can get that message if I'm now seeing the cross-mounted directory. I've been up all night working on this so maybe I'm tired and missing something. 

Your most suitable solution would be to use group policy. Using group policy will allow you to apply a standard path for all computers. This policy can be set by performing the following: 

Quest ActiveRoles Server should cover what you're looking for. Quest ARS has a feature where you can set the expiry date for a certain user and once this date is reached, the user is automatically removed from the group. Quest ARS also has other automated features along with an enhanced audit tool. URL: Quest ActiveRoles Server Website 

I am currently using roaming profiles and wante to configure all clients connected to the domain to delete the local profile once the user logs off. Could this be done via a Group Policy? Script? 

If the user has recently changed their password, this could be something trying to authenticate using the old password. I'd suggest using Account Lockout and Management Tools (click here for the instructions on using the Account Lockout and Management Tools) by Microsoft to trace where the account is being locked out; this will help determine the cause. Alternatively, if you update the post with the logs from your DC, I can attempt to trace it from there. 

At this point, you're ready to bring in your 2016 DCs. The big problem with your second bullet point is that making a new domain force all new AD accounts for your users and computers. Note that creating an account with the exact same name doesn't give the same permissions, because it's all based around SIDs. So in that scenario, you will need to rejoin all the PCs, all of your users will need to reset their passwords, and it sounds like a big bag of hurt for anything more than a trivial (<5) number of users & computers. If one of your users happened to encrypt a file client-side, that's also reliant on AD SIDs, and wiping out your AD will wipe out access to the files. As a bonus, the 2008 DC can be your secondary DC (always have 2 DCs), so you'll only need to install 1 new 2016 DC for now. That would be stable enough to let you go on to the next fire until 2008 support ends in 2020. If 2000 was good enough for the network thus far, it doesn't seem that moving to 2016 for AD is going to have huge benefits.