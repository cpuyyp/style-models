Immutable servers are servers on which no changes can be made (other than updates and security patches ideally). Instead of changing the software on the server, you spool up a new server with the desired software and then terminate the older one. This concept helps to ensure that your test, development, and QA server are all identical, which is important for multiple reasons out of the scope of this question. Another benefit of immutable servers is the ability to rollback the application onto an older server. For example, I need to change K on production server 1, so I spool up server 2 and change K. Now after 10 minutes, I notice that K broke something with my application, rather than having to fix it right away which could take hours and potentially cause downtime for my customers, I redirect the traffic back to server 1, while I figure out what is wrong with 2. 

My team and I are responsible for developing "one-offs", products that once finished are given to the client for upkeep or in some cases managed by us for a fee. We still need to maintain a solid development pipeline to handle the constant feedback from our clients in order to ensure that we ship them something reliable and proven to run. While the client doesn't care about DevOps (in most cases), it is still helpful for us. With DevOps, we can rapidly push new builds, so clients can see feedback in minutes not hours, and we are also able to catch any errors/bugs with our testing via Jenkins/Travis. To ensure our deployment strategies are the same across projects, we focus on containerizing our applications. Using Docker, we are able to easily hand off the application to our clients. The cost saved by DevOps is hard to determine. We do have extra costs in the form of software we choose to use for the pipeline (Travis, Jenkins, Puppet, what have you), but we also save time and money by fixing bugs/ giving the clients feedback quickly. Our quick response time keeps our customers happy, in turn, keeping our wallets happy. 

The point of DevOps, is that development shouldn't oppose operations, instead they should support each other. Traditionally, due to waterfall deployments and large scale updates, development would cause operations a variety of problems when deploying due to inadequate testing, changing server environments, the list goes on and on. Essentially, the updates were too large for the operations team to be able to effectively deploy them without some problems arising in the process. These problems might be why you believe that development opposes operations. On the other hand, DevOps works to reduce update size, decrease rigid environments, and generally improve the handoff of the application between development and operations by increasing the amount of times the handoff occurs each year. With the increased number of deployments comes less headaches for operations, because they have either automated a large amount of work required to update the products, or they better anticipate and prepare for the updates. Tldr: DevOps aims to nullify the theory that development opposes operations by creating a mindset where operations and development work together to frequently deploy products in a timely and easily reproducible way. 

I can think of two architectures that would support the answering of these questions, however, the enormity of the problem could well be clouding my judgement: Approach #1: Walled Garden Effectively firewall off the sources of these open source packages, i.e. npm, Docker Registry, nuget, etc., then create an internal repository of approved packages, implementing some process to whitelist packages. 

Important: Chat and ChatOps is very specific to an organisation, think of Chat as the Fabric for your team's bots to existing within it's the bots that provide the functionality that enables business and technical processes. With the brief lesson in ChatOps Theory over I can talk about the experiences that I have had with ChatOps: DevOps Support Slack and PagerDuty has fantastic integration allowing any newly raised incidents in PagerDuty then posted in one or more Slack Channels with information about the incident and buttons for acting upon the knowledge: 

Therefore the overall availability of this "system" must lower than 99.95%. My rationale for thinking this is if the SLA for both services was: 

It is also worth stating that you can model the whole pipeline in Application Release Automation tools such as BuildMaster or Nolio. Personally, I prefer to build my pipelines from multiple 3rd party SaaS solutions. 

Where is the index, i.e. , or in the above example. If you were to construct this from scratch it would be in the following format. Get the list of statuses from the commit 

Google offer a $300 free trial for 12 months in a similar deal to Amazon. In addition they have free usage tiers for many of their core offerings: 

ChatOps is an absorbing topic; practically it means something very different to each team using it. So much so that Atlassian have put together what could be considered to be a Chat maturity model. 

Again where is the - there could be many of them if one commit resulted in many builds. If the state for the build you care about is then you have your answer and you can immediately return the for the commit. Loop over all of the commits from the first phase, if you run out of commits follow the page that is included in the call to . Complete Flow Diagram At a high level the flow will look like this: 

We have a multi-tiered application hosted on Microsoft Azure Virtual Machine Scale Sets composed of: 

If for example the services as a whole were scaled to support 80,000 requests per seconds and run at about 80% of capacity, a spike in traffic that caused the service to receive 101,000 requests per second would cause 1,000 of those requests to fail. When the retry policies kick in, you end up with additional 1,000+ requests, depending on where the failure was detected which would push the service as a whole up to 102,000 requests per second - from there your service goes into a death spiral doubling the number of failed requests every second. Other than massive over-provisioning of services beyond the projected peak transaction, which would be inefficient. What strategies can you employ to avoid "retry storms"?