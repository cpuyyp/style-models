Computers are much better at splitting their attention than people are. Obviously if the server has only one processor core it can only be doing one thing at a time but if it can switch between things quickly enough the clients won't notice that. And of course many servers nowadays do have multiple processor cores. 

The interface to use. What the "next hop IP address" should be. If no next hop IP address is specified in the route then the destination is used as the next hop IP address. 

There is no way to trace the route of a packet in typical IP infrastructure. There was an experimental extension for it but it was never widely implemented. So what traceroute actually does it send out probes with increasing TTL and look for the time-exceeded messages. So in a per-packet load balanced infrstructure traceroute will be able to tell you how far along the path(s) each router it finds is but it cannot tell whether router(s) it finds at hop "n" and router(s) it finds at hop "n+1" are on the same path or different paths. 

Time spent travelling through the physical medium can only be changed by choosing a different physical medium. Time spent sitting in queues will generally be reduced by having faster links. So will time spent serialising and de-serialising data. The effects on processing can get complicated. If the processing step stays the same then it will generally take less time at a faster data rate. However techniques designed to extract more bandwidth from existing links may also introduce additional processing delays. A classic example of this is DSL interleaving. 

My guess would be that the top panel is going to a local PBX (either analog or propietary digital) for voice services which only use a single pair each. I don't think it has anything to do with your Ethernet network other than sharing the structured cabling infrastructure. 

As you say the setup is much the same either way. One converter to hook up to the ISP kit and one converter to go back to regular Ethernet. Fiber has a number of advantages. 

"theory 2" is how switches normally operate. "theory 1" would be an optimisation hack. I know the BGP EVPN guys are doing local arp/nd interception to reduce BUM traffic. I have no idea if anyone is doing it in a plain Ethernet environment. 

It doesn't explicitly notify the bridge. But typically a request will provoke a response. Typically that response will tell the bridge where the MAC address is located. Also except in cases where a bridge was rebooted without rebooting the connected devices this is unlikely to happen in the first place. Normally when hosts start to communicate they will send arp broadcasts (or for IPv6 ND "multicast") before they start sending unicast traffic. 

Twisted pair Ethernet is transformer isolated. To allow the signals to pass through the transformers (which block DC and low frequencies). the signal is transmitted at high frequency and coding schemes are used to avoid DC and near DC components in the signal. This applies regardless of whether POE is in use. POE with power on the signal pairs (POE mode A for 10/100, any POE mode for 1G and higher) seperates the power from the signals in two ways. Firstly the signal is transmitted as a voltage difference between the two wires in a pair while the power is transmitted as a voltage difference between two pairs. Secondly the power is DC, which will be blocked by the transformers. The power is applied and extracted by using transformers with a centre tap on the cable side (the transformers may or may not also have centre taps on the device side for unrelated reasons) and a sufficiently beefy core that the DC currents do not cause magnetic saturation. Isolated DC to DC converters are used to pass power to and from the Ethernet cable while maintaining isolation (this applies equally to modes A and B). 

The key difference is that a switch has the ability to receive multiple frames at the same time and store them in internal queues. Sure eventually you are going to hit the point where those queues fill up and frames have to be dropped but hopefully dropping is the exception not the rule. A hub operates at a much lower level. It never stores complete frames, it just passes traffic through as it comes in. 

It's just the way STP works. There are alternatives that can avoid these problems but they come with issues of their own. 

For any receiver there is a threshold above which the system will stop receiving correctly and a further threshold above which the receiver will actually be damaged. According to $URL$ 10km optics will normally work fine even with a very short fiber. 40km optics will not work correctly but are unlikely to be damaged. 80km optics may suffer actual damage. So basically it's a potential issue for people playing the long distance WDM or dark fiber game. It shouldn't be an issue for links within a site or links to other nearby sites. 

Forcing traffic between certain systems to go via an IP router/firewall and blocking any attempts at direct communication between them. Preventing systems from communicating with each other at all. Controlling where broadcast traffic goes and reducing the amount of Separating multiple systems with the same IP address. 

First an important concept in networking is the product of bandwidth and latency. This determines how many packets need to be "in flight" at once for full utilisation. In general this figure has grown over the years as bandwidth has increased massively while latency has remained roughly the same (pesky speed of light limits) Traditionally TCP only acked continguous received data. I do not know for sure why it was done this was but I would guess simplicity was the driving force. This left a sender with two options. It could resend a single packet and wait for a response from the receiver or it could resend a bunch of packets and possiblly end up sending duplicates. I expect that in the early internet this was not much of a problem. The bandwidth-delay products were relatively small and waiting a round trip time for each lost packet was probablly not too big a deal. As bandwidth increased this became more of an issue and after experiments in the late 80s and early 90s TCP shared acknowlagements were standardised in RFC2018 in 1996 . 

Most of the block is regular public IPs but there are a number of special things in there. Special allocations are documented at $URL$ 

Multimode fiber has a larger core, this makes the tolerances easier for termination and makes the transciever hardware cheaper but it allows multiple modes of propagation resulting in a time-smearing of the received signal. There are tricks to reduce this time-smearing resulting in a proliferation of different grades of multimode fiber. So the traditional wisdom was you would use multimode within a buliding or campus and singlemode for longer distance links between multiple sites. However that traditional wisdom has become more and more questionable. Newer multimode standards have become increasingly demanding about the type and lengths of the cables making it very difficult to future proof a multimode cable plant. This can happen even while the speed stays the same, for example early 10 gigabit stuff was often LX4 which is relatively tolerant while modern 10 gigabit multimode stuff is usually the far less tolerant SR. Meanwhile existing single mode fiber runs, at least at campus distances have remained compatible with new standards that have come along. So my advice would be, if it's a short-term installation that will be ripped out for unrelated reasons before any speed upgrade is needed then consider both singlemode and multimode and go for the more economical option. If it's a long term installation that will need speed upgrades over time then go for singlemode. 

Using a public ipv4 address for management would be "wastage" since that is expending a scarce resource on a task that could be served by a less scarce resource. So dont do that (see below) 

Link local addresses are local to a link*. Packets to/from link local addresses cannot cross any router. Furthermore to use a link local address requires knowing what interface it relates to. The trouble is interface IDs are a machine local concept and not nessacerally stable. These restrictions severely limit the utility of link local addresses. 

Do systems on the different networks need to talk to each other or are you just trying to arrange Internet access. The subnets overlap but do the host addresses actually clash? 

Part 2: sharing an internet connection From a technical point of view you can build an ethernet network that spans multiple houses, connect it all to a normal home/small buisness NAT router and it will work. The protocols have no idea if the endpoints are ithe same house or not. However there are a number of things to be aware of. 

What privilages is the server running under? A server running as root (or your operating system's equivilent) is obviously a higher risk than one running as a dedicated low-privilage user but note that privilage escalation bugs do happen. What is the server doing? A webserver than only supports static content is much lower risk than one running a complex webapp. 

Networks interconnect in two main ways. (and various variants in between the two) in a "transit" relationship there is a provider-customer relationship. The provider provides the customer with the service of carrying their data to and from the internet in general. A peering relationship is a more mutual thing, it allows network A (and their customers) to communicate with network B and their customers but it's not transitive. If A peers with B and B peers with C thendata will not be allowed to flow from A to C via B. Peering is usually settlement free (neither side pays the other though someone has to pay for the actual link) and may go via a private connection or via an internet exchange point depending on traffic volumes and local customs. There are exceptions but usually the long distance links will either be within a given providers network (and obviously paid for by that provider) or from a provider to their customer (and paid for by the customer). Peering links are usually relatively local. Larger providers will often refuse to peer with smaller ones because they see it as losing a potential customer and/or as an unbalanced relationship where the large provider does most of the work of moving data around and the small provider gets most of the benefit. This is more of an issue in the US than in Europe as the access providers are larger, more monopolistic and are often vertically integrated with tier 1 providers. At the top of the pile are the "tier 1" providers. These do not buy transit from anybody and all peer with each other. Becoming a new tier 1 is extremely difficult. As I understand it all of the tier 1 providers have a major presence in the USA (though many are now owned by foreign firms) and peer with each other there. Most of them also have a substantial presence in western Europe and peer with each other there too. That is a large part of the reason why internet transit is much cheaper in the US and western Europe than elsewhere. Sometimes a provider may establish a point of presence (a router in a rented rack, connected back to their main network) in cities or countries where they don't otherwise operate in order to participate in peering there. 

Get universal time over NTP Look up the devices IP address (if implementing on the client remember to get the public IP from a server on the Internet rather than using a local private IP) in a geolocation database to get a TZ ID. Look up the TZ ID in the TZ database to get the rules for that timezone. Convert those times to local time. 

No, when a connection is accepted the the server OS creates a new socket to represent the connection but this socket does not use a new TCP port on the server side. 

Based on your mention of ports I will assume that when you say "router" you actually mean "NAT box". In the home and small buisness markets boxes that come configured by default as NAT boxes are sold as "routers". So you have your client machine and you have two NAT boxes between your client machine and the Internet. Your client wants to retrive a web page from a server on the Internet. What happens is. 

AIUI 100BASE-TX without autonegotiation relies on carrier detection to determine if the link is up. I wonder if a possible soloution would be to get a third network card and hook it's transmit lines up to the receive lines on the card used to send data. 

They provide protection for the traffic against evesdropping, spoofing, replay attacks and so-on. They decouple your addressing and routing from the operators of your underlying networks. 

This can be done using a Linux box. It can probably also be done with some high-end routers from the likes of cisco but I have no experience of those. Linux supports what are known as "network namespaces". Each "network namespace" is a separate logical instance of the network stack. Either install lots of network controllers or connect a VLAN-supporting switch, set up the port connected to the Linux box as a trunk and create a virtual interface for each VLAN. Then move each of the network interfaces that will be used to connect devices to it's own network namespace. Connect the secondary network namespaces back to the main network namespace using virtual Ethernet (veth) devices. Now implement NAT in each of the secondary network namespaces. You will probablly want to change both the source and destination IP. 

One to many NAT (aka NAPT, PAT) hides a network behind a single IP (or sometmes a pool of IPs). To do this it keeps track of connections so it can translate between internal IP/port combinations and external ones. It is sometimes nessacery to replace the internal port number to avoid ambiguity. Different NAT implementations will have different policies on how exactly this is done and on whether the port number is replaced unconditionally or only replaced when needed to disambiguate. 

Lets assume all arp tables are initially empty (not very realistic but meh) and that all the links use Ethernet-like protocols. 

STP will hopefully prevent a loop involving the STP capable switches (unless the non-stp switches filter out the STP packets), but it won't prevent a loop involving only the non-stp switches. Possible solutions include. 

Aluminium is cheaper than copper but has higher resistivity and is more prone to unreliable terminations. Copper clad aluminium is an attempt to get some of the advantages of copper while keeping the price down. It's a clever idea in theory (in a high frequency system most current flows in the surface of the conductor anyway) but it's nonstandard and i've seen reports that it is unreliable in practice. The categories of cable are mostly about the high frequency performance. Higher categories have better high frequency performance. This is acheived through higher twist rates (which better reject high frequency capactive and inductive coupling), higher quality materials, more careful control of the geometry and in some cases shielding. The category you need will depend on the speeds you are operating at and the distance you are operating over. I would generally suggest going for cat6 solid copper cable for installation wiring to end devices, it's not terriblly expensive will support 1000BASE-T with ease ans on short runs should support 10GBASE-T . If you want to run 10GBASE-T on long links you might want to splash out on cat6A but last I checked it was substantially more expensive than cat6 and it's not clear if 10GBASE-T will ever become more than a niche product. For backbones I would seriously consider fiber at this point. 

That probablly depends on the NAT implementation. I'm pretty sure iptables could do it with only a single link to the core router, other implementions may require seperate "inside" and "outside" links. What you will need for this setup is border routers that can route based on source address (normal routing is based on destination address) so that traffic from private subnets gets directed towards the NAT while traffic from public subnets flows straight through. 

People often say "routable" when they mean "publically routable" and "non-routable" when they mean "not publically routable" The IANA maintains a list of special purpose IP addresses at $URL$ the "forwardable" column tells you whether the addresses can be routed on private networks, the "public" column tells you whether the addresses can be routed on the public Internet. If it's not on that list then it's most likely a regular publically routable IP. Note that publically routable doesn't nessacerally mean publically routed. Some ISPs (cellular providers in particular) have been known to abuse space that was either unallocated or allocated to companies who chose not to advertise it on the public Internet to give them additional space for addressing devices behind their NATs. This causes problems when the legitimate owners of the IP space later decide to start using it on the public internet. Probablly the best test is to do what you just did, compare the "WAN" IP address shown by your NAT router to the address shown by a "what is my IP" site.