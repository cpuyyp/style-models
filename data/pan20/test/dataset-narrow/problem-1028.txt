NIS exists under the premise, that all participating systems are trustworthy - that means, the system administrator, who allowed you to knew what he was doing. There is no protection (as with any system) against a rogue admin user. 

To really load a switch try multicasting! Using or to multicast a loop of a small video in very high quality/bandwidth makes for a very good traffic generator, and multicast traffic will always egress. 

If you go for sweet point between manageability and perofrmance, I suggest a two-step process (we use the same for our HTTP routing configuration): 

It is a 32 Bit CPU - there is widespread consent, that the "Bitness" of a CPU is the width of a , which in this case would be 32 

The first call will start a new instance of bash to interpret the script, meaning bash will set to its path. The second call will treat the file as executable and run it, so will point to it. The latter two calls will load the file into the current instance of bash, so will point there. NB: #2 needs the file to be executable, #1, #3 and #4 not. 

I use FAT32 with a preallocated/2G split VMDK and have never had problems: The point being, that the metadata on the file system never changes (apart from file times) - this mitigates most of FAT32's weaknesses - running FAT32 with any growing file is a risk you might or might not be willing to take. What remains is FAT32's lack of access permissions - you will have to decide, whether that's a show-stopper. 

I am quite sure, the 1 / 37 geometry is meant to be cylinders (in the old CHS-speak), not blocks: STarting block 1, Ending block 37 might not easily result in 297171 blocks ... Switch to blocks as display unit on the original disk, I am quite positive, it will show up as 63 

I did have a similar experience years ago while travelling (in Europe) after the notebook was left in the X-ray machine much longer than usual - the operator of the machine had a trainee, whom he wanted to familiarize with how different types of laptops look under the scan. This was an older model (C2 generation), and I could only resolve it by opening the case and clearing the NVRAM via the "clear CMOS" jumper. I remember, that at that time I suspected a bit flip in the NVRAM, that prevented the early boot (hardware initalization) phase. Your experience is close enough to mine, that if you fly regularily you might want to try sticking a small (1"x1") piece of double layer tinfoil in the case over the MVRAM chip. 

What you are trying to achieve is while not very usual not in the least exotic: It's called nested virtualization - all "grown-up" Hypervisors I know of support it, but I don't know about Virtual Box. Of course performance is not going to be brilliant, as the virtualization overhead becomes bigger (there is only one set of virtualization hardware in your box!), but there are use-cases. 

First of all: Write amplification is not an exclusive property of Flash, but happens with all block devices. It is a side effect of why a block device is being called a device: Data is written in portions ("blocks") consistingy typically of 512 Bytes to 4 Kilobytes. This leads to a situation, where to change a single byte on a block device, we need to first read the rest of the block (this step is usually a no-op, as OS buffers are typically at least block-sized), then the change the one byte in memory, then write the complete block to the device: To change one byte, we had to write a complete block, often thousands of bytes. This long-known mechanism has a special meaning with SSDs, as they 

Now the Yogas are notorious for providing less-than-promised current on their USB ports - this results in the disks being always close to starving for power, as writing to a 4TB drive typically comes quite close to the design limits of power draw. You could use a (quality!) powered USB hub to overcome this - in such a pattern the juice for the drive would be provided by the hub's power supply, not the Yoga. 

You run your script in a separate instance of the shell, this is the part of your script (this has the added side effect of running it in dash, not bash) If you execute your script not with but instead with the hashbang will be seen as a comment and ignored, your script will "work". So basically the script is OK, the call is not. 

Overprovisioning is an intrinsic property of the SSD. Since it involves hardware, it is not possible to "turn it on". In some cases, a firmware update can provide a higher level of overprovisioning at the cost of available storage capacity - this involves losing all data on the drive and is supported on a very small selection of drive types, expecially not the x210 

If you use HHVM or an opcode cache, this is blazingly fast: The code itself is ready, and all that needs to be done is a hashtable lookup. 

Your laptop's specs translate to: "I need a charger with close to 19V, capable of supplying at least 6.3A. I will take less than 6.3A if my load is low, but never more than 6.3A." This is perfectly fulfilled by your replacement charger, so you are fine. Rule of thumb: 

The integrated folder-sharing capability of VMware is rudimentary to say the least. We have simply given up on it. What did work reliably though, was to set up Samba on the NFS host and share the same tree through Samba and NFS - *nix users will use NFS, Windows users will use SMB ("Map network drive"). As a side effect you will likely notice a remarkable speedup, as VMware's implementation is based on rather old versions of Samba and the SMB protocol. 

Most likely, this is a bad capacitor - on the MoBo or in the PSU. Caps very often have by far the highest load on switchon - so the scenario, where a cap facilitates its own last load cycle is quite common. 

It is possible to use RAM in something like RAID1 mode - with many server mainboards (at least IBM and HP), that provide this feature under different names, "Memory Mirroring" being the one I most often read. I do not think, that any of these will work with non-ECC RAM: If the two memory modules disagree about the value stored at an address, and no ECC exists, how should the system know, which of the values to use as correct, and which to discard as wrong? This is a classic "split-brain" problem, that is hard to solve whenever a cluster of exactly 2 members work together. Things are easier in storage: Disks have their ECC built-in, so silent corruption without a read failure or other detection is less likely by orders of magnitude.