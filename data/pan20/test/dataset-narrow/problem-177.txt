If the TCP was tested, there are a lot of things you can't control or even to imagine. The difference in downstream/upstream could be easily caused by NIC internal priority settings, buffers for RX/TX and essentially low-level settings that dictate how to handle RX and TX traffic. 'sh controllers' should report any simultaneous RX and TX condition as collision if working in half-duplex mode. 

The Ethernet connections are full duplex, and in this sense there shouldn't be usually problem on a path from end user to switch, and in most of the time, from switch to ADSL router. However, depending on your end user traffic patterns (applications, time, and so on), the bandwidth available on both upstream and downstream of your ADSL service may be oversubscribed (congested) and if ADSL router can't buffer traffic long enough, drops will occur. Additionally, most of the ADSL circuits are oversubscribed anyway from ISP point of view, you may not get maximum bandwidth from the link anyway. 

So, first of all, TCP is two-way protocol. If there's data travelling one way, you'll have data travelling the other way as well even if only just for the ACKs. You are correct however, that client MAC doesn't change. The AP association/reassociation/leaving are quite interesting, and it's actually very chatty before AP and Your host assume they have a 'link up' between each other - sometimes it's 'only' four frames being exchanged, but with more security, it's usually whole discussion taking place over wireless. Take a look here for technical description of the process from 802.11 side: $URL$ Roaming itself became also quite complex process, with natural push to provide seamless mobility for the host roaming. Take a look at 802.11r if You're interested in the details: $URL$ 

That depends on the switch model you have and it's not that easy. Smaller Catalyst switches in general use at least two forms of buffer - there's usually a interface-lavel buffer, on the smaller Catalyst (2k/3k) visible in 'show buffers' under the section named 'Interface buffer pools:': 

What models are those Cisco switches? If you can stack them, then yes - You can connect them in stack and aggregate ports from both of them to the servers, and connections will work. If you can't stack them, but you can connect them together, you can still connect the servers to both of them, but you won't be able (propably) aggregate ports from both of them, as this requires features like VSS and/or mLACP. Still - rather higher-end gear. At the worst possible case, you connect server to two different switches and pray Spanning Tree will work correctly, closing one of the connections for forwarding the traffic. Otherwise, you may end up with loop in the network, or periodic loop, and they're hard to troubleshoot or nail down in non-trivial topologies given limited instrumentation on the host with two NICs (this assumes NIC driver can actually participate in the SPT, some of them can't and you'll end up with two separate links to both switches - which will work also, but isn't what you've asked for). 

First of all, T1 gives you around 1.5Mbit/s in both directions, not 3Mbit/s. If you're seeing 3Mbit/s, it may be bundled from two separate lines. Now, for VPN, if that's IP-based VPN as 99% of VPNs currently are, of course it doesn't matter if your physical interface is T1, E1, ATM OC-3 or 10GE WAN PHY - it's just used to provide higher-layer connectivity - which for VPNs (IPsec, DTLS or whatever) is usually IP connectivity. As soon as you obtain IP connectivity, you should be able to establish VPN sessions. From the description you provide, that T1 line (or bundled T1 line) is used as a hub for employee remote connectivity. This may mean, that the VPN device has T1 ports built-in and that's why the "IT guy" claims T1 is needed to provide the connectivity, or there are some other constraints. Given the costs of dedicated circuits, I'd rather ask local available ISPs about Ethernet line - be it 10Mbit/s, 100Mbit/s or sub-rate 1GE/full-rate 1GE. You'll get more for less (propably), and still get IP connectivity which is needed for VPN sessions. 

If you don't need to be connected to other ISPs directly, in other words - if you trust your ISP to function up to your SLA commitments for this web service, you can just grab IP block from him and live with that. IP block will propably come from ISP PA block (Provider Aggregatable). However, if you want to be connected to multiple ISPs, run multihoming and have added redundancy to the solution, you need to have AS to request PI block (Provider Independent). It's usual practice to follow this way, as pros of having connection to two different ISPs usually win the con of having additional connection & paying for it. 

It's quite obvious. For inbound traffic, the packet analyzer shows you already decapsulated traffic. That's why you're seeing real IPs in the header, so essentially it's already decrypted. For outbound traffic, there's new external IP header with ESP, and the IPs seems to be endpoints of IPsec tunnel judging by the topology drawing. Then, there's internal IP header that's original one, carried over and encapsulated over the ESP header. 

Yes, it's possible to have internet connectivity by means of MPLS cloud, but it either means you need to self-deploy MPLS L3 VPN for yourself, or your MPLS cloud will be provided by upstream ISPs. Usually, edge routers - the ones running MPLS, are distinct from L3 switches/routers in aggregation layer, specifically, that You also add firewalls to the picture. It's doable, but usually it's better to route at the switching layer not aggregation/edge layer. You're trying to ask very specific configuration question, not specifically technology one. It's possible to separate VLANs by means of various techniques - splitting the access ports to access and trunk is very weak and unsecure method. Please take a look at Private VLANs as one way, the other would be the firewalling segment to take responsibilities of filtering traffic between hosts or networks. Again, hard question. In this specific topology yes, they can be placed this way. Depending on the performance required or features required, they may however be required to be positioned in a different way. "Common servers" availability will be governed by configuration, not topology. We have too little data right now to decide if that's feasible or not. MPLS can be used to transport traffic of different protocols, including IPv4 and IPv6. Yes, it's possible to use IPsec over MPLS. IPsec is IP based, MPLS is transport technology for IP - be it IPv4 or IPv6. 

Are you running BGP with ISPs? Or just defaults towards Internet? You should propably configure HSRP on the internal side between routers to have single default gateway for your network - or multiple default gateways if the inside will be segmented in VLANs. If you're running BGP and you do have PI space, announce it on both links, then try to tune using the BGP traffic engineering features. If you don't have BGP, you can try to use Performance Routing coupled with NAT, because you'll need to match outgoing traffic with properly selected source IP addresses (your ISPs should do uRPF and check what source addresses you're using on links they provide you). As Mike stated, topology drawing would benefit the discussion. 

Do a 'show proc mem sorted' and check for biggest memory users. If that's something that is not related to configuration, it may be bug in the code. If that's something that's related to configuration, you may consider re/deconfigure unnecessary services. As IOS can't defragment memory and you can't reclaim it unless some big allocating process frees memory, I'm afraid that to return to normal operation you need to reboot it. Then I'd start to monitor closely memory allocation in total and for the main processes that are using it. If it grows and router is not doing anything additionally, it's propably bug in the "growing" process. 12.3(26) has some memory oriented bugs, but you'll need to audit the config to check if you're affected. 

First of all, capturing traffic on WLAN interfaces is tricky. I assume you're doing this with wireshark, so take a look here: $URL$ Next, 802.11 header is a little bit different than 802.3, take a look at standard: $URL$ 

Well, QoS can work on L2/L3/L4 information, and as soon as your voice equipment - be it Polycom - packs the voice data into payload of IP packets, 1841 can apply QoS features on them. The "voice" support on Cisco routers generally means ability to terminate voice input, or ability to output voice in digital or analog form. If that function is already embedded into voice terminal you're using, all 1841 will deal with is IP traffic. 

No, just because device supports IPv6 it doesn't mean it support IPv4<>IPv6 transition mechanisms - they're not part of IPv6 protocol specification. So, it may support translating traffic from IPv4 to IPv6 and vice versa but it needs to support mechansism like NAT64. Nodes communicate with the protocol of their choice, depending on the higher layer calls. If your browser points to a name, and the name resolves to IPv4 only, IPv4 will be called in to service it. If it resolves to both IPv6 and IPv4, IPv6 should take precedence, but a lot was done in recent years to make both calls simultaneusly and check which one is faster. You need to have node that is dual-stacked, so supports both IPv4 and IPv6 or have support of translating between protocols somewhere along the way. If your router supports it - fine, if your ISP supports it - it's also fine. You should see IPv6 as it should take precedence. If not, your IPv6 connectivity, at least to this specific site is broken. If you can use only IPv6 (you are not dual stacked) you can only reach around 4-5k prefixes around the internet, which is very small percent (out of 500k for IPv4). Normally, hosts are dual-stacked however, so you should be fine - using IPv6 for IPv6-enabled services, and IPv4 for all the rest. That depends on the type of the service your ISP provides. You may have private IPv4 assigned to your internet interface, and it gets translated somewhere at the ISP edge. You may have public IPv4. For SSL/TLS you're using names, not IPs directly. You should be fine. Yes, while there are still works to provide NAT services for IPv6, general idea about IPv6 was to stop doing NAT, and provide global connectivity. It means that with IPv6 assignment, your entire internal network may be directly reachable from other parts of the internet, if you're using IPv6 addresses from the Global Unicast space. For IPv6 you can use other types, like for example Link Local only, which would provide internal connectivity, but block ability to access from remote locations. Generally, you should filter the traffic at the edge of your network if you don't want the internet to access your resources/nodes. Unfortunately, I don't understand the question. Cloud services are usually OK with IPv6, Amazon at least is. Start from here: $URL$ 

The trouble is, as feature was implemented around 12.4T, it was rewritten at least once to my knowledge for 12.4S (which became 15S), so it may behave differently on different hardware and software mixes. YMMV, so it's best to first configure the policies with some sane defaults and 'permit' actions, and then observe your platforms and network during normal work to build baseline. Then check if everything is understood and apply 'drop' actions to established thresholds. Bear in mind 'normal work' should include reconvergence events. This is often missed with CoPP/CPPr and then leads to hard to troubleshoot problems. 

There are at least two questions in your one question :) "Throwing more bandwidth" at the problem doesn't solve anything, it just hides the problem. In IP network you should always prepare baseline QoS architecture to guarantee delivery of critical traffic and manage other traffic parameters (like jitter or delay) for different classes of traffic. You can take a look into NANOG presentation archives for extensive amount of material generated in that kind of discussions, with usual outcome being "yeah, maybe we should do QoS". Traditionally, QoS is perceived as the "hard thing to do right" as the PHB model for IP network is indeed quite complex to plan and implement right. Historically, it was usually also connected with specific hardware requirements, architectures and configuration complexity which didn't help. But when you look at traditional SPs and their networks - they generally implement at least 3-4 classes of traffic and QoS policies to manage traffic flow within their networks. Throught last couple of years traditional certification testing tends to move from testing 4 classes and queues to 8-16 for transport network. OTOH, not having any QoS in the network usually also means those saying "QoS is not needed, I don't have it and everything works OK" have no actual means of monitoring how the network behaves and what is the actual environment applications have for their own use. TCP has great adaptability to network conditions and sometimes problems are not visible with "naked" eye, but become painfully obvious when we dig into details and bit flows. As for the second part of your question - there is nothing that can help you to fight with microburst apart from having deep enough buffers to accomodate them. Which leads almost immediately to things like buffer bloat and additional delays on the path if you tend to simplify and throw packet buffers with memory fast enough to actually deal with microburst (which is not simple and cheap). QoS unfortunately (at least - the mechanisms available in the usual toolset of networking gear) doesn't help 'control' microburst. Good news however is that You'll find microburst dangerous or damaging usually only in HPC and generally DC environments, not in typical transport networks.