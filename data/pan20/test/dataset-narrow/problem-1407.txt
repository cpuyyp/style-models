Clear them when you need them cleared. As discussed in the comments, the performance degradation you are seeing is likely related to the placement of the calls in the relative call stream for the frame, and not specifically the fact that clearing the buffer is "slow" (it should be one of the faster operations available, since implementers know how often it will be called). But it will take non-zero time, and there's really no point to clearing the buffers until you need to. So, if you are rendering to them every frame, clear them every frame. But if you only render to them once every few frames, you should consider moving to clear to just before the render into that buffer. It's possible this will, itself, have performance implications based on how you are using all the other related graphics objects, including the buffer itself, so you'll need to experiment and verify; perhaps you should clear immediately before, perhaps immediately after you're done using the buffer, and so on. If there's no measurable performance difference, favor the option that is most logical. 

C# doesn't have RAII, and the pattern is for disposing unmanaged resources (or managed resources that are themselves because they contain unmanaged resources). Using it for math types will not optimize anything. 

the feature sets supported by hardware that the graphics API exposes, or the feature sets of the API itself that don't really relate to the hardware. 

A component-based entity system works best when an entity represents something in the logical game world and a component some single aspect of that entity, generally things that you'd want to compose. An entity may have a component that describes visual properties or behavior of an object. A component that represents a sprite or model, for example. It is perhaps appropriate to have a component that represents the fact that some entity emits light in a certain fashion. But those should just act as proxies, game-logic packages of information that are ultimately fed into the renderer in a more optimal form. Do not make the mistake of going overboard with your "entity system" and putting everything in there. Not everything should be a component; it is a horrible way to architect anything at scale, and trying to homogenize everything in that fashion can result in extremely confusingly-coupled and poorly-performing code. To that end, the renderer should not know about or process component types. It should understand the representation of sprites or models, shaders or lights in the viewable space and the rendering of those sprites/models/lights in an efficient manner. It should not have any dependencies on the entity/component system at all (I mean this literally: you should be able to compile the rendering code without including the component code). Rather, have the components (which are naturally a game logic domain) store pointers or references to the renderer (which is naturally a lower-level part of the technology stack) if needed to avoid duplication of data or inefficiency state transfer every frame. But do not directly couple the entity system and the renderer. 

The application of the projection matrix is not the end of the transformation pipeline in computer graphics. Applying the projection matrix to a set of geometry in computer graphics puts the object in clip space, which is a 4D parallelepiped (typically visualized as a unit cube). This space is useful because it makes the equations describing the view frustum extremely simple. For example, in D3D they (typically) end up becoming 

You can have multiple vertex buffers. In generally you have one per each mesh/model, and you refer to that single mesh/model data structure with a collection of possibly-many renderable objects which contain their own unique world transformation matrix. This way if you have 50 enemies who all use the same mesh, you only need that mesh in-memory once. Then you have 50 smaller, lightweight instance structures that refer to that mesh and hold a unique world transform used when rendering each instance. 

Thus, you still need to pay Epic the royalties you agreed upon the release of your game regardless of whether or not you are still paying for the subscription. This applies for all forms of distribution, including self-hosting the game and selling it from your website. Failure to pay Epic on time will result in late fees being incurred, and possibly eventual legal action. The license spells out the particulars of the royalty arrangement, including when you have to pay them and when you don't. "Gross revenue" is not your profit, it is the total amount of money your product generates before subtracting out other third-party cuts, refunds you may need to issue, et cetera. The license even gives an example: 

We can profile the execution of the program itself -- what functions are called when and where, how long they take, and what impact they have on the environment (allocations, locks, threads spawned, et cetera). We can profile what the user is actually doing with the program -- where they are in the game when they die, where they are when they earn the most experience, what they spend the most money on, which skills they use most often. 

You will probably want to play around with how you increment the run time, and how to damp the resulting offsets so that the effect is quite subtle, otherwise you may disorient or nauseate your players. You can also combine this with a similar effect applied to whatever gun or implement the player is holding -- this is best done with a specific animation for that object, however. You can see in the Battlefield videos that the guns precess far more than the actual view does. This disconnect in the magnitude of the relative motion helps make the illusion feel more grounded and gives it some depth (much like parallax motion) which can make it look less fake. 

Even if you have pure rotations in there, over many successive frames you may introduce enough error in the computation results that you start to observe distortion in the final model due to the fact that your error is introducing, effectively, scaling or shearing terms. The math you're doing involves several multiplies, adds, and transcendental functions (sine and cosine). It's not unreasonable that certain inputs will result in errors carried through those computations that result in a technically-mathematically-incorrect answer. The values you are reporting seem sufficiently close as to be considered normal, in practice, however. If this is not actually causing observable problems in your game, I wouldn't worry about it. (*) I say "chance" lightly; for a fixed set of inputs, a computation will be deterministic on a particular machine, but when you don't know the potential inputs it becomes much harder to determine if you'll get rounding error and such, so the amount of practical observed error can appear "random." 

No. This is generally a matter of taste and the visual style you want your game to have. You should try a few different ratios of tile size to player size to screen size and see which feels best to you. As Jimmy pointed out in the comments, the size differential between the player and the screen is likely going to have a bigger impact on the feeling of the game. The size of the tiles relative to the player should be an implementation detail (for example, consider that on many old consoles, hardware sprites were a fixed size, and so in-game "sprites" that were larger were just composed of multiple tiles). In order to do this, it's important to structure your game so that those ratios can be changed relatively easily -- so you don't want a lot of hard-coded tile bounds in your code, for example. 

The guide defines, as a subset of the "minimum view" area, a "title-safe" region and a "tag area." The title-safe region appears to be what is used to create the small banner that appears in the bottom right of your left-hand screenshot. I do not believe they ever re-scale the artwork, they just crop it according to their needs. Remember that Apple wants this artwork to display on retina (effectively double-density) screens, so what appears to be a 150x300 pixel image is really a 300x600 pixel image, which fits with their artwork metrics as called out in the guide. Part of the reason Apple's guidelines for exact pixel dimensions are loose is likely because they want to reserve the right to redesign how they present your artwork within their stores without having to get new artwork for all applications. Thus, their guidelines tell you the minimum area you will get (that title safe area), and the rest you have to assume will be dead space (and so you shouldn't put anything super important there). 

You can load that text file and read each character, using that data to initialize the individual tiles in the array you just created. You now have the basics of logical tile-based representation of the world, with collision data, using a large non-tiled map as the background. Note that while you could just render the source background image as a large texture, you probably don't want to do that beyond a certain size. You want to actually split the source image up into smaller images of some defined size (they do not have to correspond 1:1 with your tile sizes) and load and render those. This allows you to drop non-visible chunks of the map from memory. You can eventually apply a similar logic to your tile map data if your maps get large enough. You can do this splitting at load time when you read in the original source image, or you can do it offline as a pre-processing step. If you want to render grid lines, you can bake them into the texture (again, at load time or in a pre-processing tool you write) or render them dynamically overtop the texture chunks for the background. 

where top, left, bottom and right coordinates are represented as , , and respectively. The minimum and maximum depth values are and . Since the math here appears to be the identical to the math for your individual components, you're probably seeing a problem in the storage of those components (resulting in an effective transposition). I'd verify the storage location of your last three components is actually what you need it to be. (Don't just blindly transpose your storage; it's possible you have two transpose-esque bugs elsewhere cancelling eachother out and you're just adding a third; you'll want to review your matrix storage class carefully as where as everywhere in your basic pipeline that you are expecting right-handed systems and conventions to make sure you're not accidentally doing the wrong thing.) 

There are a few things you are doing that you shouldn't. You also appear to have a type on or near the line where you call , as there is an errant in the code that will render it non-compilable. Similarly with the call to -- it makes it difficult to track down the actual cause of your problem. It would also help if you described the failure better than "it doesn't work." That said, here are some things I noticed about your code: 

Storing the completion information in a local file is a simple and perfectly acceptable method of doing so. Fundamentally, this is what every game will do to track progress (in some fashion, although the specific formats used for the data and the storage mechanism will differ). Protecting the file from tampering is more difficult. If there's no compelling reason (no advantage to be gained by the player, no rewards, et cetera) you can usually get away with not caring. But if you do care, and you and if you can reasonably expect that your platform is closed (consoles and non-jailbroken-iOS devices, for example) you also don't need to worry too much. The user will not normally be physically capable of accessing the file to tamper with it (provided you use the appropriate OS APIs to store the data in "private" locations and public ones (for example, storing this file in the user's iCloud Drive on iOS is probably not a great idea). If you are absolutely concerned about tampering to the point where is must not happen (for example, where there is an advantage to be gained by a player who has more levels completed), you need to store the data server-side. Anything stored client-side can ultimately be compromised and shouldn't be trusted: it's the user's machine, in the user's hands. The control dynamic is just not in your favor. It's not strictly impossible to hack files stored server-side, either, of course, but it's much more difficult if you've got a reasonable accounting system. 

By computing the velocity as some factor of the difference between the start and end position, you can achieve the association you want: 

Remember also that any recursive solution can be written as an iterative one, and iterative solutions can be better in some cases because they do not have stack recursion limits. Although I feel the problem is more naturally explained as a recursive solution, in practice I'd suggest trying your hand at converting it to an iterative one to avoid any limitations you can run into due to stack depth, et cetera. Remember also that the above was pseudocode meant to provide a basic idea of the algorithm and certainly could be more optimally constructed in your specific language 

That should provide you a basic starting platform. Note that for API usability, I'd recommend making the above function a private implementation detail and instead exposing a cleaner public method: 

On Guild Wars 2, we used named-references to content for several years early in development. It was the wrong decision and hamstrung the performance of our tools for quite some time before we were able to transition to GUIDs. Every project I've ever worked on that used named-references had trouble with them, so I would absolutely recommend against them. The effort it takes to build tool support around GUIDs is less, in the long run, that it will take to cope with named-references. If you have a small project, just by yourself or maybe a handful of others you can get away with using IDs (giving each person a dedicated "block" of IDs, for example, can easily avoid the clashing problem for some time). But if you have a small project the overhead of GUIDs isn't likely to be problematic either, so I'd just say you should use those for the best future scalability.