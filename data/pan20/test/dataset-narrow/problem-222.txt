I have created the following as an automated job to run at midnight on every database server I manage: 

I'm looking for answers on all the services you disable, anything that you disable, uninstall, etc. The goal of this topic/question is have a running checklist of things that do NOT need to be on a SQL Server for an OLTP-type system. I've not been able to find a definitive list on this topic, just various things here and there. I wanted this list for my own edification as well as something the community could refer to as needed. My thought is to update the list as folks make suggestions in the original post. I know that some of the topics that'll come up can be considered subjective, but either way, I'd like you to explain your reasoning for why you make the suggested modification or disablement. Not all of these are blatantly obvious. 

I have several maintenance plans configured on a SQL 2008 R2 (10.50.6529). When I remotely connect to it with SSMS 2008 R2 or SSMS 2016 to edit the notify operator task there is nothing listed, just blank. If I RDP to the server and open SSMS locally, the expected checkboxes appear. Why is this so? Is this a just a one-off bug? I thought, for the most part, that it didn't matter which version of SSMS you use. 

I have found that you can do on columns using the clause(example here and here). Unfortunately, there is nothing mentioned about performance optimization in the official documentation. Could anyone tell is there any optimization at all? Has anyone made some performance test? Also if there is optimization I guess it will affect only specific situations, too. 

The general goal is to reduce the first database size and put it on SSD drives and put the historical not queried data on slow storage. The tables will have less indexes and can be additionally compressed via row,page,column store or clr compressions. It will be working under simple recovery model. I have never used linked servers and have the following questions: 

I am testing feature and once the operation of encrypting column is done I have a file with hundreds objects failed to be refresh by the procedure. Should I investigate these errors and perform the refreshing by myself? What are the risks of not doing this? 

Is there a way to search by text in packages using statement (or other language)? I want to check if certain table is used in any package as I am going to drop it - if the table is used I need to edit the package. Could you advice? 

I figured out the issue after doing some more searching and trial & error. The process I used for finding the issue: Started with the CLI and ran the following command: This will provide a list of all features that are enabled and disabled 

Short answer: The SIDs for the ‘MyReportAcct’ SQL login are different on each server instance. Long answer: The database houses the security database for each instance of SQL Server (think Active Directory for a database server). In this scenario we have two different databases, since it is a mirrored pair. Each time you create a SQL Login, there is a different SID created along with the account, this is no different than how Active Directory has always worked. When a mirrored database fails over, the SID in the database matches the SID stored in the database of the principal server (SERVER1), not the mirrored server (SERVER2). This natural, and default process of failover causes the SQL Login (MyReportAcct) to become an orphaned account on the principal server (SERVER1). This orphanhood process happens EVERY time there is a failover. The start of authority for SQL Logins are the instance that they were created (SERVER1). The failover to the mirrored server (SERVER2) is now a different start of authority, so the SIDs will be different, hence why the reports fail. Solution: 

I have found the following queries to detect the CPU usage by database, but they are showing different results: 

Its body statement is executed for 0 seconds (with given parameters). The function itself (with the same parameter is never executed - I was waiting for 20 minutes and only part of the result was returned). There must be something wrong with the statistics and respectively the query execution plan that is created because the function is executed instantly: 

The history table columns will be and I am going to save a lot of space versus ordinary implementation which is logging all data (this is due to my test and my bussness cases). As I the supports I am wondering are their any pros/cons/differences between using it and trigger-based logging? I have check few artciles (here and here) and cannot see what more can give me. 

I have many large tables that are populating with data constantly. The information is rarely or never read and I want to move them out of the database. So, the idea is to: 

I have checked thet the is decpreated. Does this mean that the results from the second query are wrong? 

The result was the same. So, it is not true that each row is occupying at least 8 KB, but the size is actually increased. I know that: 

During our recent monthly maintenance window I ran into an error installing SP2 on SQL 2014. The following is a screenshot and the associated error messages. Let me know if you need anything more. Here is a list of things that I've tried: •Tried installing CU7 - failed with similar message •Tried installing CU8 - failed with similar message •Restarted Server each time and tried installing CU7, CU8, and SP2 - all failed with similar message 

Action required: Use the following information to resolve the error, and then try the setup process again. 

In the interest of saving time and money (licenses). For example: We have a mirrored SharePoint backend as well as a mirrored Lync SQL backend. I want to use the witness for the Lync servers to be the witness for the SharePoint mirrored pair at the same time. 

This server was recently installed and configured. I was in the process of creating some maintenance plans to backup the logs and DBs on a daily basis. Regardless of my method to perform a full backup, it would fail immediately citing the generic error message 

I wonder if this question will need to be moved to the SharePoint SE site, but I believe this could be a simple a SQL Server security fix. A little back story: Back in April we upgraded our SharePoint SQL Server backend (mirrored) from SQL 2005 to SQL 2014. We did this by way of mirroring from SQL 2005 (primary) to SQL 2014 (mirror). I don't believe the security settings and logins were extracted from the old server and placed in the new. I'll have to reach out to my infrastructure department to see if the server has been completely decommissioned. My SharePoint Admin is trying to create a new site from the SharePoint Central Admin Site (SharePoint 2010), but gets the following error. 

Add column to the table called with default constraint and When data is going to be encrypted the flag is raised and the output encrypted value will be set in the existing column 

I am going to test the both variants of course but before doing that I am wondering is there another option or any issues in the above ones? 

When the temporary table is used, the correct count value is used for the rows returned by the function. All involved indexes are rebuilt. Why I am worried about this? This join is part of more complex query which execution is very slow. I believe this is due to the fact that the statistics that are used by the engine are wrong and not the optimal execution plan is used. Even when the query use parallelism again nested loop is used to join the tables. If I use a or hints on join the correct statistics are used and better execution plan is built but I prefer to find a way to provide the correct statistics instead of forcing the engine to do something. Could anyone tell why always one row is expected? Maybe because table-valued function is used, the engine thinks one row is going to be read from the table/index? 

I received alerts from one of my database servers over the weekend that was somewhat disconcerting. There was an alert for each single database within the maintenance plan. 

Actually, everything stayed the same, I found out that the service account some how lost the permission. So, I gave the service accounts the permission and all the mirrored database synced as expected! 

Is there a command at the CLI or in PowerShell that will list the components installed for SQL? I'm looking for something like the Feature List you can get from running the discovery report from Tools in the SQL Server Installation Center program option. I'm running SQL Server 2012 on the CORE version of Windows Server 2008 R2 Enterprise. I've searched around the Net, but haven't found anything useful. 

I've verified that the logs are being restored on the log shipping secondary, matched up the LSNs, also, I have the Log Shipping Monitor from Red Gate that verifies my logs are up to date. Further, the aforementioned error message is for every database in the instance. I've built a similar setup in a lab environment and I get the same error messages. 

I've recently audited a SharePoint server and found configurations that are against best practice. I'm hoping there is better and quicker way than right-clicking and changing these settings manually on over 100 database. For instance, all the databases are set to autogrow by 10MB and the log files are set to autogrow by 1%. I'd like for these to be a set number and not a percentage. Any resources or recommendations would be greatly appreciated! 

I have on virtual machine and want to install SQL Server Integration Services. On the drive is mount. I am reading a book where it is said that: 

and using command. In both cases it takes more then 19 hours. Is there a way to optimize the clustered index rebuild operation? 

I want to query spatial data for nearest neighbor. I am using this article and the following query works perfectly: 

I am testing how one of our stored procedure is working on vs editions. I have created two virtual machines and install a () and restore a database on each instance. Then I have generated some test data (large volume but the same on each database) and started testing if there is an execution time difference. I have been told that there should be better performance on the edition when a large volume of data is used because there is NUMA Aware Large Page Memory and Buffer Array Allocation. So far, there is no such difference and the execution time is almost the same (a or second difference). I cannot say I understand completely what is and how it works, but I guess the hardware is on as the following query returns me and : 

Case scenario The functionality is used to encrypted all data in a particular column. I need to encrypted only some of the data, so I need to use a or . I want to protect them with a certificate which is stored in the in order to control the access to the keys from there. Is this possible to create such certificate? 

Problem started May 3rd. We are no longer able to import SSIS packages that have been modified by Visual Studio 2017.X into our SQL Integration Services (SQL version 2017 14.0.3023). SSMS Integration Services importation component (the GUI) keeps crashing! For any NEW packages or any Packages we modify with in Visual Studio 2017 x. We are able to import historical packages and Visual Studio 2012 packages. Here is the error message from SSMS 17.5 

When I run this code, it appears things are running fine, the GUI window comes up and shows progress, then all the sudden it quits, the GUI goes away, and then I'm left with the following at the CLI: 

We created a SQL Login account for reporting use only (SSRS), we'll call it 'MyReportAcct'. We've used this account for some time and it is created for every newly installed instance. It has been working as you'd expect, except on a couple of mirrored instances. I've not seen this issue on any standalone instances in my environment. Randomly, reports will stop working and there is nothing being changed based on our internal processes for Change Management, Windows Logs, and SQL Error logs. Here are two of the error messages we receive: 

I seriously suggest building another system with SQL Server Express and configure it as your witness server. Then set your operating mode to "High safety with automatic failover (synchronous)". This solution will alleviate you of this problem. You will incur a cost for the desktop windows license, but as you may already know, SQL Server Express is of no cost monetarily. 

As it is said here it is a good practice to backup the database master key, because when the database is moved to another instance it will need the original DMK that has been used to protect the certificates in order to skip regeneration of the encrypted stuff. In the context of database backup encryption, when the DMK is stored in the database with the rest of the certificates used for backup encryption, do we need to create a backup of the DMK? Also, I am wondering, as it said that 

create linked server create new database on the linked server with mirror tables each night/several days/week a job will delete the records from the first database and insert them into the second one 

I just wanted to check if I can get different dates using sys and not sys date time function. And of course it is possible. 

I think I have found how to fix my issue, but I am not going to accept this as answer as I am not able to explain what is causing the problem and guarantee this will work anytime. It's fix found after a lot of testing and I will be glad if someone can bring more light here. 

Does this mean, that if I used same password to create and protect each DMK in my databases across all instances, the key will be the same? If not, it is OK to create a DMK on one database, and to restore it on all instances in order to have the same key everywhere and to need make a backup of only one key? 

Upon investigation of the account, it shows up under the Security object folder in SSMS. Also, we find that the account is associated to all the databases under User Mapping for the account properties. I've verified that 'MyReportAcct' has and , so on the surface every looks as expected. The rub comes when I try to alter the account or remove the mappings. I'm met with: 

Full disclosure, I'm not getting anything out of this "plug" and I don't work for Red Gate, it is a free real time monitoring tool that'll monitor log shipping. Red Gate Log Shipping Monitor Microsoft TechNet Article 

Everything in the result set was correct, save monitor_server, it had the value of OddServer03! As many of you know, when configuring Log Shipping through the GUI, it is damn near impossible to "accidentally" configure this option. We never intended having a monitor server in the mix. We use Quest Spotlight to monitor the aforementioned servers which will yield alerts when jobs fail or when log shipping gets behind. One other perplexing matter, the job that is getting created is instead of . Why is the service account trying to authenticate to a server that isn't part of the configuration? 

Or will I have to break the mirror, restore the database, then rebuild the mirror? We're in the process of upgrading our SharePoint servers. We already have two new servers in place and they are currently mirrored. If possible, I'd like to leave the servers in a mirrored state to save time during our maintenance window.