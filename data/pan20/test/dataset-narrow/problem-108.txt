The payload for UDP or TCP is the application data being transferred. The contents of the payload are only meaningful in the context of the application using the protocol for transport. As you suggest, the data may be encrypted, and there are different encryption schemes used by different applications. Some applications have application-layer protocols with headers, and some do not, but application-layer protocols are explicitly off-topic here. 

IS-IS uses Dijkstra's algorithm, like OSPF, to route through the network. The L2 routers form the backbone. Basically, you can think of the collection of L2 routers as OSPF area 0. L1/L2 routers are ABRs, with one foot in an area, and another foot in the backbone. Once a packet has reached an L2 router (including an L1/L2 router), the packet will be routed through the L2 routers via the shortest path to the L1/L2 router of the destination. 

That is not preventing you from booting to the login prompt, it is preventing the router from presenting the login prompt. The router is still booting, and it doesn't really add any time to the boot process, it just seems that way. 

No. HSRP defines the first hop for hosts sending traffic off the LAN. it has nothing to do with how traffic coming from somewhere else is routed, and any router connected to the LAN will put it on the LAN, otherwise you are adding inefficiencies. HSRP is on the LAN, not in front of the LAN in the routers. The routers communicate with HSRP messages on the LAN, and you may or may not have any other connections between the routers, so they would have no way to send the packets to the other router, anyway. The diagram shows HSRP on a link between the routers? That doesn't seem right since there are no hosts on that link. HSRP is only for hosts with configured gateways. What you really want to do is to make sure that your HSRP priorities (higher is better, like bowling) line up with your STP priorities (lower is better, like golf), so that both HSRP and STP want to deliver to the same place, otherwise you can get inefficient switching where frames are sent to the root switch, then need to be sent back to a different switch for routing. 

You will either need to shutdown the current master, or you will need to restart the stack. Once the stack is up and running, there is no election unless the current master stops. You should schedule a time to do this. There is no such thing as never being able to (at least, briefly) disconnect a device (stuff happens), but you can minimize the impact. 

PPP is an extensible encapsulation-protocol which operates over a DTE/DCE connection. This implies two endpoints (one DTE and one DCE). These endpoints are adjacent to each other over the real or virtual circuit. Cisco has a PPP description document: Point-to-Point Protocol 

IP is an OSI layer-3 protocol, while TCP and UDP are OSI layer-4 protocols. As a layer-3 protocol, IP can carry many different layer-4 protocols. TCP and UDP are probably the most common, but they are not the only ones. Layer-4 protocols are what applications use as their end-to-end connections. IP transports layer-4 protocols from network to network (host-to-host). Layer-2 protocols, like ethernet, transport layer-3 protocols on a LAN. You should research the OSI model, but realize that it is a conceptual model, and the real world often doesn't exactly match. 

Mostly, modern switches don't increase latency; they switch are wire speed, since most of it is done in hardware. Buffering traffic slows it. Switches tend to have very, very small buffers. The reasoning is that it is better to drop traffic early than to slow it down. Networks prefer that any traffic which will be dropped be dropped as soon as possible (if a switch must buffer traffic, it is likely to be dropped by subsequent network devices) to give a head start to detection and retransmission. 

Virtually all professional WAPs (what are on topic on this site) have 1 Gbps ethernet ports. A WAP is a translating bridge, it translates from ethernet to Wi-Fi and back. You need to understand that you have two different, independently-developed technologies being bridged. One technology, ethernet, has standards for different speeds (10 Mbps, 100 Mbps, 1000 Mbps, and 10,000 Mbps) on UTP. Each bump in speed costs more, and it took some years between bumps in speed. On the other hand, Wi-Fi was developed for its medium (radio), and it has multiple standards, each with its own maximum theoretical speed. Because of real-world obstacles, it is unlikely that you can get anywhere near the theoretical maximum speed on a WAP. To bridge these disparate technologies, you need to use what each technology offers and balance the price/performance ratio, otherwise your product won't sell. 

I don't think you quite understand that Alice needs Bob's MAC address before she can send anything to him. What RFC 4861, Neighbor Discovery for IP version 6 (IPv6) says about this in Section 4.3. Neighbor Solicitation Message Format: 

I assume you are using NAT to translate a private source address to a public source address. Each WAN interface is going to have a different public address. so packet leaving one WAN interface will not have the same source address as packets leaving the other WAN interface. That is one reason that per-packet load balancing is not recommended (per-flow is what you should use). Your situation will not work at all with TCP because it uses connections that are based on both the source and destination IP and TCP addresses, which would be different from each WAN interface if you use NAT. UDP doesn't use connections, so it avoid that problem, but you will need to deal with the different source IP and UDP addresses from each WAN interface in your application. Unfortunately, protocols, applications, and programming are all off-topic here. You could try to ask about that on Stack Overflow. 

You get a high number of input drops if your device cannot service the input queue fast enough. There can be many reasons for this. For instance, routing policies or other services which cause process switching will slow your CPU and increase the number of input drops. Cisco has a document, Troubleshooting Input Queue Drops and Output Queue Drops, which discusses the problem: