There is no native Python data structure really well suited to create a FIFO queue. There is in , but it is a little obscure language feature, and also not ideally suited, so I'm going to pass on using it. Your implementation using a list and removing items from the front will lead to a terrible worse case performance, probably quadratic in the number of nodes. At the cost of not releasing the memory early, I think it is better to never remove items from the queue, and use an indexing pointer. 

You basically initialize the board to all zeros, use for one player and for the other, and keep track of the sum of values in each row, column and diagonal. Whenever you add a new move, you can update all your data in constant time, and check in constant time if the player has won. 

Your solution is kind of crappy time complexity wise, as adding elements without removing any takes quadratic time, as you reverse the full stack twice for every value added. The better algorithm (which I think is amortized constant time) for this problem is to have one stack for input, and another for output. simply pushes to the , while tries to pop from the , except if it is empty, in which case it first reverses the onto the : 

Imagine you had to do the same with 4 distinct digits, , , and , and lets forget for now about numbers with less than 4 digits. There are 4! arrangements of these 4 digits, of which 3! each will have the in the first, second, third and fourth positions. So the contribution of the digit to the overall sum will be , and the total sum of all numbers generated from these four digits ends up being . It is easy to check that this works comparing to a brute-force solution: 

What your code is doing is typically described as merging both lists. The word union sounds like the set operation, where repeated values should appear only once. Assuming your interpretation is correct, you typically want to minimize the amount of work done in the inner loop of any algorithm. In your case, this is typically done by not handling the items of one list once the other is exhausted inside that loop, but afterwards. Also, the typical way of merging is that, in case of a tie, the value from the first list goes into the final list first. This is mostly irrelevant for your case, but it is a good habit to write these things conforming to that norm, so that if you ever find yourself writing code for an indirect mergesort, you willt be less likely to make it non-stable by mistake. 

For a website I'm working on, I had to get all the unique entries in an array and count their occurrence. It is possible a certain entry is only found once, but it can also be found 20 times. So I designed the following bit of code: 

(Keep in mind that I've left out all irrelevant code. If you want to see the sources, follow the link below). It's quite a bit of code, but I'm not looking for code optimisations. I only need to know whether this is a good OOP implementation. Would I be better off having a separate CollisionDetector class, where I pass my colliders (Arrow and Monster) in? Should I implement the collision checking in the colliders themselves? Or is there perhaps something I haven't thought of? If you want to see the full project, check here. It's made in Java with the Slick2D framework. 

This seems a bit better already :) But I think it would still be better to move the text to .txt files 

The array contains the the entries returned from the database. And the array contains the unique entries and how many times they occured in the array. This is my first php script (on a drupal webpage by the way) and as such I don't know that much about php. I'm pretty confident there is probably a more a efficient way to do this, using php-specific functions. Any and all tips are welcome! EDIT: I might have to clarify the structure of the arrays: has two dimensions. The first dimension is just a key for the second dimension. This one contains an array of drupal nodes for each key. uses the nodes from as a key and the value is how many times the node occured in EDIT 2: I printed the arrays, as requested by Boris Gu√©ry: 

I'm working on a clone of Hunter Story. You shoot monsters with your bow. Recently I implemented collision detection, this is all working correctly, and I don't think the code needs any dramatic optimisations. The only thing I'm a bit worried about is how exactly I implemented it. I'm not sure if it complies with OOP standards. The relevant code: Level: 

I don't know any C, so I can't comment on the actual code. But it seems to me like you could move the text to txt files or xml files, instead of literally placing it in your code. You could probably walk through the txt file and print the text in a loop, rather than each line on its own. If you really want to keep the text in the code, you could move the print lines to separate functions to clean it up. As an example, let's clean this part: 

You would of course have a larger dictionary with all possible conversions. You could get fancy and store only half the conversions: 

You should profile your code, to figure out what exactly is it that is slowing your code down. It's hard to tell without some actual measurements, but my bet is on your calls to and , as the method is notoriously (very) slow. For some operations there is really no alternative, but for addition/subtraction you can use . The transformed code would look something like: 

Note that the tests, which all pass, run your test samples against the values returned by your code. So both this and your implementation agree, which is a good thing. 

It is a little cleaner, but not more efficient, as it still has to allocate a mask of the same size as the image. 

But if the and arrays are large it may actually perform worse, as it avoids looping but creates an intermediate array of items. If you expand your expression, you could also do: 

Memoization is one of the poster childs of function decorators in Python, so an alternative approach would be something like: 

There are cleverer ways of computing a quotient of factorials, but that is left as exercise. You also have to handle all the possible permutations with less than the full possible digits. There may be a better way of not having to brute-force your way through this, but I'm out of cleverness right now, so I am going to go with something very unsophisticated: 

You can do a similar thing for the setting of zeros of the sieve for other prime numbers, but it gets complicated to figure out how many zeros to add on the right. 

Note that, since we are using sets, the exact order of iteration over the connected nodes is implementation dependent, so a failure form the above tests doesn't necessarily mean that something is broken in the algorithm. 

What exactly do you want to do with your array of booleans? If you used numpy, you could instantiate your boolean array as an array of one eighth the size of the boolean array, e.g. 

This function returns the first position in which you could insert , and keep the sorted, which will also be the first occurrence of in if there are repeated values. The neat twist is that, by replacing a single with a you get the following: 

Integer division (and that includes the modulo instruction) is a pretty expensive operation, several times slower than any other arithmetic operation, and you are having to do many of those. It would be nice if you could you a more sieve-like approach, where modulo operations are replaced by stepped iteration. Of course the issue with a sieve is that you do not know how far out you need to go to find the 10001st prime. So what we need is a sieve-like procedure that allows us to extend an existing prime list. If you are familiar with the sieve of Erathostenes, the following code should not be too hard to understand: