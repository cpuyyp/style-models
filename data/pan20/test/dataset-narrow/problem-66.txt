What you are calling PAT, is really NAPT (Network Address Port Translation). The term is defined by RFC 2663, IP Network Address Translator (NAT) Terminology and Considerations: 

As soon as the host application wants to listen to a multicast group, it sends an IGMP join message for a group to the router. The router will then set up the multicast forwarding and send the multicasts to the interface. The router will periodically send IGMP queries out the interface to see if any hosts are still interested in receiving this multicast group. If it gets no replies in the time period, it will stop sending the multicast group to the interface. You don't specify what the source type is, nor the destination application. You may have a problem with one of the other. If the source application is sending the multicasts, you may need to check the target application. You can use the interface command on your routers aid in your testing. Notes: You are setting both the RP and the source as the RP mapping agent (). You only need to do this on the RP since the RP can be the mapping agent. You should enter your loopback as the interface-id for the RP mapping agent: 

Interesting traffic is literally the traffic you are interested in for a particular reason. In the case you describe, traffic that is permitted by the ACL is the interesting traffic. When traffic is coming from an inside interface, destined for an outside interface, it is compared against the ACL to see if it should be translated before it is sent through the outside interface. Traffic that matches the ACL is what is interesting to the NAT process. 

Any host, even a router, sending a broadcast will send to the broadcast address MAC address, not a specific host MAC address. 

OK. The 5 minute rate is how many bits were received in the last 300 seconds, divided by the number of seconds, to give you the number of bits per second over the last five minutes. It is possible that you have only a minimum frame send during the last five minutes. The frame will be sent at 10 Gbps, but your five minute rate will be much less because the entire frame will be sent in just over five hundred-millionths of a second. Even a full frame is sent in about three times that period. The framing overhead (18 octets or 144 bits on non-tagged frames) takes into account the ethernet frame overhead on a frame (frames are sent one at a time on the link). Ethernet also has a seven-octet (56 bits) preamble, and a one-octet (eight bits) start of frame (SoF) delimiter, preceding each frame. There is also a 12-octet (48 bits) inter-frame gap between frames. All of that is layer-2 overhead before getting into the frame payload (the layer-3 packet). Then you have the layer-3 packet overhead, the layer-4 transport protocol datagram overhead, and (possibly) the application protocol overhead before you can even start discussing the application data sent over the link. 

You should look at one of the network models, e.g. the OSI model, but remember that the models are just models, and the real world can often be different than any of the models predict. Any application using the network will have data as a payload to the network stack. For instance, web browsers and servers use HTTP as an application-layer protocol, and HTTP uses TCP as its layer-4 protocol, so HTTP is a payload of TCP. The browser sends requests to the server, and the server returns web pages as a result. Both the requests and results are payload of TCP segments. 

STP is about providing a loop-free environment, and path cost is a secondary concern. The key is that it elects a root switch. The best metric to the root switch is the metric used to send traffic, not the best metric to the destination. This forces the traffic to travel toward the root switch in order to get to its destination. If you look at the topology, you can see how this eliminates loops. 

This is certainly something that is done. If your WAN routers have full Internet routing tables, then, at least in theory, your WAN routers know how to reach every public address on the public Internet. A default route would only allow routers configured this way to send traffic with a a destination not in the routing table to the ISP routers, but the WAN routers should have the same routing knowledge as the ISP routers. 

The host gateways, including the switch, should be set to the router address for the correct VLAN. Switch configuration: 

If you mean the optional (for IPv4, but required for IPv6) UDP checksum, then that creates a 16-bit checksum that conceptually matches multiple combinations of datagrams that are larger than 16-bits. There is no guarantee that a UDP datagram that matches the checksum is error-free, but the odds of an error are very small. Many errors that would match the checksum would prevent the datagram from reaching its destination. If the checksum indicates an error, then something is wrong somewhere, and it is almost always corruption in the datagram. Other possibilities include an incorrect or buggy checksum algorithm on the part of the sender or receiver. If you mean a checksum in the application data, that further protects the data, but that is off-topic here. There are also the possibilities that bits get flipped in RAM or on a disk drive. It does happen, but not very often. See RFC 768, User Datagram Protocol: 

It is possible, but as Ron Trunk pointed out, it is not a good idea to do it by messing with the hardware. You can use QoS to do this also. Something like: 

Frames on trunk interfaces get 802.1Q tags in order to marks which frames belong to which VLANs. Frames on access interfaces do not get tagged. The access interfaces are assigned a VLAN number (default is VLAN 1), but the traffic on the access interfaces is not tagged. Most end-devices don't understand VLAN tags (some servers do, but that would be for sending traffic for multiple VLANs on a trunk to the server). The link between your two switches would be a trunk. The gateway for each VLAN would be the address assigned to the SVI on the layer-3 switch. The broadcast address is always the last address in the network. The first address in the network is the network address. Those two addresses are unusable for host addresses. 

You must think about why wireless and bus topologies are similar. They are both half-duplex technologies, and every frame sent "on the wire" is sent to every host. That means every host will hear every frame, and some of those frames must be for a listening host. 

You could shutdown/no shutdown a port to force a refresh, but that seems rather extreme. Rather than changing the probe count, you could shorten the interval. Sending 255 probes every 30 seconds seems like a lot; it is nearly 10 per second. You could get a close calculation for the number of time a port was probed by showing how long the port was up, divide that by the probe interval, and multiply that by the number of probes configured per interval. There are also other features such as DHCP snooping which will build a database of MAC addresses and the DHCP assigned IP addresses. If what you have doesn't suffice, you can always request added feature from Cisco, although your requested features may or may not make it into a future release. Cisco may also share a roadmap of planned enhancements to you. 

I'm not sure what you mean by buffer. There no buffering like when you want to watch a video. Besides the inherent latency of the bits traveling the various media in a path, there are delays due to serialization/deserialization to get bits on/off a link, frames must be stripped so that routers can inspect the packet, delays for routing lookups, packets must be re-encapsulated in frames for the next link, possible delays for queues when there is congestion (this varies greatly depending on the traffic load, which constantly changes), and a delays for TCP when IP packets are dropped and need to be resent. Instead of buffering like you may think of it, relatively small queues (usually less than 100 packets, possibly several for various traffic types) may be used in a router, and when a queue is full, packets are just dropped. There is also RED which randomly drops packets in a queue in order to prevent a queue from filling up. Pings (ICMP in general) have a very low priority and are most likely to be dropped or put in a low-priority queue (other, higher-priority queues are served first). There is far too much chaos on the Internet to give a single answer to your question. It depends on how many hops, which medium is between each hop, the router capabilities at each hop, whether the routing in any of the hops needs to be process switched, if any of the networks through which the traffic passes have QoS policies in place (and they could all be very different), etc. You question is not really on-topic, but I gave you an answer which generally explains how things work. 

If an ISP peering with Google decides that Google must use addressing from the ISP, a foolish decision that will violate its contract with Google and cost it a fortune in revenue, then Google simply takes its business to other ISPs. 

Apparently, you are overthinking this. With a PBX you get as many PSTN lines as necessary for the total number of simultaneous PSTN calls that you may have. Usually, you get a DID range that is larger than the number PSTN of lines. You could have a single incoming PSTN line, but separate numbers in a DID range for each internal function. The PBX can then direct the call to the appropriate internal device based on the called number. 

Cisco has the command that allows an interface to assume the address of another interface for distance-vector routing protocols. If the requirement is no IP address assignment on a physical interface, you could assign a loopback with an IP address and use the on the physical interface. The physical interfaces could also use DHCP to get an IP address. The interfaces need some sort of IP address, specifically assigned, or not. Routing can't work without knowing IP addressing. Routing without IP addressing is like the post office needing to deliver mail without knowing a street address, city, or state. It's just not going to happen. 

You cannot compare metrics between different routing protocols. To solve that problem, we have Administrative Distance, which gives you a relative trustworthiness of a particular routing protocol, as defined by the router vendor. In particular, Cisco defined the AD of EIGRP to be lower (more trustworthy) than that of OSPF. It is possible to change the AD. 

Packets are a layer-3 datagrams, and they are fragmented and reassembled at layer-3. TCP is a layer-4 protocol using segments that are carried in the layer-3 packets. The layer-3 packets are fragmented and reassembled transparently to layer-4. 

Based on your comment, I think I understand your confusion. The Wi-Fi medium (radio waves) is a shared medium, and only one device at a time can send, even your PC and WAP must take turns and not send at the same time, which is why advertised Wi-Fi speeds are just so much marketing hype. If multiple devices send at the same time, you have a collision, and a device gets garbled data, which it ignores. Wi-Fi uses CSMA-CA to try to avoid collisions. The Wi-Fi protocol is set up to fairly share the airwaves with all other devices on the same frequency, even those which are not part of your network. Devices will even bow out and give time to other devices. If you and a neighbor are operating on the same frequency, each of your devices will give time to all the other devices on the same frequency. That is why your network will slow down your neighbor's network, and vice versa. Neither of you owns the public airwaves, and you must share them. 

You can control which VLANs are allowed on a trunk. For example: On the 4507 trunk interface to the 3524: 

What you are reading about the label is for the label on the WAO. That points you to the termination in the TS. Remember that your terminations in a TS are fixed, while the work area outlet, itself, may move, especially if it terminates in modular furniture. It is very common to need to know from the WAO where to go to complete a connection in a TS, but it is much less common to need to from a TS where a WAO is. For example, you connect a device at a work area, then you need to make the connection in the TS, but you usually don't make a connection in the TS, then need to find the WAO to connect a device. The formats of both guidelines are aimed at letting you identify where to make connections. In any case, you should have building drawings showing the WAOs, preferably approved by an RCDD. TIA-606-B is really a set of guidelines. You are free to add or use whatever makes sense to you, but whatever you choose must be applied consistently and uniformly to every area, and it needs to be communicated to any vendors involved. 

Cisco maintains documentation for this type of thing. It takes about 2 seconds to locate the specific document on how to do this. Active and Passive FTP Overview and Configuration: 

It really depends on which layer-3 protocol you are using. IP, itself, allows up to 256 different processes to attach to it, and some of those processes are used by IP itself (e.g. ICMP). This is rather limiting. Adding layer-4 allows a layer-4 to define a way to have more processes to attach to the network stack. For example, TCP and UDP have up to 65536 addresses (ports) each, to which processes may attach. Other layer-4 protocols can allow more, or less, processes to attach. You can also have different layer-4 protocols, which serve different purposes, (e.g. connection-oriented, connectionless, custom for a specific purpose, etc.). You can certainly let an application multiplex for itself. You can do this with TCP or UDP, for example, HTTP servers multiplex requests which come into TCP port 80. When an application does this, it needs to provide for its own protocol (e.g. HTTP). Layer-4 on one host talks to layer-4 on another host, and delivers datagrams between applications. Layer-3 is concerned with delivering packets between networks, and layer-2 is concerned with delivering frames on a LAN.