Whenever, you delete 70% or more of the table, do it like this. SMALL DELETEs If you are deleting smaller chunks, perhaps you can do it with a : 

UPDATE 2011-07-12 14:55 EDT I just thought of a cleaner, simplistic way. Instead of using a stored procedure, simply use the GROUP_CONCAT function to gather all the tables to zap. Then compose into a single query: Here is a query to drop all tables that start with wp_pol in the current database: 

The answer to that would not be a simple yes or no. It depends on what your need to read. Otherwise, transaction isolation via MVCC would become rather pointless. For example, in MySQL's InnoDB storage engine you have four levels of transaction isolation: 

It's there for me. I installed this a couple of month ago using the no-install zip file. SUGGESTION Download the latest no-install zipfile for MySQL 5.6.15 and look for the folder UPDATE 2013-12-16 13:00 EST I just downloaded the no-install zip file. I looked in it and it is in there. Please download it and extract. Of course, make sure you have Perl installed on the Windows machine. 

You will either see or . If you see , then it was an RPM install. If you see , you either have a source-compiled in or possibly a yum-installed mysqld service that's gone wild. 

As I said before, there are 1023 undo logs (a.k.a. Rollback Segments). The amount of info stored to preserve the state of would fill up just one undo log. It's not worth the effort and firepower to load everything as a single transaction and a single commit loading one undo log in the event of a crash that may never happen. Please script the retrieval from to do something like 10000 rows at a time. Since by default, a single commit will be 10000 rows. For 2.5 million rows, that would be 250 commits. 

Give it a Try !!! UPDATE 2012-06-22 08:12 EDT Since you have <50MB of total data I have another option. Instead of launching a SLEEP command into the background to hold the global read lock for 86400 sec (that 24 hr) just to get the process ID and kill outside, let's try setting a 5 second timeout in mysql rather than in the OS: 

The fact that you changed it from 4 shows that the table was created originally in an earlier version of MySQL (default pointer size is 4 in MySQL 4.1). Looking at the additional MySQL 4.1 reference for : 

Sometimes this can occur because of a combination of a certain sequence of characters and the character set of the mysql client at the time of the import. You could have trapped such errors without additional tools by doing the following 

Look over as many examples of this setting as you can find. Take note of the queries attached to and find out what those individual queries do. Then, the purpose of will become more clear to you. More example available here : $URL$ If there are any users of pgBouncer out there in the DBA.SE, please chime. I am a only nominal PostgreSQL DBA myself. 

The quick and dirty argument that should come up against such policy is the implementation of business logic. Mundane auditing of data traffic is only one good use of triggers. Maintenance of those triggers for business logic makes the use of triggers take on a life of its own, as if it is part of the software lifecycle. For some databases like Oracle, PostgreSQL and SQL Server, such use of triggers in an ACID compliant arena should never be suppressed or relegated if business logic is best implemented in the database. On the other hand, one DBMS that has issues with ACID compliance in triggers is MySQL. The stored procedure language in MySQL has a rocky history although a measure of success of implementation can be achieved. Getting away from any specific database and to keep things in perspective: If referential integrity is to be maintained, let the database's storage engine do it. Why should an application reinvent the wheel of database integrity as part of business logic ? What if a transaction (series of SQL statements) needs to be rolled back and the triggers have already fired off in the middle of the transaction ? Can the audit trail info that was recorded be rolled back ? Does the storage engine allow rollback for trigger level data ? Will you have to design the rollback features independent of the paradigms of standard SQL ? Due diligence of research on these topics will clarify whether triggers are a healthy alternative. If there are some arithmetic operations you can perform in a trigger that will not slow down the processing of each row in a table, then triggers are OK. If there is some massaging of data you need to do and you'd rather have a trigger do it instead of at the browser code (PHP, Python, Ruby, whatever) that will not slow down the processing of each row in a table, then triggers are OK. CONCLUSION IMHO you should make sure audit trails are handled in transactions rather than in triggers because each recording of a row causes intermittency of database operation, especially when doing bulk processing or in a high-trafficked website. Triggers can accomplish business logic in many (but not all) situations. 

Fulltext indexes index tokens very well. Consequently, exact strings that contains multiple tokens should take longer to process. The only way to find faster is to use a subquery. 

If the prompt has not come back, I would assume the worst and just say the is not done. Even if a certain table stops increasing in size, you can still check for write activity directly in the OS. For example, if you imported into a database called and datadir is , do this: 

This will give you every table followed by a CSV list of alphabetically-sorted columns STEP 02) Launch this Column Query From Both MySQL Instances 

That's it, right? NOPE !!! If your website has been up this whole time, there may have INSERTs running against s_relations during the loading of s_relations_new. How can you retrieve those missing rows? Go find the maximum id in s_relations_new and append everything after that ID from s_relations. To assure that the table is frozen and used only for this update, you must have a little downtime for the sake of getting those last rows that were inserted into s_relation_new. Here is what you do: In the OS, restart mysql so that no one else can log in but root@localhost (disables TCP/IP): 

The first line of the script is . This tells the session not to record in its binary logs. This prevents from running on the Master (the DB Server with the DBVIP). Once a month, you can just take down the DBVIP from one DB Server and bring up the DBVIP on the Other DB Server. When you do that, you must also setup the script to on the Other Machine. The key is to run this on the DB Server that does not have the DBVIP. Give it a Try !!! 

STEP 05 : Make changes in your code for transactional support You will have to employ the use of three commands : Before you starting writing new data, precede it once with 

From this article, I started to realize that 0 may not improve CPU a Percona Server instance, but it can slightly improve MySQL. Setting this to 64 may or may not help. Why may or may not ??? The article compares MySQL with Percona. You are using MariaDB. Therefore, you would have to experiment with this. Since innodb_thread_concurrency is dynamic, you could run 

OK, I hope you are sitting down. This is the lazy way Oracle implemented sql_mode in MySQL 5.6: There is an additional file. If you run 

aggregate functions subquery usage clauses clauses sort order of results with no explicit clause query results using older GA releases of MySQL query results using newer beta releases of MySQL the current SQL_MODE setting in the operating system the code was compiled for possibly the size of join_buffer_size with respect to its effect on the Query Optimizer possibly the size of sort_buffer_size with respect to its effect on the Query Optimizer possibly the storage engine being used (MyISAM vs InnoDB) 

That way, the A side's date range ( - ) gets handled first before the JOIN. An additional benefit of the refactored query is that the of A and B involves a smaller subset of A. If you feel uncomfortable with the refactored query, here is another suggestion: switch the range-based and clauses 

In the book MySQL Stored Procedure Programming, all cursor examples give the local variable a unique name from its corresponding table column (if you have the book, see page 108 Example 5-15). Sidenote : Where are weekly_com and monthly_com coming from ??? 

This will give you the opportunity to clean up the data Alternatively, you may decide to make it a regular nonunique index. 

There are two approaches Approach #1 : DITCH CORRELATED SUBQUERY You should ditch the correlated subquery and replace it with the JOIN of two subqueies 

The only special circumstance where a being grouped with other keys is an absolute requirement is table partitioning. It says so in the MySQL Documentation (Partitioning Keys, Primary Keys, and Unique Keys). Here is an example from the Documentation 

In most cases, crashing a MyISAM table is nothing more than throwing mud on the MyISAM file header. It keeps a running count of the number of times the file has been opened. It increments upon opening and decrements upon closing. You may want to look at the value for open-files-limit. This is an option that you cannot dynamically set with mysqld running. It can be configured at startup. What is interesting is its explanation in the MySQL Documentation: 

That sounds very unusual, but not surprising. All it takes to run is the USAGE privilege, which is just general connectivity as stated in the last sentence of the first paragraph of the MySQL Documentation on :