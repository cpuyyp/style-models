there seems to be a fairly natural way/angle to study this question that is utilized in at least 3 papers as follows. let $TM(k,l)$ be the set of Turing Machine with $k$ states and $l$ symbols. for low/small $k,l$ the machines are provably decidable, for larger $k,l$ past some threshhold they are provably undecidable. however in the intermediate region, they are not consistently known to be either decidable or undecidable (and the full table is presumably unknowable based on the same undecidability phenomena of the halting problem). the results can be displayed on a grid as in some of the following refs. also in the intermediate region it is actually known that some (unresolved) machines are capable of simulating the Collatz conjecture for some inputs. therefore there is clearly a "transition-point" like phenomena operating here but not within a computable region but in an unusual sense of between computable and uncomputable. 

this can be a subtle issue because basically any algorithm that processes requests with responses is subject to a Denial of Service attack vulnerability due to being overwhelmed with requests, such that even efficient algorithms can be overwhelmed. in a sense the algorithms are not considered "flawed" until an attacker exploits them, during an ongoing, adaptive race between hackers and researchers employing countermeasures. one famous example from history is the so-called Ping of Death which led to large attacks in 2000 against Yahoo, CNN, eBay, Dell, & Amazon by the hacker "mafiaboy". ref [1] lists the 10 most famous attacks of the past 25 years several of which are DoS attacks. however, some other algorithms are not discovered to be inefficient until hackers find methods/attack vectors for "bogging them down" and the Apache vulnerability you mention apparently fits into that category. there are large amounts of research into DoS prevention techniques eg refs below. [1] Hackersâ€™ Most Destructive Attacks, DailyBeast [2] Preventing Internet Denial-of-Service with Capabilities Anderson, Roscoe, Wetherall [3] Denial of service attacks and how to defend against them Razmov [4] Internet denial of service attacks and defense mechanisms Abliz 

however grammars may generally be too "regular" to generate interesting music. for that there are different approaches being explored eg genetic algorithms & there are many references on that. following, one highly cited article. this now known as the field of evolutionary music 

also, other interesting topics from news/headlines with a strong overlap between TCS and popular science writing/books: 

the short candid answer is no or not so far. for (1), not as hard a question, but still apparently rarely considered, did turn up the following reference which could be taken as a related case in the literature. Hardness of approximation for quantum problems by Gharibian and Kempe they consider some "monotone" problems in a quantum context eg QMSA, "Quantum Monotone Minimum Satisfying Assignment, QMSA", ie a SAT QM analog; (also another problem Quantum Monotone Minimum Weight Word, QMW) and show some approximation hardness results, ie lower bounds. they dont consider monotone quantum circuits per se but an idea could be that a quantum circuit or algorithm that solves the monotone function QMSA can be taken as a QM analog. as for (2) it would be a very advanced result if it existed which it does not seem to "so far". Razborov's thm is basically a lower bound "bottleneck" type result considered a distinct breakthrough and near-unrivalled result in (monotone) circuit theory. so roughly speaking yes of course there are some lower bound bottlenecks found in QM computing, eg related to direct product theorems, for a survey see eg Quantum Algorithms, Lower Bounds, and Time-Space Tradeoffs by Spalek however, arguably a better analogous QM computing lower bound would put a lower bound on number of qubit operations or possibly based on "complete" gates like Toffoli gates for a monotone function. am not aware of proofs of this type. another approach might limit the analysis to special quantum AND and OR gates with extra "ancilla" bits added to make the gates reversible. 

[1] Aspects of Statistical Physics in Computational Complexity / Gogioso [2] The constrainedness knife edge / Toby Walsh [3] The Monotone Complexity of k-Clique on Random Graphs / Rossman [4] Phase transitions and computational complexity / Moshe Vardi [5] Phase transitions in NP-complete problems: a challenge for probability, combinatorics, and computer science / Moore [6] Phase transition behavior / Walsh [7] Determining dynamical equations is hard / Cubitt, Eisert, Wolf [8] The steady state system problem is NP-hard even for monotone quadratic Boolean dynamical systems / Just [9] Predecessor and Permutation Existence Problems for Sequential Dynamical Systems / Barret, Hunt III, Marathe, Ravi, Rosenkrantz, Stearns. (also goes by Analysis Problems for Graphical Dynamical Systems: A Unified Approach Through Graph Predicates) [10] A Dynamical Systems Approach to Weighted Graph Matching / Zavlanos, Pappas [11] On chaotic behaviour of some np-complete problems / Perl [12] New quantum algorithm for studying NP-complete problems / Ohya, Volovich 

an older example, but still with recent/ongoing research, some of this theory shows up in the mathematics of the "perfect shuffle", seen as an element of the symmetric group & which was a famous discovery at the time. [1] mentions applications of the perfect shuffle to parallel processing algorithms and also the connection to Cooley-Tukey O(n log n) DFT. [2] is more recent. the perfect shuffle shows up in parallel processing [3], memory design, and sorting networks. [1] Mathematics of the perfect shuffle by Diaconis, Graham, Cantor. 1983 [2] Cycles of the multiway perfect shuffle permutation by Ellis, Fan, Shallit (2002) [3] Parallel processing with the perfect shuffle by Stone, 1971 [4] Omega network based on perfect shuffling [5] Parallel and sequential in-place permuting and perfect shuffling using involutions Yang et al (2012) 

you mention PDAs specifically. note a Turing machine is equivalent to a PDA with two stacks. PDAs original rationale seems to have been closely related to the development of "language theory" ala chomsky. see eg Syntactic Analysis and the Pushdown Store," Proceedings of Symposia in Applied Mathematics (Vol. 12). Providence, RI: American Mathematical Society, 1961 this is has one of the earliest references Ive seen by Oettinger, "Automatic syntactic analysis and the pushdown store" p104, dont know if there are earlier refs to the PDA. it took many years of study of all the interelated automata to start to devise a unifying theory (still being constructed). the Turing complete concepts were devised around the late 30s or so when it was seen that the lambda calculus (developed independently by Church) was equivalent to Turing machines & equivalence to Post machines was shown around the same time (although these 3 models were devised somewhat independently & not immediately realized to be Turing equivalent on their original construction). new models are still being devised eg Cellular Automata have a much more recent history and have been shown to be in various senses Turing complete. it seems fair to say that most working in computer science were familiar with Turings seminal 1936 paper & that it highly influenced all later formulations of automata constructions (particularly the concept of the state transition table which seems to have been introduced by Turing) 

empirical. generate random graphs that fit the constraints or use graphs from some dataset that match the conditions and try different algorithms on them, and look at performance. one may find that an algorithm empirically satisfies the conditions reqd. if one is more strict, one could attempt to create a proof out of the empirical observation if its 100% satisfied by large datasets. also for empirical research it often helps to know how the datasets are obtained/generated, what their nature/origination is. the question has no related citations of literature/refs. so what are the nearest types of algorithms in the literature? for this type of problem multiple types of research areas might overlap. there is research on planar graphs, graph partitions, graph cuts, graph separators, partitioning triangular graphs, etc.; its not obvious to figure out the main theme of this question so far as its formulated or which particular (graph algorithm) research sub-area would most directly impinge on it. 

one may accuse Dyakonov of near polemicism but it serves as a nearly symmetric counterpoint to some QM computing proponents who have a fervent belief in the opposing position (that there is nearly absolutely no question of its future/eventual/inevitable viability). another major theoretician arguing for inherent limitations in QM computing (based on noise) is Kalai. here is an extended debate between him and Harrow on the subject. 

as I mention in a comment many real world graphs are "small world" which tend to have highly connected hubs. have not seen papers that specifically use/exploit this property for shortest path estimation however here is one that considers the question generally, considering the existence of effective decentralized [ie using local information] short-path algorithms & proving they must exist for some graphs. 

this type of research of relating video games to computational complexity is quite intriguing but it is also quite new, generally less than a decade old. I will argue here there is subtlety that is sometimes being missed in the current analyses [have not seen/noticed this pointed out in the cited paper or other papers so far] and that impedes answering the stated question definitely. to prove a relation to a computational system, one must be able to map the computational system onto the game and vice versa. for example in the above cited paper by Viglietta there is a concept that pressure plates and doors (ie the pressure plates control doors) can be "like" QBFs. this analogy is certainly viable as they have mapped it out. one can use a QBF to solve a game with pressure plates and doors. however, here is the subtlety. in a given game, the layouts of the game are basically fixed. in video game design the concept of different layouts is called "layout design" and is not a "given" of all games. for example in the groundbreaking game Doom, the level design tools were open-sourced ie made available to players to use. in other words arbitrary level design can be regarded as part of the game. but in other games considered in papers, the video games as originally built have fixed levels. the papers are sometimes not explicitly taking this into account. therefore there is a strong argument to be made that in most games without level design, or random layouts, levels are fixed, and this has a big impact on the actual complexity of solving the "game". ie, what exactly is the "game"? does it include random layouts, and/or level design possibility? is level design part of the computational mapping? these issues are glossed over somewhat in current papers. taken to the opposite extreme of the papers, one could argue that all real video game implementations are solvable by FSMs because they have finite memory! for there to be real computational mappings, basically one must generalize the game to involve 

given those qualifications a basic theme of the question seems to be "partitioning planar graphs". here are some leading recent refs on that topic which might be helpful & show additional themes/angles of current related research. there are some algorithms implemented & they may be available on request from the authors. the 3rd involves partitioning with weights, which will generalize to equal weights, but which gives an additional framework for consideration/investigation: could all the question conditions be fulfilled by some kind of weight assignment scheme? (this could also tie in with the requirement to have some kind of dynamic control or adjustment over solutions also referred to in the question.)