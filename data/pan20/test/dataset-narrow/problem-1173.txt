Markov Chains and Mixing Times by D.A. Levin, Y. Peres, E.L. Wilmer (2008). Finally a text book covering this broad and ubiquitous topic. 

Extending what @Amir wrote, I came across the following nice web page which hosts a CNF generator for factoring circuits that one could e.g. run on some of the (now inactive) RSA Factoring Challenge numbers. The generated instances are in DIMACS format that can directly be fed to any one of the current competitors in the annual SAT solver competition. Regarding hard SAT instances in general, the benchmark problems given at the SAT competition site appear to be quite useful, also the classification into random/crafted/industrial is nice. 

Cai, Chen, Lipton, and Lu have recently proved a dichotomy theorem on tractable exponential sums. The quadratic case is in P, whereas the cubic case is already #P-complete. 

There is a paper (2001) of similar style by Lov Grover, which describes the way to his breakthrough quantum search algorithm (1996). 

There needs to be a gap between the eigenvalue of the groundspace and the first excited state that is inverse-polynomial in the system size, and indeed such a promise is required for the QMA-complete Local Hamiltonian problem. Please refer to the formal definition of the Local Hamiltonian problem and the QMA-completness proof, e.g. Definition 10 and Theorem 1 in Nagaj's thesis. If the gap is inverse-exponentially small, then the promise is not satisfied by that local Hamiltonian instance and the QMA-completness proof does not apply since a key assumption is not satisfied. 

The minimum witness size over all witnesses of a span program for a given function equals the generalized adversary bound, as shown e.g. in Theorem 1.7 here. Further, the generalized adversary bound is just a semi-definite relaxation of certificate complexity, see e.g. slide 40 in Reichardt's tutorial. The relation to deterministic and randomized query complexity is discussed in these tutorial slides as well. 

EDIT (2012-09-05): Jeff's and Radu's comments are right. The cited result does not answer the question. To expand on Radu's comment, here is a related algorithm by Bravyi which gives an algorithm for contracting matchgate tensors on a graph $G$ with genus $g$ with run-time $T=poly(n) + 2^{2g} O(m^3)$ where $m$ is the minimum number of edges one has to remove from $G$ in order to make it planar. 

This topic has been extensively investigated in recent years under the name of Holographic Algorithms by researchers such as Valiant, Cai, Lu, Xia, Lipton, and others. Essentially all tractable cases of #CSP (counting constraint satisfaction problems) have been identified in terms of dichotomy theorems (FP vs. #P-complete). In particular, Matchgate computations have been identified as the specific class of counting problems that become tractable on planar graphs. See e.g. this link for further references. 

The spectral norm $||H||$ determines the maximum energy involved in driving the evolution of the quantum system and thus the quantum computation. Any quantum evolution could be sped-up by a factor of $\lambda$ by simply driving the system with Hamiltonian $\lambda H$ as a simple consequence of Schrödinger's equation. The energy involved is simply another physical resource invested into solving the problem, that needs to be considered in complexity considerations, besides time. For example, if your Hamiltonian has a tiny spectral gap, you could of course enlarge it by simply rescaling the strengths of all interactions in your system until the gap is large enough in absolute terms. Of course, after having solved the engineering challenges involved, this will linearly accelerate your computationion, similar to overclocking your classical PC. But the speed gained was only achieved by investing another resource that needs to be kept track of. 

Here is a reference to Bordewich, Freedman, Lovász, and Welsh that develops this topic to some extent. 

You might be very interested in the works of John Rushby, one of the designers of the PVS theorem prover, who is generically interested in exactly the points you mention. You might enjoy reading this classic report to the FAA about the use of Formal Methods and the Certification of Critical Systems (1993), and his newer writings about assembling a probabilistic, formal safety case out of various means of evidence provided (testing, proofs, analyses, etc). 

The Kushilevitz-Mansour algorithm in learning theory establishes, that whenever $\hat{f}(x)$ is approximately sparse, i.e. there are only $O(poly(n))$-many large Fourier coefficients of absolute value $\Omega(1/poly(n))$, then we can find their locations and approximate their complex values in $\sf{BPP}$. Of course you can also efficiently sample from that list. To be precise, Kushilevitz-Mansour only talked about Fourier transforms over $\mathbb{Z}_2$, but generalization to FTs over general finite Abelian groups (see e.g. Akavia's thesis) are known. As an application of this to quantum computing, one can show that the output state of quantum circuits structured in blocks of Hadamard-Toffoli-Hadamard gates can be efficiently approximated given the promise that the output state written in the computational basis is approximately sparse (see my QIP'2010 poster here, and the pre-print here). If the sparsity assumption is dropped, we could simulate Simon's algorithm (or Shor's), which is of exactly that structure, contradicting the $\Omega(2^{n/2})$ query lower-bound for Simon's problem. 

This is a non-technical question, but certainly relevant for the TCS community. If considered inappropriate, feel free to close. The Complexity Zoo webpage ($URL$ has certainly been of great service to the TCS community over the years. Apparently it is down since quite a while. I was wondering, if someone is still maintaining it, if it has moved, if there is a backup server, or if there are other plans to preserve this wonderful database of complexity classes, their relationships and citations to relevant publications. If not, are there comparable webpages that could be used as a replacement? UPDATE (Aug 1): The Zoo is back online, and Scott is looking for people volunteering to mirror it to avoid any future outages. 

Let your original state machine $M(k)$ have $n$ states and transition relation $t(s,s')$, where each transition $t(s,s')$ updates the global variables $x_1,...,x_k$ by applying function $(x'_1,...,x'_k) = f_{t(s,s')} (x_1,...,x_k)$. Then $M(k)$ is equivalent to a standard FSM with $n(2r+1)^k$ states, where each state encodes a tuple $(s,x_1,...,x_k)$ with each $x_i$ encoding one fixed value in $[-r,r]$, and new transition relation $t'$ $t'( (s,x_1,...,x_k), (s',x'_1,...,x'_k)) \Leftrightarrow t(s,s') \wedge [(x'_1,...,x'_k) = f_{t(s,s')} (x_1,...,x_k)]$. 

You might like this recent paper: $URL$ The paper shows, e.g., that "for any finite graph with $n$ vertices and all $k ≥ 2$, the $k$th largest eigenvalue" of the graph's Laplacian, i.e. $L=I-A/d$, "is at most $1−\Omega(\frac{k^3}{n^3})$", where $A$ is the adjacency matrix and $d$ a bound on the degree. 

As already suggested above, process algebra or process calculus is the place to start. Quoting freely from the respective Wikipedia page, 

As far as I'm aware, parameterized complexity theory has not been formally introduced to quantum computing so far. Many problems in the field, though, are well-known to be tractable once a key parameter is fixed, such as constant spectral gaps of local Hamiltonian operators, or bounded condition numbers of various matrices. Fixing the parameter often lead to tractable subclasses of problems (see Matrix Product States and Lieb-Robinson bounds) or efficient classical or quantum algorithms (e.g. Harrow-Hassidim-Lloyd algorithm), for which the general problem is usually exponential in that parameter. There are some works that explicitly use standard parameters of the fixed-parameter tractability (FPT) literature, e.g. 

The shortest proof for me is this: By definition of $PostBQP$, $PP=PostBQP$ implies that quantum circuits with deterministic projections onto a measurement outcome can be simulated in $PP$. Following Schuch et al., a projection onto the ground state $|\psi_0\rangle$ of a $k$-local poly-gapped Hamiltonian $H$ can be achieved by imaginary time evolution of a random state $|\chi\rangle$, i.e. by applying $|\psi_0\rangle \approx \exp[-\beta H]|\chi\rangle$ which suppresses high energy levels exponentially fast. The imaginary time evolution can in turn be approximated using the Trotter decomposition, which only requires operations $\exp[-\beta/NH_i]$ acting on finitely many spins. Since those operations are linear, they can be implemented using postselection, and we see that postselection can be used to cool into the ground state. Phase estimation can then be applied to determine the groundstate energy of the $k$-local Hamiltonian, which is the prototypical $QMA$-complete problem. Thus, $QMA \subseteq PostBQP = PP$.