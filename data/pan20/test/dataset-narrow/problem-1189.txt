I agree with D.W. that this should just be a dynamic programming question. Assume that $P_B$ is known and that we have a prior on $P_A$ and that $N$ is known. (Without a prior on $P_A$ or a known $N$, I do not see how your objective or "optimal" are well-defined.) Let optimal mean "maximizes expected number of heads" with the expectation over both the coin flips and the draw of $P_A$ from the prior. (This seems to me the only natural definition of (edit: achievable) "optimal" here.) Let $Val(t,prior)$ be the expected number of heads of the optimal strategy starting at time $t$ with prior $prior$ on $P_A$. Then immediately $$ Val(N,prior) = \max\{ P_B, ~ \mathbb{E}P_A \} $$ since at the last step we should just choose the higher chance of flipping heads, and $\mathbb{E}P_A$ with respect to $prior$ is the probability of getting heads from flipping coin $A$. So we know how to choose the coin at the last step for any distribution on $P_A$. At step $t < N$, $$ Val(t,prior) = \max\{ P_B + Val(t+1,prior), ~~ \text{val if flip $A$}\} $$ where $$ \text{val if flip $A$} ~~ = \mathbb{E}P_A ~~ + (\mathbb{E}P_A) Val(t+1,posterior(prior,heads)) ~~ + (1-\mathbb{E}P_A) Val(t+1,posterior(prior,tails)) . $$ Explanation: The value for flipping $B$ is $P_B$ for this coin flip, plus the value of the optimal strategy at time $t+1$ with the same prior on $P_A$ as we currently have. The value for flipping $A$ is the expected number of heads for this round, $\mathbb{E}P_A$, plus our expected value over the two possible cases. First, if the coin comes up heads (which happens with probability $\mathbb{E}P_A$), then we will update our prior to a posterior on $P_A$ conditioned on that event, and we will play the optimal strategy at time $t+1$ with that new distribution. Similarly if it comes up tails. There are at the very most $O(n^3)$ cases to calculate because there are $N$ time steps, and at each time step $t$, we have a distribution on $P_A$ that consists of the original prior updated after observing $j=0,\dots,t$ heads and $k=0,\dots,t-j$ tails. But this should be reduced with your observation that we need only consider strategies that try $A$ for some amount of time, then (optionally) flip $B$ for the rest of the time. Why this is optimal: Assume that the strategy is optimal at time $t+1$ for the specified prior distribution. But the "correct" prior distribution is always exactly the one we plug in to the formula: After observing a heads, the correct distribution over $P_A$ is precisely $posterior(prior,heads)$, and so on. When I say correct, what I mean is that the posterior gives the exact distribution over $P_A$ given that $P_A$ is drawn from the prior and these outcomes are observed. So we really are maximizing over the "average case" in each given scenario. 

4) Same question but for an unrestricted grammar. In this case, even the question of whether there exists a derivation is undecidable. 

Papadimitriou showed that a version of this problem is PPAD-complete in the paper introducing that class, "On the complexity of the parity argument and other inefficient proofs of existence". His formulation of the problem is: 

No, it's not true. Consider this game where the row player's actions are A,B,C and column's are D,E (shown are the row player's payoffs): 

It seems at least possible to me, but currently very unlikely. To sum up the below, it's because the current mathematical statement of (say) P vs NP is completely independent of any laws of physics, so one would need to describe new models of computation that do depend on physics axioms. The key point that Peter Shor made in his comment is that CS theory questions, such as P vs NP, refer to very simple and stylized mathematical models. They aren't statements about the real world. They just say "in this mathematical model, ___ is true". Now, one does often have empirical laws, such as the Church-Turing thesis, that state that the real world acts like these mathematical models. But that's a one-way connection (it doesn't mean that mathematical models must act like the real world!). To flesh out Peter Shor's example, the Pythagorean theorem only needs the ideas of real numbers and the Euclidean plane/distance. The model is much simpler than the real world and doesn't involve e.g. gravity, electromagnetism, thermodynamics, etc. And even if the Pythagorean theorem were sometimes false in reality because of these complications, this would not affect its mathematical truth. Similarly, the model for the Turing machine and the definitions of P, NP, etc are much simpler than the real world. The model does not involve things like gravity, thermodynamic entropy, etc. The truth of P vs. NP does not depend on whether computation can actually happen efficiently in the real world. Now, it seems to me hypothetically possible that in the future, we could discover closer connections between laws of physics and laws of computation. What would happen then is that the mathematical model of the Turing Machine would have to be expanded to account for these connections. One would then have to formulate new definitions of P and NP for this new model and argue that these are "better" than the old model and definitions. Then, in this new physics-aware model, one could have physics axioms that are used in proofs. But this seems very unlikely / far from happening, at least to me. 

Proof. The natural quantity to consider is $$ H(X|Y) - H(X|Y,Z) $$ where $Z$ is the indicator, $Z=1$ if $X \neq Y$ and $Z=0$ otherwise. Let $p = \Pr[X\neq Y] = \Pr[Z=1]$. Then as Thomas points out, by the chain rule and the fact that $H(X,Y,Z) = H(X,Y)$, $$ H(X|Y) - H(X|Y,Z) = H(Z|Y) \leq H(p) . ~~~~~~~~ (*) $$ Examples showing tightness: Let $Y$ be distributed arbitrarily; then conditioned on $Y=y$, we let $X=y$ with probability $1-p$ and with probability $p$ we let $X$ be distributed arbitrarily on any set not containing $y$. To be very concrete, you could let $Y=0$ always and let $X=0$ with probability $1-p$ and otherwise $X$ is uniform on $\{1,\dots,m\}$. Choose $m$ to get the desired value of $H(X|Y)$. In these examples, $H(Z|Y) = H(Z) = H(p)$. So we can make the inequality $(*)$ tight for any $p$ and any $H(X|Y)$. $\square$ Step 2. 

It took me a while to see the nice formula, but there is one. Consider a node $w$ at height $k$. The root is at height $h$ and the leaves at height $1$. The probability that $w$ is the least common ancestor of the two nodes is the probability that: 

(Well, this is too algorithm-dependent to really have an answer. Without restrictions on the algorithm, you could have two distinct Nash equilibria and then, as you plug in smaller and smaller $\epsilon$ into the algorithm, the $\ell_1$ distance between successive outputs could still be large because the outputs oscillate between equilibria.) Suppose $p$ is a strategy profile, i.e. product distribution over the players' strategies. For what games can we say that $p$ is an $\epsilon$-Nash equilibrium implies $\|p - q\|_1 \leq \delta$ for some Nash equilibrium $q$, where $\delta \to 0$ as $\epsilon \to 0$? (Note that the converse holds if payoffs are bounded by $1$.) This is actually tricky because we in the complexity setting what we call a "game" is actually a sequence of games parameterized by $n$, the number of pure strategies ("actions"). So $n \to \infty$ as $\epsilon \to 0$, and the relative rates matter. Here is a simple counterexample to show the answer is not "all games". Suppose we fix a sequence of decreasing $\epsilon_1,\epsilon_2,\dots$. Then for each $\epsilon_n$, construct the two-player game on $n$ actions where, if a player plays the first action, they get a payoff of $1$ regardless of what the other player plays; if a player plays the second action, they get a payoff of $1-\epsilon_n$ regardless of what the other player plays; and if a player plays any other action, they get a payoff of $0$ regardless of what the other player plays. Thus each game $n$ has an $\epsilon_n$-equilibrium (both play the second action) that is maximally far in $\ell_1$ distance from its only Nash equilibrium (both play the first action). So, two interesting sub-questions: 

A common model is to assume independent samples from $p$ and construct some estimate $q$ from the samples. In the case of a discrete distribution, this is particularly well-studied theoretically (using $\ell_1$ aka "total variation" aka "statistical distance" as the most common measure of closeness). A recent paper is "Instance Optimal Learning" by Valiant and Valiant. 

I guess the following trick is essentially "Newton's identities", but this seems a much more straightforward application to your question than what's on the wikipedia page. I've seen this mentioned on math.se before but don't know of a particular reference. First, we write down the polynomial $$ p(x) = \prod_{i=1}^n (x + s_i) . $$ By simply multiplying out this polynomial (efficiently! it is $n$ products of degree $\leq n$ polynomials), we can write it as $$ p(x) = \sum_{j=1}^n \alpha_j x^j. $$ where $\alpha_j$ is the sum of all coefficients of $x^j$, that is, all possible products of $n-j$ of the $s_i$s. In particular, $$ \alpha_{n-k} = \sum_{A \in {S \choose k}} \prod_{s \in A} s .$$ 

1) We are given an "input string" $s$, an "output string" $t$, a set of pairs $F = \{(a,b) : \text{$a$ and $b$ are strings}\}$, and an integer $k$. The question is if there exists a sequence of pairs $(a_1,b_1),\dots,(a_n,b_n)$ such that: (1) each $(a_i,b_i) \in F$; (2) $a_1 = s$; (3) $b_n = t$; (4) for each $2 \leq i \leq n$, $a_i = b_{i-1}$; (5) $1 \leq n \leq k$. In English, the $(a_i,b_i) \in F$ are "transformations" taking an input string to an output string, and we want to know if there is a length-$k$ or shorter sequence of transformations turning the input into the output. This can be solved in polynomial time by Dijkstra's algorithm for shortest paths. Make $s, t$, each $a_i$, and each $b_i$ nodes in a graph, drawing a directed edge of length $1$ between $a_i$ and $b_i$ for each $(a_i,b_i) \in F$. There is a length-$k$ transformation of $s$ to $t$ if and only if there is a path of length $k$ between them in the graph. 

I think you are right that the author's phrasing doesn't seem to immediately suggest a correct formalization of equivalence, but the idea is correct. I think the easiest formalization is the following. 

Of course $2^{\sqrt{n}}$ fits in both classes. So the question is easily yes if we are just thinking about upper bounds: Naturally $2^{\sqrt{n}} < 2^n$ should be consider to lie in the class of exponential running times. What I'm not so clear on is lower bounds. Specifically, I am not sure what a generally accepted interpretation of the following statement would be: 

We can see that the polytime functions satisfy the following property: $B \in P \implies f^{-1}(B) \in P$. We would like the following to be true: They are the only such "continuous" functions (note that output-size-messiness comes in when attempting to prove this converse). I don't know if it's true and it might even be equivalent to a very hard problem. We can also see that a language $B$ is in NP if and only if it is the polytime image of a language in $P$, that is, there exists $A \in P$ and polytime $f$ with $f(A) = B$. Sketch: If $A \in P$, then to decide the language $f(A)$ in nondeterministic polynomial time, given $y$, guess $x$ and accept iff $f(x)=y$. On the other hand, if $B$ is in NP, let $A = \{(x,w) : x \in B \text{ and $w$ is an NP certificate for $x$}\}$. $A$ is decidable in polynomial time and the polytime function $f$ that projects onto the first element of the pair satisfies $f(A) = B$. Therefore, we can notice that $P = NP$ if and only if $P$ is closed under these polytime mappings, i.e. for all $A \in P$ and polytime $f$, $f(A) \in P$. The analogous statement in topology would be "all continuous mappings are open mappings". We can see that an NP-complete set $B$ has the property that, for every $A \in P$, there exists a polytime $f$ with $f^{-1}(B) = A$. If $P \neq NP$, then an NP-intermediate set $C$ would therefore satisfy that there is some $A \in P$ with, for every polytime $f$, $f^{-1}(C) \neq A$; and also that it is not decidable in polynomial time, so there is no $A \in P$ and polytime $f$ with $f^{-1}(A) = C$. 

Proof. Taking the bound in the "theorem" and taking the derivative with respect to $p$, we find that the upper bound is maximized uniquely at $p = 1 - 2^{-H(X|Y)}$. In that case, the quantity inside the brackets is zero, and we obtain \begin{align} H(X|Y) - H(X|Y, X\neq Y) &\leq \log\frac{1}{p} \\ &=\log\frac{2^{H(X|Y)}}{2^{H(X|Y)}-1} . \end{align} Again, for any $H(X|Y)$, the prior examples with this choice of $p$ make this inequality tight. $\square$ Lower Bound Step 1. 

This isn't really an answer to your questions, but I think it would help in understanding the problem (or the way to answer your questions is) to write out a formal statement and proof of the solution. The proof you've presented doesn't say what is being proven, and as written is certainly incorrect. It states (final bullet point) that the inductive hypothesis is that $k$ people with $k-1$ black hats and $> k$ white hats can tell that they all have white hats without any hesistation, but it proves that $k+1$ people with $(k, >k+1)$ hats can tell with hesitation. Writing out a more formal proof would also make it clear what modeling assumptions you require for it to work. For example, you would probably end up needing to prove "$k$ people with $(k-1,>k)$ hats can all tell if they have white hats after $k$ moments of hesistation". If so, that means you would need some formal, common-knowledge notion of "moment of hesitation". I hope that helps a little bit with question #1. (Also, the answers at math.stackexchange seem very good on this topic as well....) It might also help with #2, but I'm not sure what exactly you're asking -- I think the proof by induction would take care of this? 

Why bury ourselves in so much notation? For one thing, notice that in the formal rewrite, we realized $W$ wasn't well-defined because it depended on the algorithm (and even its randomness), so we had to introduce and define notation to capture that. We had to introduce notation $S_A$, but it will come in handy later anyway. Try not to feel frustrated or annoyed if things that sound simple take up a lot of space and require a lot of notation when written formally. Don't think of this as dirty work, think of it as a valuable part of the process to deeply understanding what you're writing. 

Yes, we can always say that $X$ has pseudoentropy at least $H(X)$. You can take $Y$ to be a completely separate, independent random variable that has the same distribution as $X$. Then $X$ and $Y$ are computationally indistinguishable (indeed they are "completely" indistinguishable): $\Pr[A(X) = 1] = \Pr[A(Y) = 1]$ for all algorithms $A$. Instead of thinking of psuedoentropy as a property of a random variable, maybe it is more helpful to think of it as a property of a distribution. Not a big difference but emphasizes that, for instance, $X$ and $Y$ are never correlated in the definition. 

Deciding the existence of an "evolutionarily stable strategy" in a normal-form game. See $URL$ . The setup is a 2-player symmetric game. An evolutionarily stable strategy is a (randomized) strategy that is (a) a symmetric nash equilibrium, and (b) there are no good "symmetric deviations": in this equilibrium, if one player can deviate to some strategy and maintain equal utility, then the other player would do strictly worse to then also deviate to this strategy. 

I'm wondering what are the current known uses/implications of a polynomial-time algorithm for the following problem: 

This may be too much to ask. How about an easier question: Do we even know that such a thing is possible? Perhaps no nontrivial uniform circuits exist? 

A course's teaching assistant has managed to write a program that (deterministically) generates difficult exam questions. Now, she'd like to write a program that generates the corresponding answers. The Examiner's Problem asks whether this is always possible; the Examiner's Conjecture states that, assuming, $\mathsf{P} \neq \mathsf{NP}$, it is not: coming up with problems is easier than coming up with their solutions. More formally, let $M$ be a deterministic Turing Machine that, on input $1^n$, generates in polynomial time a Boolean formula of size $n$. I'd like to know if, for all such $M$, there exists a deterministic polynomial-time Turing Machine $M'$ that, on input $1^n$, outputs "$1$" if $M(1^n)$ has a satisfying assignment and "$0$" otherwise. Assuming $\mathsf{P} \neq \mathsf{NP}$, has this question already been asked or answered? If not answered, what sorts of additional assumptions (e.g. one-way functions?) might bear on the result? Barring any of the above, my "conjecture" is that the "answering" TM does not always exist, but what is your intuition? Thanks!