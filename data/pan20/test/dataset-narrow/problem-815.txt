in case of centos6, you could just try to just chmod -x httpd or anything else used to start apache: 

Make sure to follow a step-by-step tutorial in setting up OpenLDAP that is written for your skill level and operating system. As SvenW noted, you don't set the password anywhere. If you don't set the password, you cannot authenticate. Then your possibilities are to either a) allow unauthenticated write access or b) use when isn't running. 

When does your project have to be production ready? Tomorrow? I'd go with 8.04 LTS. In a month? Maybe you should develop it on 8.04 and try it out on a local 10.04 virtual machine to evaluate it. In 6 months? My guess is Canonical will have fixed most problems by then. Make sure you have a simple repeatable installation routine so that you can deploy on any server you like. 

Another possibility is that you have misunderstood how ssh keypairs are supposed to work. Have you installed your public key on the server? If you have ssh-copy-id available, this is very simple. On the client: 

Did you perhaps specify this in the configuration file? According to the OpenVPN documents the relevant configuration directive is 

HDD failure, memory failure, a failure in the I/O components on the mainboard. Better run a bunch of system diagnostics. What are you running git on? Linux, windows? NFS? Local disk? 

Sounds like a WINS problem. Ping uses DNS, while CIFS uses WINS. Are both the NAS and the server in the same workgroup/domain? 

Debian wheezy 7.0 was just released. Are your sources.list files written with the codename (etch, lenny, squeeze, wheezy) or alias (oldstable, stable, testing, unstable)? Sounds like you used to point to oldstable for some packages, and oldstable just changed since a new release was made, which means a big list of dependencies for you. 

If you are willing to let go of your script-based backup system, take a look at BackupPC. It can easily restore files. Databases have to be restored some other way though. 

We've been using KVM on Debian Lenny for almost a year now. Stable, except for live migration. Apparently that would work without paravirtualized network. But we can live with short breaks until a patched version becomes available. We use DRBD to provide shared blockstorage. Nothing at the time provided a nice way to administer our specific combination so I reinvented the wheel: $URL$ 

As others have said, there is a limit to the number of nodes with DRBD. Further, it is probably the wrong solution. Puppet is nice for centralized configuration management, but I wouldn't use only puppet for delivering updated binaries. Learn to use the package tool of your Linux distribution, and set up a private repository from where the software can be installed by puppet on all of the servers. If this seems like a too complex solution, use rsync. Or even NFS-mounted /usr. 

First, remember that RAID is not backup. What you are planning with rsync is a simple form of backup. However I would suggest ZFS raid-z. Or if the machine doesn't have a fast enough processor or if the data is very important, use mirroring with a hot spare. Remember to get another backup solution if you end up using RAID. Actually do it anyway, since a once per day overwritten backup on the same machine is quite poor. 

Does Solaris have something like lspci or /proc/cpuinfo? Here are some examples of how other tools solve the detection: $URL$ $URL$ 

192.168.2.1 is not a public address either. What box is that? Does it know how to route traffic back to 192.168.1.5? Does it do NAT for networks other than 192.168.2.0/24? 

So you suspect random read performance is the problem. The solution to that would be to get storage with better IOPS (SSD, or HDD with higher rotational speed, or RAID with more spindles). More RAM (cache) can also help, if the working set (inode cache) fits in memory. One thing would be to verify that this is the case. Take a look at dstat output and iotop output. Also check that the file system for backuppc is mounted relatime or noatime, so that every file access doesn't translate into a write. 

There seems to be a redis rpm for opensuse: $URL$ . If that is not an option and docker is available I would recommend running redis in docker. 

If you don't have more than one php-fpm running, point your virtualhosts to the same php-fpm socket. 

The terminal isn't echoing the password or stars in place of the password. Try ignoring what you see and just enter the password. It is very common in unix to turn off echoing when entering passwords. 

Linux software RAID1 is fine. And in some ways better than hardware RAID. I hated not being able to upgrade the kernel of a RHEL installation because the binary drivers for the hardware RAID weren't updated for the newer kernel. And if the RAID card dies you need to get another one to get at the data (well, not necessarily with RAID1, but with RAID5 you would), but with software RAID any machine will do. 

Seems to me like you want script(1). It allows you to record and replay terminal sessions. On the other hand, if you are trying to automate setups, consider configuration management, like puppet. 

mod_rewrite using the P flags puts the request through mod_proxy. The advantage in using mod_rewrite is that you get more control for mapping requests, just like rewrite let's you rewrite URLs. But the proxying is exactly the same. The disadvantage is that mod_rewrite syntax is more complex. So my recommendation is to use mod_proxy -style configuration directives unless you need something more complicated. Others will probably recommend mod_rewrite -style, because then you only have to learn one style. 

debsums can check package files against a checksum manifest if such was shipped with the package. But as the manifest is on the same system, it is not a valid source in case you get hacked. Tripwire or aide would be better, if you store the databases somewhere that wouldn't easily get hacked in the same attack. 

I've created our own schemas, and am probably going to continue doing so when new needs pop up. I try to inherit from suitable RFC schemas, and often just have to pick some new attributes on top of when the RFC objectclass already has. Sometimes it's useful to define your own attributetypes to get naming to work. Like having device (already has serialNumber) + manufacturer, model, dateAcquired, warrantyEnds. 

I use btrfs. Why do I use something that isn't production quality? Because I've got several different backups, so corruption in one isn't a very big problem for me. And btrfs does checksums of data, so if I can recover from the backup, I can be sure that the data is intact. 

Linux + ZFS isn't quite production quality yet. Only Solaris really is. But you can check out illumos and FreeBSD. 

Reading the man-page of , it seems that it should copy all the keys from the ssh-agent that aren't accepted for login. So, load all the keypairs into ssh-agent using and use after that. If that doesn't work, you can try specifying the keys for : 

Check out pGina. It doesn't have a Kerberos plugin, so you'll have to write one. Alternatively you can use OpenLDAP as a proxy and use the pGina LDAP plugin. 

We use DRBD in production with KVM, works like a charm. We also use it without a filesystem, so the setup is very similar. 

No. You need to unmount it. Boot an installer from a CD, USB-stick or via netboot, and create the VG from there. 

An empty base is a special case for retrieving information about the OpenLDAP server that can host several databases (or "namingContexts" or "bases"). E.g.: 

Why do you allow ftp and dns? Does your server provide those services? FTP shouldn't really be used, except for some very specific use cases, use SFTP instead (not FTPS). Also, why specify all the other ports by symbolic names and http by numeric 80? Did you just copy this from somewhere else? No copying and advise is going to make up for lack of understanding. Make sure you understand TCP, IP, firewalls, and the protocols of the services you are going to provide. 

which seems to suggest that the links will be created Most of the files also point to which states that udev and lvm2 will create devices for LVs in . The symlinks in seem to be the doing of . Device Mapper can be used without Logical Volume Manager for e.g. encryption with LUKS. 

I agree that you should probably just bind to the addresses you want to listen. But in case this isn't a solution, you could try iptables: 

What kind of connection do you have between the peers? Is your network stack doing retransmits because some ACKs are delayed? 

In Debian (and probably Debian-derivatives like Ubuntu) the options are documented on the man-page initramfs-tools(8). 

The negative number is because of an integer overflow for the signed 32 bit integer used to report the number of blocks. I've had the same problem on a Linux-based NAS. I was able to fake a larger block size in Linux, which prevented the integer overflow and the product of block size * number of blocks resulted in the correct amount of storage. The bug is reported for Net-SNMP and there's a patch available. I'm unsure if you're able to tweak a Windows system in the same way. 

Either configure Kerberos and GSS or make sure you don't use them. There's a related bug report on launchpad that suggests either setting or disabling GSS by blacklisting the module (in , after which you need a restart). 

Virtualbox used to have better Windows drivers available than KVM, so that's what I would try first. 

Have you looked at your firewall log to see if packets are being rejected? Which client/browser are you using? If chome, can you see how connecting to turn works from chrome://webrtc-internals ? 

As others have said, under /usr/local/ , not /opt/. I usually also have these sorts of scripts in /root/ , but that can be considered bad practice. One possibility is also /etc/cron.daily/ . But you really should be asking yourself why you are doing this. Homegrown backup scripts are easier to get wrong than some off-the-shelf backup solution. And remember, you don't want backups, you want working restores.