Perhaps you could cluster the items, then those items with the furthest distance from the midpoint of any cluster would be candidates for outliers. 

As you've described it, Step 4 is where you want to use TF-IDF. Essentially, TD-IDF will count each term in each document, and assign a score given the relative frequency across the collection of documents. There's one big step missing from your process, however: annotating a training set. Before you train your classifier, you'll need to manually annotate a sample of your data with the labels you want to be able to apply automatically using the classifier. To make all of this easier, you might want to consider using the Stanford Classifier. It will perform the feature extraction and build the classifier model (supporting several different machine learning algorithms), but you'll still need to annotate the training data by hand. 

Also, consider checking out this textbook to get started: Building Natural Language Generation Systems 

Since it sounds like you're interested in abstractive summarization (which is much harder than traditional extractive summarization), I'd recommend the following academic papers: 

Without that context, there's no way to know which is the correct category. I'd suggest looking into how named entity recognition tools like Stanford NER work -- that will help you better understand how to do something like this. You'll see that the input to an NER tool generally needs to be a sentence, in order to take advantage of the context to properly categorize the extracted entities. 

Sheldon is correct, this sounds like a fairly typical use case for supervised classification. If all of your customer complaints are either software or hardware (i.e., zero individual complaints cover both categories, and zero are outside these two classes), then all you need is a binary classifier, which makes things simpler than they otherwise could be. If you're looking for a Java-based NLP toolkit that supports something like this, you should check out the Stanford Classifier: $URL$ -- it's licensed as open source software under the GPL. Their wiki page should help you get started using the classifier: $URL$ -- keep in mind that you'll need to manually annotate a large sample of your data as a training set, as Sheldon mentioned. 

There is no single transformation that will be appropriate in all cases, whether the properties/values are known or unknown. Even with known properties, you'll likely need a unique transformation for each type: mean, median, mode, min, max, boolean, etc. 

I highly recommend this tutorial: Getting Started with Topic Modeling and MALLET Here are some additional links to help you get started... Good introductory materials (including links to research papers): $URL$ Software: 

Same answer for both: you can't do this for unknown properties, and for known properties it will depend on how the values were computed. As you alluded to: 

I'm not sure I fully understand your question, but it seems to me that you're trying to determine the category of the string/entity "titanic" out of context. Your data tells you that "titanic" could be a book, a movie, or a product, and you want to figure out which one is correct -- is that what you're trying to do? If so, the problem is that you've dropped the context in which the string/entity "titanic" appears in your original text. For example... 

What you're describing is often achieved using a simple combination of TF-IDF and extractive summarization. In a nutshell, TF-IDF tells you the relative importance of each word in each document, in comparison to the rest of your corpus. At this point, you have a score for each word in each document approximating its "importance." Then you can use these individual word scores to compute a composite score for each sentence by summing the scores of each word in each sentence. Finally, simply take the top-N scoring sentences from each document as its summary. Earlier this year, I put together an iPython Notebook that culminates with an implementation of this in Python using NLTK and Scikit-learn: A Smattering of NLP in Python. 

There's also Richard Socher's recent PhD dissertation on intersection of NLP and deep learning: Recursive Deep Learning for Natural Language Processing and Computer Vision 

Classes related to Artificial Intelligence are typically taught in Computer Science departments. Looking at the IT Project Subjects offered by your university, I suspect Data Analytics would indeed be more relevant to AI than Internetworking and Applications. Looking at the courses offered by your department, the following likely involve aspects of AI: 

The bottom four rows are the table stakes -- the cost of admission just to play the game. These are foundational skills that all aspiring data scientists must obtain. Every data scientist must be a competent programmer. He or she must also have a solid grasp of math, statistics, and analytic methodology. Data science and "big data" go hand-in-hand, so all data scientists need to be familiar with frameworks for distributed computing. Finally, data scientists must have a basic understanding of the domains in which they operate, as well as excellent communications skills and the ability to tell a good story with data. With these basics covered, the next step is to develop deep expertise in one or more of the vertical areas. "Data Science" is really an umbrella term for a collection of interrelated techniques and approaches taken from a variety of disciplines, including mathematics, statistics, computer science, and software engineering. The goal of these diverse methods is to extract actionable intelligence from data of all kinds, enabling clients to make better data-driven decisions. No one person can ever possibly master all aspects of data science; doing so would require multiple lifetimes of training and experience. The best data scientists are therefore "T-shaped" individuals -- that is, they possess a breadth of knowledge across all areas of data science, along with deep expertise in at least one. Accordingly, the best data science teams bring together a set of individuals with complementary skillsets spanning the entire spectrum. 

Regarding your first question... Do you anticipate the majority category to be similarly over-represented in real-world data as it is in your training data? If so, perhaps you could perform two-step classification: 

There are several third-party Java APIs for WordNet listed here: $URL$ In the past, I've used JWNL the most: $URL$ The documentation for JWNL isn't great, but it should provide the functionality you need. 

In terms of open source NLG components, I'm most familiar with Mumble and FUF/SURGE. They've got both similarities and differences, so it's hard to say which is better... Mumble: 

I get asked this question all the time, so earlier this year I wrote an article (What is Data Science?) based on a presentation I've given a few times. Here's the gist... First, a few definitions of data science offered by others: Josh Wills from Cloudera says a data scientist is someone "who is better at statistics than any software engineer and better at software engineering than any statistician." A frequently-heard joke is that a "Data Scientist" is a Data Analyst who lives in California. According to Big Data Borat, Data Science is statistics on a Mac. In Drew Conway's famous Data Science Venn Diagram, it's the intersection of Hacking Skills, Math & Statistics Knowledge, and Substantive Expertise. Here's another good definition I found on the ITProPortal blog: 

So if you are able to ranked features, you can use it to select features, and if you can select a subset of useful features, you've done at least a partial ranking by removing the useless ones. This Wikipedia page and this Quora post should give some ideas. The distinction filter methods vs. wrapper based methods vs. embedded methods is the most common one. 

I want to train word embeddings using word2vec. My corpus is split into several documents (it's a large set of patient notes). Should I just concatenate all documents into one before running word2vec on it, or is there a better way? 

What are the pros/cons of using external GPUs (e.g., connected through thunderbolt) vs. internal GPUs for machine learning? 

where corresponds to $\frac{\partial Q^{\theta}(s,a)}{\partial a}$, and corresponds to $\frac{\partial \mu(s|\theta)}{\partial \theta}$, but I see no multiplication. Where does $\frac{\partial Q^{\theta}(s,a)}{\partial a}$ get multiplied by $\frac{\partial \mu(s|\theta)}{\partial \theta}$? 

Is there any comprehensive list of past, current and future NLP challenges? E.g. for NLP conferences, Joel Tetreault's unofficially official conference calendar and WikiCFP are pretty good. The "Competitions and Challenges" page on the ACL wiki quite incomplete. 

I agree that the current trend is to use Python/R and to bind it to some C/C++ extensions for computationally expensive tasks. However, if you want to stay in C/C++, you might want to have a look at Dlib: 

I am annotating a new corpus with BRAT. I have a set of files to annotate. Is it possible to configure BRAT so that if no file is found, then an empty file is created? Or am I supposed to myself provide the empty files? 

Quote from Alan, Agresti. "Categorical data analysis." A John Wiley and Sons, Inc. Publication, Hoboken, New Jersey, USA (2002), page 273: 

The second advantage, which is also very important for large databases, is that column-based storage allows better compression, since the data in one specific column is indeed homogeneous than across all the columns. The main drawback of a column-oriented approach is that manipulating (lookup, update or delete) an entire given row is inefficient. However the situation should occur rarely in databases for analytics (“warehousing”), which means most operations are read-only, rarely read many attributes in the same table and writes are only appends. Some RDMS offer a column-oriented storage engine option. For example, PostgreSQL has natively no option to store tables in a column-based fashion, but Greenplum has created a closed-source one (DBMS2, 2009). Interestingly, Greenplum is also behind the open-source library for scalable in-database analytics, MADlib (Hellerstein et al., 2012), which is no coincidence. More recently, CitusDB, a startup working on high speed, analytic database, released their own open-source columnar store extension for PostgreSQL, CSTORE (Miller, 2014). Google’s system for large scale machine learning Sibyl also uses column-oriented data format (Chandra et al., 2010). This trend reflects the growing interest around column-oriented storage for large-scale analytics. Stonebraker et al. (2005) further discuss the advantages of column-oriented DBMS. Two concrete use cases: How are most datasets for large-scale machine learning stored? (most of the answer comes from Appendix C of: BeatDB: An end-to-end approach to unveil saliencies from massive signal data sets. Franck Dernoncourt, S.M, thesis, MIT Dept of EECS) 

As Dawny33 says, TensorFlow is just getting started, but it is interesting to note that the number of questions on TensorFlow (244) on Stack Overflow already surpasses Torch (166) and will probably catch up with Theano (672) in 2016. 

from Michael Collins given in his MOOC on NLP (18 - 5 - The Brown Clustering Algorithm (Part 3) (9-18)) 

I know that Torch supports multi-GPU computation on the same machine (Example). Is it possible to perform multi-GPU, multi-machine computations with Torch? 

Typically they specify somewhere whether they talk about the forward (a.k.a. inference a.k.a. test) time, e.g. from the page you mentioned in your question: 

Can BRAT be used for text classification annotation? I.e., given the text, annotate whether it belongs to some classes? 

However they don't seem to give any instructions for Microsoft Windows. I don't want to use some in emulation of Unix such as virtual machines or Cygwin. 

Xudong Cao. "A practical theory for designing very deep convolutional neural networks". 2015. $URL$ explains how to compute the capacity of a layer: 

I am looking for a Python library that can perform segmented regression (a.k.a. piecewise regression). Example: 

I want to try the IBM speech to text API. I created an IBM cloud account and went to $URL$ I see the error message: 

Is there any Python library that provides ready-to-use metrics to analyze the performance of a classifier for a multioutput-multiclass classification task? scikit-learn doesn't have this option yet (as stated in the documentation and in the corresponding feature request on GitHub). 

However, on $URL$ I don't see any entities that existing services. How can I create a new project? I want to use the speech to text API. 

I'm looking for a Python package that implements multivariate linear regression. (Terminological note: multivariate regression deals with the case where there are more than one dependent variables while multiple regression deals with the case where there is one dependent variable but more than one independent variables.) 

Microsoft Cognition Toolkit (previously known as CNTK) has a Python API. Amongst other things, it is supposed to be good for multi-GPU: 

You might want to take into consideration that Pylearn2 has no more developer, and now points to other Theano-based libraries: 

I am looking for a program that would allow me to fine-tune pre-trained word embeddings on my data set. Ideally, open source and working on Linux or Windows. 

You can look at nolearn/lasagne/util.py to see how learning capacity and image coverage are computed for each layer: 

I sometimes want to benchmark Theano, either to compare different versions of Theano, or to compare two different computing environment with the same version of Theano. Is there any Theano code I could use to benchmark the main functions of Theano? I plan to use Theano only for artificial neural networks (RNN and CNN). 

which in the code corresponds to: . In the method, I fail to see where $\frac{\partial Q^{\theta}(s,a)}{\partial a}$ gets multiplied by $\frac{\partial \mu(s|\theta)}{\partial \theta}$. I did read: 

If you use scikit-learn, check out module-sklearn.feature_selection. I'd guess Weka has some similar functions. 

A column-oriented database (=columnar data-store) stores the data of a table column by column on the disk, while a row-oriented database stores the data of a table row by row. There are two main advantages of using a column-oriented database in comparison with a row-oriented database. The first advantage relates to the amount of data one’s need to read in case we perform an operation on just a few features. Consider a simple query: 

I am trying to understand the training phase of the tutorial Using Keras and Deep Deterministic Policy Gradient to play TORCS (mirror, code) by Ben Lau published on October 11, 2016. The tutorial says: