{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from transformers import BertForMaskedLM, BertConfig\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from nltk.parse.corenlp import CoreNLPParser, CoreNLPDependencyParser \n",
    "from nltk.tag.hunpos import HunposTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import stanza\n",
    "import nltk\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from numerize import numerize\n",
    "import wandb\n",
    "import os \n",
    "import typing\n",
    "import tokenizers\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5101f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagset \n",
    "def get_pos_vocab(tagger, tagset='xpos'):\n",
    "#     upos_vocab = ['ADJ',\n",
    "#                 'ADP',\n",
    "#                 'ADV',\n",
    "#                 'AUX',\n",
    "#                 'CCONJ',\n",
    "#                 'DET',\n",
    "#                 'INTJ',\n",
    "#                 'NOUN',\n",
    "#                 'NUM',\n",
    "#                 'PART',\n",
    "#                 'PRON',\n",
    "#                 'PROPN',\n",
    "#                 'PUNCT',\n",
    "#                 'SCONJ',\n",
    "#                 'SYM',\n",
    "#                 'VERB',\n",
    "#                 'X']\n",
    "    # if use the simple conversion, upos vocab is smaller\n",
    "    upos_vocab = ['ADJ',\n",
    "                 'ADP',\n",
    "                 'ADV',\n",
    "                 'CCONJ',\n",
    "                 'DET',\n",
    "                 'INTJ',\n",
    "                 'NOUN',\n",
    "                 'NUM',\n",
    "                 'PART',\n",
    "                 'PRON',\n",
    "                 'PROPN',\n",
    "                 'PUNCT',\n",
    "                 'SYM',\n",
    "                 'VERB',\n",
    "                 'X']\n",
    "    from nltk.data import load\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "    xpos_vocab = list(tagdict.keys())\n",
    "    xpos_vocab = sorted(xpos_vocab)\n",
    "    if tagset=='xpos':\n",
    "        return xpos_vocab\n",
    "    else:\n",
    "        return upos_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267287aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this conversion comes from https://universaldependencies.org/tagset-conversion/en-penn-uposf.html\n",
    "# however, it's just impossible to convert to upos without knowing the context. \n",
    "# Manning's word here: https://github.com/UniversalDependencies/docs/issues/212#issuecomment-148846154\n",
    "# how to use Manning's converter: https://github.com/clulab/processors/wiki/Converting-from-Penn-Treebank-to-Basic-Stanford-Dependencies\n",
    "xpos2upos = {'#': 'SYM',\n",
    "             '$': 'SYM',\n",
    "             \"''\": 'PUNCT',\n",
    "             ',': 'PUNCT',\n",
    "             '-LRB-': 'PUNCT',\n",
    "             '-RRB-': 'PUNCT',\n",
    "             '.': 'PUNCT',\n",
    "             ':': 'PUNCT',\n",
    "             'AFX': 'ADJ',\n",
    "             'CC': 'CCONJ',\n",
    "             'CD': 'NUM',\n",
    "             'DT': 'DET',\n",
    "             'EX': 'PRON',\n",
    "             'FW': 'X',\n",
    "             'HYPH': 'PUNCT',\n",
    "             'IN': 'ADP',\n",
    "             'JJ': 'ADJ',\n",
    "             'JJR': 'ADJ',\n",
    "             'JJS': 'ADJ',\n",
    "             'LS': 'X',\n",
    "             'MD': 'VERB',\n",
    "             'NFP': 'PUNCT', # manually added. \n",
    "             'NIL': 'X',\n",
    "             'NN': 'NOUN',\n",
    "             'NNP': 'PROPN',\n",
    "             'NNPS': 'PROPN',\n",
    "             'NNS': 'NOUN',\n",
    "             'PDT': 'DET',\n",
    "             'POS': 'PART',\n",
    "             'PRP': 'PRON',\n",
    "             'PRP$': 'DET',\n",
    "             'RB': 'ADV',\n",
    "             'RBR': 'ADV',\n",
    "             'RBS': 'ADV',\n",
    "             'RP': 'ADP',\n",
    "             'SYM': 'SYM',\n",
    "             'TO': 'PART',\n",
    "             'UH': 'INTJ',\n",
    "             'VB': 'VERB',\n",
    "             'VBD': 'VERB',\n",
    "             'VBG': 'VERB',\n",
    "             'VBN': 'VERB',\n",
    "             'VBP': 'VERB',\n",
    "             'VBZ': 'VERB',\n",
    "             'WDT': 'DET',\n",
    "             'WP': 'PRON',\n",
    "             'WP$': 'DET',\n",
    "             'WRB': 'ADV',\n",
    "             '``': 'PUNCT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3112d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(vocab, model_max_length = 128):\n",
    "    # Tokenizer is from tokenizers package. PreTrainedTokenizerFast is from tranformers package.\n",
    "    # PreTrainedTokenizerFast can load vocab saved/trained by Tokenizer\n",
    "    t = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    t.pre_tokenizer = Whitespace()\n",
    "    t.add_special_tokens([\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\",])\n",
    "\n",
    "    t.add_tokens(vocab) \n",
    "#     trainer makes \"-LRB-\" 3 tokens\n",
    "#     trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "#     data = [' '.join(vocab)]\n",
    "#     t.train_from_iterator(data, trainer=trainer)\n",
    "\n",
    "    t.post_processor = TemplateProcessing(\n",
    "        single=\"[CLS] $A [SEP]\",\n",
    "        pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "        special_tokens=[\n",
    "            (\"[CLS]\", t.token_to_id(\"[CLS]\")),\n",
    "            (\"[SEP]\", t.token_to_id(\"[SEP]\")),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    t.enable_padding(pad_id=t.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\")\n",
    "    t.enable_truncation(max_length=model_max_length)\n",
    "    t.save('/home/jz17d/Desktop/upos_tokenizer.json')\n",
    "\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/home/jz17d/Desktop/upos_tokenizer.json\", unk_token=\"[UNK]\")\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "    tokenizer.mask_token = '[MASK]'\n",
    "    tokenizer.unk_token = '[UNK]'\n",
    "    special_tokens = {\n",
    "         \"unk_token\": \"[UNK]\",\n",
    "         \"sep_token\": \"[SEP]\",\n",
    "         \"pad_token\": \"[PAD]\",\n",
    "         \"cls_token\": \"[CLS]\",\n",
    "         \"mask_token\": \"[MASK]\" }\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    # tokenizer.add_special_tokens({'unk_token':'[UNK]'})\n",
    "    tokenizer.model_max_length=model_max_length\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710be700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xpos tokenizer, use its convert_ids_to_tokens function later\n",
    "xpos_tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/home/jz17d/Desktop/my_tokenizer.json\", unk_token=\"[UNK]\")\n",
    "xpos_tokenizer.pad_token = '[PAD]'\n",
    "xpos_tokenizer.mask_token = '[MASK]'\n",
    "xpos_tokenizer.unk_token = '[UNK]'\n",
    "special_tokens = {\n",
    "     \"unk_token\": \"[UNK]\",\n",
    "     \"sep_token\": \"[SEP]\",\n",
    "     \"pad_token\": \"[PAD]\",\n",
    "     \"cls_token\": \"[CLS]\",\n",
    "     \"mask_token\": \"[MASK]\" }\n",
    "xpos_tokenizer.add_special_tokens(special_tokens)\n",
    "# tokenizer.add_special_tokens({'unk_token':'[UNK]'})\n",
    "xpos_tokenizer.model_max_length=model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7512893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xpos2upos_batch(samples):\n",
    "    new = []\n",
    "    for input_ids in samples['input_ids']:\n",
    "        seq = xpos_tokenizer.convert_ids_to_tokens(input_ids)\n",
    "        for i in range(len(seq)):\n",
    "            if seq[i] in xpos2upos:\n",
    "                seq[i] = xpos2upos[seq[i]]\n",
    "        new.append(tokenizer.convert_tokens_to_ids(seq))\n",
    "    samples['input_ids'] = new\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796d280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect tagset and create tokenizer\n",
    "tagger = 'corenlp'\n",
    "tagset = 'upos'\n",
    "select = 1000000\n",
    "model_max_length = 128\n",
    "\n",
    "vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09c0d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30bee6ee30ad47ddbab89b8d140c3e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load processed xpos corpus, convert it to upos corpus\n",
    "xpos_cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "trainset = load_from_disk(xpos_cache_location)\n",
    "\n",
    "trainset = trainset.map(xpos2upos_batch, batched=True)\n",
    "upos_cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_upos_transformed.hf'\n",
    "trainset.save_to_disk(upos_cache_location)\n",
    "\n",
    "trainset = trainset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683fbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "271a94b147da4c5d8a18556241b43d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# same for test set\n",
    "xpos_cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "testset = load_from_disk(xpos_cache_location)\n",
    "\n",
    "testset = testset.map(xpos2upos_batch, batched=True)\n",
    "upos_cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_upos_transformed_test.hf'\n",
    "testset.save_to_disk(upos_cache_location)\n",
    "\n",
    "testset = testset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f33e0e5",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c4a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce33fb8fea474a98994be15f7c25eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230112_135719-nnluog3g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29/runs/nnluog3g\" target=\"_blank\">run 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 5:09:45, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.697400</td>\n",
       "      <td>1.271106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.378200</td>\n",
       "      <td>1.181196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.291100</td>\n",
       "      <td>1.128774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.234800</td>\n",
       "      <td>1.113014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.205300</td>\n",
       "      <td>1.093791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.188900</td>\n",
       "      <td>1.081578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.174300</td>\n",
       "      <td>1.068646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.164700</td>\n",
       "      <td>1.066440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.155400</td>\n",
       "      <td>1.069607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.148600</td>\n",
       "      <td>1.061451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.142800</td>\n",
       "      <td>1.047217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.137200</td>\n",
       "      <td>1.055016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.132500</td>\n",
       "      <td>1.053740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.128100</td>\n",
       "      <td>1.049508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.123200</td>\n",
       "      <td>1.040295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.122000</td>\n",
       "      <td>1.041377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.119000</td>\n",
       "      <td>1.044718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.116500</td>\n",
       "      <td>1.036915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.115300</td>\n",
       "      <td>1.034689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.111700</td>\n",
       "      <td>1.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.110900</td>\n",
       "      <td>1.035401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.107800</td>\n",
       "      <td>1.035596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.105600</td>\n",
       "      <td>1.030921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.103600</td>\n",
       "      <td>1.025896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.102800</td>\n",
       "      <td>1.028658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.102100</td>\n",
       "      <td>1.031273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.099400</td>\n",
       "      <td>1.024601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.098500</td>\n",
       "      <td>1.024174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.097500</td>\n",
       "      <td>1.021009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.095700</td>\n",
       "      <td>1.022390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.097400</td>\n",
       "      <td>1.019783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-45000] due to args.save_total_limit\n",
      "wandb: Network error (SSLError), entering retry loop.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_0/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▅▂▁▃▅▂▆▇▆▅▆▂▁▁▃▇▅▃▂▃▂▂▁▄▄▂▃█▃▆</td></tr><tr><td>eval/samples_per_second</td><td>▆▄▇█▆▃▆▃▂▃▄▂▇██▆▂▄▆▇▆▇▇█▅▅▇▆▁▆▃</td></tr><tr><td>eval/steps_per_second</td><td>▆▄▇█▆▃▆▃▂▃▄▂▇██▆▂▄▆▇▆▇▇█▅▅▇▆▁▆▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.01978</td></tr><tr><td>eval/runtime</td><td>15.3638</td></tr><tr><td>eval/samples_per_second</td><td>3254.393</td></tr><tr><td>eval/steps_per_second</td><td>25.449</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.0974</td></tr><tr><td>train/total_flos</td><td>355277097077760.0</td></tr><tr><td>train/train_loss</td><td>1.16102</td></tr><tr><td>train/train_runtime</td><td>18719.2758</td></tr><tr><td>train/train_samples_per_second</td><td>1068.417</td></tr><tr><td>train/train_steps_per_second</td><td>8.348</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">run 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29/runs/nnluog3g\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29/runs/nnluog3g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230112_135719-nnluog3g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230112_190943-3innjj3w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29/runs/3innjj3w\" target=\"_blank\">run 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20UPOS%20%28simple%20conversion%29\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56017' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 56017/156260 2:35:23 < 4:38:04, 6.01 it/s, Epoch 7.17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.654000</td>\n",
       "      <td>1.226765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.314600</td>\n",
       "      <td>1.140550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.220700</td>\n",
       "      <td>1.099715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.182800</td>\n",
       "      <td>1.084653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.163100</td>\n",
       "      <td>1.070345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.152100</td>\n",
       "      <td>1.059517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.140600</td>\n",
       "      <td>1.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.134800</td>\n",
       "      <td>1.048019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.127300</td>\n",
       "      <td>1.051631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.122300</td>\n",
       "      <td>1.043344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.117700</td>\n",
       "      <td>1.030918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/upos_mlm_corenlp/run_1/checkpoint-45000] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# bert related args\n",
    "model_max_length = 128\n",
    "hidden_size = 32\n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 20\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "NUM_LAYERS = [4]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4, 7e-4, 9e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/upos_mlm_corenlp/run_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM UPOS (simple conversion)\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'run {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cced43e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
