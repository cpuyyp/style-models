{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c3b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from transformers import BertForMaskedLM, BertConfig\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from nltk.parse.corenlp import CoreNLPParser, CoreNLPDependencyParser\n",
    "from nltk.tag.hunpos import HunposTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "# import stanza\n",
    "import nltk\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from numerize import numerize\n",
    "import wandb\n",
    "import os \n",
    "import typing\n",
    "import tokenizers\n",
    "from tqdm.auto import trange, tqdm\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c86bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = stanza.Pipeline(lang='en', processors='tokenize,pos')\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "# ht = HunposTagger('/home/jz17d/bin/english.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42e1a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://emorynlp.github.io/nlp4j/components/part-of-speech-tagging.html\n",
    "corenlp_vocab = '''$ \tDollar \t1.0.0\n",
    ": \tColon \t1.0.0\n",
    ", \tComma \t1.0.0\n",
    ". \tPeriod \t1.0.0\n",
    "`` \tLeft quote \t1.0.0\n",
    "'' \tRight quote \t1.0.0\n",
    "-LRB- \tLeft bracket \t1.0.0\n",
    "-RRB- \tRight bracket \t1.0.0\n",
    "ADD \tEmail \t1.0.0\n",
    "AFX \tAffix \t1.0.0\n",
    "CC \tCoordinating conjunction \t1.0.0\n",
    "CD \tCardinal number \t1.0.0\n",
    "DT \tDeterminer \t1.0.0\n",
    "EX \tExistential there \t1.0.0\n",
    "FW \tForeign word \t1.0.0\n",
    "GW \tGo with \t1.0.0\n",
    "HYPH \tHyphen \t1.0.0\n",
    "IN \tPreposition or subordinating conjunction \t1.0.0\n",
    "JJ \tAdjective \t1.0.0\n",
    "JJR \tAdjective, comparative \t1.0.0\n",
    "JJS \tAdjective, superlative \t1.0.0\n",
    "LS \tList item marker \t1.0.0\n",
    "MD \tModal \t1.0.0\n",
    "NFP \tSuperfluous punctuation \t1.0.0\n",
    "NN \tNoun, singular or mass \t1.0.0\n",
    "NNS \tNoun, plural \t1.0.0\n",
    "NNP \tProper noun, singular \t1.0.0\n",
    "NNPS \tProper noun, plural \t1.0.0\n",
    "PDT \tPredeterminer \t1.0.0\n",
    "POS \tPossessive ending \t1.0.0\n",
    "PRP \tPersonal pronoun \t1.0.0\n",
    "PRP$ \tPossessive pronoun \t1.0.0\n",
    "RB \tAdverb \t1.0.0\n",
    "RBR \tAdverb, comparative \t1.0.0\n",
    "RBS \tAdverb, superlative \t1.0.0\n",
    "RP \tParticle \t1.0.0\n",
    "SYM \tSymbol \t1.0.0\n",
    "TO \tTo \t1.0.0\n",
    "UH \tInterjection \t1.0.0\n",
    "VB \tVerb, base form \t1.0.0\n",
    "VBD \tVerb, past tense \t1.0.0\n",
    "VBG \tVerb, gerund or present participle \t1.0.0\n",
    "VBN \tVerb, past participle \t1.0.0\n",
    "VBP \tVerb, non-3rd person singular present \t1.0.0\n",
    "VBZ \tVerb, 3rd person singular present \t1.0.0\n",
    "WDT \tWh-determiner \t1.0.0\n",
    "WP \tWh-pronoun \t1.0.0\n",
    "WP$ \tWh-pronoun, possessive \t1.0.0\n",
    "WRB \tWh-adverb \t1.0.0\n",
    "XX'''.split('\\n')\n",
    "for i in range(len(corenlp_vocab)):\n",
    "    corenlp_vocab[i] = corenlp_vocab[i].split('\\t')[0].strip()\n",
    "num_xpos_tokens = len(corenlp_vocab)\n",
    "corenlp_token2id = {corenlp_vocab[i]:i for i in range(num_xpos_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "250c5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagset \n",
    "def get_pos_vocab(tagger, tagset='xpos'):\n",
    "    if tagset == 'upos':\n",
    "        assert tagger == 'stanza', 'only stanza support upos'\n",
    "    # the full list of upos tokens\n",
    "    upos_vocab = ['ADJ',\n",
    "                'ADP',\n",
    "                'ADV',\n",
    "                'AUX',\n",
    "                'CCONJ',\n",
    "                'DET',\n",
    "                'INTJ',\n",
    "                'NOUN',\n",
    "                'NUM',\n",
    "                'PART',\n",
    "                'PRON',\n",
    "                'PROPN',\n",
    "                'PUNCT',\n",
    "                'SCONJ',\n",
    "                'SYM',\n",
    "                'VERB',\n",
    "                'X']\n",
    "    # if use the simple conversion, upos vocab is smaller\n",
    "#     upos_vocab = ['ADJ',\n",
    "#                  'ADP',\n",
    "#                  'ADV',\n",
    "#                  'CCONJ',\n",
    "#                  'DET',\n",
    "#                  'INTJ',\n",
    "#                  'NOUN',\n",
    "#                  'NUM',\n",
    "#                  'PART',\n",
    "#                  'PRON',\n",
    "#                  'PROPN',\n",
    "#                  'PUNCT',\n",
    "#                  'SYM',\n",
    "#                  'VERB',\n",
    "#                  'X']\n",
    "\n",
    "    from nltk.data import load\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "\n",
    "    xpos_vocab = list(tagdict.keys())\n",
    "    if tagger == 'corenlp':\n",
    "        xpos_vocab = corenlp_vocab\n",
    "    xpos_vocab = sorted(xpos_vocab)\n",
    "    if tagset=='xpos':\n",
    "        return xpos_vocab\n",
    "    else:\n",
    "        return upos_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52e74274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_tagging(examples, tag_set='xpos'): # stanza\n",
    "    all_upos = []\n",
    "    all_xpos = []\n",
    "    for text in examples['text']:\n",
    "        doc = nlp(text)\n",
    "        upos = []\n",
    "        xpos = []\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                upos.append(word.upos)\n",
    "                xpos.append(word.xpos)  \n",
    "        all_upos.append(' '.join(upos))   \n",
    "        all_xpos.append(' '.join(xpos))   \n",
    "    if tag_set == 'upos':\n",
    "        return tokenizer(all_upos, truncation=True) \n",
    "    else:\n",
    "        return tokenizer(all_xpos, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23020480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hunpos_tagging(examples): # hunpos\n",
    "    xpos = []\n",
    "    for sentence in examples['text']:\n",
    "        tagged = ht.tag(word_tokenize(sentence))\n",
    "        pos = []\n",
    "        for word in tagged:\n",
    "            pos.append(word[1].decode('utf-8'))\n",
    "        xpos.append(' '.join(pos))\n",
    "    return tokenizer(xpos, truncation=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8a36bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corenlp_tagging(examples): # corenlp\n",
    "    xpos = []\n",
    "    tagged = list(pos_tagger.raw_tag_sents(examples['text']))\n",
    "    for sentence in tagged:\n",
    "        pos = []\n",
    "        for word in sentence[0]:\n",
    "            pos.append(word[1])\n",
    "        xpos.append(' '.join(pos))\n",
    "    return tokenizer(xpos, truncation=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9688d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger2func = {'stanza': stanza_tagging,\n",
    "               'hunpos': hunpos_tagging,\n",
    "               'corenlp': corenlp_tagging,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f25421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(vocab, model_max_length = 128):\n",
    "    # Tokenizer is from tokenizers package. PreTrainedTokenizerFast is from tranformers package.\n",
    "    # PreTrainedTokenizerFast can load vocab saved/trained by Tokenizer\n",
    "    t = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    t.pre_tokenizer = Whitespace()\n",
    "    t.add_special_tokens([\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\",])\n",
    "\n",
    "    t.add_tokens(vocab) \n",
    "#     trainer makes \"-LRB-\" 3 tokens\n",
    "#     trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "#     data = [' '.join(vocab)]\n",
    "#     t.train_from_iterator(data, trainer=trainer)\n",
    "\n",
    "    t.post_processor = TemplateProcessing(\n",
    "        single=\"[CLS] $A [SEP]\",\n",
    "        pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "        special_tokens=[\n",
    "            (\"[CLS]\", t.token_to_id(\"[CLS]\")),\n",
    "            (\"[SEP]\", t.token_to_id(\"[SEP]\")),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    t.enable_padding(pad_id=t.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\")\n",
    "    t.enable_truncation(max_length=model_max_length)\n",
    "    t.save('/home/jz17d/Desktop/pos_tokenizer.json')\n",
    "\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/home/jz17d/Desktop/pos_tokenizer.json\", unk_token=\"[UNK]\")\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "    tokenizer.mask_token = '[MASK]'\n",
    "    tokenizer.unk_token = '[UNK]'\n",
    "    special_tokens = {\n",
    "         \"unk_token\": \"[UNK]\",\n",
    "         \"sep_token\": \"[SEP]\",\n",
    "         \"pad_token\": \"[PAD]\",\n",
    "         \"cls_token\": \"[CLS]\",\n",
    "         \"mask_token\": \"[MASK]\" }\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    # tokenizer.add_special_tokens({'unk_token':'[UNK]'})\n",
    "    tokenizer.model_max_length=model_max_length\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_ppl(model, input_ids, stride=128, max_length=128):\n",
    "#     '''\n",
    "#     Example from https://huggingface.co/docs/transformers/perplexity\n",
    "#     '''\n",
    "#     seq_len = input_ids.size(1)\n",
    "#     nlls = []\n",
    "#     prev_end_loc = 0\n",
    "#     for begin_loc in range(0, seq_len, stride):\n",
    "#         end_loc = min(begin_loc + max_length, seq_len)\n",
    "#         trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "#         curr_input_ids = input_ids[:, begin_loc:end_loc].to(device)\n",
    "#         target_ids = curr_input_ids.clone()\n",
    "#         target_ids[:, :-trg_len] = -100\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(curr_input_ids, labels=target_ids)\n",
    "#             # loss is calculated using CrossEntropyLoss which averages over input tokens.\n",
    "#             # Multiply it with trg_len to get the summation instead of average.\n",
    "#             # We will take average over all the tokens to get the true average\n",
    "#             # in the last step of this example.\n",
    "#             neg_log_likelihood = outputs.loss * trg_len\n",
    "\n",
    "#         nlls.append(neg_log_likelihood)\n",
    "\n",
    "#         prev_end_loc = end_loc\n",
    "#         if end_loc == seq_len:\n",
    "#             break\n",
    "#     ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "#     return ppl.cpu().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d043f1ec",
   "metadata": {},
   "source": [
    "# skip the section below unless need to reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa84910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e466f738c704f5dbeefcde7f96cb815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.25k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f7fa15a77646b69fb1f3e281c683af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.67k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675a334f0b9b4811977a10ff28294fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.50k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bookcorpus (/scratch/data_jz17d/hf_datasets_cache/bookcorpus/plain_text/1.0.0/eddee3cae1cc263a431aa98207d4d27fd8a73b0a9742f692af0e6c65afa4d75f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf4b440d0a04023bcf0ae6343ba91ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187582/3640843141.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load raw bookcorpus dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'HF_DATASETS_CACHE'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/scratch/data_jz17d/hf_datasets_cache'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bookcorpus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/scratch/data_jz17d/hf_datasets_cache\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkeep_in_memory\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_small_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m     )\n\u001b[0;32m-> 1754\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_verifications\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_verifications\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_in_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1755\u001b[0m     \u001b[0;31m# Rename and cast features to match task schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36mas_dataset\u001b[0;34m(self, split, run_post_process, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;31m# Create a dataset for each of the given splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         datasets = map_nested(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             partial(\n\u001b[1;32m   1016\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_single_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0mnum_proc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparallel_min_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         mapped = [\n\u001b[0m\u001b[1;32m    430\u001b[0m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_proc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mparallel_min_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         mapped = [\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0m_single_map_nested\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         ]\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;31m# Singleton first to spare some computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_struct\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m     \u001b[0;31m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_build_single_dataset\u001b[0;34m(self, split, run_post_process, ignore_verifications, in_memory)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# Build base dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         ds = self._as_dataset(\n\u001b[0m\u001b[1;32m   1046\u001b[0m             \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m             \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_as_dataset\u001b[0;34m(self, split, in_memory)\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \"\"\"\n\u001b[1;32m   1113\u001b[0m         \u001b[0mcache_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strip_protocol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m         dataset_kwargs = ArrowReader(cache_dir, self.info).read(\n\u001b[0m\u001b[1;32m   1115\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0minstructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, name, instructions, split_infos, in_memory)\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Instruction \"{instructions}\" corresponds to no data!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstructions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     def read_files(\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(self, files, original_instructions, in_memory)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Prepend path to filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mpa_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;31m# If original_instructions is not None, convert it to a human-readable NamedSplit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moriginal_instructions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m_read_files\u001b[0;34m(self, files, in_memory)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf_dict\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_table_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0mpa_tables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mpa_tables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpa_tables\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36m_get_table_from_filename\u001b[0;34m(self, filename_skip_take, in_memory)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mfilename_skip_take\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"take\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"take\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilename_skip_take\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         )\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArrowReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_memory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0;31m# here we don't want to slice an empty table, or it may segfault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtake\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtake\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/arrow_reader.py\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(filename, in_memory)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \"\"\"\n\u001b[1;32m    324\u001b[0m         \u001b[0mtable_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInMemoryTable\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0min_memory\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mMemoryMappedTable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtable_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/table.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, filename, replays)\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_memory_mapped_arrow_table_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m         \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_replays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/datasets/table.py\u001b[0m in \u001b[0;36m_memory_mapped_arrow_table_from_file\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mmemory_mapped_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mopened_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mipc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_mapped_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mpa_table\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopened_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# load raw bookcorpus dataset\n",
    "os.environ['HF_DATASETS_CACHE'] = '/scratch/data_jz17d/hf_datasets_cache'\n",
    "dataset = load_dataset(\"bookcorpus\", cache_dir=\"/scratch/data_jz17d/hf_datasets_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcaa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4259a37594027882c90aa2bdb9f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reprocess corenlp with correct tag list \n",
    "tagger = 'corenlp'\n",
    "tagset = 'xpos'\n",
    "reprocess = True\n",
    "select = 1000000\n",
    "model_max_length = 128\n",
    "\n",
    "vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    tagging_func = tagger2func[tagger]\n",
    "    trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "    trainset.save_to_disk(cache_location)\n",
    "else:\n",
    "    trainset = load_from_disk(cache_location)\n",
    "trainset = trainset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f198745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aedd7b70c34e07b68989a806d554ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reprocess = True\n",
    "select2 = range(select,select+50000)\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    tagging_func = tagger2func[tagger]\n",
    "    testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "    testset.save_to_disk(cache_location)\n",
    "else:\n",
    "    testset = load_from_disk(cache_location)\n",
    "testset = testset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60780185",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2079c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85807bcba2784e65b77a11e24c05d40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2eesmz6z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2eesmz6z\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2eesmz6z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_110955-2eesmz6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2eesmz6z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbcd193423041e58c01cb800c06218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.033339222272237144, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_111035-2dei7y98</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98\" target=\"_blank\">pos mlm 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:43:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.691900</td>\n",
       "      <td>2.283304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.350500</td>\n",
       "      <td>2.093428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.220300</td>\n",
       "      <td>1.927104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.098500</td>\n",
       "      <td>1.765798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.998800</td>\n",
       "      <td>1.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.919500</td>\n",
       "      <td>1.577371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.851400</td>\n",
       "      <td>1.513302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.782000</td>\n",
       "      <td>1.456283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.725400</td>\n",
       "      <td>1.432919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.691200</td>\n",
       "      <td>1.405770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.658800</td>\n",
       "      <td>1.381955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.631400</td>\n",
       "      <td>1.376401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.610300</td>\n",
       "      <td>1.361557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.350170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.575100</td>\n",
       "      <td>1.340339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.564300</td>\n",
       "      <td>1.332251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.556300</td>\n",
       "      <td>1.333331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.547000</td>\n",
       "      <td>1.327982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.540100</td>\n",
       "      <td>1.320817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.534200</td>\n",
       "      <td>1.321154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.530500</td>\n",
       "      <td>1.322502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.524100</td>\n",
       "      <td>1.317376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.520900</td>\n",
       "      <td>1.315069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.515200</td>\n",
       "      <td>1.300987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.312259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.308862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.510100</td>\n",
       "      <td>1.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.508600</td>\n",
       "      <td>1.300892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.505500</td>\n",
       "      <td>1.297899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.505700</td>\n",
       "      <td>1.303157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.507600</td>\n",
       "      <td>1.299217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▄▃▃▃█▄▂▆▅▃▁▁▂▁▁▅▅▂▂▂▁▁▁▄▆▃▁▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▅▆▆▆▁▅▇▃▄▆██▇██▄▄▇▇▇▇██▅▃▆█▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▅▆▆▆▁▅▇▃▄▆██▇██▄▄▇▇▇▇██▅▃▆█▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.29922</td></tr><tr><td>eval/runtime</td><td>13.5053</td></tr><tr><td>eval/samples_per_second</td><td>3702.238</td></tr><tr><td>eval/steps_per_second</td><td>28.952</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5076</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.7014</td></tr><tr><td>train/train_runtime</td><td>9835.0244</td></tr><tr><td>train/train_samples_per_second</td><td>2033.549</td></tr><tr><td>train/train_steps_per_second</td><td>15.888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_111035-2dei7y98/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_135449-1pfrep5j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j\" target=\"_blank\">pos mlm 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:52:06, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>1.507956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.616400</td>\n",
       "      <td>1.357430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.513700</td>\n",
       "      <td>1.312450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.467100</td>\n",
       "      <td>1.288372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.440900</td>\n",
       "      <td>1.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.426100</td>\n",
       "      <td>1.259849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.410500</td>\n",
       "      <td>1.246999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.404300</td>\n",
       "      <td>1.244564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.391900</td>\n",
       "      <td>1.245173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.387800</td>\n",
       "      <td>1.242039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.382800</td>\n",
       "      <td>1.223743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.379100</td>\n",
       "      <td>1.235590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.226788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.368300</td>\n",
       "      <td>1.225584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.364900</td>\n",
       "      <td>1.218081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.364300</td>\n",
       "      <td>1.218443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.362400</td>\n",
       "      <td>1.223904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.219311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.210993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.353700</td>\n",
       "      <td>1.213950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.354000</td>\n",
       "      <td>1.217250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.350500</td>\n",
       "      <td>1.213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.348500</td>\n",
       "      <td>1.212676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.347200</td>\n",
       "      <td>1.201242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.346600</td>\n",
       "      <td>1.210703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.347000</td>\n",
       "      <td>1.205936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.344200</td>\n",
       "      <td>1.200450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.342200</td>\n",
       "      <td>1.202423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>1.196322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.340100</td>\n",
       "      <td>1.203914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.342100</td>\n",
       "      <td>1.199652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000] due to args.save_total_limit\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▆█▅▇▁▁▅▃▅▆▅▅▆▂▂▁▂▂▁▆▁▂▂▂▅▂▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▃▁▄▂██▄▆▄▃▄▄▃▇▇█▇▇█▃█▇▇▇▄▇▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▃▁▄▂██▄▆▄▃▄▄▃▇▇█▇▇█▃█▇▇▇▄▇▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.19965</td></tr><tr><td>eval/runtime</td><td>13.5082</td></tr><tr><td>eval/samples_per_second</td><td>3701.468</td></tr><tr><td>eval/steps_per_second</td><td>28.945</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3421</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.41094</td></tr><tr><td>train/train_runtime</td><td>10326.7383</td></tr><tr><td>train/train_samples_per_second</td><td>1936.72</td></tr><tr><td>train/train_steps_per_second</td><td>15.132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_135449-1pfrep5j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_164709-2t67ykkt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt\" target=\"_blank\">pos mlm 2</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:45:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.002900</td>\n",
       "      <td>1.378969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.530800</td>\n",
       "      <td>1.325399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.474900</td>\n",
       "      <td>1.290930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.442000</td>\n",
       "      <td>1.270840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.422900</td>\n",
       "      <td>1.261166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.412000</td>\n",
       "      <td>1.249452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>1.234677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.396200</td>\n",
       "      <td>1.234411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.386000</td>\n",
       "      <td>1.239756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.383100</td>\n",
       "      <td>1.231708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.378400</td>\n",
       "      <td>1.218516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.227519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.371000</td>\n",
       "      <td>1.221422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.366400</td>\n",
       "      <td>1.219766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.362400</td>\n",
       "      <td>1.213243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.361500</td>\n",
       "      <td>1.212827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.360300</td>\n",
       "      <td>1.216861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.356700</td>\n",
       "      <td>1.215684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.354900</td>\n",
       "      <td>1.203871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.351600</td>\n",
       "      <td>1.205807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.350700</td>\n",
       "      <td>1.212221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.347500</td>\n",
       "      <td>1.207736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.345900</td>\n",
       "      <td>1.207615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.343600</td>\n",
       "      <td>1.195014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.343200</td>\n",
       "      <td>1.205048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.342400</td>\n",
       "      <td>1.199801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.339200</td>\n",
       "      <td>1.194750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.338000</td>\n",
       "      <td>1.196007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.334900</td>\n",
       "      <td>1.190289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.334900</td>\n",
       "      <td>1.196634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.336800</td>\n",
       "      <td>1.192421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▃▃██▆▂▄▃▂▁▃▁▅▃▂▇▅▅▁▆▂▄▂▃▄▇▃▁▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▆▁▁▃▆▅▆▇▇▆█▄▆▇▂▄▄█▃▇▅▇▆▅▂▆█▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▆▁▁▃▆▅▆▇▇▆█▄▆▇▂▄▄█▃▇▅▇▆▅▂▆█▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.19242</td></tr><tr><td>eval/runtime</td><td>13.7237</td></tr><tr><td>eval/samples_per_second</td><td>3643.345</td></tr><tr><td>eval/steps_per_second</td><td>28.491</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3368</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.39454</td></tr><tr><td>train/train_runtime</td><td>9907.5017</td></tr><tr><td>train/train_samples_per_second</td><td>2018.672</td></tr><tr><td>train/train_steps_per_second</td><td>15.772</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 2</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_164709-2t67ykkt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_193229-1qb9z6gl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl\" target=\"_blank\">pos mlm 3</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:57:25, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.696200</td>\n",
       "      <td>2.284791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.326600</td>\n",
       "      <td>2.024099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.162900</td>\n",
       "      <td>1.842095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.039900</td>\n",
       "      <td>1.693693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.931300</td>\n",
       "      <td>1.583185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.840400</td>\n",
       "      <td>1.508486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.774100</td>\n",
       "      <td>1.463975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.733400</td>\n",
       "      <td>1.437089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.695300</td>\n",
       "      <td>1.418838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.664100</td>\n",
       "      <td>1.396953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.625900</td>\n",
       "      <td>1.362829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.597300</td>\n",
       "      <td>1.362430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.577100</td>\n",
       "      <td>1.345369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.556500</td>\n",
       "      <td>1.340125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.544400</td>\n",
       "      <td>1.329006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.533900</td>\n",
       "      <td>1.322145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.524600</td>\n",
       "      <td>1.323571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.515800</td>\n",
       "      <td>1.317697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.508300</td>\n",
       "      <td>1.309377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.501300</td>\n",
       "      <td>1.309991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.496700</td>\n",
       "      <td>1.311114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>1.309142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.486500</td>\n",
       "      <td>1.302536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>1.290455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.479700</td>\n",
       "      <td>1.301674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.478800</td>\n",
       "      <td>1.298783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.474800</td>\n",
       "      <td>1.290145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.473100</td>\n",
       "      <td>1.291290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.470400</td>\n",
       "      <td>1.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.294184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.472700</td>\n",
       "      <td>1.290210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▆▆▄▃▄▄▄▆▅▄▅▃▃▅▇▃▃▃▃▄▇▄▃▂█▆▄▃▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▃▅▆▅▅▄▃▄▅▄▆▆▄▂▆▆▆▆▅▂▅▆▆▁▃▅▆▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▃▅▆▅▅▄▃▄▅▄▆▆▄▂▆▆▆▆▅▂▅▆▆▁▃▅▆▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.29021</td></tr><tr><td>eval/runtime</td><td>14.0638</td></tr><tr><td>eval/samples_per_second</td><td>3555.218</td></tr><tr><td>eval/steps_per_second</td><td>27.802</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4727</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.66373</td></tr><tr><td>train/train_runtime</td><td>14245.3032</td></tr><tr><td>train/train_samples_per_second</td><td>1403.972</td></tr><tr><td>train/train_steps_per_second</td><td>10.969</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 3</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_193229-1qb9z6gl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_233006-1vmxpi8y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y\" target=\"_blank\">pos mlm 4</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:14:38, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.242100</td>\n",
       "      <td>1.600359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.717800</td>\n",
       "      <td>1.378072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.535000</td>\n",
       "      <td>1.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.468100</td>\n",
       "      <td>1.282308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.431800</td>\n",
       "      <td>1.262799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.412000</td>\n",
       "      <td>1.247404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.392700</td>\n",
       "      <td>1.227851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.382500</td>\n",
       "      <td>1.226134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.369200</td>\n",
       "      <td>1.226744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.363600</td>\n",
       "      <td>1.219057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.355700</td>\n",
       "      <td>1.204390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.350400</td>\n",
       "      <td>1.211484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.344800</td>\n",
       "      <td>1.204477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.338700</td>\n",
       "      <td>1.204433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.334100</td>\n",
       "      <td>1.194529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.332000</td>\n",
       "      <td>1.194333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.329900</td>\n",
       "      <td>1.200817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.192896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.323200</td>\n",
       "      <td>1.185678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.320100</td>\n",
       "      <td>1.186128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.192829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.314500</td>\n",
       "      <td>1.188919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.312300</td>\n",
       "      <td>1.187458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.309500</td>\n",
       "      <td>1.174109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.183862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.309100</td>\n",
       "      <td>1.179524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>1.173911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.304300</td>\n",
       "      <td>1.176781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.302200</td>\n",
       "      <td>1.169905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.301700</td>\n",
       "      <td>1.176751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.303200</td>\n",
       "      <td>1.172170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▅▃▃▃▃▃█▃▃▃█▃▃▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▄▆▆▆▆▆▁▆▆▆▁▆▆██▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▄▆▆▆▆▆▁▆▆▆▁▆▆██▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.17217</td></tr><tr><td>eval/runtime</td><td>14.1117</td></tr><tr><td>eval/samples_per_second</td><td>3543.147</td></tr><tr><td>eval/steps_per_second</td><td>27.707</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3032</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.38826</td></tr><tr><td>train/train_runtime</td><td>11678.8877</td></tr><tr><td>train/train_samples_per_second</td><td>1712.492</td></tr><tr><td>train/train_steps_per_second</td><td>13.38</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 4</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_233006-1vmxpi8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_024458-287qxgaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa\" target=\"_blank\">pos mlm 5</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:43:49, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.072800</td>\n",
       "      <td>1.410241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.546300</td>\n",
       "      <td>1.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.449100</td>\n",
       "      <td>1.265374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.402100</td>\n",
       "      <td>1.245277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.377300</td>\n",
       "      <td>1.233929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.363700</td>\n",
       "      <td>1.221093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.349500</td>\n",
       "      <td>1.200732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.344200</td>\n",
       "      <td>1.203284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.333700</td>\n",
       "      <td>1.203784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.329400</td>\n",
       "      <td>1.199546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.323400</td>\n",
       "      <td>1.185081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.319700</td>\n",
       "      <td>1.195089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.315800</td>\n",
       "      <td>1.186125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.185308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.306900</td>\n",
       "      <td>1.176049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.305600</td>\n",
       "      <td>1.176790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.303900</td>\n",
       "      <td>1.183256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.299700</td>\n",
       "      <td>1.178057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.298200</td>\n",
       "      <td>1.166044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.293900</td>\n",
       "      <td>1.170990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.293500</td>\n",
       "      <td>1.175670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.290300</td>\n",
       "      <td>1.172185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.287800</td>\n",
       "      <td>1.168431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.285000</td>\n",
       "      <td>1.157376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.284400</td>\n",
       "      <td>1.167173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.284000</td>\n",
       "      <td>1.160903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.279900</td>\n",
       "      <td>1.156389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.279300</td>\n",
       "      <td>1.159037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.275800</td>\n",
       "      <td>1.152051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.275700</td>\n",
       "      <td>1.160056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.276700</td>\n",
       "      <td>1.153124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▁▂▂▂▂▅▂▃▂▆▂▂▃▆█▂▁▁▄▃▂▂▃▅▁▂▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▆██▇▇▇▇▄▇▆▇▃▇▇▆▂▁▇██▅▆▇▇▆▄█▇▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▆██▇▇▇▇▄▇▆▇▃▇▇▆▂▁▇██▅▆▇▇▆▄█▇▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.15312</td></tr><tr><td>eval/runtime</td><td>14.3395</td></tr><tr><td>eval/samples_per_second</td><td>3486.874</td></tr><tr><td>eval/steps_per_second</td><td>27.267</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2767</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.34646</td></tr><tr><td>train/train_runtime</td><td>13430.3282</td></tr><tr><td>train/train_samples_per_second</td><td>1489.167</td></tr><tr><td>train/train_steps_per_second</td><td>11.635</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 5</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_024458-287qxgaa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_062901-2ucel8at</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2ucel8at\" target=\"_blank\">pos mlm 6</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97926' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 97926/156260 3:22:23 < 2:00:33, 8.06 it/s, Epoch 12.53/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.674200</td>\n",
       "      <td>2.247338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.288800</td>\n",
       "      <td>1.983894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.123800</td>\n",
       "      <td>1.802521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.990400</td>\n",
       "      <td>1.647753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.881300</td>\n",
       "      <td>1.552505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>1.480862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.734600</td>\n",
       "      <td>1.437792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.694500</td>\n",
       "      <td>1.410568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.654100</td>\n",
       "      <td>1.392488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.620500</td>\n",
       "      <td>1.368134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.585700</td>\n",
       "      <td>1.339652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.557900</td>\n",
       "      <td>1.340592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.536800</td>\n",
       "      <td>1.323589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.516800</td>\n",
       "      <td>1.319812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.502400</td>\n",
       "      <td>1.306314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.492500</td>\n",
       "      <td>1.299359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.482400</td>\n",
       "      <td>1.301254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.294463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.467600</td>\n",
       "      <td>1.285691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 128\n",
    "hidden_size = 32\n",
    "# num_hidden_layers = 3 \n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 20\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [2, 3, 4]\n",
    "MLM_P = [0.15, 0.25]\n",
    "LR = [1e-4, 5e-4, 8e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_{i_run+starting_i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm {i_run+starting_i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d660754",
   "metadata": {},
   "source": [
    "## retrain with correct tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846f5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb308665425f4a46bd25217d7efe6810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_135952-meq7masg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg\" target=\"_blank\">pos mlm 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:33:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.197700</td>\n",
       "      <td>1.503165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.621600</td>\n",
       "      <td>1.332788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.480200</td>\n",
       "      <td>1.282856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.422800</td>\n",
       "      <td>1.256439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.391100</td>\n",
       "      <td>1.235706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.371700</td>\n",
       "      <td>1.220973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.351500</td>\n",
       "      <td>1.200947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.341400</td>\n",
       "      <td>1.197688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.327900</td>\n",
       "      <td>1.200239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.320200</td>\n",
       "      <td>1.194722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.312800</td>\n",
       "      <td>1.182932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.307800</td>\n",
       "      <td>1.186158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.301500</td>\n",
       "      <td>1.178639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.295400</td>\n",
       "      <td>1.177755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.289200</td>\n",
       "      <td>1.165696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.287600</td>\n",
       "      <td>1.166491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.284900</td>\n",
       "      <td>1.173814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.281100</td>\n",
       "      <td>1.166083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>1.157503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.274000</td>\n",
       "      <td>1.159682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.273300</td>\n",
       "      <td>1.160969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.269900</td>\n",
       "      <td>1.158978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.267000</td>\n",
       "      <td>1.161546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.265100</td>\n",
       "      <td>1.145952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.263900</td>\n",
       "      <td>1.157450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.262900</td>\n",
       "      <td>1.152030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.259500</td>\n",
       "      <td>1.144415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.258500</td>\n",
       "      <td>1.147812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.256900</td>\n",
       "      <td>1.141821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.255700</td>\n",
       "      <td>1.149476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.257100</td>\n",
       "      <td>1.144939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▁▂▂▂▁▂▂▁▂▂▂▅▂█▆▂▁▂▃▆▂▂▂▁▂▃▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▆██▇▇▇█▇▇█▇▇▇▄▇▁▃▇█▇▆▂▇▇▇█▇▆▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▆██▇▇▇█▇▇█▇▇▇▄▇▁▃▇█▇▆▂▇▇▇█▇▆▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.14494</td></tr><tr><td>eval/runtime</td><td>14.433</td></tr><tr><td>eval/samples_per_second</td><td>3464.28</td></tr><tr><td>eval/steps_per_second</td><td>27.091</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2571</td></tr><tr><td>train/total_flos</td><td>355516133955840.0</td></tr><tr><td>train/train_loss</td><td>1.34217</td></tr><tr><td>train/train_runtime</td><td>12829.5392</td></tr><tr><td>train/train_samples_per_second</td><td>1558.902</td></tr><tr><td>train/train_steps_per_second</td><td>12.18</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_135952-meq7masg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_173621-2xm5n7kp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp\" target=\"_blank\">pos mlm 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:34:29, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.029900</td>\n",
       "      <td>1.427583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.546600</td>\n",
       "      <td>1.307512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.438800</td>\n",
       "      <td>1.266698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.386700</td>\n",
       "      <td>1.239994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.357000</td>\n",
       "      <td>1.218349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.340300</td>\n",
       "      <td>1.204897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.324300</td>\n",
       "      <td>1.189534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.316700</td>\n",
       "      <td>1.187331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.304900</td>\n",
       "      <td>1.189532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>1.185083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.291900</td>\n",
       "      <td>1.169276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.286800</td>\n",
       "      <td>1.175554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.282600</td>\n",
       "      <td>1.168246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.276900</td>\n",
       "      <td>1.167330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.271300</td>\n",
       "      <td>1.160178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.269000</td>\n",
       "      <td>1.157567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.266800</td>\n",
       "      <td>1.165419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.263800</td>\n",
       "      <td>1.156068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.261200</td>\n",
       "      <td>1.146525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.256800</td>\n",
       "      <td>1.149183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.255300</td>\n",
       "      <td>1.149836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.251200</td>\n",
       "      <td>1.149080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.248600</td>\n",
       "      <td>1.147295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.246300</td>\n",
       "      <td>1.135344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.244700</td>\n",
       "      <td>1.146625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.243600</td>\n",
       "      <td>1.141015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.239900</td>\n",
       "      <td>1.133747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.239100</td>\n",
       "      <td>1.135363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.236500</td>\n",
       "      <td>1.127683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.235100</td>\n",
       "      <td>1.137296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.236600</td>\n",
       "      <td>1.131848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▇▆▆▆▆▆▆█▂▃▂▁▂▂▁▅▂▁▁▂▅▁▁▆▁▁▁▁▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▂▃▃▃▃▃▃▁▇▆▇█▇▇█▄▇██▇▄██▃████▇█</td></tr><tr><td>eval/steps_per_second</td><td>▃▂▃▃▃▃▃▃▁▇▆▇█▇▇█▄▇██▇▄██▃████▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.13185</td></tr><tr><td>eval/runtime</td><td>14.4942</td></tr><tr><td>eval/samples_per_second</td><td>3449.664</td></tr><tr><td>eval/steps_per_second</td><td>26.976</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2366</td></tr><tr><td>train/total_flos</td><td>355516133955840.0</td></tr><tr><td>train/train_loss</td><td>1.31382</td></tr><tr><td>train/train_runtime</td><td>12869.7623</td></tr><tr><td>train/train_samples_per_second</td><td>1554.03</td></tr><tr><td>train/train_steps_per_second</td><td>12.142</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_173621-2xm5n7kp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 128\n",
    "hidden_size = 32\n",
    "# num_hidden_layers = 3 \n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 20\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [4]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4, 8e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5508bcd",
   "metadata": {},
   "source": [
    "# retrain length 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f99a266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53dbae617e81434e9fe7cc5f9b5f466a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1ut4zhun) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm retrain 256 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1ut4zhun\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1ut4zhun</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230210_192351-1ut4zhun/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1ut4zhun). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09de45336ba943b2b0b8cd861007b815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.03334148724873861, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230210_192427-hbbr099w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/hbbr099w\" target=\"_blank\">pos mlm retrain 256 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 390650\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13366' max='390650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 13366/390650 15:41 < 7:23:08, 14.19 it/s, Epoch 1.71/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.154800</td>\n",
       "      <td>1.500060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.660500</td>\n",
       "      <td>1.357067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_40832/1815172027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtestset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m     \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1395\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1396\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, features, return_tensors)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"np\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_call\u001b[0;34m(self, examples)\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"special_tokens_mask\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             batch[\"input_ids\"], batch[\"labels\"] = self.torch_mask_tokens(\n\u001b[0m\u001b[1;32m    739\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mtorch_mask_tokens\u001b[0;34m(self, inputs, special_tokens_mask)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mprobability_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlm_probability\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             special_tokens_mask = [\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_special_tokens_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malready_has_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             ]\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             special_tokens_mask = [\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_special_tokens_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malready_has_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m             ]\n\u001b[1;32m    761\u001b[0m             \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mget_special_tokens_mask\u001b[0;34m(self, token_ids_0, token_ids_1, already_has_special_tokens)\u001b[0m\n\u001b[1;32m   3345\u001b[0m         \u001b[0mall_special_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m  \u001b[0;31m# cache the property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3347\u001b[0;31m         \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_special_ids\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_ids_0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3345\u001b[0m         \u001b[0mall_special_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_ids\u001b[0m  \u001b[0;31m# cache the property\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3347\u001b[0;31m         \u001b[0mspecial_tokens_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_special_ids\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtoken_ids_0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspecial_tokens_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 256\n",
    "hidden_size = 32\n",
    "# num_hidden_layers = 3 \n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 50\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [4]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_256_pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm retrain 256 {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb89361",
   "metadata": {},
   "source": [
    "# retrain length 256, all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "075935c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback, IntervalStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7235dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53bf07cf2f469eb216f90f0bca2e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.10 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230216_162023-qbxwkr2j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/qbxwkr2j\" target=\"_blank\">pos mlm 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/qbxwkr2j\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/qbxwkr2j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch113/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 50\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 390650\n",
      "  Number of trainable parameters = 36663\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116289' max='390650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116289/390650 1:43:07 < 4:03:18, 18.79 it/s, Epoch 14.88/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.288400</td>\n",
       "      <td>1.610491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.759400</td>\n",
       "      <td>1.386697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.600200</td>\n",
       "      <td>1.329584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.552600</td>\n",
       "      <td>1.314830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.528600</td>\n",
       "      <td>1.291728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.513500</td>\n",
       "      <td>1.288923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.500900</td>\n",
       "      <td>1.291031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.491700</td>\n",
       "      <td>1.279018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.483200</td>\n",
       "      <td>1.258894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.476900</td>\n",
       "      <td>1.262129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.470400</td>\n",
       "      <td>1.267644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.467800</td>\n",
       "      <td>1.260592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.460500</td>\n",
       "      <td>1.258115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.458700</td>\n",
       "      <td>1.253296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.453900</td>\n",
       "      <td>1.242121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.447700</td>\n",
       "      <td>1.258020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.442100</td>\n",
       "      <td>1.247184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.432500</td>\n",
       "      <td>1.237517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.423900</td>\n",
       "      <td>1.238617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.417400</td>\n",
       "      <td>1.234057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.414400</td>\n",
       "      <td>1.245624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.407100</td>\n",
       "      <td>1.233095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.403900</td>\n",
       "      <td>1.235185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000/generation_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000/config.json\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000/generation_config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 256\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 50\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "# HIDDEN_SIZE = [16,32,64]\n",
    "NUM_LAYERS = [2,4,6]\n",
    "NUM_ATT = [2,4,6,8]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4]\n",
    "\n",
    "NUM_LAYERS, NUM_ATT, MLM_P, LR = np.meshgrid(NUM_LAYERS, NUM_ATT, MLM_P, LR)\n",
    "NUM_LAYERS, NUM_ATT, MLM_P, LR = NUM_LAYERS.flatten(), NUM_ATT.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "\n",
    "starting_i_run = 2\n",
    "for i_run in trange(num_runs):\n",
    "#     hidden_size = int(HIDDEN_SIZE[i_run])\n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    \n",
    "    num_attention_heads = int(NUM_ATT[i_run])\n",
    "    \n",
    "    hidden_size = num_attention_heads * 16\n",
    "    intermediate_size = hidden_size * 4\n",
    "    \n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        load_best_model_at_end=True,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "        callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caf7cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bc5b936",
   "metadata": {},
   "source": [
    "# bigram pos bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1827334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagset \n",
    "def get_bigram_pos_vocab(tagger, tagset='xpos'):\n",
    "    # if use the simple conversion, upos vocab is smaller\n",
    "    upos_vocab = ['ADJ',\n",
    "                 'ADP',\n",
    "                 'ADV',\n",
    "                 'CCONJ',\n",
    "                 'DET',\n",
    "                 'INTJ',\n",
    "                 'NOUN',\n",
    "                 'NUM',\n",
    "                 'PART',\n",
    "                 'PRON',\n",
    "                 'PROPN',\n",
    "                 'PUNCT',\n",
    "                 'SYM',\n",
    "                 'VERB',\n",
    "                 'X']\n",
    "\n",
    "    from nltk.data import load\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "\n",
    "    xpos_vocab = list(tagdict.keys())\n",
    "    if tagger == 'corenlp':\n",
    "        xpos_vocab = corenlp_vocab\n",
    "    xpos_vocab = sorted(xpos_vocab)\n",
    "    if tagset=='xpos':\n",
    "        vocab = xpos_vocab\n",
    "    else:\n",
    "        vocab = upos_vocab\n",
    "    bigram_vocab = []\n",
    "    for i in range(len(vocab)):\n",
    "        for j in range(len(vocab)):\n",
    "            bigram_vocab.append(f\"{vocab[i]}+{vocab[j]}\")\n",
    "    return bigram_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a67aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_bigram_tokenizer(vocab, model_max_length = 128):\n",
    "    # Tokenizer is from tokenizers package. PreTrainedTokenizerFast is from tranformers package.\n",
    "    # PreTrainedTokenizerFast can load vocab saved/trained by Tokenizer\n",
    "    t = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    t.pre_tokenizer = Whitespace()\n",
    "    t.add_special_tokens([\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\",])\n",
    "\n",
    "    t.add_tokens(vocab) \n",
    "#     trainer makes \"-LRB-\" 3 tokens\n",
    "#     trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "#     data = [' '.join(vocab)]\n",
    "#     t.train_from_iterator(data, trainer=trainer)\n",
    "\n",
    "    t.post_processor = TemplateProcessing(\n",
    "        single=\"[CLS] $A [SEP]\",\n",
    "        pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "        special_tokens=[\n",
    "            (\"[CLS]\", t.token_to_id(\"[CLS]\")),\n",
    "            (\"[SEP]\", t.token_to_id(\"[SEP]\")),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    t.enable_padding(pad_id=t.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\")\n",
    "    t.enable_truncation(max_length=model_max_length)\n",
    "    t.save('/home/jz17d/Desktop/pos_bigram_tokenizer.json')\n",
    "\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/home/jz17d/Desktop/pos_bigram_tokenizer.json\", unk_token=\"[UNK]\")\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "    tokenizer.mask_token = '[MASK]'\n",
    "    tokenizer.unk_token = '[UNK]'\n",
    "    special_tokens = {\n",
    "         \"unk_token\": \"[UNK]\",\n",
    "         \"sep_token\": \"[SEP]\",\n",
    "         \"pad_token\": \"[PAD]\",\n",
    "         \"cls_token\": \"[CLS]\",\n",
    "         \"mask_token\": \"[MASK]\" }\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    # tokenizer.add_special_tokens({'unk_token':'[UNK]'})\n",
    "    tokenizer.model_max_length=model_max_length\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f432ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return f\"{x[0]}+{x[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4910e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corenlp_bigram_tagging(examples): # corenlp\n",
    "    xpos = []\n",
    "    tagged = list(pos_tagger.raw_tag_sents(examples['text']))\n",
    "    for sentence in tagged:\n",
    "        pos = []\n",
    "        for word in sentence[0]:\n",
    "            pos.append(word[1])\n",
    "        if pos:\n",
    "            pos = ngrams(pos, 2)\n",
    "            pos = map(f, pos)\n",
    "            xpos.append(' '.join(pos))\n",
    "\n",
    "    return tokenizer(xpos, truncation=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e9e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bookcorpus (/scratch/data_jz17d/hf_datasets_cache/bookcorpus/plain_text/1.0.0/eddee3cae1cc263a431aa98207d4d27fd8a73b0a9742f692af0e6c65afa4d75f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd6685c8e16747bb97e0e44701e32f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load raw bookcorpus dataset\n",
    "os.environ['HF_DATASETS_CACHE'] = '/scratch/data_jz17d/hf_datasets_cache'\n",
    "dataset = load_dataset(\"bookcorpus\", cache_dir=\"/scratch/data_jz17d/hf_datasets_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22d0665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e3082566d04ed099c0ef538025e2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reprocess corenlp with correct tag list \n",
    "tagger = 'corenlp'\n",
    "tagset = 'xpos'\n",
    "reprocess = True\n",
    "select = 2000000\n",
    "model_max_length = 256\n",
    "\n",
    "vocab = get_bigram_pos_vocab(tagger, tagset=tagset)\n",
    "tokenizer = get_pos_bigram_tokenizer(vocab, model_max_length = model_max_length)\n",
    "\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_bigram_transformed.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    trainset = dataset['train'].select(range(select)).map(corenlp_bigram_tagging, batched=True)\n",
    "    trainset.save_to_disk(cache_location)\n",
    "else:\n",
    "    trainset = load_from_disk(cache_location)\n",
    "trainset = trainset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94458dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec5fed53b3c4406a3d4a391e2862c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "select2 = range(select,select+50000)\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_bigram_transformed_test.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    testset = dataset['train'].select(select2).map(corenlp_bigram_tagging, batched=True)\n",
    "    testset.save_to_disk(cache_location)\n",
    "else:\n",
    "    testset = load_from_disk(cache_location)\n",
    "testset = testset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc71de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e496fba7687f41389afb62d03025aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536fe7beedf84537b6a460552542e5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.033351953824361166, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230126_113803-259qbd8n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/259qbd8n\" target=\"_blank\">run 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000000\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 937500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937500' max='937500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937500/937500 14:59:20, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.598500</td>\n",
       "      <td>0.639652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.542076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.570300</td>\n",
       "      <td>0.530268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.537300</td>\n",
       "      <td>0.505145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.493833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.518900</td>\n",
       "      <td>0.502631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.468932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.502600</td>\n",
       "      <td>0.476024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.498500</td>\n",
       "      <td>0.476908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.490800</td>\n",
       "      <td>0.469109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.486800</td>\n",
       "      <td>0.460868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.486100</td>\n",
       "      <td>0.462609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.459209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.478600</td>\n",
       "      <td>0.462440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.478100</td>\n",
       "      <td>0.455688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.453806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.449258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.446776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.454554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.461600</td>\n",
       "      <td>0.446935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.465100</td>\n",
       "      <td>0.442894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.440543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.461600</td>\n",
       "      <td>0.451617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.460800</td>\n",
       "      <td>0.444300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.465489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.451569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>0.457100</td>\n",
       "      <td>0.439228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.449200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.440871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.438230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.436330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.437997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>0.449400</td>\n",
       "      <td>0.431756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.437645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.443304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.451900</td>\n",
       "      <td>0.434863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.440716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>0.426453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>0.446700</td>\n",
       "      <td>0.436973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.430742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.431952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.444900</td>\n",
       "      <td>0.429444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>0.443100</td>\n",
       "      <td>0.431350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.425669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>0.442900</td>\n",
       "      <td>0.435505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>0.439900</td>\n",
       "      <td>0.428401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>0.430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.425289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.435428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.434748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>0.440300</td>\n",
       "      <td>0.429020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>0.436300</td>\n",
       "      <td>0.430606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>0.437900</td>\n",
       "      <td>0.423943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>0.435200</td>\n",
       "      <td>0.419341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.414671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.416459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.417360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.418879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>0.433800</td>\n",
       "      <td>0.422827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.420623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>0.430800</td>\n",
       "      <td>0.420583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.426024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.426348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.420761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.420505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.426171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.420931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>0.430200</td>\n",
       "      <td>0.410863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>0.428800</td>\n",
       "      <td>0.416080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.407429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>0.425500</td>\n",
       "      <td>0.414227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.415236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>0.426100</td>\n",
       "      <td>0.424921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.422094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>0.426700</td>\n",
       "      <td>0.416483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.417461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.420681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.416436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>0.421900</td>\n",
       "      <td>0.414865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.414431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.417075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.421943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>0.412347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.416337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>0.424100</td>\n",
       "      <td>0.413774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.412613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.410330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>0.420100</td>\n",
       "      <td>0.422838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.413141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.412192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.408723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.415226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.412242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.402768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>0.417300</td>\n",
       "      <td>0.404632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.412781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.412567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.406411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.407752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.412811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.414333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.410439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.403115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.402709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.402413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>0.411800</td>\n",
       "      <td>0.406316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.420995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.402577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>0.412700</td>\n",
       "      <td>0.398951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.407479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.402870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.403496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.398317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>0.412300</td>\n",
       "      <td>0.406699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.398359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.407623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.400628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.406502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.403112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>0.412000</td>\n",
       "      <td>0.400279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.401348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>0.410400</td>\n",
       "      <td>0.399278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.390042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.399586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>0.404800</td>\n",
       "      <td>0.399331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.399199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.396635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>0.406500</td>\n",
       "      <td>0.402485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.397755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.396184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.397605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.396529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.405293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.399620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.388910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.393846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>0.403300</td>\n",
       "      <td>0.402882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>0.392355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>0.403000</td>\n",
       "      <td>0.391026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>0.404500</td>\n",
       "      <td>0.403740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.396931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.398780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.398210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.399545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.388987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.397741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>0.402000</td>\n",
       "      <td>0.381451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.388957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.392479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>0.400700</td>\n",
       "      <td>0.393968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>0.398600</td>\n",
       "      <td>0.397987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.397710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.395926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>0.401400</td>\n",
       "      <td>0.386842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.385337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.390060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>0.382770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>0.388651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.401104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>0.398100</td>\n",
       "      <td>0.390360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>0.392000</td>\n",
       "      <td>0.390739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.386885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>0.396497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>0.383898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.389922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>0.390400</td>\n",
       "      <td>0.387924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.391501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.384681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.391119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>0.394600</td>\n",
       "      <td>0.390437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>0.391300</td>\n",
       "      <td>0.385488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.389755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.388777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.387702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.382019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>0.392100</td>\n",
       "      <td>0.384025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>0.390500</td>\n",
       "      <td>0.406256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>0.394200</td>\n",
       "      <td>0.386825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.391995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.382133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.389776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>0.387700</td>\n",
       "      <td>0.381903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>0.390900</td>\n",
       "      <td>0.388245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>0.388800</td>\n",
       "      <td>0.385057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>0.387000</td>\n",
       "      <td>0.386990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.385580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.389450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-145000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-150000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-155000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-160000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-165000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-170000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-175000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-180000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-185000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-190000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-195000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-200000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-205000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-210000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-215000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-220000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-225000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-230000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-235000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-240000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-245000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-250000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-255000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-260000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-265000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-270000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-275000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-280000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-285000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-290000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-295000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-300000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-305000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-310000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-315000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-320000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-325000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-330000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-335000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-340000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-345000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-350000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-355000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-360000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-365000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-370000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-375000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-380000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-385000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-390000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-395000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-400000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-405000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-410000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-415000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-420000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-425000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-430000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-435000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-440000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-445000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-450000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-455000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-460000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-465000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-470000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-475000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-480000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-485000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-490000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-495000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-500000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-505000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-510000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-515000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-520000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-525000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-530000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-535000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-540000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-545000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-550000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-555000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-560000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-565000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-570000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-575000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-580000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-585000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-590000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-595000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-600000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-605000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-610000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-615000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-620000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-625000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-630000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-635000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-640000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-645000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-650000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-655000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-660000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-665000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-670000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-675000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-680000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-685000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-690000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-695000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-700000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-705000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-710000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-715000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-720000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-725000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-730000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-735000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-740000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-745000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-750000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-755000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-760000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-765000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-770000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-775000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-780000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-785000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-790000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-795000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-800000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-805000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-810000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-815000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-820000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-825000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-830000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-835000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-840000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-845000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-850000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-855000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-860000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-865000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-870000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-875000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-880000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-885000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-890000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-895000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-900000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-905000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-910000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-915000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-930000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-930000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-930000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-930000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-930000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-920000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-935000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-935000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-935000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-935000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-935000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_0/checkpoint-925000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▃▃▁▅▃▂▃▃▃▃▃▃▃▃▂▃▃▃▄▄▃▄▃▄▄▅▄▅▅▅▅▅▆▆▆▇▇▇█</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▆█▄▆▇▆▆▆▆▆▆▆▆▇▆▆▆▅▅▆▅▆▅▅▄▄▄▄▄▄▄▃▃▃▂▂▂▁</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▆█▄▆▇▆▆▆▆▆▆▆▆▇▆▆▆▅▅▆▅▆▅▅▄▅▄▄▄▄▄▃▃▃▂▂▂▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.38945</td></tr><tr><td>eval/runtime</td><td>14.7161</td></tr><tr><td>eval/samples_per_second</td><td>3397.645</td></tr><tr><td>eval/steps_per_second</td><td>53.139</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>937500</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3906</td></tr><tr><td>train/total_flos</td><td>1.3472471428560768e+16</td></tr><tr><td>train/train_loss</td><td>0.43258</td></tr><tr><td>train/train_runtime</td><td>53960.7923</td></tr><tr><td>train/train_samples_per_second</td><td>1111.918</td></tr><tr><td>train/train_steps_per_second</td><td>17.374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">run 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/259qbd8n\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/259qbd8n</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230126_113803-259qbd8n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230127_023747-39agv34a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/39agv34a\" target=\"_blank\">run 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000000\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 937500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937500' max='937500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937500/937500 15:02:05, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.359600</td>\n",
       "      <td>0.606914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.609500</td>\n",
       "      <td>0.533817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.571000</td>\n",
       "      <td>0.538181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.546300</td>\n",
       "      <td>0.510843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>0.505803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.532900</td>\n",
       "      <td>0.511211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.519800</td>\n",
       "      <td>0.479464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.488138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.513500</td>\n",
       "      <td>0.486996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.506500</td>\n",
       "      <td>0.477756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.502700</td>\n",
       "      <td>0.468617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.501600</td>\n",
       "      <td>0.470553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.467528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.495700</td>\n",
       "      <td>0.471111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.493400</td>\n",
       "      <td>0.464367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.488900</td>\n",
       "      <td>0.466165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.491200</td>\n",
       "      <td>0.460624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.483900</td>\n",
       "      <td>0.456046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.463997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.476700</td>\n",
       "      <td>0.454870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.479900</td>\n",
       "      <td>0.457214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.449483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.477800</td>\n",
       "      <td>0.460791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.476100</td>\n",
       "      <td>0.453093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.475053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.461481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>0.472300</td>\n",
       "      <td>0.450732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.459789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>0.470500</td>\n",
       "      <td>0.449105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.448367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.470600</td>\n",
       "      <td>0.444291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.468200</td>\n",
       "      <td>0.445376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>0.464600</td>\n",
       "      <td>0.441013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.464000</td>\n",
       "      <td>0.448094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>0.460100</td>\n",
       "      <td>0.450662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.466200</td>\n",
       "      <td>0.445187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.451409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.462200</td>\n",
       "      <td>0.436552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>0.460400</td>\n",
       "      <td>0.444953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.440822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.441985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.459300</td>\n",
       "      <td>0.441152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>0.457000</td>\n",
       "      <td>0.442988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.457100</td>\n",
       "      <td>0.438219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>0.456300</td>\n",
       "      <td>0.445978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.439893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>0.454000</td>\n",
       "      <td>0.443172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.438004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>0.449500</td>\n",
       "      <td>0.441255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.443674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>0.453600</td>\n",
       "      <td>0.440604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>0.450200</td>\n",
       "      <td>0.442176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>0.450700</td>\n",
       "      <td>0.432503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.430523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>0.447400</td>\n",
       "      <td>0.426637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>0.449300</td>\n",
       "      <td>0.427379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>0.451200</td>\n",
       "      <td>0.425402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>0.445600</td>\n",
       "      <td>0.435308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>0.447700</td>\n",
       "      <td>0.432670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0.445000</td>\n",
       "      <td>0.429474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>0.433248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>0.446000</td>\n",
       "      <td>0.437242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>0.447100</td>\n",
       "      <td>0.438089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.428839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>0.446800</td>\n",
       "      <td>0.430811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.432600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>0.443900</td>\n",
       "      <td>0.430089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>0.441900</td>\n",
       "      <td>0.418623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>0.442600</td>\n",
       "      <td>0.428321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>0.439200</td>\n",
       "      <td>0.417297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>0.437000</td>\n",
       "      <td>0.422654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>0.438100</td>\n",
       "      <td>0.424253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.434169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>0.440200</td>\n",
       "      <td>0.428958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>0.439700</td>\n",
       "      <td>0.427196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>0.439700</td>\n",
       "      <td>0.427977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>0.438700</td>\n",
       "      <td>0.429204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.427102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>0.433200</td>\n",
       "      <td>0.419279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>0.433900</td>\n",
       "      <td>0.424347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>0.427067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>0.433700</td>\n",
       "      <td>0.430309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>0.433100</td>\n",
       "      <td>0.421945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>0.438300</td>\n",
       "      <td>0.421606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.424112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.420191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>0.429700</td>\n",
       "      <td>0.417107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.430915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>0.432200</td>\n",
       "      <td>0.421972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.419649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>0.431800</td>\n",
       "      <td>0.417646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.418767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>0.430300</td>\n",
       "      <td>0.419216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.411847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>0.428800</td>\n",
       "      <td>0.414107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>0.431500</td>\n",
       "      <td>0.421762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.421065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>0.413086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.416143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.424455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>0.424900</td>\n",
       "      <td>0.423335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>0.424700</td>\n",
       "      <td>0.420393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.412405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.411346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>0.410658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>0.421800</td>\n",
       "      <td>0.416067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.428531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>0.425300</td>\n",
       "      <td>0.410755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.408243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.416486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>0.422500</td>\n",
       "      <td>0.413030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>0.424500</td>\n",
       "      <td>0.413082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>0.421300</td>\n",
       "      <td>0.407276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.413486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>0.420300</td>\n",
       "      <td>0.404607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.415315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>0.419900</td>\n",
       "      <td>0.407473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>0.418900</td>\n",
       "      <td>0.413697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>0.417600</td>\n",
       "      <td>0.411202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>0.420600</td>\n",
       "      <td>0.408682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.410795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.407048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.395393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>0.416900</td>\n",
       "      <td>0.407875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>0.412500</td>\n",
       "      <td>0.405463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.406820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>0.415700</td>\n",
       "      <td>0.404304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.409748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>0.414200</td>\n",
       "      <td>0.403952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>0.413600</td>\n",
       "      <td>0.404705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>0.417700</td>\n",
       "      <td>0.403521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.403692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>0.410100</td>\n",
       "      <td>0.413995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.404700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>0.394662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>0.413700</td>\n",
       "      <td>0.400543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.411560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>0.410600</td>\n",
       "      <td>0.400029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>0.410500</td>\n",
       "      <td>0.399006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>0.412100</td>\n",
       "      <td>0.409627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.403704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>0.405153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.406895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>0.408800</td>\n",
       "      <td>0.406410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>0.409000</td>\n",
       "      <td>0.396972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>0.406300</td>\n",
       "      <td>0.406095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.387902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>0.407000</td>\n",
       "      <td>0.396216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>0.409900</td>\n",
       "      <td>0.398888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.400972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>0.405100</td>\n",
       "      <td>0.402893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>0.407400</td>\n",
       "      <td>0.404634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.403635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.392484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.390083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.395363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.387274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>0.403700</td>\n",
       "      <td>0.393391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>0.400500</td>\n",
       "      <td>0.407918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>0.402400</td>\n",
       "      <td>0.399224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.394949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>0.399700</td>\n",
       "      <td>0.392223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.401211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>0.402100</td>\n",
       "      <td>0.389075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.394868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.392650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>0.399000</td>\n",
       "      <td>0.394807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.389834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>0.396900</td>\n",
       "      <td>0.397546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.393992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>0.395500</td>\n",
       "      <td>0.391200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.397084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.394104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.392372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>0.386851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>0.396100</td>\n",
       "      <td>0.387058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.412198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>0.397800</td>\n",
       "      <td>0.390234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.397787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.386563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>0.394900</td>\n",
       "      <td>0.395205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.385112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.392130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.390571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>0.390600</td>\n",
       "      <td>0.390858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.390599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>0.394100</td>\n",
       "      <td>0.393133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-95000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-145000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-150000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-155000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-160000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-165000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-170000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-175000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-180000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-185000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-190000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-195000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-200000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-205000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-210000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-215000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-220000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-225000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-230000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-235000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-240000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-245000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-250000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-255000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-260000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-265000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-270000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-275000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-280000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-285000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-290000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-295000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-300000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-305000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-310000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-315000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-320000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-325000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-330000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-335000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-340000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-345000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-350000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-355000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-360000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-365000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-370000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-375000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-380000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-385000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-390000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-395000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-400000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-405000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-410000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-415000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-420000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-425000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-430000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-435000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-440000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-445000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-450000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-455000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-460000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-465000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-470000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-475000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-480000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-485000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-490000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-495000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-500000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-505000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-510000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-515000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-520000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-525000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-530000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-535000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-540000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-545000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-550000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-555000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-560000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-565000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-570000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-575000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-580000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-585000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-590000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-595000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-600000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-605000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-610000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-615000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-620000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-625000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-630000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-635000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-640000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-645000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-650000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-655000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-660000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-665000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-670000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-675000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-680000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-685000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-690000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-695000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-700000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-705000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-710000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-715000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-720000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-725000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-730000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-735000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-740000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-745000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-750000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-755000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-760000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-765000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-770000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-775000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-780000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-785000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-790000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-795000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-800000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-805000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-810000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-815000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-820000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-825000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-830000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-835000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-840000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-845000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-850000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-855000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-860000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-865000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-870000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-875000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-880000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-885000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-890000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-895000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-900000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-905000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-910000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-915000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-930000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-930000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-930000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-930000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-930000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-920000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-935000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-935000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-935000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-935000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-935000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_1/checkpoint-925000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▅▅▄▄▄▄▃▃▃▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂▂▂▃▂▃▂▂▂▁▂▂▂▂█▂▅▃▃▃▃▃▃▃▄▃▄▄▄▄▄▄▄▆▆▆▇▇▇</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▇▇▆▇▆▇▇▇█▇▇▇▇▁▇▄▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▃▃▃▂▂▂</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▇▇▆▇▆▇▇▇█▇▇▇▇▁▇▄▆▆▆▆▆▆▆▅▆▅▅▅▅▅▅▅▃▂▃▂▂▂</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.39313</td></tr><tr><td>eval/runtime</td><td>14.8619</td></tr><tr><td>eval/samples_per_second</td><td>3364.297</td></tr><tr><td>eval/steps_per_second</td><td>52.618</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>937500</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3941</td></tr><tr><td>train/total_flos</td><td>1.3472471428560768e+16</td></tr><tr><td>train/train_loss</td><td>0.44125</td></tr><tr><td>train/train_runtime</td><td>54125.4538</td></tr><tr><td>train/train_samples_per_second</td><td>1108.536</td></tr><tr><td>train/train_steps_per_second</td><td>17.321</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">run 1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/39agv34a\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/39agv34a</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230127_023747-39agv34a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230127_174011-1be3a87l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/1be3a87l\" target=\"_blank\">run 2</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000000\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 937500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937500' max='937500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937500/937500 19:17:49, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.597700</td>\n",
       "      <td>0.626570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>0.529678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.523193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.496353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.509500</td>\n",
       "      <td>0.489768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.508500</td>\n",
       "      <td>0.494274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.495500</td>\n",
       "      <td>0.464232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.493900</td>\n",
       "      <td>0.474719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.489800</td>\n",
       "      <td>0.474372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.482600</td>\n",
       "      <td>0.464143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.457265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.479200</td>\n",
       "      <td>0.457280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.457485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.459779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.471100</td>\n",
       "      <td>0.450876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>0.447837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.468700</td>\n",
       "      <td>0.445024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.463700</td>\n",
       "      <td>0.443039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.465000</td>\n",
       "      <td>0.452463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.442509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.441527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>0.436149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.456400</td>\n",
       "      <td>0.450359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.456800</td>\n",
       "      <td>0.441510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.455400</td>\n",
       "      <td>0.462028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.444971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>0.451300</td>\n",
       "      <td>0.436374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.451600</td>\n",
       "      <td>0.443248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.434994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.436442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.451000</td>\n",
       "      <td>0.434003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.448900</td>\n",
       "      <td>0.434388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>0.445700</td>\n",
       "      <td>0.428223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.445200</td>\n",
       "      <td>0.436228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.437503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.448100</td>\n",
       "      <td>0.430890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>0.442200</td>\n",
       "      <td>0.438769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.443500</td>\n",
       "      <td>0.423623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>0.441100</td>\n",
       "      <td>0.433405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.439200</td>\n",
       "      <td>0.428263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>0.443000</td>\n",
       "      <td>0.426235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.426471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.429727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.438300</td>\n",
       "      <td>0.424763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.432607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>0.435800</td>\n",
       "      <td>0.428093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>0.436100</td>\n",
       "      <td>0.425854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>0.435500</td>\n",
       "      <td>0.423322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>0.430700</td>\n",
       "      <td>0.429289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>0.434700</td>\n",
       "      <td>0.429674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>0.434100</td>\n",
       "      <td>0.426273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>0.432800</td>\n",
       "      <td>0.426184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.418287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.416674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.412010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>0.430400</td>\n",
       "      <td>0.414377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.413838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>0.413004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>0.429600</td>\n",
       "      <td>0.421765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0.428000</td>\n",
       "      <td>0.414508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.416829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>0.423625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>0.429000</td>\n",
       "      <td>0.423462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>0.425900</td>\n",
       "      <td>0.413963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>0.429900</td>\n",
       "      <td>0.415497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>0.422750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.418321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>0.425100</td>\n",
       "      <td>0.405693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>0.424300</td>\n",
       "      <td>0.413071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.405282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>0.420500</td>\n",
       "      <td>0.409704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.409675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>0.420900</td>\n",
       "      <td>0.421068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>0.423400</td>\n",
       "      <td>0.414384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>0.421700</td>\n",
       "      <td>0.415247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>0.422200</td>\n",
       "      <td>0.413863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.416008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>0.421600</td>\n",
       "      <td>0.411382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.408726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>0.417100</td>\n",
       "      <td>0.411828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.414149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>0.417200</td>\n",
       "      <td>0.417427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>0.416200</td>\n",
       "      <td>0.408017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.411845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.410427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.406646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>0.413400</td>\n",
       "      <td>0.403788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>0.415100</td>\n",
       "      <td>0.416032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>0.415600</td>\n",
       "      <td>0.407733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>0.416100</td>\n",
       "      <td>0.405863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>0.415000</td>\n",
       "      <td>0.402541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>0.412800</td>\n",
       "      <td>0.408472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>0.413900</td>\n",
       "      <td>0.406553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>0.402502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.401790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>0.415200</td>\n",
       "      <td>0.409079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.407074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>0.400685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.401219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>0.410800</td>\n",
       "      <td>0.409346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>0.408900</td>\n",
       "      <td>0.410596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.406146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.399435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>0.409600</td>\n",
       "      <td>0.398332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.396679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.400849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.415966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>0.410200</td>\n",
       "      <td>0.398611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.394522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>0.403100</td>\n",
       "      <td>0.404101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>0.406700</td>\n",
       "      <td>0.399131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.399370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>0.405400</td>\n",
       "      <td>0.394777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>0.406600</td>\n",
       "      <td>0.400989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.393169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>0.402300</td>\n",
       "      <td>0.400245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>0.404400</td>\n",
       "      <td>0.395984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>0.403600</td>\n",
       "      <td>0.402393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.398338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.395022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.396655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>0.395032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.385162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>0.401900</td>\n",
       "      <td>0.392997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>0.397400</td>\n",
       "      <td>0.392982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>0.401800</td>\n",
       "      <td>0.394284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>0.401300</td>\n",
       "      <td>0.391231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>0.400100</td>\n",
       "      <td>0.395539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>0.398400</td>\n",
       "      <td>0.391911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>0.399100</td>\n",
       "      <td>0.391312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>0.403100</td>\n",
       "      <td>0.391676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>0.396600</td>\n",
       "      <td>0.391846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>0.396000</td>\n",
       "      <td>0.399452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.393504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>0.400900</td>\n",
       "      <td>0.382087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>0.400200</td>\n",
       "      <td>0.390040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>0.396300</td>\n",
       "      <td>0.397390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.388229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>0.396200</td>\n",
       "      <td>0.387134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>0.398000</td>\n",
       "      <td>0.396568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.389549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.394159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.392763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>0.395200</td>\n",
       "      <td>0.393056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>0.394700</td>\n",
       "      <td>0.383839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>0.393200</td>\n",
       "      <td>0.391448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.375375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>0.393100</td>\n",
       "      <td>0.382459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.386968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>0.393900</td>\n",
       "      <td>0.387224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>0.391400</td>\n",
       "      <td>0.392015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.391860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.390600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.380436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.379079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>0.389100</td>\n",
       "      <td>0.382536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.375483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.381185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.396088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.387093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.383267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>0.387200</td>\n",
       "      <td>0.380016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>0.389300</td>\n",
       "      <td>0.389019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>0.389700</td>\n",
       "      <td>0.378377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>0.387100</td>\n",
       "      <td>0.382532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>0.383100</td>\n",
       "      <td>0.382037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.383850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>0.388500</td>\n",
       "      <td>0.378702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.384187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>0.387500</td>\n",
       "      <td>0.383314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.380674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>0.387200</td>\n",
       "      <td>0.384341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>0.386200</td>\n",
       "      <td>0.382455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.379691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>0.382400</td>\n",
       "      <td>0.375377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>0.384100</td>\n",
       "      <td>0.377716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>0.383000</td>\n",
       "      <td>0.400702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.379661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.387138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>0.384900</td>\n",
       "      <td>0.375294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.383953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.374839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>0.382800</td>\n",
       "      <td>0.381727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>0.381200</td>\n",
       "      <td>0.379858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.379774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>0.382100</td>\n",
       "      <td>0.379336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>0.382700</td>\n",
       "      <td>0.383596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-95000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-145000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-150000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-155000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-160000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-165000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-170000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-175000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-180000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-185000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-190000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-195000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-200000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-205000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-210000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-215000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-220000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-225000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-230000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-235000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-240000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-245000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-250000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-255000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-260000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-265000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-270000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-275000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-280000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-285000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-290000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-295000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-300000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-305000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-310000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-315000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-320000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-325000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-330000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-335000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-340000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-345000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-350000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-355000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-360000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-365000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-370000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-375000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-380000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-385000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-390000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-395000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-400000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-405000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-410000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-415000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-420000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-425000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-430000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-435000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-440000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-445000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-450000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-455000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-460000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-465000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-470000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-475000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-480000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-485000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-490000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-495000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-500000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-505000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-510000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-515000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-520000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-525000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-530000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-535000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-540000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-545000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-550000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-555000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-560000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-565000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-570000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-575000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-580000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-585000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-590000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-595000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-600000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-605000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-610000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-615000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-620000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-625000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-630000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-635000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-640000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-645000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-650000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-655000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-660000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-665000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-670000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-675000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-680000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-685000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-690000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-695000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-700000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-705000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-710000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-715000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-720000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-725000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-730000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-735000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-740000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-745000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-750000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-755000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-760000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-765000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-770000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-775000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-780000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-785000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-790000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-795000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-800000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-805000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-810000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-815000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-820000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-825000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-830000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-835000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-840000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-845000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-850000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-855000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-860000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-865000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-870000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-875000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-880000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-885000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-890000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-895000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-900000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-905000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-910000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-915000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-930000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-930000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-930000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-930000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-930000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-920000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-935000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-935000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-935000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-935000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-935000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_2/checkpoint-925000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▄▄▄▄▃▃▃▃▃▃▂▃▃▃▂▂▃▃▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▂▂▁▂▁▂▂▃▃▆▂▂▄▂▆█▄▇▄▄▃▅▃▄▅▅▅▅▅▅▆▆▆▇▆▇███</td></tr><tr><td>eval/samples_per_second</td><td>▅▇▇█▇█▇▇▆▆▃▇▇▅▇▃▁▅▂▄▅▆▄▆▅▄▄▄▄▄▄▃▃▃▂▃▂▁▁▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▇▇█▇█▇▇▆▆▃▇▇▅▇▃▁▅▂▄▅▆▄▆▅▄▄▄▄▄▄▃▃▃▂▃▂▁▁▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.3836</td></tr><tr><td>eval/runtime</td><td>16.3149</td></tr><tr><td>eval/samples_per_second</td><td>3064.692</td></tr><tr><td>eval/steps_per_second</td><td>47.932</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>937500</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3827</td></tr><tr><td>train/total_flos</td><td>2.0046820365596544e+16</td></tr><tr><td>train/train_loss</td><td>0.42627</td></tr><tr><td>train/train_runtime</td><td>69470.2622</td></tr><tr><td>train/train_samples_per_second</td><td>863.679</td></tr><tr><td>train/train_steps_per_second</td><td>13.495</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">run 2</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/1be3a87l\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/1be3a87l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230127_174011-1be3a87l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230128_125821-2jq8x72g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/2jq8x72g\" target=\"_blank\">run 3</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2000000\n",
      "  Num Epochs = 30\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 937500\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='937500' max='937500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [937500/937500 19:11:56, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.368400</td>\n",
       "      <td>0.621337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.617500</td>\n",
       "      <td>0.542728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>0.540385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.513748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.537400</td>\n",
       "      <td>0.508453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.534800</td>\n",
       "      <td>0.509095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.482624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.520700</td>\n",
       "      <td>0.490011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.515200</td>\n",
       "      <td>0.490037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.479343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.475753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.503600</td>\n",
       "      <td>0.469371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>0.471981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.469805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.467866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>0.464508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.492600</td>\n",
       "      <td>0.458669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.457952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>0.488200</td>\n",
       "      <td>0.462633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>0.479000</td>\n",
       "      <td>0.454960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>0.482300</td>\n",
       "      <td>0.457028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.445849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>0.479100</td>\n",
       "      <td>0.461411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>0.478900</td>\n",
       "      <td>0.454613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.476436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>0.462606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>0.473900</td>\n",
       "      <td>0.448943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.461262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>0.472600</td>\n",
       "      <td>0.450450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>0.470100</td>\n",
       "      <td>0.451401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.444774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160000</td>\n",
       "      <td>0.470400</td>\n",
       "      <td>0.446523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165000</td>\n",
       "      <td>0.466100</td>\n",
       "      <td>0.441139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170000</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.450595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175000</td>\n",
       "      <td>0.461800</td>\n",
       "      <td>0.448607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180000</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0.445900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185000</td>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.453558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190000</td>\n",
       "      <td>0.464400</td>\n",
       "      <td>0.434837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195000</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.445458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.440703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205000</td>\n",
       "      <td>0.463900</td>\n",
       "      <td>0.440931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210000</td>\n",
       "      <td>0.460700</td>\n",
       "      <td>0.442112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215000</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.441925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220000</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.438437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225000</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.446992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230000</td>\n",
       "      <td>0.455600</td>\n",
       "      <td>0.440015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235000</td>\n",
       "      <td>0.456100</td>\n",
       "      <td>0.439708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240000</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.436344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>245000</td>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.443541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250000</td>\n",
       "      <td>0.453400</td>\n",
       "      <td>0.441517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>255000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>0.439069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260000</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.440050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>265000</td>\n",
       "      <td>0.453200</td>\n",
       "      <td>0.433561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270000</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.430289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>275000</td>\n",
       "      <td>0.448600</td>\n",
       "      <td>0.423986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280000</td>\n",
       "      <td>0.450600</td>\n",
       "      <td>0.425459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>285000</td>\n",
       "      <td>0.453100</td>\n",
       "      <td>0.428166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290000</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>0.428949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295000</td>\n",
       "      <td>0.450100</td>\n",
       "      <td>0.431953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300000</td>\n",
       "      <td>0.446300</td>\n",
       "      <td>0.428949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>305000</td>\n",
       "      <td>0.445100</td>\n",
       "      <td>0.430002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310000</td>\n",
       "      <td>0.447500</td>\n",
       "      <td>0.440195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>315000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>0.437651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320000</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.429212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>325000</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>0.429535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330000</td>\n",
       "      <td>0.441600</td>\n",
       "      <td>0.434847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335000</td>\n",
       "      <td>0.445800</td>\n",
       "      <td>0.434933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340000</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.420742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>345000</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.425906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350000</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>0.418538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355000</td>\n",
       "      <td>0.438200</td>\n",
       "      <td>0.425185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360000</td>\n",
       "      <td>0.439300</td>\n",
       "      <td>0.424571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>365000</td>\n",
       "      <td>0.439800</td>\n",
       "      <td>0.437777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370000</td>\n",
       "      <td>0.442300</td>\n",
       "      <td>0.430003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>375000</td>\n",
       "      <td>0.439500</td>\n",
       "      <td>0.429258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380000</td>\n",
       "      <td>0.441400</td>\n",
       "      <td>0.430714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>385000</td>\n",
       "      <td>0.441200</td>\n",
       "      <td>0.430327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390000</td>\n",
       "      <td>0.439700</td>\n",
       "      <td>0.427048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395000</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>0.420549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400000</td>\n",
       "      <td>0.437100</td>\n",
       "      <td>0.425671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>405000</td>\n",
       "      <td>0.433400</td>\n",
       "      <td>0.428704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410000</td>\n",
       "      <td>0.434800</td>\n",
       "      <td>0.432110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>415000</td>\n",
       "      <td>0.434500</td>\n",
       "      <td>0.420009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420000</td>\n",
       "      <td>0.439600</td>\n",
       "      <td>0.425964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>425000</td>\n",
       "      <td>0.435300</td>\n",
       "      <td>0.424213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430000</td>\n",
       "      <td>0.434200</td>\n",
       "      <td>0.421451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435000</td>\n",
       "      <td>0.431600</td>\n",
       "      <td>0.417671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440000</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.431468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>445000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.422413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450000</td>\n",
       "      <td>0.433500</td>\n",
       "      <td>0.422071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>455000</td>\n",
       "      <td>0.432700</td>\n",
       "      <td>0.416250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460000</td>\n",
       "      <td>0.430700</td>\n",
       "      <td>0.421578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>465000</td>\n",
       "      <td>0.431400</td>\n",
       "      <td>0.421426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470000</td>\n",
       "      <td>0.428600</td>\n",
       "      <td>0.413129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>475000</td>\n",
       "      <td>0.430000</td>\n",
       "      <td>0.412760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480000</td>\n",
       "      <td>0.432100</td>\n",
       "      <td>0.420053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>485000</td>\n",
       "      <td>0.427600</td>\n",
       "      <td>0.420866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490000</td>\n",
       "      <td>0.430600</td>\n",
       "      <td>0.415886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>495000</td>\n",
       "      <td>0.425600</td>\n",
       "      <td>0.417251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500000</td>\n",
       "      <td>0.428100</td>\n",
       "      <td>0.422666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505000</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.422630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510000</td>\n",
       "      <td>0.425500</td>\n",
       "      <td>0.421380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515000</td>\n",
       "      <td>0.428700</td>\n",
       "      <td>0.411946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520000</td>\n",
       "      <td>0.426300</td>\n",
       "      <td>0.412199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525000</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.411717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530000</td>\n",
       "      <td>0.423100</td>\n",
       "      <td>0.414693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535000</td>\n",
       "      <td>0.427200</td>\n",
       "      <td>0.430568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540000</td>\n",
       "      <td>0.426000</td>\n",
       "      <td>0.413377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>545000</td>\n",
       "      <td>0.422800</td>\n",
       "      <td>0.409158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.417011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>555000</td>\n",
       "      <td>0.422600</td>\n",
       "      <td>0.414781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560000</td>\n",
       "      <td>0.426200</td>\n",
       "      <td>0.413208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565000</td>\n",
       "      <td>0.421100</td>\n",
       "      <td>0.408670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570000</td>\n",
       "      <td>0.422900</td>\n",
       "      <td>0.415287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>575000</td>\n",
       "      <td>0.421200</td>\n",
       "      <td>0.405820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.416382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585000</td>\n",
       "      <td>0.420200</td>\n",
       "      <td>0.410429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590000</td>\n",
       "      <td>0.418500</td>\n",
       "      <td>0.415651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>595000</td>\n",
       "      <td>0.418600</td>\n",
       "      <td>0.412002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.411084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>605000</td>\n",
       "      <td>0.419800</td>\n",
       "      <td>0.411705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610000</td>\n",
       "      <td>0.419300</td>\n",
       "      <td>0.410038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>615000</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.395576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620000</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.407436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625000</td>\n",
       "      <td>0.413500</td>\n",
       "      <td>0.405912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630000</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.407204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>635000</td>\n",
       "      <td>0.416800</td>\n",
       "      <td>0.406550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640000</td>\n",
       "      <td>0.415300</td>\n",
       "      <td>0.409920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>645000</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.407701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650000</td>\n",
       "      <td>0.414800</td>\n",
       "      <td>0.404710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>655000</td>\n",
       "      <td>0.418000</td>\n",
       "      <td>0.405720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660000</td>\n",
       "      <td>0.411000</td>\n",
       "      <td>0.406502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>665000</td>\n",
       "      <td>0.410700</td>\n",
       "      <td>0.413940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670000</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.404338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>675000</td>\n",
       "      <td>0.415900</td>\n",
       "      <td>0.394248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680000</td>\n",
       "      <td>0.414600</td>\n",
       "      <td>0.400726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>685000</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>0.411484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690000</td>\n",
       "      <td>0.411300</td>\n",
       "      <td>0.402042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695000</td>\n",
       "      <td>0.411600</td>\n",
       "      <td>0.400131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700000</td>\n",
       "      <td>0.412600</td>\n",
       "      <td>0.410845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>705000</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.404425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710000</td>\n",
       "      <td>0.409500</td>\n",
       "      <td>0.406843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>715000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.407828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720000</td>\n",
       "      <td>0.408600</td>\n",
       "      <td>0.407664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>725000</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.396433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730000</td>\n",
       "      <td>0.406900</td>\n",
       "      <td>0.404904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>735000</td>\n",
       "      <td>0.409200</td>\n",
       "      <td>0.388833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740000</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>0.396826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>745000</td>\n",
       "      <td>0.410300</td>\n",
       "      <td>0.399645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750000</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.401893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>755000</td>\n",
       "      <td>0.404600</td>\n",
       "      <td>0.405997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760000</td>\n",
       "      <td>0.407300</td>\n",
       "      <td>0.407346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>765000</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.403501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770000</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>0.391429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>775000</td>\n",
       "      <td>0.405500</td>\n",
       "      <td>0.391855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780000</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>0.395830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>785000</td>\n",
       "      <td>0.405700</td>\n",
       "      <td>0.389942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790000</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.395027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>795000</td>\n",
       "      <td>0.399900</td>\n",
       "      <td>0.407210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800000</td>\n",
       "      <td>0.403200</td>\n",
       "      <td>0.399457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>805000</td>\n",
       "      <td>0.397700</td>\n",
       "      <td>0.396912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810000</td>\n",
       "      <td>0.399800</td>\n",
       "      <td>0.391845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>815000</td>\n",
       "      <td>0.402200</td>\n",
       "      <td>0.402488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820000</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>0.391498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>825000</td>\n",
       "      <td>0.398800</td>\n",
       "      <td>0.394709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830000</td>\n",
       "      <td>0.395100</td>\n",
       "      <td>0.394606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>835000</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.395655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840000</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845000</td>\n",
       "      <td>0.396700</td>\n",
       "      <td>0.398778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850000</td>\n",
       "      <td>0.399400</td>\n",
       "      <td>0.396696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>855000</td>\n",
       "      <td>0.395300</td>\n",
       "      <td>0.391854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860000</td>\n",
       "      <td>0.399600</td>\n",
       "      <td>0.396499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>865000</td>\n",
       "      <td>0.398600</td>\n",
       "      <td>0.394282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870000</td>\n",
       "      <td>0.398300</td>\n",
       "      <td>0.391666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>875000</td>\n",
       "      <td>0.394500</td>\n",
       "      <td>0.387137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880000</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.389226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>885000</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.412535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890000</td>\n",
       "      <td>0.398200</td>\n",
       "      <td>0.391757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>895000</td>\n",
       "      <td>0.395700</td>\n",
       "      <td>0.398781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900000</td>\n",
       "      <td>0.395400</td>\n",
       "      <td>0.385392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>905000</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.395335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910000</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.386124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>915000</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.394036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920000</td>\n",
       "      <td>0.391700</td>\n",
       "      <td>0.389702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>925000</td>\n",
       "      <td>0.389800</td>\n",
       "      <td>0.391625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930000</td>\n",
       "      <td>0.392700</td>\n",
       "      <td>0.391225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935000</td>\n",
       "      <td>0.394400</td>\n",
       "      <td>0.393396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000/tokenizer_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-95000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-145000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-150000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-155000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-160000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-165000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-170000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-175000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-180000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-185000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-190000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-195000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-200000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-205000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-210000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-215000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-220000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-225000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-230000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-235000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-240000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-245000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-250000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-255000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-260000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-265000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-270000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-275000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-280000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-285000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-290000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-295000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-300000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-305000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-310000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-315000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-320000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-325000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-330000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-335000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-340000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-345000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-350000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-355000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-360000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-365000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-370000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-375000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-380000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-385000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-390000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-395000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-400000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-405000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-410000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-415000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-420000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-425000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-430000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-435000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-440000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-445000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-450000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-455000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-460000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-465000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-470000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-475000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-480000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-485000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-490000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-495000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-500000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-505000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-510000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-515000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-520000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-525000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-530000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-535000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-540000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-545000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-550000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-555000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-560000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-565000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-570000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-575000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-580000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-585000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-590000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-595000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-600000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-605000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-610000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-615000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-620000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-625000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-630000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-635000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-640000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-645000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-650000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-655000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-660000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-665000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-670000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-675000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-680000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-685000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-690000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-695000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-700000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-705000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-710000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-715000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-720000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-725000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-730000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-735000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-740000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-745000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-750000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-755000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-760000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-765000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-770000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-775000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-780000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-785000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-790000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-795000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-800000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-805000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-810000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-815000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-820000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-825000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-830000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-835000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-840000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-845000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-850000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-855000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-860000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-865000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-870000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-875000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-880000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-885000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-890000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-895000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-900000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-905000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-910000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-915000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-930000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-930000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-930000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-930000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-930000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-920000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-935000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-935000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-935000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-935000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-935000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_3/checkpoint-925000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▅▅▄▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂▁▁▁▂▁▁▁▁▁▂▂▁▂▂▃▃▂▂▂▂▃▃▆▃▃▂▃▃▇▄▅▃▄▄▅▅█▆</td></tr><tr><td>eval/samples_per_second</td><td>▇▇███▇███▇█▇▇█▇▇▆▆▇▇▇▇▆▆▃▆▆▇▆▆▂▅▄▆▅▅▄▄▁▃</td></tr><tr><td>eval/steps_per_second</td><td>▇▇███▇███▇█▇▇█▇▇▆▆▇▇▇▇▆▆▃▆▆▇▆▆▂▅▄▆▅▅▄▄▁▃</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▅▄▄▄▃▃▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.3934</td></tr><tr><td>eval/runtime</td><td>16.324</td></tr><tr><td>eval/samples_per_second</td><td>3062.981</td></tr><tr><td>eval/steps_per_second</td><td>47.905</td></tr><tr><td>train/epoch</td><td>30.0</td></tr><tr><td>train/global_step</td><td>937500</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.3944</td></tr><tr><td>train/total_flos</td><td>2.0046820365596544e+16</td></tr><tr><td>train/train_loss</td><td>0.44239</td></tr><tr><td>train/train_runtime</td><td>69116.9938</td></tr><tr><td>train/train_samples_per_second</td><td>868.093</td></tr><tr><td>train/train_steps_per_second</td><td>13.564</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">run 3</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/2jq8x72g\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/Bigram%20POS%20MLM%20CoreNLP/runs/2jq8x72g</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230128_125821-2jq8x72g/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 2000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 256\n",
    "hidden_size = 128\n",
    "num_attention_heads = 4\n",
    "intermediate_size = 512\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 30\n",
    "batchsize = 64\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [4, 6]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4, 8e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_bigram_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_pos_bigram_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/bigram_pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"Bigram POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'run {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df19ea3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
