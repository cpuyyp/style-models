{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from transformers import PreTrainedTokenizer, PreTrainedTokenizerFast\n",
    "from transformers import BertForMaskedLM, BertConfig\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "from nltk.parse.corenlp import CoreNLPParser, CoreNLPDependencyParser\n",
    "from nltk.tag.hunpos import HunposTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "import stanza\n",
    "import nltk\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from numerize import numerize\n",
    "import wandb\n",
    "import os \n",
    "import typing\n",
    "import tokenizers\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86bce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = stanza.Pipeline(lang='en', processors='tokenize,pos')\n",
    "pos_tagger = CoreNLPParser(url='http://localhost:9000', tagtype='pos')\n",
    "# ht = HunposTagger('/home/jz17d/bin/english.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e1a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://emorynlp.github.io/nlp4j/components/part-of-speech-tagging.html\n",
    "corenlp_vocab = '''$ \tDollar \t1.0.0\n",
    ": \tColon \t1.0.0\n",
    ", \tComma \t1.0.0\n",
    ". \tPeriod \t1.0.0\n",
    "`` \tLeft quote \t1.0.0\n",
    "'' \tRight quote \t1.0.0\n",
    "-LRB- \tLeft bracket \t1.0.0\n",
    "-RRB- \tRight bracket \t1.0.0\n",
    "ADD \tEmail \t1.0.0\n",
    "AFX \tAffix \t1.0.0\n",
    "CC \tCoordinating conjunction \t1.0.0\n",
    "CD \tCardinal number \t1.0.0\n",
    "DT \tDeterminer \t1.0.0\n",
    "EX \tExistential there \t1.0.0\n",
    "FW \tForeign word \t1.0.0\n",
    "GW \tGo with \t1.0.0\n",
    "HYPH \tHyphen \t1.0.0\n",
    "IN \tPreposition or subordinating conjunction \t1.0.0\n",
    "JJ \tAdjective \t1.0.0\n",
    "JJR \tAdjective, comparative \t1.0.0\n",
    "JJS \tAdjective, superlative \t1.0.0\n",
    "LS \tList item marker \t1.0.0\n",
    "MD \tModal \t1.0.0\n",
    "NFP \tSuperfluous punctuation \t1.0.0\n",
    "NN \tNoun, singular or mass \t1.0.0\n",
    "NNS \tNoun, plural \t1.0.0\n",
    "NNP \tProper noun, singular \t1.0.0\n",
    "NNPS \tProper noun, plural \t1.0.0\n",
    "PDT \tPredeterminer \t1.0.0\n",
    "POS \tPossessive ending \t1.0.0\n",
    "PRP \tPersonal pronoun \t1.0.0\n",
    "PRP$ \tPossessive pronoun \t1.0.0\n",
    "RB \tAdverb \t1.0.0\n",
    "RBR \tAdverb, comparative \t1.0.0\n",
    "RBS \tAdverb, superlative \t1.0.0\n",
    "RP \tParticle \t1.0.0\n",
    "SYM \tSymbol \t1.0.0\n",
    "TO \tTo \t1.0.0\n",
    "UH \tInterjection \t1.0.0\n",
    "VB \tVerb, base form \t1.0.0\n",
    "VBD \tVerb, past tense \t1.0.0\n",
    "VBG \tVerb, gerund or present participle \t1.0.0\n",
    "VBN \tVerb, past participle \t1.0.0\n",
    "VBP \tVerb, non-3rd person singular present \t1.0.0\n",
    "VBZ \tVerb, 3rd person singular present \t1.0.0\n",
    "WDT \tWh-determiner \t1.0.0\n",
    "WP \tWh-pronoun \t1.0.0\n",
    "WP$ \tWh-pronoun, possessive \t1.0.0\n",
    "WRB \tWh-adverb \t1.0.0\n",
    "XX'''.split('\\n')\n",
    "for i in range(len(corenlp_vocab)):\n",
    "    corenlp_vocab[i] = corenlp_vocab[i].split('\\t')[0].strip()\n",
    "num_xpos_tokens = len(corenlp_vocab)\n",
    "corenlp_token2id = {corenlp_vocab[i]:i for i in range(num_xpos_tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c5f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagset \n",
    "def get_pos_vocab(tagger, tagset='xpos'):\n",
    "    if tagset == 'upos':\n",
    "        assert tagger == 'stanza', 'only stanza support upos'\n",
    "    # the full list of upos tokens\n",
    "    upos_vocab = ['ADJ',\n",
    "                'ADP',\n",
    "                'ADV',\n",
    "                'AUX',\n",
    "                'CCONJ',\n",
    "                'DET',\n",
    "                'INTJ',\n",
    "                'NOUN',\n",
    "                'NUM',\n",
    "                'PART',\n",
    "                'PRON',\n",
    "                'PROPN',\n",
    "                'PUNCT',\n",
    "                'SCONJ',\n",
    "                'SYM',\n",
    "                'VERB',\n",
    "                'X']\n",
    "    # if use the simple conversion, upos vocab is smaller\n",
    "#     upos_vocab = ['ADJ',\n",
    "#                  'ADP',\n",
    "#                  'ADV',\n",
    "#                  'CCONJ',\n",
    "#                  'DET',\n",
    "#                  'INTJ',\n",
    "#                  'NOUN',\n",
    "#                  'NUM',\n",
    "#                  'PART',\n",
    "#                  'PRON',\n",
    "#                  'PROPN',\n",
    "#                  'PUNCT',\n",
    "#                  'SYM',\n",
    "#                  'VERB',\n",
    "#                  'X']\n",
    "\n",
    "    from nltk.data import load\n",
    "    tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
    "\n",
    "    xpos_vocab = list(tagdict.keys())\n",
    "    if tagger == 'corenlp':\n",
    "        xpos_vocab = corenlp_vocab\n",
    "    xpos_vocab = sorted(xpos_vocab)\n",
    "    if tagset=='xpos':\n",
    "        return xpos_vocab\n",
    "    else:\n",
    "        return upos_vocab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e74274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stanza_tagging(examples, tag_set='xpos'): # stanza\n",
    "    all_upos = []\n",
    "    all_xpos = []\n",
    "    for text in examples['text']:\n",
    "        doc = nlp(text)\n",
    "        upos = []\n",
    "        xpos = []\n",
    "        for sentence in doc.sentences:\n",
    "            for word in sentence.words:\n",
    "                upos.append(word.upos)\n",
    "                xpos.append(word.xpos)  \n",
    "        all_upos.append(' '.join(upos))   \n",
    "        all_xpos.append(' '.join(xpos))   \n",
    "    if tag_set == 'upos':\n",
    "        return tokenizer(all_upos, truncation=True) \n",
    "    else:\n",
    "        return tokenizer(all_xpos, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23020480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hunpos_tagging(examples): # hunpos\n",
    "    xpos = []\n",
    "    for sentence in examples['text']:\n",
    "        tagged = ht.tag(word_tokenize(sentence))\n",
    "        pos = []\n",
    "        for word in tagged:\n",
    "            pos.append(word[1].decode('utf-8'))\n",
    "        xpos.append(' '.join(pos))\n",
    "    return tokenizer(xpos, truncation=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a36bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corenlp_tagging(examples): # corenlp\n",
    "    xpos = []\n",
    "    tagged = list(pos_tagger.raw_tag_sents(examples['text']))\n",
    "    for sentence in tagged:\n",
    "        pos = []\n",
    "        for word in sentence[0]:\n",
    "            pos.append(word[1])\n",
    "        xpos.append(' '.join(pos))\n",
    "    return tokenizer(xpos, truncation=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9688d254",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger2func = {'stanza': stanza_tagging,\n",
    "               'hunpos': hunpos_tagging,\n",
    "               'corenlp': corenlp_tagging,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f25421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(vocab, model_max_length = 128):\n",
    "    # Tokenizer is from tokenizers package. PreTrainedTokenizerFast is from tranformers package.\n",
    "    # PreTrainedTokenizerFast can load vocab saved/trained by Tokenizer\n",
    "    t = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "    t.pre_tokenizer = Whitespace()\n",
    "    t.add_special_tokens([\"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\", \"[UNK]\",])\n",
    "\n",
    "    t.add_tokens(vocab) \n",
    "#     trainer makes \"-LRB-\" 3 tokens\n",
    "#     trainer = WordLevelTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "#     data = [' '.join(vocab)]\n",
    "#     t.train_from_iterator(data, trainer=trainer)\n",
    "\n",
    "    t.post_processor = TemplateProcessing(\n",
    "        single=\"[CLS] $A [SEP]\",\n",
    "        pair=\"[CLS] $A [SEP] $B:1 [SEP]:1\",\n",
    "        special_tokens=[\n",
    "            (\"[CLS]\", t.token_to_id(\"[CLS]\")),\n",
    "            (\"[SEP]\", t.token_to_id(\"[SEP]\")),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    t.enable_padding(pad_id=t.token_to_id(\"[PAD]\"), pad_token=\"[PAD]\")\n",
    "    t.enable_truncation(max_length=model_max_length)\n",
    "    t.save('/home/jz17d/Desktop/pos_tokenizer.json')\n",
    "\n",
    "    tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/home/jz17d/Desktop/pos_tokenizer.json\", unk_token=\"[UNK]\")\n",
    "    tokenizer.pad_token = '[PAD]'\n",
    "    tokenizer.mask_token = '[MASK]'\n",
    "    tokenizer.unk_token = '[UNK]'\n",
    "    special_tokens = {\n",
    "         \"unk_token\": \"[UNK]\",\n",
    "         \"sep_token\": \"[SEP]\",\n",
    "         \"pad_token\": \"[PAD]\",\n",
    "         \"cls_token\": \"[CLS]\",\n",
    "         \"mask_token\": \"[MASK]\" }\n",
    "    tokenizer.add_special_tokens(special_tokens)\n",
    "    # tokenizer.add_special_tokens({'unk_token':'[UNK]'})\n",
    "    tokenizer.model_max_length=model_max_length\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea44c5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_ppl(model, input_ids, stride=128, max_length=128):\n",
    "#     '''\n",
    "#     Example from https://huggingface.co/docs/transformers/perplexity\n",
    "#     '''\n",
    "#     seq_len = input_ids.size(1)\n",
    "#     nlls = []\n",
    "#     prev_end_loc = 0\n",
    "#     for begin_loc in range(0, seq_len, stride):\n",
    "#         end_loc = min(begin_loc + max_length, seq_len)\n",
    "#         trg_len = end_loc - prev_end_loc  # may be different from stride on last loop\n",
    "#         curr_input_ids = input_ids[:, begin_loc:end_loc].to(device)\n",
    "#         target_ids = curr_input_ids.clone()\n",
    "#         target_ids[:, :-trg_len] = -100\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             outputs = model(curr_input_ids, labels=target_ids)\n",
    "#             # loss is calculated using CrossEntropyLoss which averages over input tokens.\n",
    "#             # Multiply it with trg_len to get the summation instead of average.\n",
    "#             # We will take average over all the tokens to get the true average\n",
    "#             # in the last step of this example.\n",
    "#             neg_log_likelihood = outputs.loss * trg_len\n",
    "\n",
    "#         nlls.append(neg_log_likelihood)\n",
    "\n",
    "#         prev_end_loc = end_loc\n",
    "#         if end_loc == seq_len:\n",
    "#             break\n",
    "#     ppl = torch.exp(torch.stack(nlls).sum() / end_loc)\n",
    "#     return ppl.cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa84910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset bookcorpus (/scratch/data_jz17d/hf_datasets_cache/bookcorpus/plain_text/1.0.0/eddee3cae1cc263a431aa98207d4d27fd8a73b0a9742f692af0e6c65afa4d75f)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1011447ec97044a69a88a3cf61275cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load raw bookcorpus dataset\n",
    "os.environ['HF_DATASETS_CACHE'] = '/scratch/data_jz17d/hf_datasets_cache'\n",
    "dataset = load_dataset(\"bookcorpus\", cache_dir=\"/scratch/data_jz17d/hf_datasets_cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcaa5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be4259a37594027882c90aa2bdb9f94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reprocess corenlp with correct tag list \n",
    "tagger = 'corenlp'\n",
    "tagset = 'xpos'\n",
    "reprocess = True\n",
    "select = 1000000\n",
    "model_max_length = 128\n",
    "\n",
    "vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    tagging_func = tagger2func[tagger]\n",
    "    trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "    trainset.save_to_disk(cache_location)\n",
    "else:\n",
    "    trainset = load_from_disk(cache_location)\n",
    "trainset = trainset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f198745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4aedd7b70c34e07b68989a806d554ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reprocess = True\n",
    "select2 = range(select,select+50000)\n",
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "if not os.path.exists(cache_location) or reprocess:\n",
    "    tagging_func = tagger2func[tagger]\n",
    "    testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "    testset.save_to_disk(cache_location)\n",
    "else:\n",
    "    testset = load_from_disk(cache_location)\n",
    "testset = testset.remove_columns(['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2079c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85807bcba2784e65b77a11e24c05d40a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2eesmz6z) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2eesmz6z\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2eesmz6z</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_110955-2eesmz6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:2eesmz6z). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbcd193423041e58c01cb800c06218c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.033339222272237144, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_111035-2dei7y98</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98\" target=\"_blank\">pos mlm 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:43:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.691900</td>\n",
       "      <td>2.283304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.350500</td>\n",
       "      <td>2.093428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.220300</td>\n",
       "      <td>1.927104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.098500</td>\n",
       "      <td>1.765798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.998800</td>\n",
       "      <td>1.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.919500</td>\n",
       "      <td>1.577371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.851400</td>\n",
       "      <td>1.513302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.782000</td>\n",
       "      <td>1.456283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.725400</td>\n",
       "      <td>1.432919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.691200</td>\n",
       "      <td>1.405770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.658800</td>\n",
       "      <td>1.381955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.631400</td>\n",
       "      <td>1.376401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.610300</td>\n",
       "      <td>1.361557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.589500</td>\n",
       "      <td>1.350170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.575100</td>\n",
       "      <td>1.340339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.564300</td>\n",
       "      <td>1.332251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.556300</td>\n",
       "      <td>1.333331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.547000</td>\n",
       "      <td>1.327982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.540100</td>\n",
       "      <td>1.320817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.534200</td>\n",
       "      <td>1.321154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.530500</td>\n",
       "      <td>1.322502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.524100</td>\n",
       "      <td>1.317376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.520900</td>\n",
       "      <td>1.315069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.515200</td>\n",
       "      <td>1.300987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.312259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.514100</td>\n",
       "      <td>1.308862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.510100</td>\n",
       "      <td>1.301800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.508600</td>\n",
       "      <td>1.300892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.505500</td>\n",
       "      <td>1.297899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.505700</td>\n",
       "      <td>1.303157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.507600</td>\n",
       "      <td>1.299217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_0/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▄▃▃▃█▄▂▆▅▃▁▁▂▁▁▅▅▂▂▂▁▁▁▄▆▃▁▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▅▆▆▆▁▅▇▃▄▆██▇██▄▄▇▇▇▇██▅▃▆█▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▅▆▆▆▁▅▇▃▄▆██▇██▄▄▇▇▇▇██▅▃▆█▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.29922</td></tr><tr><td>eval/runtime</td><td>13.5053</td></tr><tr><td>eval/samples_per_second</td><td>3702.238</td></tr><tr><td>eval/steps_per_second</td><td>28.952</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.5076</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.7014</td></tr><tr><td>train/train_runtime</td><td>9835.0244</td></tr><tr><td>train/train_samples_per_second</td><td>2033.549</td></tr><tr><td>train/train_steps_per_second</td><td>15.888</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2dei7y98</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_111035-2dei7y98/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_135449-1pfrep5j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j\" target=\"_blank\">pos mlm 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:52:06, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>1.507956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.616400</td>\n",
       "      <td>1.357430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.513700</td>\n",
       "      <td>1.312450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.467100</td>\n",
       "      <td>1.288372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.440900</td>\n",
       "      <td>1.275900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.426100</td>\n",
       "      <td>1.259849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.410500</td>\n",
       "      <td>1.246999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.404300</td>\n",
       "      <td>1.244564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.391900</td>\n",
       "      <td>1.245173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.387800</td>\n",
       "      <td>1.242039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.382800</td>\n",
       "      <td>1.223743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.379100</td>\n",
       "      <td>1.235590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.226788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.368300</td>\n",
       "      <td>1.225584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.364900</td>\n",
       "      <td>1.218081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.364300</td>\n",
       "      <td>1.218443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.362400</td>\n",
       "      <td>1.223904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.358700</td>\n",
       "      <td>1.219311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.357300</td>\n",
       "      <td>1.210993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.353700</td>\n",
       "      <td>1.213950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.354000</td>\n",
       "      <td>1.217250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.350500</td>\n",
       "      <td>1.213361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.348500</td>\n",
       "      <td>1.212676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.347200</td>\n",
       "      <td>1.201242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.346600</td>\n",
       "      <td>1.210703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.347000</td>\n",
       "      <td>1.205936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.344200</td>\n",
       "      <td>1.200450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.342200</td>\n",
       "      <td>1.202423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.340000</td>\n",
       "      <td>1.196322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.340100</td>\n",
       "      <td>1.203914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.342100</td>\n",
       "      <td>1.199652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-65000] due to args.save_total_limit\n",
      "wandb: Network error (ReadTimeout), entering retry loop.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_1/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▄▄▆█▅▇▁▁▅▃▅▆▅▅▆▂▂▁▂▂▁▆▁▂▂▂▅▂▂▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▅▅▃▁▄▂██▄▆▄▃▄▄▃▇▇█▇▇█▃█▇▇▇▄▇▇▇█</td></tr><tr><td>eval/steps_per_second</td><td>▅▅▃▁▄▂██▄▆▄▃▄▄▃▇▇█▇▇█▃█▇▇▇▄▇▇▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.19965</td></tr><tr><td>eval/runtime</td><td>13.5082</td></tr><tr><td>eval/samples_per_second</td><td>3701.468</td></tr><tr><td>eval/steps_per_second</td><td>28.945</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3421</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.41094</td></tr><tr><td>train/train_runtime</td><td>10326.7383</td></tr><tr><td>train/train_samples_per_second</td><td>1936.72</td></tr><tr><td>train/train_steps_per_second</td><td>15.132</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1pfrep5j</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_135449-1pfrep5j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_164709-2t67ykkt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt\" target=\"_blank\">pos mlm 2</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 2:45:07, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.002900</td>\n",
       "      <td>1.378969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.530800</td>\n",
       "      <td>1.325399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.474900</td>\n",
       "      <td>1.290930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.442000</td>\n",
       "      <td>1.270840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.422900</td>\n",
       "      <td>1.261166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.412000</td>\n",
       "      <td>1.249452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.400300</td>\n",
       "      <td>1.234677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.396200</td>\n",
       "      <td>1.234411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.386000</td>\n",
       "      <td>1.239756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.383100</td>\n",
       "      <td>1.231708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.378400</td>\n",
       "      <td>1.218516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.374200</td>\n",
       "      <td>1.227519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.371000</td>\n",
       "      <td>1.221422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.366400</td>\n",
       "      <td>1.219766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.362400</td>\n",
       "      <td>1.213243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.361500</td>\n",
       "      <td>1.212827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.360300</td>\n",
       "      <td>1.216861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.356700</td>\n",
       "      <td>1.215684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.354900</td>\n",
       "      <td>1.203871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.351600</td>\n",
       "      <td>1.205807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.350700</td>\n",
       "      <td>1.212221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.347500</td>\n",
       "      <td>1.207736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.345900</td>\n",
       "      <td>1.207615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.343600</td>\n",
       "      <td>1.195014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.343200</td>\n",
       "      <td>1.205048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.342400</td>\n",
       "      <td>1.199801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.339200</td>\n",
       "      <td>1.194750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.338000</td>\n",
       "      <td>1.196007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.334900</td>\n",
       "      <td>1.190289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.334900</td>\n",
       "      <td>1.196634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.336800</td>\n",
       "      <td>1.192421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_2/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▃▃██▆▂▄▃▂▁▃▁▅▃▂▇▅▅▁▆▂▄▂▃▄▇▃▁▄▄</td></tr><tr><td>eval/samples_per_second</td><td>▆▆▆▁▁▃▆▅▆▇▇▆█▄▆▇▂▄▄█▃▇▅▇▆▅▂▆█▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▆▆▁▁▃▆▅▆▇▇▆█▄▆▇▂▄▄█▃▇▅▇▆▅▂▆█▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.19242</td></tr><tr><td>eval/runtime</td><td>13.7237</td></tr><tr><td>eval/samples_per_second</td><td>3643.345</td></tr><tr><td>eval/steps_per_second</td><td>28.491</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.3368</td></tr><tr><td>train/total_flos</td><td>181982190094848.0</td></tr><tr><td>train/train_loss</td><td>1.39454</td></tr><tr><td>train/train_runtime</td><td>9907.5017</td></tr><tr><td>train/train_samples_per_second</td><td>2018.672</td></tr><tr><td>train/train_steps_per_second</td><td>15.772</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 2</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2t67ykkt</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_164709-2t67ykkt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_193229-1qb9z6gl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl\" target=\"_blank\">pos mlm 3</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:57:25, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.696200</td>\n",
       "      <td>2.284791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.326600</td>\n",
       "      <td>2.024099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.162900</td>\n",
       "      <td>1.842095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.039900</td>\n",
       "      <td>1.693693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.931300</td>\n",
       "      <td>1.583185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.840400</td>\n",
       "      <td>1.508486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.774100</td>\n",
       "      <td>1.463975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.733400</td>\n",
       "      <td>1.437089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.695300</td>\n",
       "      <td>1.418838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.664100</td>\n",
       "      <td>1.396953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.625900</td>\n",
       "      <td>1.362829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.597300</td>\n",
       "      <td>1.362430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.577100</td>\n",
       "      <td>1.345369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.556500</td>\n",
       "      <td>1.340125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.544400</td>\n",
       "      <td>1.329006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.533900</td>\n",
       "      <td>1.322145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.524600</td>\n",
       "      <td>1.323571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.515800</td>\n",
       "      <td>1.317697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.508300</td>\n",
       "      <td>1.309377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.501300</td>\n",
       "      <td>1.309991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.496700</td>\n",
       "      <td>1.311114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>1.309142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.486500</td>\n",
       "      <td>1.302536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.482500</td>\n",
       "      <td>1.290455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.479700</td>\n",
       "      <td>1.301674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.478800</td>\n",
       "      <td>1.298783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.474800</td>\n",
       "      <td>1.290145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.473100</td>\n",
       "      <td>1.291290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.470400</td>\n",
       "      <td>1.287500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.470000</td>\n",
       "      <td>1.294184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.472700</td>\n",
       "      <td>1.290210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_3/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>█▆▆▄▃▄▄▄▆▅▄▅▃▃▅▇▃▃▃▃▄▇▄▃▂█▆▄▃▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▃▃▅▆▅▅▄▃▄▅▄▆▆▄▂▆▆▆▆▅▂▅▆▆▁▃▅▆▇█</td></tr><tr><td>eval/steps_per_second</td><td>▁▃▃▅▆▅▅▄▃▄▅▄▆▆▄▂▆▆▆▆▅▂▅▆▆▁▃▅▆▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.29021</td></tr><tr><td>eval/runtime</td><td>14.0638</td></tr><tr><td>eval/samples_per_second</td><td>3555.218</td></tr><tr><td>eval/steps_per_second</td><td>27.802</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.4727</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.66373</td></tr><tr><td>train/train_runtime</td><td>14245.3032</td></tr><tr><td>train/train_samples_per_second</td><td>1403.972</td></tr><tr><td>train/train_steps_per_second</td><td>10.969</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 3</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1qb9z6gl</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_193229-1qb9z6gl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_233006-1vmxpi8y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y\" target=\"_blank\">pos mlm 4</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:14:38, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.242100</td>\n",
       "      <td>1.600359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.717800</td>\n",
       "      <td>1.378072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.535000</td>\n",
       "      <td>1.315400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.468100</td>\n",
       "      <td>1.282308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.431800</td>\n",
       "      <td>1.262799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.412000</td>\n",
       "      <td>1.247404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.392700</td>\n",
       "      <td>1.227851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.382500</td>\n",
       "      <td>1.226134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.369200</td>\n",
       "      <td>1.226744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.363600</td>\n",
       "      <td>1.219057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.355700</td>\n",
       "      <td>1.204390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.350400</td>\n",
       "      <td>1.211484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.344800</td>\n",
       "      <td>1.204477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.338700</td>\n",
       "      <td>1.204433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.334100</td>\n",
       "      <td>1.194529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.332000</td>\n",
       "      <td>1.194333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.329900</td>\n",
       "      <td>1.200817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.325300</td>\n",
       "      <td>1.192896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.323200</td>\n",
       "      <td>1.185678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.320100</td>\n",
       "      <td>1.186128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.317900</td>\n",
       "      <td>1.192829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.314500</td>\n",
       "      <td>1.188919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.312300</td>\n",
       "      <td>1.187458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.309500</td>\n",
       "      <td>1.174109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.183862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.309100</td>\n",
       "      <td>1.179524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.304100</td>\n",
       "      <td>1.173911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.304300</td>\n",
       "      <td>1.176781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.302200</td>\n",
       "      <td>1.169905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.301700</td>\n",
       "      <td>1.176751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.303200</td>\n",
       "      <td>1.172170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_4/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▄▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▂▂▂▂▂▂▂▂▁▂▂▂▂▂▅▃▃▃▃▃█▃▃▃█▃▃▁▁▂</td></tr><tr><td>eval/samples_per_second</td><td>▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▄▆▆▆▆▆▁▆▆▆▁▆▆██▇</td></tr><tr><td>eval/steps_per_second</td><td>▅▇▆▇▇▇▇▇▇▇▇▇▇▇▇▄▆▆▆▆▆▁▆▆▆▁▆▆██▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.17217</td></tr><tr><td>eval/runtime</td><td>14.1117</td></tr><tr><td>eval/samples_per_second</td><td>3543.147</td></tr><tr><td>eval/steps_per_second</td><td>27.707</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.3032</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.38826</td></tr><tr><td>train/train_runtime</td><td>11678.8877</td></tr><tr><td>train/train_samples_per_second</td><td>1712.492</td></tr><tr><td>train/train_steps_per_second</td><td>13.38</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 4</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/1vmxpi8y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221108_233006-1vmxpi8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_024458-287qxgaa</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa\" target=\"_blank\">pos mlm 5</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:43:49, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.072800</td>\n",
       "      <td>1.410241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.546300</td>\n",
       "      <td>1.308700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.449100</td>\n",
       "      <td>1.265374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.402100</td>\n",
       "      <td>1.245277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.377300</td>\n",
       "      <td>1.233929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.363700</td>\n",
       "      <td>1.221093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.349500</td>\n",
       "      <td>1.200732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.344200</td>\n",
       "      <td>1.203284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.333700</td>\n",
       "      <td>1.203784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.329400</td>\n",
       "      <td>1.199546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.323400</td>\n",
       "      <td>1.185081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.319700</td>\n",
       "      <td>1.195089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.315800</td>\n",
       "      <td>1.186125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.310400</td>\n",
       "      <td>1.185308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.306900</td>\n",
       "      <td>1.176049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.305600</td>\n",
       "      <td>1.176790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.303900</td>\n",
       "      <td>1.183256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.299700</td>\n",
       "      <td>1.178057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.298200</td>\n",
       "      <td>1.166044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.293900</td>\n",
       "      <td>1.170990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.293500</td>\n",
       "      <td>1.175670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.290300</td>\n",
       "      <td>1.172185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.287800</td>\n",
       "      <td>1.168431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.285000</td>\n",
       "      <td>1.157376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.284400</td>\n",
       "      <td>1.167173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.284000</td>\n",
       "      <td>1.160903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.279900</td>\n",
       "      <td>1.156389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.279300</td>\n",
       "      <td>1.159037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.275800</td>\n",
       "      <td>1.152051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.275700</td>\n",
       "      <td>1.160056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.276700</td>\n",
       "      <td>1.153124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-100000] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_5/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▁▂▂▂▂▅▂▃▂▆▂▂▃▆█▂▁▁▄▃▂▂▃▅▁▂▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▆██▇▇▇▇▄▇▆▇▃▇▇▆▂▁▇██▅▆▇▇▆▄█▇▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▆██▇▇▇▇▄▇▆▇▃▇▇▆▂▁▇██▅▆▇▇▆▄█▇▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.15312</td></tr><tr><td>eval/runtime</td><td>14.3395</td></tr><tr><td>eval/samples_per_second</td><td>3486.874</td></tr><tr><td>eval/steps_per_second</td><td>27.267</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2767</td></tr><tr><td>train/total_flos</td><td>268745747212800.0</td></tr><tr><td>train/train_loss</td><td>1.34646</td></tr><tr><td>train/train_runtime</td><td>13430.3282</td></tr><tr><td>train/train_samples_per_second</td><td>1489.167</td></tr><tr><td>train/train_steps_per_second</td><td>11.635</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 5</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/287qxgaa</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_024458-287qxgaa/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20221109_062901-2ucel8at</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2ucel8at\" target=\"_blank\">pos mlm 6</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='97926' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 97926/156260 3:22:23 < 2:00:33, 8.06 it/s, Epoch 12.53/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.674200</td>\n",
       "      <td>2.247338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.288800</td>\n",
       "      <td>1.983894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.123800</td>\n",
       "      <td>1.802521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.990400</td>\n",
       "      <td>1.647753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.881300</td>\n",
       "      <td>1.552505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.797000</td>\n",
       "      <td>1.480862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.734600</td>\n",
       "      <td>1.437792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.694500</td>\n",
       "      <td>1.410568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.654100</td>\n",
       "      <td>1.392488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.620500</td>\n",
       "      <td>1.368134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.585700</td>\n",
       "      <td>1.339652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.557900</td>\n",
       "      <td>1.340592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.536800</td>\n",
       "      <td>1.323589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.516800</td>\n",
       "      <td>1.319812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.502400</td>\n",
       "      <td>1.306314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.492500</td>\n",
       "      <td>1.299359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.482400</td>\n",
       "      <td>1.301254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.474100</td>\n",
       "      <td>1.294463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.467600</td>\n",
       "      <td>1.285691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_6/checkpoint-85000] due to args.save_total_limit\n"
     ]
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 128\n",
    "hidden_size = 32\n",
    "# num_hidden_layers = 3 \n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 20\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [2, 3, 4]\n",
    "MLM_P = [0.15, 0.25]\n",
    "LR = [1e-4, 5e-4, 8e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d660754",
   "metadata": {},
   "source": [
    "## retrain with correct tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846f5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb308665425f4a46bd25217d7efe6810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_135952-meq7masg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg\" target=\"_blank\">pos mlm 0</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:33:41, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.197700</td>\n",
       "      <td>1.503165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.621600</td>\n",
       "      <td>1.332788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.480200</td>\n",
       "      <td>1.282856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.422800</td>\n",
       "      <td>1.256439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.391100</td>\n",
       "      <td>1.235706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.371700</td>\n",
       "      <td>1.220973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.351500</td>\n",
       "      <td>1.200947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.341400</td>\n",
       "      <td>1.197688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.327900</td>\n",
       "      <td>1.200239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.320200</td>\n",
       "      <td>1.194722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.312800</td>\n",
       "      <td>1.182932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.307800</td>\n",
       "      <td>1.186158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.301500</td>\n",
       "      <td>1.178639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.295400</td>\n",
       "      <td>1.177755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.289200</td>\n",
       "      <td>1.165696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.287600</td>\n",
       "      <td>1.166491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.284900</td>\n",
       "      <td>1.173814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.281100</td>\n",
       "      <td>1.166083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.279200</td>\n",
       "      <td>1.157503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.274000</td>\n",
       "      <td>1.159682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.273300</td>\n",
       "      <td>1.160969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.269900</td>\n",
       "      <td>1.158978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.267000</td>\n",
       "      <td>1.161546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.265100</td>\n",
       "      <td>1.145952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.263900</td>\n",
       "      <td>1.157450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.262900</td>\n",
       "      <td>1.152030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.259500</td>\n",
       "      <td>1.144415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.258500</td>\n",
       "      <td>1.147812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.256900</td>\n",
       "      <td>1.141821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.255700</td>\n",
       "      <td>1.149476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.257100</td>\n",
       "      <td>1.144939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_0/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▃▁▁▂▂▂▁▂▂▁▂▂▂▅▂█▆▂▁▂▃▆▂▂▂▁▂▃▂▂▂</td></tr><tr><td>eval/samples_per_second</td><td>▆██▇▇▇█▇▇█▇▇▇▄▇▁▃▇█▇▆▂▇▇▇█▇▆▇▇▇</td></tr><tr><td>eval/steps_per_second</td><td>▆██▇▇▇█▇▇█▇▇▇▄▇▁▃▇█▇▆▂▇▇▇█▇▆▇▇▇</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.14494</td></tr><tr><td>eval/runtime</td><td>14.433</td></tr><tr><td>eval/samples_per_second</td><td>3464.28</td></tr><tr><td>eval/steps_per_second</td><td>27.091</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>1.2571</td></tr><tr><td>train/total_flos</td><td>355516133955840.0</td></tr><tr><td>train/train_loss</td><td>1.34217</td></tr><tr><td>train/train_runtime</td><td>12829.5392</td></tr><tr><td>train/train_samples_per_second</td><td>1558.902</td></tr><tr><td>train/train_steps_per_second</td><td>12.18</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 0</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/meq7masg</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_135952-meq7masg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning [UNK] to the unk_token key of the tokenizer\n",
      "Assigning [SEP] to the sep_token key of the tokenizer\n",
      "Assigning [PAD] to the pad_token key of the tokenizer\n",
      "Assigning [CLS] to the cls_token key of the tokenizer\n",
      "Assigning [MASK] to the mask_token key of the tokenizer\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.13.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_173621-2xm5n7kp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp\" target=\"_blank\">pos mlm 1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1000000\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 156260\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='156260' max='156260' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [156260/156260 3:34:29, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.029900</td>\n",
       "      <td>1.427583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.546600</td>\n",
       "      <td>1.307512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.438800</td>\n",
       "      <td>1.266698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.386700</td>\n",
       "      <td>1.239994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.357000</td>\n",
       "      <td>1.218349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.340300</td>\n",
       "      <td>1.204897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>1.324300</td>\n",
       "      <td>1.189534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>1.316700</td>\n",
       "      <td>1.187331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>1.304900</td>\n",
       "      <td>1.189532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>1.299000</td>\n",
       "      <td>1.185083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>1.291900</td>\n",
       "      <td>1.169276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>1.286800</td>\n",
       "      <td>1.175554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>1.282600</td>\n",
       "      <td>1.168246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>1.276900</td>\n",
       "      <td>1.167330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>1.271300</td>\n",
       "      <td>1.160178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>1.269000</td>\n",
       "      <td>1.157567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>1.266800</td>\n",
       "      <td>1.165419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90000</td>\n",
       "      <td>1.263800</td>\n",
       "      <td>1.156068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95000</td>\n",
       "      <td>1.261200</td>\n",
       "      <td>1.146525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100000</td>\n",
       "      <td>1.256800</td>\n",
       "      <td>1.149183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105000</td>\n",
       "      <td>1.255300</td>\n",
       "      <td>1.149836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110000</td>\n",
       "      <td>1.251200</td>\n",
       "      <td>1.149080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115000</td>\n",
       "      <td>1.248600</td>\n",
       "      <td>1.147295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120000</td>\n",
       "      <td>1.246300</td>\n",
       "      <td>1.135344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125000</td>\n",
       "      <td>1.244700</td>\n",
       "      <td>1.146625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130000</td>\n",
       "      <td>1.243600</td>\n",
       "      <td>1.141015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135000</td>\n",
       "      <td>1.239900</td>\n",
       "      <td>1.133747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140000</td>\n",
       "      <td>1.239100</td>\n",
       "      <td>1.135363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145000</td>\n",
       "      <td>1.236500</td>\n",
       "      <td>1.127683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150000</td>\n",
       "      <td>1.235100</td>\n",
       "      <td>1.137296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155000</td>\n",
       "      <td>1.236600</td>\n",
       "      <td>1.131848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-10000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-15000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-20000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-25000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-30000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-35000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-40000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-45000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-50000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-55000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-60000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-65000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-70000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-75000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-80000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-85000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-90000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-95000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-100000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-105000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-110000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-115000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-120000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-125000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-130000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-135000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-150000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-140000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 50000\n",
      "  Batch size = 128\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000\n",
      "Configuration saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-155000/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_1/checkpoint-145000] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▆▇▆▆▆▆▆▆█▂▃▂▁▂▂▁▅▂▁▁▂▅▁▁▆▁▁▁▁▂▁</td></tr><tr><td>eval/samples_per_second</td><td>▃▂▃▃▃▃▃▃▁▇▆▇█▇▇█▄▇██▇▄██▃████▇█</td></tr><tr><td>eval/steps_per_second</td><td>▃▂▃▃▃▃▃▃▁▇▆▇█▇▇█▄▇██▇▄██▃████▇█</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▄▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>1.13185</td></tr><tr><td>eval/runtime</td><td>14.4942</td></tr><tr><td>eval/samples_per_second</td><td>3449.664</td></tr><tr><td>eval/steps_per_second</td><td>26.976</td></tr><tr><td>train/epoch</td><td>20.0</td></tr><tr><td>train/global_step</td><td>156260</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>1.2366</td></tr><tr><td>train/total_flos</td><td>355516133955840.0</td></tr><tr><td>train/train_loss</td><td>1.31382</td></tr><tr><td>train/train_runtime</td><td>12869.7623</td></tr><tr><td>train/train_samples_per_second</td><td>1554.03</td></tr><tr><td>train/train_steps_per_second</td><td>12.142</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">pos mlm 1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/POS%20MLM%20CoreNLP/runs/2xm5n7kp</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20230116_173621-2xm5n7kp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data related args\n",
    "tagset = 'xpos'\n",
    "select = 1000000\n",
    "reprocess = False\n",
    "\n",
    "# bert related args\n",
    "model_max_length = 128\n",
    "hidden_size = 32\n",
    "# num_hidden_layers = 3 \n",
    "num_attention_heads = 4\n",
    "intermediate_size = 128\n",
    "\n",
    "# training related args\n",
    "control_steps = 5000 # num_steps to log and save\n",
    "num_train_epochs = 20\n",
    "batchsize = 128\n",
    "dropout_prob = 0.1\n",
    "tagger = 'corenlp'\n",
    "\n",
    "# sweep variables\n",
    "# TAGGER = ['corenlp']\n",
    "# TAGGER = ['hunpos', 'corenlp', 'stanza']\n",
    "NUM_LAYERS = [4]\n",
    "MLM_P = [0.15]\n",
    "LR = [5e-4, 8e-4]\n",
    "\n",
    "NUM_LAYERS, MLM_P, LR = np.meshgrid(NUM_LAYERS, MLM_P, LR)\n",
    "NUM_LAYERS, MLM_P, LR = NUM_LAYERS.flatten(), MLM_P.flatten(), LR.flatten()\n",
    "num_runs = len(LR)\n",
    "\n",
    "for i_run in trange(num_runs):\n",
    "    \n",
    "    num_hidden_layers = int(NUM_LAYERS[i_run])\n",
    "    mlm_probability = float(MLM_P[i_run])\n",
    "    lr = float(LR[i_run])\n",
    "    \n",
    "    # create tokenizer\n",
    "    vocab = get_pos_vocab(tagger, tagset=tagset)\n",
    "    tokenizer = get_tokenizer(vocab, model_max_length = model_max_length)\n",
    "    \n",
    "    # transform or load dataset\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        trainset = dataset['train'].select(range(select)).map(tagging_func, batched=True)\n",
    "        trainset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        trainset = load_from_disk(cache_location)\n",
    "    trainset = trainset.remove_columns(['text'])\n",
    "    \n",
    "    select2 = range(select,select+50000)\n",
    "    cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_50k_{tagger}_transformed_test.hf'\n",
    "    if not os.path.exists(cache_location) or reprocess:\n",
    "        tagging_func = tagger2func[tagger]\n",
    "        testset = dataset['train'].select(select2).map(tagging_func, batched=True)\n",
    "        testset.save_to_disk(cache_location)\n",
    "    else:\n",
    "        testset = load_from_disk(cache_location)\n",
    "    testset = testset.remove_columns(['text'])\n",
    "#     test_input_ids = torch.LongTensor([[1]+[item for t in testset['input_ids'] for item in t[1:-1]]+[2]])\n",
    "\n",
    "    # mlm data collater\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=True,\n",
    "        mlm_probability=mlm_probability\n",
    "    )\n",
    "\n",
    "    # model config\n",
    "    config = BertConfig(vocab_size = len(tokenizer.get_vocab()),\n",
    "                        hidden_size = hidden_size,\n",
    "                        num_hidden_layers = num_hidden_layers,\n",
    "                        num_attention_heads = num_attention_heads,\n",
    "                        intermediate_size = intermediate_size,\n",
    "                        hidden_act = 'gelu',\n",
    "                        hidden_dropout_prob = dropout_prob,\n",
    "                        attention_probs_dropout_prob = dropout_prob,\n",
    "                        max_position_embeddings = model_max_length,\n",
    "                        type_vocab_size = 2,\n",
    "                        initializer_range = 0.02,\n",
    "                        layer_norm_eps = 1e-12,\n",
    "                        pad_token_id = tokenizer.pad_token_id)\n",
    "    # init model\n",
    "    bert = BertForMaskedLM(config)\n",
    "\n",
    "    # trainer config\n",
    "    training_args = TrainingArguments(\n",
    "        learning_rate=lr,\n",
    "        output_dir= f\"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_pos_mlm_{i_run}\",\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batchsize,\n",
    "        per_device_eval_batch_size=batchsize,\n",
    "        evaluation_strategy='steps',\n",
    "        save_steps=control_steps,\n",
    "        logging_steps=control_steps,\n",
    "        eval_steps=control_steps,\n",
    "        save_total_limit=2,\n",
    "        prediction_loss_only=True,\n",
    "        remove_unused_columns=False,\n",
    "#         report_to='wandb',\n",
    "        )\n",
    "    \n",
    "    # wandb config\n",
    "    wconfig = {}\n",
    "    wconfig['num_hidden_layers'] = num_hidden_layers\n",
    "    wconfig['mlm_probability'] = mlm_probability\n",
    "    wconfig['lr'] = lr\n",
    "    run = wandb.init(project=\"POS MLM CoreNLP\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'pos mlm {i_run}',\n",
    "                     reinit=True)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=bert,\n",
    "        args=training_args,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        train_dataset=trainset,\n",
    "        eval_dataset=testset,\n",
    "    )\n",
    "    trainer.train()\n",
    "    run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_location = f'/scratch/data_jz17d/data/bookcorpus/bookcorpus_{numerize.numerize(select).lower()}_{tagger}_transformed.hf'\n",
    "\n",
    "trainset = load_from_disk(cache_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711e270a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
