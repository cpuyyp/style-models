{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "567d35eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self defined library\n",
    "from data_utils import keystoint, get_seg_loader # other unneeded definitions: MyData, MyDataset, SegmentBatchCollater, SegmentDataLoader, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c714154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import trange, tqdm\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional, Sequence, Union\n",
    "\n",
    "import collections\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import wandb\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GATConv, GATv2Conv, TransformerConv, PDNConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.utils import scatter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "\n",
    "import transformers\n",
    "from transformers import get_scheduler, AutoTokenizer\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "\n",
    "import evaluate\n",
    "from sklearn.metrics import top_k_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4aa9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.26.0', '2.2.0', '1.13.1', device(type='cuda'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transformers.__version__, pyg.__version__, torch.__version__,device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "70da8683",
   "metadata": {},
   "source": [
    "# definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "612c538f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a9f72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyConfig:\n",
    "    # dataset configs\n",
    "    dataset: str\n",
    "    num_classes: int \n",
    "    segment_length: int = 'doc'\n",
    "\n",
    "    # model archtectures\n",
    "    pos_emb_dim: int = 64 # this is determined by the pretrained pos bert\n",
    "    dep_emb_dim: int = 32 # edge attribute dim\n",
    "    hidden_dim: int = field(init=False)\n",
    "    # these 4 parameters below are not changable\n",
    "    num_dep_type: int = 37 # this is determined by dependency2id\n",
    "    # max syllable for common word is 17. However, the longest word in English is a protein that has 189819 letters! \n",
    "    # That must have much more syllables. Truncate to 32 to simplify.\n",
    "    max_num_syllables: int = 32  \n",
    "    max_sentence_num: int = 64 \n",
    "    # zipf frequency bins. 0-8 stands for its frequency between 10**(x-1) and 10**x. 9 is for punctuations. 10 is for CLS and SEP\n",
    "    num_freq_type: int = 11\n",
    "\n",
    "    num_layers: int = 4\n",
    "    heads: int = 4\n",
    "    num_hierarchy: int = 1\n",
    "\n",
    "    add_self_loops: bool = False\n",
    "    add_syllables: bool = True\n",
    "    add_word_freq: bool = True\n",
    "    add_dep: bool = True\n",
    "    add_sentence_order: bool = True # only if num_hierarchy > 0\n",
    "    \n",
    "    # training configs\n",
    "    max_length: int = 256 # this is only for pos tokenizer, bert tokenizer use default 512\n",
    "    dropout: float = 0.1\n",
    "    batch_size: int = 128\n",
    "    epochs: int = 100\n",
    "    warmup_ratio: float = 0.15\n",
    "    lr: float = 2e-3\n",
    "    save_location: str = None\n",
    "\n",
    "    # pretrained checkpoints\n",
    "    pos_checkpoint: str = field(init=False)\n",
    "    bert_checkpoint: str = 'bert-base-uncased'\n",
    "\n",
    "    def __post_init__(self):\n",
    "        assert self.pos_emb_dim % self.heads==0, 'make sure pos_emb_dim is dividable to heads'\n",
    "        self.hidden_dim = self.pos_emb_dim//self.heads\n",
    "\n",
    "        pos_emb_dim2pos_checkpoint = {64: \"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_22/checkpoint-95000/\",\n",
    "                                    48: \"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_16/checkpoint-95000/\",\n",
    "                                    32: \"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_10/checkpoint-145000/\",\n",
    "                                    16: \"/scratch/data_jz17d/result/pos_mlm_corenlp/retrained_all_pos_mlm_5/checkpoint-95000/\",}\n",
    "        self.pos_checkpoint = pos_emb_dim2pos_checkpoint[self.pos_emb_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "038ca9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class myGNNoutput:\n",
    "    loss: None\n",
    "    logit: None\n",
    "    emb: None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac635a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GNNtype2layer = {'GATConv':GATConv, 'GATv2Conv':GATv2Conv, 'TransformerConv':TransformerConv, 'PDNConv':PDNConv}\n",
    "\n",
    "class MyGNNBlock(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 heads,\n",
    "                 dropout=0.1,\n",
    "                 dropout_position='last',\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(in_channels)\n",
    "        self.gnnlayer = TransformerConv(in_channels=in_channels, out_channels=out_channels, heads=heads, beta=True, **kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.dropout_position = dropout_position\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        if self.dropout_position=='last':\n",
    "            x += self.gnnlayer(self.layernorm(x), edge_index, edge_attr).relu()\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        elif self.dropout_position=='first':\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            x += self.gnnlayer(self.layernorm(x), edge_index, edge_attr).relu()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9842321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierGNN(torch.nn.Module):\n",
    "    def __init__(self, myconfig):\n",
    "        super().__init__()\n",
    "        self.num_classes = myconfig.num_classes\n",
    "    \n",
    "        # model archtectures\n",
    "        self.pos_emb_dim = myconfig.pos_emb_dim\n",
    "        self.dep_emb_dim = myconfig.dep_emb_dim\n",
    "        self.hidden_dim = myconfig.hidden_dim\n",
    "        \n",
    "        # these 4 parameters are not changable\n",
    "        self.num_dep_type = myconfig.num_dep_type\n",
    "        self.max_num_syllables = myconfig.max_num_syllables\n",
    "        self.max_sentence_num = myconfig.max_sentence_num\n",
    "        self.num_freq_type = myconfig.num_freq_type\n",
    "\n",
    "        self.num_layers = myconfig.num_layers\n",
    "        self.heads = myconfig.heads\n",
    "        self.num_hierarchy = myconfig.num_hierarchy\n",
    "\n",
    "        self.add_self_loops = myconfig.add_self_loops\n",
    "        self.add_syllables = myconfig.add_syllables\n",
    "        self.add_word_freq = myconfig.add_word_freq\n",
    "        self.add_dep = myconfig.add_dep\n",
    "        self.add_sentence_order = myconfig.add_sentence_order\n",
    "\n",
    "        # model misc\n",
    "        self.max_length = myconfig.max_length # this is for pos tokenizer\n",
    "        self.dropout = myconfig.dropout\n",
    "\n",
    "        # pretrained checkpoints\n",
    "        self.pos_checkpoint = myconfig.pos_checkpoint\n",
    "        # self.bert_checkpoint = myconfig.bert_checkpoint\n",
    "\n",
    "        # loading pretrained models\n",
    "        self.pos_tokenizer = AutoTokenizer.from_pretrained(self.pos_checkpoint, local_files_only=True)\n",
    "        self.pos_bert = BertModel.from_pretrained(self.pos_checkpoint, local_files_only=True, add_pooling_layer = False).to(device)\n",
    "        \n",
    "        # embedding layers\n",
    "        if self.add_syllables:\n",
    "            # the longest word in the world has 17 syllables. However, if either processing error or people speak like that, such there is no space between words, error will arise.\n",
    "            self.syllable_emb_layer = nn.Embedding(self.max_num_syllables, self.pos_emb_dim)\n",
    "        if self.add_word_freq:\n",
    "            self.freq_emb_layer = nn.Embedding(self.num_freq_type, self.pos_emb_dim)\n",
    "        if self.add_dep:\n",
    "            self.dep_emb_layer = nn.Embedding(self.num_dep_type, self.dep_emb_dim)\n",
    "        \n",
    "        # gnns within sentences\n",
    "        self.gnns = nn.ModuleList()\n",
    "        for i in range(self.num_layers):\n",
    "            if self.add_dep:\n",
    "                self.gnns.append(MyGNNBlock(self.pos_emb_dim, self.hidden_dim, heads = self.heads, add_self_loops=self.add_self_loops, dropout=self.dropout, edge_dim=self.dep_emb_dim, beta=True))\n",
    "            else:\n",
    "                self.gnns.append(MyGNNBlock(self.pos_emb_dim, self.hidden_dim, heads = self.heads, add_self_loops=self.add_self_loops, dropout=self.dropout, beta=True))\n",
    "\n",
    "        if self.num_hierarchy:\n",
    "            # for sentence order\n",
    "            # the longest text has 104 lines. how to deal with super long text?\n",
    "            if self.add_sentence_order:\n",
    "                self.sentence_position_emb_layer = nn.Embedding(self.max_sentence_num, 2*self.pos_emb_dim) \n",
    "            \n",
    "            # hierarchical layer\n",
    "            self.hierarchy_gnns = nn.ModuleList()\n",
    "            for i in range(self.num_hierarchy):\n",
    "                self.hierarchy_gnns.append(MyGNNBlock(2*self.pos_emb_dim, 2*self.hidden_dim, heads = self.heads, add_self_loops=self.add_self_loops, dropout=self.dropout, beta=True))\n",
    "            \n",
    "            self.classifier = nn.Linear(4*self.pos_emb_dim, self.num_classes)\n",
    "        else:\n",
    "            self.classifier = nn.Linear(2*self.pos_emb_dim, self.num_classes)\n",
    "            \n",
    "        self.lossfn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, pos, edge_index, edge_type_ids, batch, ptr, y, segment_ids, num_syllable, word_freq):\n",
    "        # get pos embeddings, reshape and squeeze the dimension 0 to match pyg batching fashion\n",
    "        # x.shape = (sum of #sentence, max_length, pos_emb_dim)\n",
    "        tokens = self.pos_tokenizer(pos, padding=True, truncation=True, max_length=self.max_length, return_tensors='pt').to(device)\n",
    "        x = self.pos_bert(**tokens).last_hidden_state\n",
    "        # reshape! drop padded tokens!\n",
    "        # x.shape = (sum of #token, pos_emb_dim)\n",
    "        x = x.masked_select(tokens.attention_mask.ge(0.5).unsqueeze(2)).reshape((-1,self.pos_emb_dim))\n",
    "        \n",
    "        # add syllables embedding to pos embeddings\n",
    "        if self.add_syllables:\n",
    "            x += self.syllable_emb_layer(torch.clip(num_syllable, max=self.max_num_syllables-1)) # clip to make sure no error\n",
    "\n",
    "        # add freq embedding to pos embeddings\n",
    "        if self.add_word_freq:\n",
    "            x += self.freq_emb_layer(word_freq)\n",
    "\n",
    "        # get edge embeddings\n",
    "        if self.add_dep:\n",
    "            edge_attr = self.dep_emb_layer(edge_type_ids)\n",
    "\n",
    "        # graph conv\n",
    "        for i in range(self.num_layers):\n",
    "            x += self.gnns[i](x, edge_index, edge_attr=edge_attr).relu() if self.add_dep else self.gnns[i](x, edge_index).relu()\n",
    "        \n",
    "        if self.hierarchy:\n",
    "            # readout to get sentence embeddings\n",
    "            # x.shape = (#sentence, pos_emb_dim*2)\n",
    "            non_zero_i, non_zero_j = tokens.attention_mask.nonzero(as_tuple=True)\n",
    "            # the input batch is segment level batch indices. Need sentence level batch indices here\n",
    "            sent_batch = (((torch.arange(len(text)).to(device)+1).unsqueeze(1)*tokens.attention_mask)[non_zero_i, non_zero_j] - 1)\n",
    "            x = torch.cat([global_mean_pool(x, sent_batch), global_max_pool(x, sent_batch)], axis=1)\n",
    "\n",
    "            # calculate edge_index between sentences from the same paragraph\n",
    "            edges_among_sentences = torch.LongTensor().to(device)\n",
    "            if self.add_sentence_order: \n",
    "                sentence_id = torch.LongTensor()\n",
    "            for i in range(segment_ids.max().item()+1):\n",
    "                idx = (segment_ids==i).nonzero().long().squeeze(1)  # select all sentence id belong to current segment\n",
    "                edge_x, edge_y = torch.meshgrid(idx, idx)\n",
    "                edge = torch.vstack([edge_x.flatten(), edge_y.flatten()])\n",
    "                edges_among_sentences = torch.cat([edges_among_sentences, edge], axis = 1)\n",
    "                if self.add_sentence_order: \n",
    "                    sentence_id = torch.cat([sentence_id, torch.arange(len(idx), dtype=torch.long)])\n",
    "            \n",
    "            # add sentence position\n",
    "            if self.add_sentence_order:\n",
    "                sentence_id = sentence_id.to(device)\n",
    "                x += self.sentence_position_emb_layer(torch.clip(sentence_id, max=self.max_sentence_num-1))\n",
    "\n",
    "            # hierarchical layers\n",
    "            for i in range(self.num_hierarchy):\n",
    "                x += self.hierarchy_gnns[i](x, edges_among_sentences).relu()\n",
    "\n",
    "            # readout to get segment/doc embeddings\n",
    "            # x.shape = (#segment/#doc, pos_emb_dim*4)\n",
    "            x = torch.cat([global_mean_pool(x, segment_ids), global_max_pool(x, segment_ids)], axis=1)\n",
    "\n",
    "        else: \n",
    "            # readout to get segment/doc embeddings\n",
    "            # x.shape = (#segment/#doc, pos_emb_dim*2)\n",
    "            x = torch.cat([global_mean_pool(x, batch), global_max_pool(x, batch)], axis=1)\n",
    "\n",
    "        # prepare logits and output\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        logit = self.classifier(x)\n",
    "        loss = self.lossfn(logit, y)\n",
    "        return myGNNoutput(loss=loss, logit=logit, emb=x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c385e825",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "470911fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_configs(dataset, num_classes, exclude_keys=['repeat'], **kwargs):\n",
    "    '''\n",
    "    If want to try different settings, give a list. Otherwise, just a number/str.\n",
    "    '''\n",
    "    keys = []\n",
    "    values = []\n",
    "    direct_kwargs = {}\n",
    "    for k,v in kwargs.items():\n",
    "        if k.lower() not in exclude_keys:\n",
    "            assert k.lower() in MyConfig.__dict__['__annotations__'], f\"{k} doesn't match any MyConfig option\"\n",
    "        if isinstance(v, list):\n",
    "            keys.append(k)\n",
    "            values.append(v)\n",
    "        else:\n",
    "            direct_kwargs[k]=v\n",
    "\n",
    "    CONFIGS = itertools.product(*values)\n",
    "    config_lists = []\n",
    "    for raw_config in CONFIGS:\n",
    "        myconfig = MyConfig(dataset=dataset, num_classes=num_classes, **direct_kwargs)\n",
    "        for k,v in zip(keys, raw_config):\n",
    "            if k.lower() not in exclude_keys:\n",
    "                myconfig.__dict__[k.lower()] = v\n",
    "        myconfig.__post_init__()\n",
    "        config_lists.append(myconfig)\n",
    "    return config_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fe50c1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3804908e279f43b48f036255b7e5fda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'relation2id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mdataset_dir\u001b[39m}\u001b[39;00m\u001b[39m/test_docid2index.json\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     30\u001b[0m     test_docid2index \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f, object_hook\u001b[39m=\u001b[39mkeystoint)\n\u001b[0;32m---> 32\u001b[0m train_loader \u001b[39m=\u001b[39m get_seg_loader(dataset\u001b[39m=\u001b[39;49mdataset, segment_length\u001b[39m=\u001b[39;49mmyconfig\u001b[39m.\u001b[39;49msegment_length, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49mmyconfig\u001b[39m.\u001b[39;49mbatch_size, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, max_length\u001b[39m=\u001b[39;49mmyconfig\u001b[39m.\u001b[39;49mmax_length)\n\u001b[1;32m     33\u001b[0m num_training_steps \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(train_loader)\n\u001b[1;32m     34\u001b[0m test_loader \u001b[39m=\u001b[39m get_seg_loader(dataset\u001b[39m=\u001b[39mdataset, segment_length\u001b[39m=\u001b[39mmyconfig\u001b[39m.\u001b[39msegment_length, split\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, batch_size\u001b[39m=\u001b[39mmyconfig\u001b[39m.\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, max_length\u001b[39m=\u001b[39mmyconfig\u001b[39m.\u001b[39mmax_length)\n",
      "File \u001b[0;32m~/Desktop/style-models/code/POS/data_utils.py:244\u001b[0m, in \u001b[0;36mget_seg_loader\u001b[0;34m(dataset, segment_length, split, batch_size, shuffle, max_length, num_workers, pin_memory, persistent_workers)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[39mdir\u001b[39m \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m/segment_\u001b[39m\u001b[39m{\u001b[39;00msegment_length\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m segment_length \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdoc\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mlocation\u001b[39m}\u001b[39;00m\u001b[39m/doc_\u001b[39m\u001b[39m{\u001b[39;00msplit\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 244\u001b[0m     mydataset \u001b[39m=\u001b[39m MyDataset(\u001b[39mdir\u001b[39;49m)\n\u001b[1;32m    245\u001b[0m     loader \u001b[39m=\u001b[39m SegmentDataLoader(mydataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39mshuffle, num_workers\u001b[39m=\u001b[39mnum_workers, pin_memory\u001b[39m=\u001b[39mpin_memory, persistent_workers\u001b[39m=\u001b[39mpersistent_workers)\n\u001b[1;32m    246\u001b[0m \u001b[39mreturn\u001b[39;00m loader\n",
      "File \u001b[0;32m~/Desktop/style-models/code/POS/data_utils.py:43\u001b[0m, in \u001b[0;36mMyDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, max_length)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_files \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength)]\n\u001b[1;32m     41\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_files \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength)]\n\u001b[0;32m---> 43\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch113/lib/python3.9/site-packages/torch_geometric/data/dataset.py:94\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[1;32m     93\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch113/lib/python3.9/site-packages/torch_geometric/data/dataset.py:211\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m    210\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[0;32m--> 211\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[1;32m    213\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    214\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "File \u001b[0;32m~/Desktop/style-models/code/POS/data_utils.py:78\u001b[0m, in \u001b[0;36mMyDataset.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m temp_data \u001b[39m=\u001b[39m MyData()\n\u001b[1;32m     72\u001b[0m temp_data\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([torch\u001b[39m.\u001b[39mLongTensor([[\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m]]),  \u001b[39m# for self loop of CLS token\u001b[39;00m\n\u001b[1;32m     73\u001b[0m                              torch\u001b[39m.\u001b[39mLongTensor(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m.\u001b[39mT, \n\u001b[1;32m     74\u001b[0m                              \u001b[39m# for batching purpose, if data.x is missing, edge_index is used to inference batch\u001b[39;00m\n\u001b[1;32m     75\u001b[0m                              \u001b[39m# an isolated node (the SEP in this case) will mess all up\u001b[39;00m\n\u001b[1;32m     76\u001b[0m                              torch\u001b[39m.\u001b[39mLongTensor([[\u001b[39mlen\u001b[39m(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m],[\u001b[39mlen\u001b[39m(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]])], \n\u001b[1;32m     77\u001b[0m                             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m temp_data\u001b[39m.\u001b[39medge_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([\u001b[39m36\u001b[39m]\u001b[39m+\u001b[39m[relation2id[t\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m curr[\u001b[39m'\u001b[39m\u001b[39mhetoro_edges\u001b[39m\u001b[39m'\u001b[39m][j]]\u001b[39m+\u001b[39m[\u001b[39m36\u001b[39m])\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m temp_data\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     80\u001b[0m     error_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/style-models/code/POS/data_utils.py:78\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m temp_data \u001b[39m=\u001b[39m MyData()\n\u001b[1;32m     72\u001b[0m temp_data\u001b[39m.\u001b[39medge_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([torch\u001b[39m.\u001b[39mLongTensor([[\u001b[39m0\u001b[39m],[\u001b[39m0\u001b[39m]]),  \u001b[39m# for self loop of CLS token\u001b[39;00m\n\u001b[1;32m     73\u001b[0m                              torch\u001b[39m.\u001b[39mLongTensor(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m.\u001b[39mT, \n\u001b[1;32m     74\u001b[0m                              \u001b[39m# for batching purpose, if data.x is missing, edge_index is used to inference batch\u001b[39;00m\n\u001b[1;32m     75\u001b[0m                              \u001b[39m# an isolated node (the SEP in this case) will mess all up\u001b[39;00m\n\u001b[1;32m     76\u001b[0m                              torch\u001b[39m.\u001b[39mLongTensor([[\u001b[39mlen\u001b[39m(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m],[\u001b[39mlen\u001b[39m(curr[\u001b[39m'\u001b[39m\u001b[39medge_indexs\u001b[39m\u001b[39m'\u001b[39m][j])\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]])], \n\u001b[1;32m     77\u001b[0m                             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m temp_data\u001b[39m.\u001b[39medge_type_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor([\u001b[39m36\u001b[39m]\u001b[39m+\u001b[39m[relation2id[t\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m curr[\u001b[39m'\u001b[39m\u001b[39mhetoro_edges\u001b[39m\u001b[39m'\u001b[39m][j]]\u001b[39m+\u001b[39m[\u001b[39m36\u001b[39m])\n\u001b[1;32m     79\u001b[0m \u001b[39mif\u001b[39;00m temp_data\u001b[39m.\u001b[39medge_index\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_length\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m     80\u001b[0m     error_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'relation2id' is not defined"
     ]
    }
   ],
   "source": [
    "dataset='ccat50'\n",
    "scratch_data_dir = '/scratch/data_jz17d/data'\n",
    "dataset_dir = f'{scratch_data_dir}/{dataset}'\n",
    "\n",
    "model_name = 'POS GNN'\n",
    "\n",
    "config_lists = get_configs(dataset='ccat50', \n",
    "                           num_classes=50,\n",
    "                           segment_length=[2, 3, 4, 'doc'],\n",
    "                           num_hierarchy=[0, 1, 2],\n",
    "                           add_sentence_order=[True, False],\n",
    "                           batch_size = 64,\n",
    "                           )\n",
    "\n",
    "skip_runs = -1\n",
    "######################## in most cases, no need to edit the section below ##########################\n",
    "run_pbar = trange(len(config_lists), leave=False)\n",
    "for i_run, myconfig in enumerate(config_lists):\n",
    "\n",
    "    if i_run <= skip_runs:\n",
    "        run_pbar.update(1)\n",
    "        continue\n",
    "    \n",
    "    seed = int(datetime.now().timestamp())\n",
    "    set_seed(seed)\n",
    "    \n",
    "    # load necessary files and dataset\n",
    "    doc_true = np.load(f'{dataset_dir}/doc_true.npy')\n",
    "    with open(f'{dataset_dir}/test_docid2index.json') as f:\n",
    "        test_docid2index = json.load(f, object_hook=keystoint)\n",
    "    \n",
    "    train_loader = get_seg_loader(dataset=dataset, segment_length=myconfig.segment_length, split='train', batch_size=myconfig.batch_size, shuffle=True, max_length=myconfig.max_length)\n",
    "    num_training_steps = len(train_loader)\n",
    "    test_loader = get_seg_loader(dataset=dataset, segment_length=myconfig.segment_length, split='test', batch_size=myconfig.batch_size, shuffle=True, max_length=myconfig.max_length)\n",
    "    # num_test_steps = len(test_loader)\n",
    "    \n",
    "    # initialize model, optimizere, and lr scheduler\n",
    "    model = HierGNN(myconfig)\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=myconfig.lr)\n",
    "    scheduler = get_scheduler(\"linear\",\n",
    "                            optimizer=optimizer,\n",
    "                            num_warmup_steps=int(myconfig.warmup_ratio*myconfig.epochs*num_training_steps),\n",
    "                            num_training_steps=myconfig.epochs*num_training_steps)\n",
    "    # start sync to wandb\n",
    "    wconfig = {}\n",
    "    wconfig['seed'] = seed\n",
    "    wconfig.update(myconfig.__dict__)\n",
    "    run = wandb.init(project=f\"{model_name} {dataset}\", \n",
    "                     entity=\"fsu-dsc-cil\", \n",
    "                     dir='/scratch/data_jz17d/wandb_tmp/', \n",
    "                     config=wconfig,\n",
    "                     name=f'run_{i_run}',\n",
    "                     reinit=True,\n",
    "                     settings=wandb.Settings(start_method='thread'))\n",
    "    \n",
    "    best_evaluation = collections.defaultdict(float)\n",
    "    pbar = trange(myconfig.epochs*num_training_steps, leave=False)\n",
    "    for i_epoch in range(myconfig.epochs):\n",
    "        # train\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch.pos, batch.edge_index, batch.edge_type_ids, batch.batch, batch.ptr, batch.y, batch.segment_ids, batch.num_syllables, batch.word_freqs)\n",
    "            output.loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            pbar.update(1)\n",
    "\n",
    "        # evaluate on test set\n",
    "        model.eval()\n",
    "        doc_score = 1e-8*np.ones((len(test_docid2index), myconfig.num_classes))\n",
    "        metric = evaluate.load('/home/jz17d/Desktop/metrics/accuracy')\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device, non_blocking=True)\n",
    "            output = model(batch.pos, batch.edge_index, batch.edge_type_ids, batch.batch, batch.ptr, batch.y, batch.segment_ids, batch.num_syllables, batch.word_freqs)\n",
    "            pred = output.logit.argmax(axis=-1).cpu().detach().numpy()\n",
    "            metric.add_batch(predictions=pred, references=batch.y.cpu().numpy())\n",
    "            doc_id = np.vectorize(test_docid2index.get)(batch.doc_id.cpu().detach().numpy()) \n",
    "            doc_score[doc_id,pred] += 1\n",
    "        \n",
    "        # logging current\n",
    "        evaluation = metric.compute()\n",
    "        for k in range(1, 6):\n",
    "            evaluation.update({f'test_doc_acc@{k}': top_k_accuracy_score(doc_true, doc_score, k=k)})\n",
    "        wandb.log(evaluation, step=pbar.n)\n",
    "        \n",
    "        # logging best\n",
    "        for key in evaluation:\n",
    "            best_evaluation[f'best_{key}'] = max(best_evaluation[f'best_{key}'], evaluation[key])\n",
    "        wandb.log(best_evaluation, step=pbar.n)\n",
    "    \n",
    "    run.finish()\n",
    "    run_pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a490a2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "eff459b455d2c0757a4e89f8cb2c37a927eff263cb260980ebfa13f3344fc7e6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
