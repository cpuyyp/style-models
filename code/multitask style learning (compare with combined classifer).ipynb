{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed7de70",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#multi-task-dataloader\" data-toc-modified-id=\"multi-task-dataloader-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>multi-task dataloader</a></span></li><li><span><a href=\"#multi-task-model\" data-toc-modified-id=\"multi-task-model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>multi-task model</a></span></li><li><span><a href=\"#train\" data-toc-modified-id=\"train-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>train</a></span><ul class=\"toc-item\"><li><span><a href=\"#single-task\" data-toc-modified-id=\"single-task-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>single task</a></span><ul class=\"toc-item\"><li><span><a href=\"#ShortHumor\" data-toc-modified-id=\"ShortHumor-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>ShortHumor</a></span><ul class=\"toc-item\"><li><span><a href=\"#freeze\" data-toc-modified-id=\"freeze-3.1.1.1\"><span class=\"toc-item-num\">3.1.1.1&nbsp;&nbsp;</span>freeze</a></span></li><li><span><a href=\"#unfreeze\" data-toc-modified-id=\"unfreeze-3.1.1.2\"><span class=\"toc-item-num\">3.1.1.2&nbsp;&nbsp;</span>unfreeze</a></span></li></ul></li><li><span><a href=\"#SarcasmGhosh\" data-toc-modified-id=\"SarcasmGhosh-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>SarcasmGhosh</a></span><ul class=\"toc-item\"><li><span><a href=\"#freeze\" data-toc-modified-id=\"freeze-3.1.2.1\"><span class=\"toc-item-num\">3.1.2.1&nbsp;&nbsp;</span>freeze</a></span></li><li><span><a href=\"#unfreeze\" data-toc-modified-id=\"unfreeze-3.1.2.2\"><span class=\"toc-item-num\">3.1.2.2&nbsp;&nbsp;</span>unfreeze</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785f4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import collections\n",
    "import json\n",
    "from tqdm.auto import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import *\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29182ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/issues/5486\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15b969b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    \"bert\": (BertConfig, BertPreTrainedModel, BertModel, BertTokenizer),\n",
    "    \"roberta\": (RobertaConfig, RobertaPreTrainedModel, RobertaModel, RobertaTokenizer),\n",
    "    \"albert\": (AlbertConfig, AlbertPreTrainedModel, AlbertModel, AlbertTokenizer),\n",
    "    \"distilbert\": (DistilBertConfig, DistilBertPreTrainedModel, DistilBertModel, DistilBertTokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36730747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = 'distilbert'\n",
    "# model_name = 'distilbert-base-uncased'\n",
    "\n",
    "model_type = 'bert'\n",
    "model_name = 'bert-base-uncased'\n",
    "config_class, pretrained_model_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "186facb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8839076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrowdFlower': 13,\n",
       " 'DailyDialog': 7,\n",
       " 'EmoBank_Valence': 1,\n",
       " 'EmoBank_Arousal': 1,\n",
       " 'EmoBank_Dominance': 1,\n",
       " 'HateOffensive': 3,\n",
       " 'PASTEL_age': 8,\n",
       " 'PASTEL_country': 2,\n",
       " 'PASTEL_education': 10,\n",
       " 'PASTEL_ethnic': 10,\n",
       " 'PASTEL_gender': 3,\n",
       " 'PASTEL_politics': 3,\n",
       " 'PASTEL_tod': 5,\n",
       " 'SARC': 2,\n",
       " 'SarcasmGhosh': 2,\n",
       " 'SentiTreeBank': 1,\n",
       " 'ShortHumor': 2,\n",
       " 'ShortJokeKaggle': 2,\n",
       " 'ShortRomance': 2,\n",
       " 'StanfordPoliteness': 1,\n",
       " 'TroFi': 2,\n",
       " 'VUA': 2}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../data/xslue/tasks.json', 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02ae7ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrowdFlower': 0,\n",
       " 'DailyDialog': 1,\n",
       " 'EmoBank_Valence': 2,\n",
       " 'EmoBank_Arousal': 3,\n",
       " 'EmoBank_Dominance': 4,\n",
       " 'HateOffensive': 5,\n",
       " 'PASTEL_age': 6,\n",
       " 'PASTEL_country': 7,\n",
       " 'PASTEL_education': 8,\n",
       " 'PASTEL_ethnic': 9,\n",
       " 'PASTEL_gender': 10,\n",
       " 'PASTEL_politics': 11,\n",
       " 'PASTEL_tod': 12,\n",
       " 'SARC': 13,\n",
       " 'SarcasmGhosh': 14,\n",
       " 'SentiTreeBank': 15,\n",
       " 'ShortHumor': 16,\n",
       " 'ShortJokeKaggle': 17,\n",
       " 'ShortRomance': 18,\n",
       " 'StanfordPoliteness': 19,\n",
       " 'TroFi': 20,\n",
       " 'VUA': 21}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks2idx = {}\n",
    "for i,k in enumerate(tasks):\n",
    "    tasks2idx[k] = i\n",
    "tasks2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d23f160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task and their (train) dataset size \n",
    "selected_task = ['PASTEL_country', # 33224\n",
    "#                  'SARC', # 205645\n",
    "                 'SarcasmGhosh', # 39780\n",
    "                 'ShortHumor', # 37801\n",
    "#                  'ShortJokeKaggle', # 406682\n",
    "#                  'ShortRomance', # 1902\n",
    "#                  'TroFi', # 3335\n",
    "                 'VUA', # 15157\n",
    "                ] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bd186",
   "metadata": {},
   "source": [
    "# multi-task dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00309940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    # currently it's a Mapping-style dataset. Not sure if a Iterable-style dataset will be better\n",
    "    def __init__(self, tsv_file):\n",
    "        self.df = pd.read_csv(tsv_file, sep='\\t')\n",
    "        self.df = self.df.dropna()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        if self.df['label'].dtype == 'float64':\n",
    "            self.df['label'] = self.df['label'].astype('float32')\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        dataslice = self.df.iloc[idx]\n",
    "        sample = {'text':dataslice['text'], 'label':dataslice['label']}\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6463e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTrainDataLoader():\n",
    "    '''\n",
    "    Each time, a random integer selects a dataset and load a batch of data {text, label} from it. Return i_task and data\n",
    "    \n",
    "    a iterator\n",
    "    Known issue: large dataset may have not iterate once, small datasets may have been iterated many times\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, selected_task, batch_size, shuffle, num_workers):\n",
    "        self.tasks = selected_task\n",
    "        self.split = 'train'\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.num_tasks = len(self.tasks)\n",
    "        self.datasets = []\n",
    "        self.dataloaders = []\n",
    "        self.dataloaderiters = []\n",
    "        self.len = 0\n",
    "        for task in self.tasks:\n",
    "            self.datasets.append(MyDataset(f'../data/xslue/processed/{self.split}/{task}.tsv'))\n",
    "            self.dataloaders.append(DataLoader(self.datasets[-1], batch_size=self.batch_size, shuffle=self.shuffle, num_workers=self.num_workers)) \n",
    "            self.dataloaderiters.append(self.dataloaders[-1]._get_iterator())\n",
    "            self.len += len(self.dataloaders[-1])\n",
    "    def __len__(self):   \n",
    "        return self.len\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        i_task = np.random.randint(self.num_tasks)\n",
    "        if self.n < self.len:\n",
    "            self.n += 1\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        dataloaderiter = self.dataloaderiters[i_task]    \n",
    "        try: \n",
    "            batch = next(dataloaderiter)\n",
    "        except StopIteration:\n",
    "#             self.dataloaderiters[i_task]._reset(self.dataloaders[i_task])\n",
    "#             dataloaderiter = self.dataloaderiters[i_task]\n",
    "            self.dataloaderiters[i_task] = iter(self.dataloaders[i_task])\n",
    "            dataloaderiter = self.dataloaderiters[i_task]\n",
    "            batch = next(dataloaderiter)\n",
    "        return i_task, batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61019a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskTestDataLoader():\n",
    "    '''\n",
    "    For dev and test\n",
    "    \n",
    "    a generator\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, tasks, split, batch_size, shuffle, num_workers):\n",
    "        assert split in ['dev', 'test'], 'not implemented'\n",
    "        self.tasks = tasks\n",
    "        self.split = split\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.num_tasks = len(tasks)\n",
    "        self.datasets = []\n",
    "        self.dataloaders = []\n",
    "        self.dataloaderiters = []\n",
    "        self.len = 0\n",
    "        for task in tasks:\n",
    "            self.datasets.append(MyDataset(f'../data/xslue/processed/{self.split}/{task}.tsv'))\n",
    "            self.dataloaders.append(DataLoader(self.datasets[-1], batch_size=self.batch_size, shuffle=self.shuffle, num_workers=self.num_workers))\n",
    "            self.len += len(self.dataloaders[-1])\n",
    "        self.i_task = 0\n",
    "    def __len__(self):   \n",
    "        return self.len\n",
    "\n",
    "    def __iter__(self):\n",
    "        for i_task in range(self.num_tasks):\n",
    "            dataloader = self.dataloaders[i_task]\n",
    "            for batch in dataloader:\n",
    "                yield i_task, batch\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a28b2",
   "metadata": {},
   "source": [
    "# multi-task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed50b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        output = self.hidden(self.dropout(sent_emb)).squeeze(1)\n",
    "\n",
    "        loss = self.loss_fn(output, label)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c097a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, num_labels, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, self.num_labels)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        output = self.hidden(self.dropout(sent_emb))\n",
    "        \n",
    "        loss = self.loss_fn(output.view(-1, self.num_labels), label.view(-1))\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eec4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskBert(pretrained_model_class):\n",
    "    def __init__(self, config, selected_task):\n",
    "        super().__init__(config)\n",
    "        self.basemodel = model_class.from_pretrained(model_name)\n",
    "        self.style_heads = nn.ModuleList()\n",
    "        for task in selected_task:\n",
    "            if tasks[task] == 1:\n",
    "                self.style_heads.append(RegressionHead())\n",
    "            else:\n",
    "                self.style_heads.append(ClassificationHead(tasks[task]))\n",
    "    def forward(self, i_task=None, label=None, **kwargs):\n",
    "        output = self.basemodel(**kwargs)\n",
    "        if 'pooler_output' in output:\n",
    "            sent_emb = output['pooler_output']\n",
    "        else:\n",
    "            sent_emb = output['last_hidden_state'][:,0,:]\n",
    "        \n",
    "        output, loss = self.style_heads[i_task](sent_emb, label) \n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6acf874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss(losses):\n",
    "    for k in losses:\n",
    "        print(f'{losses[k]:4.4f}', end=' ')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7439d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, selected_task, split):\n",
    "    val_loss = collections.defaultdict(float)\n",
    "    val_size = collections.defaultdict(int)\n",
    "    overall_acc = torchmetrics.Accuracy() \n",
    "    task_accs = [torchmetrics.Accuracy() for i in range(len(selected_task))] \n",
    "    \n",
    "    if split == 'train':\n",
    "        mt_dataloader = MultiTaskTrainDataLoader(selected_task, 32, False, 4)\n",
    "    else:\n",
    "        mt_dataloader = MultiTaskTestDataLoader(selected_task, 'dev', 32, False, 4)\n",
    "        \n",
    "    model.eval()\n",
    "    for data in tqdm(mt_dataloader, leave=False):  \n",
    "        i_task, batch = data\n",
    "        label = batch['label'].to(device)\n",
    "        size = len(label)\n",
    "        del batch['label']\n",
    "        tokens = tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "        output, loss = model(**tokens, i_task=i_task,  label=label)\n",
    "        overall_acc.update(output.to('cpu').detach(), label.to('cpu').detach())\n",
    "        task_accs[i_task].update(output.to('cpu').detach(), label.to('cpu').detach())\n",
    "        tokens = None\n",
    "        output = None\n",
    "        val_loss[i_task] += loss.detach().item()*size\n",
    "        val_size[i_task] += size\n",
    "    \n",
    "    accs = []\n",
    "    for i_task in val_loss:\n",
    "        val_loss[i_task] /= val_size[i_task]\n",
    "        accs.append(task_accs[i_task].compute())\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    return val_loss, overall_acc.compute(), accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01767cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n",
    "    \"\"\"\n",
    "    Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after\n",
    "    a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.\n",
    "    Args:\n",
    "        optimizer ([`~torch.optim.Optimizer`]):\n",
    "            The optimizer for which to schedule the learning rate.\n",
    "        num_warmup_steps (`int`):\n",
    "            The number of steps for the warmup phase.\n",
    "        num_training_steps (`int`):\n",
    "            The total number of training steps.\n",
    "        last_epoch (`int`, *optional*, defaults to -1):\n",
    "            The index of the last epoch when resuming training.\n",
    "    Return:\n",
    "        `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    def lr_lambda(current_step: int):\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        return max(\n",
    "            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        )\n",
    "\n",
    "    return lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d73059",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6fdc2",
   "metadata": {},
   "source": [
    "## single task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a61ee71",
   "metadata": {},
   "source": [
    "### ShortHumor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ad00f0",
   "metadata": {},
   "source": [
    "#### freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "801bd0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_task = [\n",
    "                 'ShortHumor', \n",
    "#                  'VUA',\n",
    "                ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8edd545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = MultiTaskTrainDataLoader(selected_task, 32, False, 4)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6225c252",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "327851f1facb48928c6da65fd9df5f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 0, 'train_loss': 0.6093603514596295, 'train_acc': 0.6768603920936584, 'val_loss': 0.6037419830616592, 'val_acc': 0.6787695288658142}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f773cbd96f1464eaeb51eea492b96be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 1, 'train_loss': 0.5694271674443419, 'train_acc': 0.6997169256210327, 'val_loss': 0.5666932542697986, 'val_acc': 0.7009581327438354}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89f9d15df2c4093a7533bed82f3dc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 2, 'train_loss': 0.542740888546511, 'train_acc': 0.7273352742195129, 'val_loss': 0.5414822714171262, 'val_acc': 0.7216339111328125}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db90ff53549c4b0db4dcf65b89ea9a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 3, 'train_loss': 0.5291925388148391, 'train_acc': 0.7452183961868286, 'val_loss': 0.5293197461408133, 'val_acc': 0.7367624640464783}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6ffbe6f79045bca1def22ea7263751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 4, 'train_loss': 0.5281198126989516, 'train_acc': 0.7454035878181458, 'val_loss': 0.5283215008657266, 'val_acc': 0.738779604434967}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "num_epoch = 5\n",
    "\n",
    "mt_model = MultiTaskBert(config, selected_task).to(device)\n",
    "for param in mt_model.basemodel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(mt_model.parameters(), lr=5e-5)\n",
    "# optimizer = optim.SGD(mt_model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=500)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5, total_steps=num_epoch*len(train_dataloader)) \n",
    "\n",
    "df = pd.DataFrame(columns=['i_iter', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "for i_epoch in range(num_epoch):\n",
    "    for i_iter, data in enumerate(tqdm(train_dataloader)):  \n",
    "\n",
    "        i_task, batch = data\n",
    "        optimizer.zero_grad()\n",
    "        label = batch['label'].to(device)\n",
    "        del batch['label']\n",
    "        tokens = tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "        output, loss = mt_model(**tokens, i_task=i_task,  label=label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "#         if i_iter in [0, 10, 25, 50, 100]:\n",
    "#             train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "#             val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "#             result = {'i_iter':i_iter, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "#             df = df.append(result , ignore_index=True)\n",
    "#             print(result)\n",
    "#         if i_iter>100:\n",
    "#             break\n",
    "\n",
    "    train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "    val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "    result = {'i_epoch':i_epoch, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "    df = df.append(result , ignore_index=True)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60261c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_iter</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>i_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609360</td>\n",
       "      <td>0.676860</td>\n",
       "      <td>0.603742</td>\n",
       "      <td>0.678770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.569427</td>\n",
       "      <td>0.699717</td>\n",
       "      <td>0.566693</td>\n",
       "      <td>0.700958</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542741</td>\n",
       "      <td>0.727335</td>\n",
       "      <td>0.541482</td>\n",
       "      <td>0.721634</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.529193</td>\n",
       "      <td>0.745218</td>\n",
       "      <td>0.529320</td>\n",
       "      <td>0.736762</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528120</td>\n",
       "      <td>0.745404</td>\n",
       "      <td>0.528322</td>\n",
       "      <td>0.738780</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_iter  train_loss  train_acc  val_loss   val_acc  i_epoch\n",
       "0     NaN    0.609360   0.676860  0.603742  0.678770      0.0\n",
       "1     NaN    0.569427   0.699717  0.566693  0.700958      1.0\n",
       "2     NaN    0.542741   0.727335  0.541482  0.721634      2.0\n",
       "3     NaN    0.529193   0.745218  0.529320  0.736762      3.0\n",
       "4     NaN    0.528120   0.745404  0.528322  0.738780      4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with onecycle lr_scheduler\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c48428",
   "metadata": {},
   "source": [
    "#### unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8acd7892",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_task = [\n",
    "                 'ShortHumor', \n",
    "#                  'VUA',\n",
    "                ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54b39cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = MultiTaskTrainDataLoader(selected_task, 32, False, 4)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98a062bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 0, 'train_loss': 0.07624205425341254, 'train_acc': 0.9742070436477661, 'val_loss': 0.1591183666442298, 'val_acc': 0.940494179725647}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f19a2515550>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f19a2515550>Exception ignored in: \n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f19a2515550><function _MultiProcessingDataLoaderIter.__del__ at 0x7f19a2515550>Traceback (most recent call last):\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "\n",
      "          File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "if w.is_alive():\n",
      "        if w.is_alive():if w.is_alive():\n",
      "    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "  File \"/home/jz17d/anaconda3/envs/torch/lib/python3.9/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError            assert self._parent_pid == os.getpid(), 'can only test a child process'assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      ": AssertionErrorcan only test a child process: \n",
      "AssertionError: can only test a child processcan only test a child process\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 1, 'train_loss': 0.030277462488580556, 'train_acc': 0.9911113381385803, 'val_loss': 0.14881271859926823, 'val_acc': 0.9520927667617798}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 2, 'train_loss': 0.011882821528125562, 'train_acc': 0.9964551329612732, 'val_loss': 0.15233089646162015, 'val_acc': 0.9546142220497131}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 3, 'train_loss': 0.0017386663505057035, 'train_acc': 0.9996032118797302, 'val_loss': 0.14110398142522484, 'val_acc': 0.9667171239852905}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1182 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/62 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 4, 'train_loss': 0.000905192531714256, 'train_acc': 0.9998412728309631, 'val_loss': 0.15679824659722963, 'val_acc': 0.9636913537979126}\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "num_epoch = 5\n",
    "\n",
    "mt_model = MultiTaskBert(config, selected_task).to(device)\n",
    "# for param in mt_model.basemodel.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(mt_model.parameters(), lr=5e-5)\n",
    "# optimizer = optim.SGD(mt_model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=500)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5, total_steps=num_epoch*len(train_dataloader)) \n",
    "\n",
    "df = pd.DataFrame(columns=['i_iter', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "for i_epoch in range(num_epoch):\n",
    "    for i_iter, data in enumerate(tqdm(train_dataloader)):  \n",
    "\n",
    "        i_task, batch = data\n",
    "        optimizer.zero_grad()\n",
    "        label = batch['label'].to(device)\n",
    "        del batch['label']\n",
    "        tokens = tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "        output, loss = mt_model(**tokens, i_task=i_task,  label=label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "#         if i_iter in [0, 10, 25, 50, 100]:\n",
    "#             train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "#             val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "#             result = {'i_iter':i_iter, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "#             df = df.append(result , ignore_index=True)\n",
    "#             print(result)\n",
    "#         if i_iter>100:\n",
    "#             break\n",
    "\n",
    "    train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "    val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "    result = {'i_epoch':i_epoch, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "    df = df.append(result , ignore_index=True)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57e225a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_iter</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>i_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076242</td>\n",
       "      <td>0.974207</td>\n",
       "      <td>0.159118</td>\n",
       "      <td>0.940494</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030277</td>\n",
       "      <td>0.991111</td>\n",
       "      <td>0.148813</td>\n",
       "      <td>0.952093</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>0.996455</td>\n",
       "      <td>0.152331</td>\n",
       "      <td>0.954614</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.999603</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>0.966717</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.156798</td>\n",
       "      <td>0.963691</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_iter  train_loss  train_acc  val_loss   val_acc  i_epoch\n",
       "0     NaN    0.076242   0.974207  0.159118  0.940494      0.0\n",
       "1     NaN    0.030277   0.991111  0.148813  0.952093      1.0\n",
       "2     NaN    0.011883   0.996455  0.152331  0.954614      2.0\n",
       "3     NaN    0.001739   0.999603  0.141104  0.966717      3.0\n",
       "4     NaN    0.000905   0.999841  0.156798  0.963691      4.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df # ShortHumor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6f88a",
   "metadata": {},
   "source": [
    "### SarcasmGhosh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a5c0d",
   "metadata": {},
   "source": [
    "#### freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d64db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_task = [\n",
    "                'SarcasmGhosh',\n",
    "#                 'SARC',\n",
    "                ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928cc7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = MultiTaskTrainDataLoader(selected_task, 32, False, 4)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a39f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/xslue/processed/train/SarcasmGhosh.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31b2b916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, {'text': ['@0430yes i hope youre lurking rn. i want to listen to hallucination & wanna love you again live someday, pretty please?! 😭 😭 😭', \"05 really taught me a valuable lesson I'm never gonna be late again! #Not\", '@098BERRY Never had a voice to protest, so you fed me shit to digest. I wish I had a reason, my flaws are open season.', '@0hMySt4rs Rest in peace & love to you and your family', '100 days until Christmas! 🌲 #too soon #not ready yet', \"@100_ThingsILove @WhatNinaSpotted yay! Can't wait to be reunited with you huni! Xx\", \"100 words short of the word requirement but I don't care, I'm going to bed. #rebel #ihatehistory\", '@1010xlhacker it was nice hanging out this afternoon. I had a great time!', '10k walk this morning. We did an awesome job.', '10 minutes to eat #challengeaccepted', '10 Times One Direction Had the Perfect Love Song for Every Relationship :', \"#10TurnOns Yet again if you list them on twitter you're garbage.\", '@11aawwgg021 wow! sweet butt for all of them i love :)', \"11 o'clock cant come no faster\", \"11pm on a Saturday night and Im in my room feeling bad for the lady who didn't get bail yesterday\", \"12:30 can't come any faster\", '$13, 180 invested in our mission on #GiveMiamiDay! Thank you! So close to our 15k goal. Help us get there!', '15-year-old boy fighting for his life and another injured after stabbing at London school', '17 years ago today we made one of the best choices of our lives. Here \" s to 17 years of being smoke free!', '180 days until summer! #notthatbad on the bright side we only have 2 days until a 4 day weekend', '1966 was when In Cold Blood scared us, Bruno Sammartino slammed us & John Lennon shocked us :', '19 Million Project brings journalists, coders and humanitarians together around the migrant crisis', '1 am and I can already tell today will be a great day', \"@1dChicas_ @kingjennny first reaction to the pants I yelled WHAT ARE THOSE PANTS! But I fucking love those pants. They're so Harry\", \"1D family! We want to see all of the fan art you've made over the years, show us using #1DUltimateArt!\", \"1D give boring performances it's always the same #MTVStars One Direction\", '#1DonJonathanRoss i have never laughed so much in an interview 😂 H : His face says \" shit i\\'ve got chlamydia \"', '#1DonJonathanRoss IVE NEVER LAUGHED SO MUCH IN MY LIFE', '1d the kings of never promoting yet keeping their winning streak', '1) Good Grades 2) Social Life 3) Excel in your sport 4) Sleep You may only choose 2... Good luck', '@1kunalbahl Can you please reply', \"1 sleep until #StrictlyAgainstBreastCancer at Dublin's convention centre. Can't wait 2 c all the brave dancers @BreastCancerIre\"], 'label': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0])})\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataloader:\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15ce777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13cc65494b34153a5ffa2eab19486c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 0, 'train_loss': 2.3325773350359724, 'train_acc': 0.4652840495109558, 'val_loss': 4.353245750458509, 'val_acc': 0.03819223493337631}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5ce61b63e1448e9c9d7bf9c0352830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 1, 'train_loss': 2.197716439109672, 'train_acc': 0.4651834964752197, 'val_loss': 4.086464829083691, 'val_acc': 0.03819223493337631}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0dea53a7ad4d8bbcb2b4f7a77d48d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770f5d1d8922404eb518112dc4760ced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1068934/1759285739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#             break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_overall_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_task_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m     \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_overall_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_task_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'i_epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_overall_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mval_overall_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1068934/1364713271.py\u001b[0m in \u001b[0;36mvalidate\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi_task\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moverall_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mtask_accs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_task\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchmetrics/metric.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_called\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchmetrics/classification/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \"\"\"\n\u001b[1;32m    227\u001b[0m         \u001b[0;34m\"\"\" returns the mode of the data (binary, multi label, multi class, multi-dim multi class) \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchmetrics/functional/classification/accuracy.py\u001b[0m in \u001b[0;36m_mode\u001b[0;34m(preds, target, threshold, top_k, num_classes, multiclass)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \"\"\"\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     mode = _check_classification_inputs(\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmulticlass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_check_classification_inputs\u001b[0;34m(preds, target, threshold, num_classes, multiclass, top_k)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# Basic validation (that does not need case/type information)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0m_basic_input_validation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulticlass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;31m# Check that shape/types fall into one of the cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torchmetrics/utilities/checks.py\u001b[0m in \u001b[0;36m_basic_input_validation\u001b[0;34m(preds, target, threshold, multiclass)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be an integer tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The `target` has to be a non-negative tensor.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "num_epoch = 5\n",
    "\n",
    "mt_model = MultiTaskBert(config, selected_task).to(device)\n",
    "for param in mt_model.basemodel.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(mt_model.parameters(), lr=5e-5)\n",
    "# optimizer = optim.SGD(mt_model.parameters(), lr=0.001)\n",
    "\n",
    "num_warmup_steps=500\n",
    "num_training_steps=num_epoch*len(train_dataloader)\n",
    "def lr_lambda(current_step: int):\n",
    "    if current_step < num_warmup_steps:\n",
    "        return float(current_step) / float(max(1, num_warmup_steps))\n",
    "    return max(\n",
    "        0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "    )\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda, -1)\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=500)\n",
    "# scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5, total_steps=num_epoch*len(train_dataloader)) \n",
    "\n",
    "df = pd.DataFrame(columns=['i_iter', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "for i_epoch in range(num_epoch):\n",
    "    for i_iter, data in enumerate(tqdm(train_dataloader)):  \n",
    "\n",
    "        i_task, batch = data\n",
    "        optimizer.zero_grad()\n",
    "        label = batch['label'].to(device)\n",
    "        del batch['label']\n",
    "        tokens = tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "        output, loss = mt_model(**tokens, i_task=i_task,  label=label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "#         if i_iter in [0, 10, 25, 50, 100]:\n",
    "#             train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "#             val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "#             result = {'i_iter':i_iter, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "#             df = df.append(result , ignore_index=True)\n",
    "#             print(result)\n",
    "#         if i_iter>100:\n",
    "#             break\n",
    "\n",
    "    train_loss, train_overall_acc, train_task_accs = validate(mt_model, selected_task, split='train')\n",
    "    val_loss, val_overall_acc, val_task_accs = validate(mt_model, selected_task, split='val')\n",
    "    result = {'i_epoch':i_epoch, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "    df = df.append(result , ignore_index=True)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d1567af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SarcasmGhosh']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15f7a9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(float, {0: 2.197716439109672})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4167148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b4aece",
   "metadata": {},
   "source": [
    "#### unfreeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc47e55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_task = [\n",
    "                'SarcasmGhosh',\n",
    "                ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "243e5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = MultiTaskTrainDataLoader(selected_task, 32, False, 4)\n",
    "\n",
    "config = config_class.from_pretrained(model_name)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "114e36c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c21a6f35da44519e24e78214514384",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'i_epoch': 0, 'train_loss': 4.307537162129135, 'train_acc': 0.46475616097450256, 'val_loss': 7.750239974564804, 'val_acc': 0.036919157952070236}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbcd7f2145db4fd282504ce08964e916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1244 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1051488/2159772640.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi_task\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/optim/adamw.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             F.adamw(params_with_grad,\n\u001b[0m\u001b[1;32m    138\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "num_epoch = 5\n",
    "\n",
    "mt_model = MultiTaskBert(config, selected_task).to(device)\n",
    "# for param in mt_model.basemodel.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "optimizer = optim.AdamW(mt_model.parameters(), lr=5e-5)\n",
    "# optimizer = optim.SGD(mt_model.parameters(), lr=0.001)\n",
    "\n",
    "# scheduler = lr_scheduler.LinearLR(optimizer, start_factor=0.01, total_iters=500)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer, max_lr=5e-5, total_steps=num_epoch*len(train_dataloader)) \n",
    "\n",
    "df = pd.DataFrame(columns=['i_iter', 'train_loss', 'train_acc', 'val_loss', 'val_acc'])\n",
    "\n",
    "for i_epoch in range(num_epoch):\n",
    "    for i_iter, data in enumerate(tqdm(train_dataloader)):  \n",
    "\n",
    "        i_task, batch = data\n",
    "        optimizer.zero_grad()\n",
    "        label = batch['label'].to(device)\n",
    "        del batch['label']\n",
    "        tokens = tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "        output, loss = mt_model(**tokens, i_task=i_task,  label=label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "#         if i_iter in [0, 10, 25, 50, 100]:\n",
    "#             train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "#             val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "#             result = {'i_iter':i_iter, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "#             df = df.append(result , ignore_index=True)\n",
    "#             print(result)\n",
    "#         if i_iter>100:\n",
    "#             break\n",
    "\n",
    "    train_loss, train_overall_acc, train_task_accs = validate(mt_model, 'train')\n",
    "    val_loss, val_overall_acc, val_task_accs = validate(mt_model, 'val')\n",
    "    result = {'i_epoch':i_epoch, 'train_loss':train_loss[0], 'train_acc':train_overall_acc.item(), 'val_loss':val_loss[0], 'val_acc':val_overall_acc.item()}\n",
    "    df = df.append(result , ignore_index=True)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c6acea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i_iter</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_acc</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>i_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.307537</td>\n",
       "      <td>0.464756</td>\n",
       "      <td>7.75024</td>\n",
       "      <td>0.036919</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i_iter  train_loss  train_acc  val_loss   val_acc  i_epoch\n",
       "0     NaN    4.307537   0.464756   7.75024  0.036919      0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e170e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "372.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
