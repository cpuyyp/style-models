{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f27686",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#imports-and-functions\" data-toc-modified-id=\"imports-and-functions-1\">imports and functions</a></span></li><li><span><a href=\"#experiments\" data-toc-modified-id=\"experiments-2\">experiments</a></span><ul class=\"toc-item\"><li><span><a href=\"#0\" data-toc-modified-id=\"0-2.1\">0</a></span></li><li><span><a href=\"#1\" data-toc-modified-id=\"1-2.2\">1</a></span></li><li><span><a href=\"#2\" data-toc-modified-id=\"2-2.3\">2</a></span></li><li><span><a href=\"#3\" data-toc-modified-id=\"3-2.4\">3</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c7646e",
   "metadata": {},
   "source": [
    "# imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ffd9154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "# import torchmetrics\n",
    "\n",
    "import datasets\n",
    "from datasets import load_metric\n",
    "from transformers import AutoConfig, AutoTokenizer, BertModel, RobertaModel\n",
    "from transformers import BertForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1417f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/issues/5486\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477d9170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bce83c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrowdFlower': 13,\n",
       " 'DailyDialog': 7,\n",
       " 'EmoBank_Valence': 1,\n",
       " 'EmoBank_Arousal': 1,\n",
       " 'EmoBank_Dominance': 1,\n",
       " 'HateOffensive': 3,\n",
       " 'PASTEL_age': 8,\n",
       " 'PASTEL_country': 2,\n",
       " 'PASTEL_education': 10,\n",
       " 'PASTEL_ethnic': 10,\n",
       " 'PASTEL_gender': 3,\n",
       " 'PASTEL_politics': 3,\n",
       " 'PASTEL_tod': 5,\n",
       " 'SARC': 2,\n",
       " 'SarcasmGhosh': 2,\n",
       " 'SentiTreeBank': 1,\n",
       " 'ShortHumor': 2,\n",
       " 'ShortJokeKaggle': 2,\n",
       " 'ShortRomance': 2,\n",
       " 'StanfordPoliteness': 1,\n",
       " 'TroFi': 2,\n",
       " 'VUA': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../../data/xslue/tasks.json', 'r') as f:\n",
    "    tasks = json.load(f)\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5440114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    # currently it's a Mapping-style dataset. Not sure if a Iterable-style dataset will be better\n",
    "    def __init__(self, tsv_file):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "        self.df = pd.read_csv(tsv_file, sep='\\t')\n",
    "        self.df = self.df.dropna()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        self.encodings = self.tokenizer(self.df['text'].tolist(), truncation=True, padding=True, max_length=128)\n",
    "        if self.df['label'].dtype == 'float64':\n",
    "            self.df['label'] = self.df['label'].astype('float32')\n",
    "        self.labels = self.df['label'].tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        item = {k: torch.tensor(v[idx]) for k, v in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor([self.labels[idx]])\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e597b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr = load_metric(\"pearsonr\")\n",
    "spearmanr = load_metric(\"spearmanr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84965a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU memory usage: 6617 - 6680mb with bs 32\n",
    "# bs 64 gives OOM\n",
    "# bs 48 GPU memory 7894\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5106faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(task, freeze_bert=False):\n",
    "    torch.cuda.empty_cache()\n",
    "    model = None\n",
    "    trainer = None \n",
    "    num_labels = tasks[task]\n",
    "    \n",
    "    data_folder = '../../data/xslue'\n",
    "    train_dataset = MyDataset(f'{data_folder}/processed/train/{task}.tsv')\n",
    "    test_dataset = MyDataset(f'{data_folder}/processed/test/{task}.tsv')\n",
    "    valid_dataset = MyDataset(f'{data_folder}/processed/dev/{task}.tsv')\n",
    "    \n",
    "    singletaskbert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels) \n",
    "    if freeze_bert:\n",
    "        for param in singletaskbert.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    result_folder = '../../result'\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f\"{result_folder}/baselines/{task+'_freezed' if freeze_bert else task}\",   # output directory\n",
    "        num_train_epochs=5,              # total number of training epochs\n",
    "        per_device_train_batch_size=batch_size,  # batch size per device during training\n",
    "        per_device_eval_batch_size=batch_size,   # batch size for evaluation\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir=f\"{result_folder}/baselines/{task+'_freezed' if freeze_bert else task}/logs\",  # directory for storing logs\n",
    "#         logging_first_step = True, \n",
    "#         logging_steps=500,               # log & save weights each logging_steps\n",
    "#         save_steps=500,\n",
    "        evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "        save_total_limit = 1,\n",
    "        save_strategy = 'epoch',\n",
    "        load_best_model_at_end=True, # decide on loss\n",
    "    )\n",
    "    \n",
    "    if num_labels == 1:\n",
    "        def compute_metrics(pred):\n",
    "            predictions, labels = pred\n",
    "            rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "            return {\"rmse\": rmse}\n",
    "    elif num_labels == 2:\n",
    "        def compute_metrics(pred):\n",
    "            labels = pred.label_ids\n",
    "            preds = pred.predictions.argmax(-1)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            return {\n",
    "                'accuracy': acc,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            }\n",
    "    else:\n",
    "        def compute_metrics(pred):\n",
    "            labels = pred.label_ids\n",
    "            preds = pred.predictions.argmax(-1)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
    "            acc = accuracy_score(labels, preds)\n",
    "            return {\n",
    "                'accuracy': acc,\n",
    "                'f1': f1,\n",
    "                'precision': precision,\n",
    "                'recall': recall\n",
    "            }\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model=singletaskbert,   # the instantiated Transformers model to be trained\n",
    "        args=training_args,                  # training arguments, defined above\n",
    "        train_dataset=train_dataset,         # training dataset\n",
    "        eval_dataset=valid_dataset,          # evaluation dataset\n",
    "#         test_dataset=test_dataset,            # test dataset\n",
    "        compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    "    )\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cbcb8a",
   "metadata": {},
   "source": [
    "# experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c41714",
   "metadata": {},
   "source": [
    "## 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8304207b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 36010\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 5630\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1242' max='5630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1242/5630 10:04 < 35:39, 2.05 it/s, Epoch 1.10/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.833100</td>\n",
       "      <td>1.836723</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>0.268430</td>\n",
       "      <td>0.185773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1968\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ../../result/baselines/CrowdFlower/checkpoint-1126\n",
      "Configuration saved in ../../result/baselines/CrowdFlower/checkpoint-1126/config.json\n",
      "Model weights saved in ../../result/baselines/CrowdFlower/checkpoint-1126/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "task = list(tasks.keys())[0]\n",
    "train_baseline(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921fd381",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[0]\n",
    "train_baseline(task, freeze_bert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd85f3d",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d556d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[1]\n",
    "train_baseline(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db281c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[1]\n",
    "train_baseline(task, freeze_bert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126960c5",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57883728",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[2]\n",
    "train_baseline(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54edf21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[2]\n",
    "train_baseline(task, freeze_bert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a795a",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[3]\n",
    "train_baseline(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4481ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = list(tasks.keys())[3]\n",
    "train_baseline(task, freeze_bert=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3eb65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
