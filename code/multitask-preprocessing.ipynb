{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90028d8f",
   "metadata": {},
   "source": [
    "# Preprocessing all datasets \n",
    "The purpose is making all files have exactly the same columns \"index\", \"text\", and \"label\".  \n",
    "A dictionary named tasks is also generated, specifying number of labels for each task. If number of labels is one, means it's a regression task\n",
    "\n",
    "Classification tasks are transformed into 0-indexed labels, while regression tasks are transformed with MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4323776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c48cdd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        'CrowdFlower',  # not used in xslue \n",
    "        'DailyDialog',\n",
    "        'EmoBank',\n",
    "        #  'GYAFC', # no data provided\n",
    "        'HateOffensive',\n",
    "        'PASTEL',\n",
    "        'SARC',\n",
    "        'SarcasmGhosh',\n",
    "        'SentiTreeBank',\n",
    "        'ShortHumor',\n",
    "        'ShortJokeKaggle',\n",
    "        'ShortRomance',\n",
    "        'StanfordPoliteness',\n",
    "        'TroFi',\n",
    "        'VUA',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e0315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = ['train', 'test', 'dev']\n",
    "in_dir = '../data/xslue/raw'\n",
    "out_dir = '../data/xslue/processed'\n",
    "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "tasks = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b724cc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CrowdFlower\n",
    "dataset = datasets[0]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None, usecols = [0,1,2])\n",
    "    df.columns = ['index', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0420d3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DailyDialog\n",
    "dataset = datasets[1]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df = df.reset_index()\n",
    "    df.columns = ['index', 'text', 'label']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "            \n",
    "    df.to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce043e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.fit_transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.fit_transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.fit_transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
      "/tmp/ipykernel_24173/1328781712.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = df[attr]\n",
      "/tmp/ipykernel_24173/1328781712.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n"
     ]
    }
   ],
   "source": [
    "# EmoBank\n",
    "dataset = datasets[2]\n",
    "attributes = ['Valence', 'Arousal', 'Dominance']\n",
    "for attr in attributes:\n",
    "    for s in split:\n",
    "        df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "        df.columns = ['index', 'Valence', 'Arousal', 'Dominance', 'text']\n",
    "        df_temp = df[['index', 'text']]\n",
    "        df_temp['label'] = df[attr]\n",
    "        \n",
    "        if s == 'train':\n",
    "            num_label = len(df_temp['label'].unique())\n",
    "            if num_label < 20: # classification task\n",
    "                tasks[dataset+'_'+attr] = num_label \n",
    "                le = preprocessing.LabelEncoder()\n",
    "                df_temp['label'] = le.fit_transform(df_temp['label'])\n",
    "            else: # regression task\n",
    "                tasks[dataset+'_'+attr] = 1 \n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                df_temp['label'] = scaler.fit_transform(df_temp['label'].values.reshape(-1,1))\n",
    "        else:\n",
    "            if num_label < 20: # classification task\n",
    "                df_temp['label'] = le.transform(df_temp['label'])\n",
    "            else: # regression task\n",
    "                df_temp['label'] = scaler.transform(df_temp['label'].values.reshape(-1,1))\n",
    "        \n",
    "        df_temp.to_csv(os.path.join(out_dir, s, dataset+'_'+attr+'.tsv'), sep = '\\t', index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a11c85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HateOffensive\n",
    "dataset = datasets[3]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "166bd049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASTEL\n",
    "dataset = datasets[4]\n",
    "attributes = ['age', 'country', 'education', 'ethnic', 'gender', 'politics', 'tod']\n",
    "for attr in attributes:\n",
    "    for s in split:\n",
    "        df = pd.read_csv(os.path.join(in_dir, dataset, s+'_'+attr+'.tsv'), sep = '\\t', header=None, usecols=[0,1,2])\n",
    "        df.columns = ['index', 'label', 'text']\n",
    "        \n",
    "        if s == 'train':\n",
    "            num_label = len(df['label'].unique())\n",
    "            if num_label < 20: # classification task\n",
    "                tasks[dataset+'_'+attr] = num_label \n",
    "                le = preprocessing.LabelEncoder()\n",
    "                df['label'] = le.fit_transform(df['label'])\n",
    "            else: # regression task\n",
    "                tasks[dataset+'_'+attr] = 1 \n",
    "                scaler = preprocessing.MinMaxScaler()\n",
    "                df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "        else:\n",
    "            if num_label < 20: # classification task\n",
    "                df['label'] = le.transform(df['label'])\n",
    "            else: # regression task\n",
    "                df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "        \n",
    "        df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'_'+attr+'.tsv'), sep = '\\t', index=False)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8a646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SARC\n",
    "dataset = datasets[5]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f15fcd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SarcasmGhosh\n",
    "dataset = datasets[6]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d7f795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentiTreeBank\n",
    "# I only choose to use the sentiment col. The fine and coarse columns are infered from the sentiment col. \n",
    "# In xslue, sentiment col is transformed into a binary classification\n",
    "dataset = datasets[7]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t')\n",
    "    df = df[['id', 'phrase', 'sentiment']].rename(columns={'id':'index', 'phrase':'text', 'sentiment':'label'})\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "                \n",
    "    df.to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28904313",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n",
      "\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "Skipping line 185: '\t' expected after '\"'\n",
      "Skipping line 1118: '\t' expected after '\"'\n",
      "Skipping line 1223: '\t' expected after '\"'\n",
      "Skipping line 1854: '\t' expected after '\"'\n",
      "Skipping line 1866: '\t' expected after '\"'\n",
      "Skipping line 1989: unexpected end of data\n"
     ]
    }
   ],
   "source": [
    "# ShortHumor\n",
    "# The source (I named it) may be used as labels too. The xslue paper only use the binary label.\n",
    "dataset = datasets[8]\n",
    "for s in split:\n",
    "    if s == 'dev':\n",
    "        df = pd.read_csv(os.path.join(in_dir, dataset, 'dev.tsv'), error_bad_lines=False, engine=\"python\", sep = '\\t', header=None)\n",
    "    else:    \n",
    "        df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'source', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "374cdba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShortJokeKaggle\n",
    "# The source (I named it) may be used as labels too. The xslue paper only use the binary label.\n",
    "dataset = datasets[9]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'source', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "            \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d26749dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ShortRomance\n",
    "# The source (I named it) may be used as labels too. The xslue paper only use the binary label.\n",
    "dataset = datasets[10]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'source', 'label', 'text']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "            \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46f4443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# StanfordPoliteness\n",
    "# I use the float score. In the xslue paper, the scores are transformed into a binary category variable\n",
    "dataset = datasets[11]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['source', 'index', 'text', 'label']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "            \n",
    "    df[['index', 'text', 'label']].to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f2d057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TroFi\n",
    "dataset = datasets[12]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'text', 'label']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df.to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0450ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VUA\n",
    "dataset = datasets[13]\n",
    "for s in split:\n",
    "    df = pd.read_csv(os.path.join(in_dir, dataset, s+'.tsv'), sep = '\\t', header=None)\n",
    "    df.columns = ['index', 'text', 'label']\n",
    "    \n",
    "    if s == 'train':\n",
    "        num_label = len(df['label'].unique())\n",
    "        if num_label < 20: # classification task\n",
    "            tasks[dataset] = num_label \n",
    "            le = preprocessing.LabelEncoder()\n",
    "            df['label'] = le.fit_transform(df['label'])\n",
    "        else: # regression task\n",
    "            tasks[dataset] = 1 \n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df['label'] = scaler.fit_transform(df['label'].values.reshape(-1,1))\n",
    "    else:\n",
    "        if num_label < 20: # classification task\n",
    "            df['label'] = le.transform(df['label'])\n",
    "        else: # regression task\n",
    "            df['label'] = scaler.transform(df['label'].values.reshape(-1,1))\n",
    "    \n",
    "    df.to_csv(os.path.join(out_dir, s, dataset+'.tsv'), sep = '\\t', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5cdcb83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CrowdFlower': 13,\n",
       " 'DailyDialog': 7,\n",
       " 'EmoBank_Valence': 1,\n",
       " 'EmoBank_Arousal': 1,\n",
       " 'EmoBank_Dominance': 1,\n",
       " 'HateOffensive': 3,\n",
       " 'PASTEL_age': 8,\n",
       " 'PASTEL_country': 2,\n",
       " 'PASTEL_education': 10,\n",
       " 'PASTEL_ethnic': 10,\n",
       " 'PASTEL_gender': 3,\n",
       " 'PASTEL_politics': 3,\n",
       " 'PASTEL_tod': 5,\n",
       " 'SARC': 2,\n",
       " 'SarcasmGhosh': 2,\n",
       " 'SentiTreeBank': 1,\n",
       " 'ShortHumor': 2,\n",
       " 'ShortJokeKaggle': 2,\n",
       " 'ShortRomance': 2,\n",
       " 'StanfordPoliteness': 1,\n",
       " 'TroFi': 2,\n",
       " 'VUA': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed603ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('../data/xslue', 'tasks.json'), 'w') as fp:\n",
    "    json.dump(tasks, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843c282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764534ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8eca20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f8823bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VUA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1k-fragment02</td>\n",
       "      <td>Ca n't fail to be entertaining . fail</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdb-fragment04</td>\n",
       "      <td>How much was he going to tell her ? go</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ac2-fragment06</td>\n",
       "      <td>Up until that news hit the Committee , Don had...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kbc-fragment13</td>\n",
       "      <td>Could go on to the rugby and go with them coul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ahb-fragment51</td>\n",
       "      <td>Finally , we went to the office and they gave ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15152</th>\n",
       "      <td>a1n-fragment09</td>\n",
       "      <td>EACH new indignity in the heap visited on Wels...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15153</th>\n",
       "      <td>fef-fragment03</td>\n",
       "      <td>Substituting the above equation into eqn ( 3.1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15154</th>\n",
       "      <td>amm-fragment02</td>\n",
       "      <td>A fern-like plant , beautifully preserved in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15155</th>\n",
       "      <td>ahf-fragment24</td>\n",
       "      <td>And there were never more than a few dozen rin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15156</th>\n",
       "      <td>ahb-fragment51</td>\n",
       "      <td>They lost over ÇÎ£4,000 dealing with two lett...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15157 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                index                                               text  \\\n",
       "0      a1k-fragment02              Ca n't fail to be entertaining . fail   \n",
       "1      cdb-fragment04             How much was he going to tell her ? go   \n",
       "2      ac2-fragment06  Up until that news hit the Committee , Don had...   \n",
       "3      kbc-fragment13  Could go on to the rugby and go with them coul...   \n",
       "4      ahb-fragment51  Finally , we went to the office and they gave ...   \n",
       "...               ...                                                ...   \n",
       "15152  a1n-fragment09  EACH new indignity in the heap visited on Wels...   \n",
       "15153  fef-fragment03  Substituting the above equation into eqn ( 3.1...   \n",
       "15154  amm-fragment02  A fern-like plant , beautifully preserved in a...   \n",
       "15155  ahf-fragment24  And there were never more than a few dozen rin...   \n",
       "15156  ahb-fragment51  They lost over ÇÎ£4,000 dealing with two lett...   \n",
       "\n",
       "       label  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "15152      1  \n",
       "15153      1  \n",
       "15154      0  \n",
       "15155      0  \n",
       "15156      1  \n",
       "\n",
       "[15157 rows x 3 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select dataset one by one\n",
    "dataset = datasets[13]\n",
    "print(dataset)\n",
    "df = pd.read_csv(os.path.join(in_dir, dataset, 'train.tsv'), sep = '\\t', header=None)\n",
    "# df = pd.read_csv(os.path.join(in_dir, dataset, 'test_age.tsv'), sep = '\\t', header=None)\n",
    "df.columns = ['index', 'text', 'label']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a8c48a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
