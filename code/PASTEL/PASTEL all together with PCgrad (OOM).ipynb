{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b71f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcgrad import PCGrad\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "from itertools import cycle\n",
    "from ast import literal_eval\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchmetrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import *\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, ModelOutput\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92b87bc",
   "metadata": {},
   "source": [
    "# definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a499f05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_folder = os.environ[\"scratch_result_folder\"] if \"scratch_result_folder\" in os.environ else '../result'\n",
    "scratch_data_folder = os.environ[\"scratch_data_folder\"] if \"scratch_data_folder\" in os.environ else None\n",
    "repo_folder = os.environ[\"style_models_repo_folder\"] if \"style_models_repo_folder\" in os.environ else None\n",
    "data_folder = f\"{repo_folder}/data\" if repo_folder else '../../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ab2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# https://github.com/huggingface/transformers/issues/5486\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edc6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: task_name: number_of_labels\n",
    "with open(f'{data_folder}/pastel/pastel_tasks2labels.json', 'r') as f:\n",
    "    tasks2labels = json.load(f)\n",
    "# Dictionary: task_name: task index\n",
    "tasks2idx = {k:i for i,k in enumerate(tasks2labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b042d536",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyTrainingArgs:\n",
    "    # training args\n",
    "    selected_tasks: List\n",
    "    base_model_name: str \n",
    "    freeze_bert: bool\n",
    "    use_pooler: bool\n",
    "    num_epoch: int\n",
    "    lr: float = 5e-5\n",
    "    num_warmup_steps = 500\n",
    "    model_folder: str = None # if None, this will be inferred based on tasks\n",
    "    model_name: str = None # if provide, use to name model_folder, otherwise use style to name model_folder\n",
    "        \n",
    "    # data loader args\n",
    "    batch_size: int = 32\n",
    "    max_length: int = 64\n",
    "    shuffle: bool = False\n",
    "    num_workers: int = 4\n",
    "    data_limit: int = None # if not None, truncate dataset to keep only top {data_limit} rows\n",
    "    \n",
    "    # post training args\n",
    "    save_best: bool = True\n",
    "    load_best_at_end: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        excute_time = datetime.now() \n",
    "        model_name = self.model_name if self.model_name else '+'.join(self.selected_tasks)\n",
    "        model_folder = f\"{result_folder}/{model_name}/{excute_time.now().strftime('%Y%m%d-%H:%M:%S')}\"\n",
    "        self.model_folder = model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1338e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    # currently it's a Mapping-style dataset. Not sure if a Iterable-style dataset will be better\n",
    "    # this works for standard class indices and also class probilities\n",
    "    # limit: use to truncate dataset. This will drop rows after certain index. May influence label distribution.\n",
    "    def __init__(self, training_args, split, label_prefix = None):\n",
    "        self.tasks = training_args.selected_tasks\n",
    "        self.max_length = training_args.max_length\n",
    "        self.split = split\n",
    "        self.label_prefix = label_prefix\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(training_args.base_model_name)\n",
    "        self.df = pd.read_csv(f\"{data_folder}/pastel/processed/{self.split}/{self.tasks[0] if len(self.tasks)==1 else 'pastel'}.csv\")\n",
    "        self.df = self.df.dropna()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "        \n",
    "        # for distill model, logits that written to files need eval to be correctly recognized\n",
    "        # also apply softmax on logits\n",
    "        for task in self.tasks:\n",
    "            if self.label_prefix is not None:\n",
    "                task = self.label_prefix + task\n",
    "            if isinstance(self.df[task][0], str):\n",
    "                self.df[task] = torch.tensor(self.df[task].apply(literal_eval)).softmax(dim=1).numpy().tolist()\n",
    "\n",
    "        if training_args.data_limit:\n",
    "            self.df = self.df.iloc[:training_args.data_limit]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        dataslice = self.df.iloc[idx]\n",
    "#         item = {k: v for k, v in self.tokenizer(dataslice['output.sentences'], truncation=True, padding=True, max_length=self.max_length).items()}\n",
    "        item = {'text':dataslice['output.sentences']}\n",
    "        item.update({task: dataslice[task] if self.label_prefix is None else dataslice[self.label_prefix+task] for task in self.tasks}) \n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee72916",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        batchsize = sent_emb.shape[0]\n",
    "        output = self.hidden(self.dropout(sent_emb)).squeeze(1)\n",
    "\n",
    "        loss = self.loss_fn(output, label.view(batchsize, -1).squeeze(-1))\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9294042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, num_labels, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, self.num_labels)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        batchsize = sent_emb.shape[0]\n",
    "        output = self.hidden(self.dropout(sent_emb))\n",
    "        \n",
    "        loss = self.loss_fn(output.view(-1, self.num_labels), label.view(batchsize, -1).squeeze(-1))\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e911dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MultiTaskOutput(ModelOutput):\n",
    "    total_loss: torch.FloatTensor = None\n",
    "    losses: List[torch.FloatTensor] = None\n",
    "    sent_emb: torch.FloatTensor = None\n",
    "    all_logits: Optional[Dict[str, torch.FloatTensor]] = None\n",
    "    bert_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    bert_attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25c4ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskBert(PreTrainedModel):\n",
    "    def __init__(self, config, training_args):\n",
    "        super().__init__(config)\n",
    "#         self.training_args = training_args\n",
    "        self.tasks = training_args.selected_tasks\n",
    "        self.use_pooler = training_args.use_pooler\n",
    "        self.basemodel = AutoModel.from_pretrained(training_args.base_model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(training_args.base_model_name)\n",
    "        self.style_heads = nn.ModuleList()\n",
    "        \n",
    "        for task in self.tasks:\n",
    "            if tasks2labels[task] == 1:\n",
    "                self.style_heads.append(RegressionHead())\n",
    "            else:\n",
    "                self.style_heads.append(ClassificationHead(tasks2labels[task]))\n",
    "                \n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, return_logits=False, return_sent_emb=True, **kwargs):\n",
    "        output = self.basemodel(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        if self.use_pooler and ('pooler_output' in output):\n",
    "            sent_emb = output['pooler_output']\n",
    "        else:\n",
    "            sent_emb = output['last_hidden_state'][:,0,:]\n",
    "        \n",
    "        total_loss = None\n",
    "        losses = []\n",
    "        all_logits = None\n",
    "        if return_logits:\n",
    "            all_logits = {}\n",
    "        all_logits = {}\n",
    "        for task in kwargs:\n",
    "            i_task = self.tasks.index(task)\n",
    "            logits, loss = self.style_heads[i_task](sent_emb, kwargs[task]) \n",
    "            losses.append(loss)\n",
    "            if total_loss is None:\n",
    "                total_loss = loss\n",
    "            else:\n",
    "                total_loss += loss\n",
    "            if return_logits:\n",
    "                all_logits[task] = logits.detach()\n",
    "        return MultiTaskOutput(total_loss=total_loss, losses=losses, sent_emb=sent_emb, all_logits=all_logits, bert_hidden_states=output.hidden_states, bert_attentions=output.attentions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9b2c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(training_args):\n",
    "    config = AutoConfig.from_pretrained(training_args.base_model_name) \n",
    "    model = MultiTaskBert(config, training_args).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0cbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, freeze_bert):\n",
    "    '''\n",
    "    if freeze_bert == True, freeze all layer. \n",
    "    if freeze_bert is a positive integer, freeze the bottom {freeze_bert} attention layers\n",
    "    negative integer should also work\n",
    "    '''\n",
    "    if freeze_bert==True:\n",
    "        for param in model.basemodel.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif isinstance(freeze_bert, int):\n",
    "        for layer in model.basemodel.encoder.layer[:freeze_bert]: \n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2b011",
   "metadata": {},
   "source": [
    "# training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                                  model_name=f'PASTEL all together',\n",
    "                                  base_model_name='bert-base-uncased',\n",
    "                                  freeze_bert=False,\n",
    "                                  use_pooler=False,\n",
    "                                  num_epoch=5,\n",
    "                                  batch_size=4,\n",
    "#                                   data_limit=30000,\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20bb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    batch_out = collections.defaultdict(list)\n",
    "    for item in batch:\n",
    "        for col in item:\n",
    "            batch_out[col].append(item[col])\n",
    "    for col in batch_out:\n",
    "        if col != 'text':\n",
    "            batch_out[col] = torch.tensor(batch_out[col], dtype=torch.int64).to(device)\n",
    "            \n",
    "    batch_out.update({k:v for k,v in tokenizer(text = batch_out['text'], return_tensors='pt', padding=True, truncation=True, max_length=64).to(device).items()})\n",
    "    \n",
    "    del batch_out['text']\n",
    "    return batch_out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2123f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MyDataset(my_training_args, 'train')\n",
    "train_loader = DataLoader(train_data, batch_size=my_training_args.batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "num_training_steps = len(train_loader)\n",
    "cycle_train_loader = cycle(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d1f504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = init_model(my_training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c414915",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 418.00 MiB (GPU 0; 10.92 GiB total capacity; 9.56 GiB already allocated; 81.69 MiB free; 9.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_187998/1300800535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'losses'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpc_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# sum(losses).backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/style-models/code/PASTEL/pcgrad.py\u001b[0m in \u001b[0;36mpc_backward\u001b[0;34m(self, objectives)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pack_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjectives\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mpc_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_project_conflicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mpc_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unflatten_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/style-models/code/PASTEL/pcgrad.py\u001b[0m in \u001b[0;36m_project_conflicting\u001b[0;34m(self, grads, has_grads, shapes)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0mg_i_g_j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_j\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mg_i_g_j\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                     \u001b[0mg_i\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg_i_g_j\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg_j\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg_j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mmerged_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reduction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 418.00 MiB (GPU 0; 10.92 GiB total capacity; 9.56 GiB already allocated; 81.69 MiB free; 9.91 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "optimizer = PCGrad(optimizer)\n",
    "\n",
    "for i_epoch in range(num_epochs):\n",
    "    for i_step in range(num_training_steps):\n",
    "        \n",
    "        batch = next(cycle_train_loader)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(**batch)\n",
    "        \n",
    "        losses = output['losses']\n",
    "        optimizer.pc_backward(losses)\n",
    "        # sum(losses).backward()\n",
    "        optimizer.step()\n",
    "        print(print(output['total_loss'].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48668ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
