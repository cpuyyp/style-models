{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dff693",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#train\" data-toc-modified-id=\"train-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>train</a></span><ul class=\"toc-item\"><li><span><a href=\"#with-predicted-labels\" data-toc-modified-id=\"with-predicted-labels-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>with predicted labels</a></span></li><li><span><a href=\"#with-predicted-logits\" data-toc-modified-id=\"with-predicted-logits-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>with predicted logits</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6eff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./PASTEL_MTL_training_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20220920_180238-r5g81rh9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9\" target=\"_blank\">winter-jazz-1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'PASTEL train on prediction.ipynb'\n",
    "import wandb\n",
    "wandb.init(project=\"PASTEL train on prediction\", entity=\"fsu-dsc-cil\", dir='/scratch/data_jz17d/wandb_tmp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78da45",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe01c70",
   "metadata": {},
   "source": [
    "## with predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "***** Running training *****\n",
      "  Num examples = 31806\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4970\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4970' max='4970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4970/4970 19:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Country</th>\n",
       "      <th>F1 Country</th>\n",
       "      <th>Precision Country</th>\n",
       "      <th>Recall Country</th>\n",
       "      <th>Accuracy Politics</th>\n",
       "      <th>F1 Politics</th>\n",
       "      <th>Precision Politics</th>\n",
       "      <th>Recall Politics</th>\n",
       "      <th>Accuracy Tod</th>\n",
       "      <th>F1 Tod</th>\n",
       "      <th>Precision Tod</th>\n",
       "      <th>Recall Tod</th>\n",
       "      <th>Accuracy Age</th>\n",
       "      <th>F1 Age</th>\n",
       "      <th>Precision Age</th>\n",
       "      <th>Recall Age</th>\n",
       "      <th>Accuracy Education</th>\n",
       "      <th>F1 Education</th>\n",
       "      <th>Precision Education</th>\n",
       "      <th>Recall Education</th>\n",
       "      <th>Accuracy Ethnic</th>\n",
       "      <th>F1 Ethnic</th>\n",
       "      <th>Precision Ethnic</th>\n",
       "      <th>Recall Ethnic</th>\n",
       "      <th>Accuracy Gender</th>\n",
       "      <th>F1 Gender</th>\n",
       "      <th>Precision Gender</th>\n",
       "      <th>Recall Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.904800</td>\n",
       "      <td>14.768373</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.341448</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.375249</td>\n",
       "      <td>0.446115</td>\n",
       "      <td>0.206354</td>\n",
       "      <td>0.209450</td>\n",
       "      <td>0.255830</td>\n",
       "      <td>0.420802</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.236990</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.401253</td>\n",
       "      <td>0.146594</td>\n",
       "      <td>0.168016</td>\n",
       "      <td>0.168759</td>\n",
       "      <td>0.825564</td>\n",
       "      <td>0.189769</td>\n",
       "      <td>0.236170</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.426309</td>\n",
       "      <td>0.514238</td>\n",
       "      <td>0.428488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>17.609226</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.472932</td>\n",
       "      <td>0.341997</td>\n",
       "      <td>0.315092</td>\n",
       "      <td>0.376336</td>\n",
       "      <td>0.446617</td>\n",
       "      <td>0.207484</td>\n",
       "      <td>0.345434</td>\n",
       "      <td>0.256243</td>\n",
       "      <td>0.420050</td>\n",
       "      <td>0.154868</td>\n",
       "      <td>0.199464</td>\n",
       "      <td>0.165263</td>\n",
       "      <td>0.405764</td>\n",
       "      <td>0.145953</td>\n",
       "      <td>0.182978</td>\n",
       "      <td>0.168064</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.191496</td>\n",
       "      <td>0.361805</td>\n",
       "      <td>0.191494</td>\n",
       "      <td>0.719799</td>\n",
       "      <td>0.424517</td>\n",
       "      <td>0.503423</td>\n",
       "      <td>0.426582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401600</td>\n",
       "      <td>20.277220</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.344534</td>\n",
       "      <td>0.317302</td>\n",
       "      <td>0.378962</td>\n",
       "      <td>0.445865</td>\n",
       "      <td>0.207406</td>\n",
       "      <td>0.260728</td>\n",
       "      <td>0.255928</td>\n",
       "      <td>0.425564</td>\n",
       "      <td>0.151912</td>\n",
       "      <td>0.259470</td>\n",
       "      <td>0.164727</td>\n",
       "      <td>0.405764</td>\n",
       "      <td>0.145162</td>\n",
       "      <td>0.182955</td>\n",
       "      <td>0.166430</td>\n",
       "      <td>0.825815</td>\n",
       "      <td>0.189794</td>\n",
       "      <td>0.340020</td>\n",
       "      <td>0.188727</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.423932</td>\n",
       "      <td>0.511114</td>\n",
       "      <td>0.426581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196700</td>\n",
       "      <td>21.946714</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.477945</td>\n",
       "      <td>0.346430</td>\n",
       "      <td>0.318370</td>\n",
       "      <td>0.380504</td>\n",
       "      <td>0.446617</td>\n",
       "      <td>0.208152</td>\n",
       "      <td>0.254955</td>\n",
       "      <td>0.256521</td>\n",
       "      <td>0.421303</td>\n",
       "      <td>0.153650</td>\n",
       "      <td>0.245795</td>\n",
       "      <td>0.164935</td>\n",
       "      <td>0.401754</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.175891</td>\n",
       "      <td>0.167497</td>\n",
       "      <td>0.826566</td>\n",
       "      <td>0.189538</td>\n",
       "      <td>0.329348</td>\n",
       "      <td>0.192353</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>0.425979</td>\n",
       "      <td>0.505917</td>\n",
       "      <td>0.427801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>23.201609</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.477694</td>\n",
       "      <td>0.345950</td>\n",
       "      <td>0.318280</td>\n",
       "      <td>0.380227</td>\n",
       "      <td>0.446867</td>\n",
       "      <td>0.208526</td>\n",
       "      <td>0.259754</td>\n",
       "      <td>0.256811</td>\n",
       "      <td>0.420802</td>\n",
       "      <td>0.156146</td>\n",
       "      <td>0.249882</td>\n",
       "      <td>0.165889</td>\n",
       "      <td>0.403008</td>\n",
       "      <td>0.144296</td>\n",
       "      <td>0.177672</td>\n",
       "      <td>0.166595</td>\n",
       "      <td>0.826065</td>\n",
       "      <td>0.189856</td>\n",
       "      <td>0.330450</td>\n",
       "      <td>0.190741</td>\n",
       "      <td>0.721554</td>\n",
       "      <td>0.424579</td>\n",
       "      <td>0.508859</td>\n",
       "      <td>0.426932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-1988] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-2982] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-4970\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-4970/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-4970/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-4970/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-4970/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-3976] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4970, training_loss=0.6989823193617271, metrics={'train_runtime': 1174.9433, 'train_samples_per_second': 135.351, 'train_steps_per_second': 4.23, 'total_flos': 2334434796900360.0, 'train_loss': 0.6989823193617271, 'epoch': 5.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0.8\n",
    "label_prefix='predicted_' # 'predicted_' or 'logits_'\n",
    "\n",
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                                  model_name=f'PASTEL train on predicted labels p={p}',\n",
    "                                  base_model_name='bert-base-uncased',\n",
    "                                  freeze_bert=False,\n",
    "                                  use_pooler=False,\n",
    "                                  num_epoch=5,\n",
    "#                                   data_limit=30000,\n",
    "                                 )\n",
    "\n",
    "hg_training_args = TrainingArguments(\n",
    "    output_dir=my_training_args.model_folder,   # output directory\n",
    "    num_train_epochs=my_training_args.num_epoch,     # total number of training epochs\n",
    "    per_device_train_batch_size=my_training_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=my_training_args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=my_training_args.num_warmup_steps,    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f\"{my_training_args.model_folder}/logs\",  # directory for storing logs\n",
    "    logging_first_step = True, \n",
    "    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "    save_total_limit = 1,\n",
    "    save_strategy = 'epoch',\n",
    "    report_to = 'wandb',\n",
    "#     load_best_model_at_end=True, # decide on loss\n",
    ")\n",
    "\n",
    "model = init_model(my_training_args)\n",
    "freeze_model(model, my_training_args.freeze_bert)\n",
    "\n",
    "train_dataset = MyDataset(my_training_args, f'p={p}_predicted', label_prefix=label_prefix)\n",
    "val_dataset = MyDataset(my_training_args, 'valid')\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,   # the instantiated Transformers model to be trained\n",
    "    args=hg_training_args,                  # training arguments, defined above\n",
    "    tokenizer=model.tokenizer, \n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9eb55c",
   "metadata": {},
   "source": [
    "## with predicted logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5e701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /home/jz17d/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of BertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertModel for predictions without further training.\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jz17d/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/jz17d/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jz17d/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jz17d/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/jz17d/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jz17d/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/jz17d/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/jz17d/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/jz17d/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/jz17d/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.12.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "***** Running training *****\n",
      "  Num examples = 31806\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4970\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4970' max='4970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4970/4970 19:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Country</th>\n",
       "      <th>F1 Country</th>\n",
       "      <th>Precision Country</th>\n",
       "      <th>Recall Country</th>\n",
       "      <th>Accuracy Politics</th>\n",
       "      <th>F1 Politics</th>\n",
       "      <th>Precision Politics</th>\n",
       "      <th>Recall Politics</th>\n",
       "      <th>Accuracy Tod</th>\n",
       "      <th>F1 Tod</th>\n",
       "      <th>Precision Tod</th>\n",
       "      <th>Recall Tod</th>\n",
       "      <th>Accuracy Age</th>\n",
       "      <th>F1 Age</th>\n",
       "      <th>Precision Age</th>\n",
       "      <th>Recall Age</th>\n",
       "      <th>Accuracy Education</th>\n",
       "      <th>F1 Education</th>\n",
       "      <th>Precision Education</th>\n",
       "      <th>Recall Education</th>\n",
       "      <th>Accuracy Ethnic</th>\n",
       "      <th>F1 Ethnic</th>\n",
       "      <th>Precision Ethnic</th>\n",
       "      <th>Recall Ethnic</th>\n",
       "      <th>Accuracy Gender</th>\n",
       "      <th>F1 Gender</th>\n",
       "      <th>Precision Gender</th>\n",
       "      <th>Recall Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.184900</td>\n",
       "      <td>6.777673</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.472431</td>\n",
       "      <td>0.342519</td>\n",
       "      <td>0.314643</td>\n",
       "      <td>0.376138</td>\n",
       "      <td>0.442356</td>\n",
       "      <td>0.205021</td>\n",
       "      <td>0.206999</td>\n",
       "      <td>0.253822</td>\n",
       "      <td>0.414035</td>\n",
       "      <td>0.150229</td>\n",
       "      <td>0.255614</td>\n",
       "      <td>0.162716</td>\n",
       "      <td>0.402256</td>\n",
       "      <td>0.142738</td>\n",
       "      <td>0.166166</td>\n",
       "      <td>0.166120</td>\n",
       "      <td>0.825063</td>\n",
       "      <td>0.189431</td>\n",
       "      <td>0.323571</td>\n",
       "      <td>0.189369</td>\n",
       "      <td>0.722306</td>\n",
       "      <td>0.428261</td>\n",
       "      <td>0.504085</td>\n",
       "      <td>0.429357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>6.550000</td>\n",
       "      <td>6.771091</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.343771</td>\n",
       "      <td>0.315728</td>\n",
       "      <td>0.377281</td>\n",
       "      <td>0.445614</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>0.275741</td>\n",
       "      <td>0.256364</td>\n",
       "      <td>0.420301</td>\n",
       "      <td>0.161789</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>0.169617</td>\n",
       "      <td>0.406266</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>0.181541</td>\n",
       "      <td>0.167827</td>\n",
       "      <td>0.825313</td>\n",
       "      <td>0.189628</td>\n",
       "      <td>0.325949</td>\n",
       "      <td>0.189650</td>\n",
       "      <td>0.723308</td>\n",
       "      <td>0.426548</td>\n",
       "      <td>0.510819</td>\n",
       "      <td>0.428440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.557400</td>\n",
       "      <td>6.774335</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.474937</td>\n",
       "      <td>0.343780</td>\n",
       "      <td>0.316562</td>\n",
       "      <td>0.377993</td>\n",
       "      <td>0.443860</td>\n",
       "      <td>0.207248</td>\n",
       "      <td>0.268126</td>\n",
       "      <td>0.255166</td>\n",
       "      <td>0.423308</td>\n",
       "      <td>0.158367</td>\n",
       "      <td>0.262601</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>0.405764</td>\n",
       "      <td>0.145877</td>\n",
       "      <td>0.201770</td>\n",
       "      <td>0.168620</td>\n",
       "      <td>0.824311</td>\n",
       "      <td>0.187244</td>\n",
       "      <td>0.279304</td>\n",
       "      <td>0.186916</td>\n",
       "      <td>0.723308</td>\n",
       "      <td>0.427319</td>\n",
       "      <td>0.509145</td>\n",
       "      <td>0.428923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.543800</td>\n",
       "      <td>6.772632</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.340293</td>\n",
       "      <td>0.314690</td>\n",
       "      <td>0.375388</td>\n",
       "      <td>0.445865</td>\n",
       "      <td>0.209764</td>\n",
       "      <td>0.271434</td>\n",
       "      <td>0.256765</td>\n",
       "      <td>0.422055</td>\n",
       "      <td>0.163877</td>\n",
       "      <td>0.250683</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.403759</td>\n",
       "      <td>0.145124</td>\n",
       "      <td>0.272849</td>\n",
       "      <td>0.167487</td>\n",
       "      <td>0.828070</td>\n",
       "      <td>0.191283</td>\n",
       "      <td>0.287765</td>\n",
       "      <td>0.192988</td>\n",
       "      <td>0.722306</td>\n",
       "      <td>0.426746</td>\n",
       "      <td>0.507156</td>\n",
       "      <td>0.428392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.533500</td>\n",
       "      <td>6.767854</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.470677</td>\n",
       "      <td>0.341066</td>\n",
       "      <td>0.313473</td>\n",
       "      <td>0.374691</td>\n",
       "      <td>0.444862</td>\n",
       "      <td>0.209468</td>\n",
       "      <td>0.276494</td>\n",
       "      <td>0.256375</td>\n",
       "      <td>0.423810</td>\n",
       "      <td>0.161211</td>\n",
       "      <td>0.255924</td>\n",
       "      <td>0.169381</td>\n",
       "      <td>0.403509</td>\n",
       "      <td>0.145081</td>\n",
       "      <td>0.172949</td>\n",
       "      <td>0.167366</td>\n",
       "      <td>0.826316</td>\n",
       "      <td>0.190205</td>\n",
       "      <td>0.281905</td>\n",
       "      <td>0.190279</td>\n",
       "      <td>0.722556</td>\n",
       "      <td>0.427042</td>\n",
       "      <td>0.507331</td>\n",
       "      <td>0.428621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-994] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-1988] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-2982] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-4970\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-4970/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-4970/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-4970/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-4970/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/PASTEL train on predicted logits p=0.8/20220920-18:23:15/checkpoint-3976] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4970, training_loss=6.619331955669871, metrics={'train_runtime': 1167.6314, 'train_samples_per_second': 136.199, 'train_steps_per_second': 4.256, 'total_flos': 2334434796900360.0, 'train_loss': 6.619331955669871, 'epoch': 5.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p=0.8\n",
    "label_prefix='logits_' # 'predicted_' or 'logits_'\n",
    "\n",
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                                  model_name=f'PASTEL train on predicted logits p={p}',\n",
    "                                  base_model_name='bert-base-uncased',\n",
    "                                  freeze_bert=False,\n",
    "                                  use_pooler=False,\n",
    "                                  num_epoch=5,\n",
    "#                                   data_limit=30000,\n",
    "                                 )\n",
    "\n",
    "hg_training_args = TrainingArguments(\n",
    "    output_dir=my_training_args.model_folder,   # output directory\n",
    "    num_train_epochs=my_training_args.num_epoch,     # total number of training epochs\n",
    "    per_device_train_batch_size=my_training_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=my_training_args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=my_training_args.num_warmup_steps,    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f\"{my_training_args.model_folder}/logs\",  # directory for storing logs\n",
    "    logging_first_step = True, \n",
    "    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "    save_total_limit = 1,\n",
    "    save_strategy = 'epoch',\n",
    "    report_to = 'wandb',\n",
    "#     load_best_model_at_end=True, # decide on loss\n",
    ")\n",
    "\n",
    "model = init_model(my_training_args)\n",
    "freeze_model(model, my_training_args.freeze_bert)\n",
    "\n",
    "train_dataset = MyDataset(my_training_args, f'p={p}_predicted', label_prefix=label_prefix)\n",
    "val_dataset = MyDataset(my_training_args, 'valid')\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,   # the instantiated Transformers model to be trained\n",
    "    args=hg_training_args,                  # training arguments, defined above\n",
    "    tokenizer=model.tokenizer, \n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ad664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_age</td><td></td></tr><tr><td>eval/accuracy_country</td><td></td></tr><tr><td>eval/accuracy_education</td><td></td></tr><tr><td>eval/accuracy_ethnic</td><td></td></tr><tr><td>eval/accuracy_gender</td><td></td></tr><tr><td>eval/accuracy_politics</td><td></td></tr><tr><td>eval/accuracy_tod</td><td></td></tr><tr><td>eval/f1_age</td><td></td></tr><tr><td>eval/f1_country</td><td></td></tr><tr><td>eval/f1_education</td><td></td></tr><tr><td>eval/f1_ethnic</td><td></td></tr><tr><td>eval/f1_gender</td><td></td></tr><tr><td>eval/f1_politics</td><td></td></tr><tr><td>eval/f1_tod</td><td></td></tr><tr><td>eval/loss</td><td></td></tr><tr><td>eval/precision_age</td><td></td></tr><tr><td>eval/precision_country</td><td></td></tr><tr><td>eval/precision_education</td><td></td></tr><tr><td>eval/precision_ethnic</td><td></td></tr><tr><td>eval/precision_gender</td><td></td></tr><tr><td>eval/precision_politics</td><td></td></tr><tr><td>eval/precision_tod</td><td></td></tr><tr><td>eval/recall_age</td><td></td></tr><tr><td>eval/recall_country</td><td></td></tr><tr><td>eval/recall_education</td><td></td></tr><tr><td>eval/recall_ethnic</td><td></td></tr><tr><td>eval/recall_gender</td><td></td></tr><tr><td>eval/recall_politics</td><td></td></tr><tr><td>eval/recall_tod</td><td></td></tr><tr><td>eval/runtime</td><td></td></tr><tr><td>eval/samples_per_second</td><td></td></tr><tr><td>eval/steps_per_second</td><td></td></tr><tr><td>train/epoch</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>train/learning_rate</td><td></td></tr><tr><td>train/loss</td><td></td></tr><tr><td>train/total_flos</td><td></td></tr><tr><td>train/train_loss</td><td></td></tr><tr><td>train/train_runtime</td><td></td></tr><tr><td>train/train_samples_per_second</td><td></td></tr><tr><td>train/train_steps_per_second</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_age</td><td>0.42381</td></tr><tr><td>eval/accuracy_country</td><td>0.97519</td></tr><tr><td>eval/accuracy_education</td><td>0.40351</td></tr><tr><td>eval/accuracy_ethnic</td><td>0.82632</td></tr><tr><td>eval/accuracy_gender</td><td>0.72256</td></tr><tr><td>eval/accuracy_politics</td><td>0.47068</td></tr><tr><td>eval/accuracy_tod</td><td>0.44486</td></tr><tr><td>eval/f1_age</td><td>0.16121</td></tr><tr><td>eval/f1_country</td><td>0.32915</td></tr><tr><td>eval/f1_education</td><td>0.14508</td></tr><tr><td>eval/f1_ethnic</td><td>0.19021</td></tr><tr><td>eval/f1_gender</td><td>0.42704</td></tr><tr><td>eval/f1_politics</td><td>0.34107</td></tr><tr><td>eval/f1_tod</td><td>0.20947</td></tr><tr><td>eval/loss</td><td>6.76785</td></tr><tr><td>eval/precision_age</td><td>0.25592</td></tr><tr><td>eval/precision_country</td><td>0.32506</td></tr><tr><td>eval/precision_education</td><td>0.17295</td></tr><tr><td>eval/precision_ethnic</td><td>0.28191</td></tr><tr><td>eval/precision_gender</td><td>0.50733</td></tr><tr><td>eval/precision_politics</td><td>0.31347</td></tr><tr><td>eval/precision_tod</td><td>0.27649</td></tr><tr><td>eval/recall_age</td><td>0.16938</td></tr><tr><td>eval/recall_country</td><td>0.33333</td></tr><tr><td>eval/recall_education</td><td>0.16737</td></tr><tr><td>eval/recall_ethnic</td><td>0.19028</td></tr><tr><td>eval/recall_gender</td><td>0.42862</td></tr><tr><td>eval/recall_politics</td><td>0.37469</td></tr><tr><td>eval/recall_tod</td><td>0.25638</td></tr><tr><td>eval/runtime</td><td>8.7148</td></tr><tr><td>eval/samples_per_second</td><td>457.84</td></tr><tr><td>eval/steps_per_second</td><td>14.343</td></tr><tr><td>train/epoch</td><td>5.0</td></tr><tr><td>train/global_step</td><td>4970</td></tr><tr><td>train/learning_rate</td><td>1e-05</td></tr><tr><td>train/loss</td><td>6.5335</td></tr><tr><td>train/total_flos</td><td>2334434796900360.0</td></tr><tr><td>train/train_loss</td><td>6.61933</td></tr><tr><td>train/train_runtime</td><td>1167.6314</td></tr><tr><td>train/train_samples_per_second</td><td>136.199</td></tr><tr><td>train/train_steps_per_second</td><td>4.256</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">winter-jazz-1</strong>: <a href=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9\" target=\"_blank\">https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20220920_180238-r5g81rh9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed59e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
