{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7dff693",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#train\" data-toc-modified-id=\"train-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>train</a></span><ul class=\"toc-item\"><li><span><a href=\"#with-predicted-labels\" data-toc-modified-id=\"with-predicted-labels-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>with predicted labels</a></span></li><li><span><a href=\"#with-predicted-logits\" data-toc-modified-id=\"with-predicted-logits-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>with predicted logits</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6eff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./PASTEL_MTL_training_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f8bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcpuyyp\u001b[0m (\u001b[33mfsu-dsc-cil\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/scratch/data_jz17d/wandb_tmp/wandb/run-20220920_180238-r5g81rh9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9\" target=\"_blank\">winter-jazz-1</a></strong> to <a href=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/fsu-dsc-cil/PASTEL%20train%20on%20prediction/runs/r5g81rh9?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'PASTEL train on prediction.ipynb'\n",
    "import wandb\n",
    "wandb.init(project=\"PASTEL train on prediction\", entity=\"fsu-dsc-cil\", dir='/scratch/data_jz17d/wandb_tmp/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78da45",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe01c70",
   "metadata": {},
   "source": [
    "## with predicted labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c7aa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "***** Running training *****\n",
      "  Num examples = 31806\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4970\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1451' max='4970' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1451/4970 05:22 < 13:02, 4.50 it/s, Epoch 1.46/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Country</th>\n",
       "      <th>F1 Country</th>\n",
       "      <th>Precision Country</th>\n",
       "      <th>Recall Country</th>\n",
       "      <th>Accuracy Politics</th>\n",
       "      <th>F1 Politics</th>\n",
       "      <th>Precision Politics</th>\n",
       "      <th>Recall Politics</th>\n",
       "      <th>Accuracy Tod</th>\n",
       "      <th>F1 Tod</th>\n",
       "      <th>Precision Tod</th>\n",
       "      <th>Recall Tod</th>\n",
       "      <th>Accuracy Age</th>\n",
       "      <th>F1 Age</th>\n",
       "      <th>Precision Age</th>\n",
       "      <th>Recall Age</th>\n",
       "      <th>Accuracy Education</th>\n",
       "      <th>F1 Education</th>\n",
       "      <th>Precision Education</th>\n",
       "      <th>Recall Education</th>\n",
       "      <th>Accuracy Ethnic</th>\n",
       "      <th>F1 Ethnic</th>\n",
       "      <th>Precision Ethnic</th>\n",
       "      <th>Recall Ethnic</th>\n",
       "      <th>Accuracy Gender</th>\n",
       "      <th>F1 Gender</th>\n",
       "      <th>Precision Gender</th>\n",
       "      <th>Recall Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.904800</td>\n",
       "      <td>14.768373</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.341448</td>\n",
       "      <td>0.314046</td>\n",
       "      <td>0.375249</td>\n",
       "      <td>0.446115</td>\n",
       "      <td>0.206354</td>\n",
       "      <td>0.209450</td>\n",
       "      <td>0.255830</td>\n",
       "      <td>0.420802</td>\n",
       "      <td>0.149393</td>\n",
       "      <td>0.236990</td>\n",
       "      <td>0.163061</td>\n",
       "      <td>0.401253</td>\n",
       "      <td>0.146594</td>\n",
       "      <td>0.168016</td>\n",
       "      <td>0.168759</td>\n",
       "      <td>0.825564</td>\n",
       "      <td>0.189769</td>\n",
       "      <td>0.236170</td>\n",
       "      <td>0.190032</td>\n",
       "      <td>0.724311</td>\n",
       "      <td>0.426309</td>\n",
       "      <td>0.514238</td>\n",
       "      <td>0.428488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994\n",
      "Configuration saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/PASTEL train on predicted labels p=0.8/20220920-18:03:28/checkpoint-994/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "p=0.8\n",
    "label_prefix='predicted_' # 'predicted_' or 'logits_'\n",
    "\n",
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                                  model_name=f'PASTEL train on predicted labels p={p}',\n",
    "                                  base_model_name='bert-base-uncased',\n",
    "                                  freeze_bert=False,\n",
    "                                  use_pooler=False,\n",
    "                                  num_epoch=5,\n",
    "#                                   data_limit=30000,\n",
    "                                 )\n",
    "\n",
    "hg_training_args = TrainingArguments(\n",
    "    output_dir=my_training_args.model_folder,   # output directory\n",
    "    num_train_epochs=my_training_args.num_epoch,     # total number of training epochs\n",
    "    per_device_train_batch_size=my_training_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=my_training_args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=my_training_args.num_warmup_steps,    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f\"{my_training_args.model_folder}/logs\",  # directory for storing logs\n",
    "    logging_first_step = True, \n",
    "    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "    save_total_limit = 1,\n",
    "    save_strategy = 'epoch',\n",
    "    report_to = 'wandb',\n",
    "#     load_best_model_at_end=True, # decide on loss\n",
    ")\n",
    "\n",
    "model = init_model(my_training_args)\n",
    "freeze_model(model, my_training_args.freeze_bert)\n",
    "\n",
    "train_dataset = MyDataset(my_training_args, f'p={p}_predicted', label_prefix=label_prefix)\n",
    "val_dataset = MyDataset(my_training_args, 'valid')\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,   # the instantiated Transformers model to be trained\n",
    "    args=hg_training_args,                  # training arguments, defined above\n",
    "    tokenizer=model.tokenizer, \n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9eb55c",
   "metadata": {},
   "source": [
    "## with predicted logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f5e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.8\n",
    "label_prefix='logits_' # 'predicted_' or 'logits_'\n",
    "\n",
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                                  model_name=f'PASTEL train on predicted logits p={p}',\n",
    "                                  base_model_name='bert-base-uncased',\n",
    "                                  freeze_bert=False,\n",
    "                                  use_pooler=False,\n",
    "                                  num_epoch=5,\n",
    "#                                   data_limit=30000,\n",
    "                                 )\n",
    "\n",
    "hg_training_args = TrainingArguments(\n",
    "    output_dir=my_training_args.model_folder,   # output directory\n",
    "    num_train_epochs=my_training_args.num_epoch,     # total number of training epochs\n",
    "    per_device_train_batch_size=my_training_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=my_training_args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=my_training_args.num_warmup_steps,    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f\"{my_training_args.model_folder}/logs\",  # directory for storing logs\n",
    "    logging_first_step = True, \n",
    "    evaluation_strategy=\"epoch\",     # evaluate each `logging_steps`\n",
    "    save_total_limit = 1,\n",
    "    save_strategy = 'epoch',\n",
    "    report_to = 'wandb',\n",
    "#     load_best_model_at_end=True, # decide on loss\n",
    ")\n",
    "\n",
    "model = init_model(my_training_args)\n",
    "freeze_model(model, my_training_args.freeze_bert)\n",
    "\n",
    "train_dataset = MyDataset(my_training_args, f'p={p}_predicted', label_prefix=label_prefix)\n",
    "val_dataset = MyDataset(my_training_args, 'valid')\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,   # the instantiated Transformers model to be trained\n",
    "    args=hg_training_args,                  # training arguments, defined above\n",
    "    tokenizer=model.tokenizer, \n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435ad664",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09a676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
