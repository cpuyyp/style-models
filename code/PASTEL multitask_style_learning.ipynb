{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c212946",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#README-BEFORE-RUN\" data-toc-modified-id=\"README-BEFORE-RUN-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>README BEFORE RUN</a></span></li><li><span><a href=\"#functions\" data-toc-modified-id=\"functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#multi-task-dataset\" data-toc-modified-id=\"multi-task-dataset-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>multi-task dataset</a></span></li><li><span><a href=\"#multi-task-model\" data-toc-modified-id=\"multi-task-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>multi-task model</a></span></li><li><span><a href=\"#trainer\" data-toc-modified-id=\"trainer-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>trainer</a></span></li></ul></li><li><span><a href=\"#train\" data-toc-modified-id=\"train-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>train</a></span><ul class=\"toc-item\"><li><span><a href=\"#bertology\" data-toc-modified-id=\"bertology-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>bertology</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8796ad85",
   "metadata": {},
   "source": [
    "# README BEFORE RUN\n",
    "**Before run this notebook, must find the source code of the functions below and modify them to work with dict as below**  \n",
    "\n",
    "These functions are in \\<your-env\\>/site-packages/transformers/trainer_pt_utils.py. Search for the function names and replace them with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9107ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!! Must find the source code of these functions and modify them to work with dict as below\n",
    "\n",
    "# def nested_concat(tensors, new_tensors, padding_index=-100):\n",
    "#     \"\"\"\n",
    "#     Concat the `new_tensors` to `tensors` on the first dim and pad them on the second if needed. Works for tensors or\n",
    "#     nested list/tuples/dict of tensors.\n",
    "#     \"\"\"\n",
    "#     assert type(tensors) == type(\n",
    "#         new_tensors\n",
    "#     ), f\"Expected `tensors` and `new_tensors` to have the same type but found {type(tensors)} and {type(new_tensors)}.\"\n",
    "#     if isinstance(tensors, (list, tuple)):\n",
    "#         return type(tensors)(nested_concat(t, n, padding_index=padding_index) for t, n in zip(tensors, new_tensors))\n",
    "#     elif isinstance(tensors, torch.Tensor):\n",
    "#         return torch_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)\n",
    "#     elif isinstance(tensors, np.ndarray):\n",
    "#         return numpy_pad_and_concatenate(tensors, new_tensors, padding_index=padding_index)\n",
    "#     elif isinstance(tensors, dict): ### JOEY EDITTED\n",
    "#         return {k: nested_concat(tensors[k], new_tensors[k], padding_index=padding_index) for k in tensors}\n",
    "#     else:\n",
    "#         raise TypeError(f\"Unsupported type for concatenation: got {type(tensors)}\")\n",
    "\n",
    "# def nested_numpify(tensors):\n",
    "#     \"Numpify `tensors` (even if it's a nested list/tuple/dict of tensors).\"\n",
    "#     if isinstance(tensors, (list, tuple)):\n",
    "#         return type(tensors)(nested_numpify(t) for t in tensors)\n",
    "#     elif isinstance(tensors, dict): ### JOEY EDITTED\n",
    "#         return {k: nested_numpify(tensors[k]) for k in tensors}\n",
    "#     return tensors.cpu().numpy()\n",
    "\n",
    "# def nested_detach(tensors):\n",
    "#     \"Detach `tensors` (even if it's a nested list/tuple/dict of tensors).\"\n",
    "#     if isinstance(tensors, (list, tuple)):\n",
    "#         return type(tensors)(nested_detach(t) for t in tensors)\n",
    "#     elif isinstance(tensors, dict): ### JOEY EDITTED\n",
    "#         return {k:nested_detach(tensors[k]) for k in tensors}\n",
    "#     return tensors.detach()\n",
    "\n",
    "# def nested_truncate(tensors, limit):\n",
    "#     \"Truncate `tensors` at `limit` (even if it's a nested list/tuple of tensors).\"\n",
    "#     if isinstance(tensors, (list, tuple)):\n",
    "#         return type(tensors)(nested_truncate(t, limit) for t in tensors)\n",
    "#     elif isinstance(tensors, dict): ### JOEY EDITTED\n",
    "#         return {k: nested_truncate(tensors[k], limit) for k in tensors}\n",
    "#     return tensors[:limit]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5484ef75",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7220ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f4cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import collections\n",
    "import json\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchmetrics\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from transformers import *\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput, ModelOutput\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5168db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "result_folder = os.environ[\"scratch_result_folder\"] if \"scratch_result_folder\" in os.environ else './result'\n",
    "scratch_data_folder = os.environ[\"scratch_data_folder\"] if \"scratch_data_folder\" in os.environ else None\n",
    "data_folder = '../data'\n",
    "\n",
    "# https://github.com/huggingface/transformers/issues/5486\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8839076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary: task_name: number_of_labels\n",
    "with open(f'{data_folder}/pastel/pastel_tasks2labels.json', 'r') as f:\n",
    "    tasks2labels = json.load(f)\n",
    "# Dictionary: task_name: task index\n",
    "tasks2idx = {k:i for i,k in enumerate(tasks2labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e0949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'country': 3,\n",
       " 'politics': 3,\n",
       " 'tod': 5,\n",
       " 'age': 8,\n",
       " 'education': 10,\n",
       " 'ethnic': 10,\n",
       " 'gender': 3}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tasks2labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130dc200",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MyTrainingArgs:\n",
    "    # training args\n",
    "    selected_tasks: List\n",
    "    base_model_name: str \n",
    "    freeze_bert: bool\n",
    "    use_pooler: bool\n",
    "    num_epoch: int\n",
    "    lr: float = 5e-5\n",
    "    num_warmup_steps = 500\n",
    "    model_folder: str = None # this will be inferred based on tasks\n",
    "    model_name: str = None # if provide, use to name model_folder, otherwise use style to name model_folder\n",
    "        \n",
    "    # data loader args\n",
    "    batch_size: int = 32\n",
    "    max_length: int = 64\n",
    "    shuffle: bool = False\n",
    "    num_workers: int = 4\n",
    "    data_limit: int = None # if not None, truncate dataset to keep only top {data_limit} rows\n",
    "    \n",
    "    # post training args\n",
    "    save_best: bool = True\n",
    "    load_best_at_end: bool = True\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        excute_time = datetime.now() \n",
    "        model_name = self.model_name if self.model_name else '+'.join(self.selected_tasks)\n",
    "        model_folder = f\"{result_folder}/{model_name}/{excute_time.now().strftime('%Y%m%d-%H:%M:%S')}\"\n",
    "        self.model_folder = model_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bd186",
   "metadata": {},
   "source": [
    "## multi-task dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e8f997",
   "metadata": {},
   "source": [
    "One sentence with multiple labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00309940",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset): \n",
    "    # currently it's a Mapping-style dataset. Not sure if a Iterable-style dataset will be better\n",
    "    # limit: use to truncate dataset. This will drop rows after certain index. May influence label distribution.\n",
    "    def __init__(self, training_args, split):\n",
    "        self.max_length = training_args.max_length\n",
    "        self.split = split\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(training_args.base_model_name)\n",
    "        self.df = pd.read_csv(f'{data_folder}/pastel/processed/{self.split}/pastel.csv')\n",
    "        self.df = self.df.dropna()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "\n",
    "        if training_args.data_limit:\n",
    "            self.df = self.df.iloc[:training_args.data_limit]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        dataslice = self.df.iloc[idx]\n",
    "        item = {k: v for k, v in self.tokenizer(dataslice['output.sentences'], truncation=True, padding=True, max_length=self.max_length).items()}\n",
    "        item.update({k: dataslice[k] for k in tasks2labels}) \n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100a28b2",
   "metadata": {},
   "source": [
    "## multi-task model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957b24e7",
   "metadata": {},
   "source": [
    "Given selected tasks, the model will add corresponding classification heads on the top of pretrained bert/(other bert). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed50b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionHead(nn.Module):\n",
    "    def __init__(self, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, 1)\n",
    "        \n",
    "        self.loss_fn = nn.MSELoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        output = self.hidden(self.dropout(sent_emb)).squeeze(1)\n",
    "\n",
    "        loss = self.loss_fn(output, label)\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c097a3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, num_labels, embedding_dim = 768, hidden_dim = 128):\n",
    "        super().__init__()\n",
    "        self.num_labels = num_labels\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.hidden = nn.Linear(embedding_dim, self.num_labels)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    def forward(self, sent_emb, label):\n",
    "        output = self.hidden(self.dropout(sent_emb))\n",
    "        \n",
    "        loss = self.loss_fn(output.view(-1, self.num_labels), label.view(-1))\n",
    "        return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e69dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MultiTaskOutput(ModelOutput):\n",
    "    loss: torch.FloatTensor = None\n",
    "    sent_emb: torch.FloatTensor = None\n",
    "    all_logits: Optional[Dict[str, torch.FloatTensor]] = None\n",
    "    bert_hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    bert_attentions: Optional[Tuple[torch.FloatTensor]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eec4f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskBert(PreTrainedModel):\n",
    "    def __init__(self, config, training_args):\n",
    "        super().__init__(config)\n",
    "#         self.training_args = training_args\n",
    "        self.tasks = training_args.selected_tasks\n",
    "        self.use_pooler = training_args.use_pooler\n",
    "        self.basemodel = AutoModel.from_pretrained(training_args.base_model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(training_args.base_model_name)\n",
    "        self.style_heads = nn.ModuleList()\n",
    "        \n",
    "        for task in self.tasks:\n",
    "            if tasks2labels[task] == 1:\n",
    "                self.style_heads.append(RegressionHead())\n",
    "            else:\n",
    "                self.style_heads.append(ClassificationHead(tasks2labels[task]))\n",
    "                \n",
    "    def forward(self, input_ids, token_type_ids, attention_mask, return_logits=False, return_sent_emb=True, **kwargs):\n",
    "        output = self.basemodel(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        if self.use_pooler and ('pooler_output' in output):\n",
    "            sent_emb = output['pooler_output']\n",
    "        else:\n",
    "            sent_emb = output['last_hidden_state'][:,0,:]\n",
    "        \n",
    "        total_loss = None\n",
    "        all_logits = None\n",
    "        if return_logits:\n",
    "            all_logits = {}\n",
    "        all_logits = {}\n",
    "        for task in kwargs:\n",
    "            i_task = tasks2idx[task]\n",
    "            logits, loss = self.style_heads[i_task](sent_emb, kwargs[task]) \n",
    "            if total_loss is None:\n",
    "                total_loss = loss\n",
    "            else:\n",
    "                total_loss += loss\n",
    "            if return_logits:\n",
    "                all_logits[task] = logits.detach()\n",
    "        return MultiTaskOutput(loss=total_loss, sent_emb=sent_emb, all_logits=all_logits, bert_hidden_states=output.hidden_states, bert_attentions=output.attentions)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067bbd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(training_args):\n",
    "    config = AutoConfig.from_pretrained(training_args.base_model_name) \n",
    "    model = MultiTaskBert(config, training_args).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1302944",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_model(model, freeze_bert):\n",
    "    '''\n",
    "    if freeze_bert == True, freeze all layer. \n",
    "    if freeze_bert is a positive integer, freeze the bottom {freeze_bert} attention layers\n",
    "    negative integer should also work\n",
    "    '''\n",
    "    if freeze_bert==True:\n",
    "        for param in model.basemodel.parameters():\n",
    "            param.requires_grad = False\n",
    "    elif isinstance(freeze_bert, int):\n",
    "        for layer in model.basemodel.encoder.layer[:freeze_bert]: \n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e122f3b",
   "metadata": {},
   "source": [
    "## trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c8a7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_detach(tensors):\n",
    "    \"Detach `tensors` (even if it's a nested list/tuple of tensors).\"\n",
    "    if isinstance(tensors, (list, tuple)):\n",
    "        return type(tensors)(nested_detach(t) for t in tensors)\n",
    "    if isinstance(tensors, dict):\n",
    "        return {k:nested_detach(tensors[k]) for k in tensors}\n",
    "    return tensors.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_to(tensors, device):\n",
    "    if isinstance(tensors, (list, tuple)):\n",
    "        return type(tensors)(nested_to(t, device) for t in tensors)\n",
    "    if isinstance(tensors, dict):\n",
    "        return {k: nested_to(tensors[k], device) for k in tensors}\n",
    "    return tensors.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fa181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)    \n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        return (outputs.loss, outputs.all_logits) if return_outputs else outputs.loss\n",
    "    \n",
    "    def prediction_step(self,\n",
    "        model: nn.Module,\n",
    "        inputs: Dict[str, Union[torch.Tensor, Any]],\n",
    "        prediction_loss_only: bool,\n",
    "        ignore_keys: Optional[List[str]] = None,\n",
    "    ) -> Tuple[Optional[torch.Tensor], Optional[torch.Tensor], Optional[torch.Tensor]]:\n",
    "        inputs = nested_to(inputs, model.device)\n",
    "        labels = {}\n",
    "        for task in model.tasks:\n",
    "            labels[task] = inputs[task]\n",
    "        outputs = model(**inputs, return_logits=True)\n",
    "        loss = outputs.loss.detach()\n",
    "        \n",
    "        if prediction_loss_only:\n",
    "            return (loss, None, None)\n",
    "        logits = nested_detach(outputs.all_logits)\n",
    "        return (loss, logits, labels)    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe3d40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions # .argmax(-1)\n",
    "    res = {}\n",
    "    for task in labels:\n",
    "        if tasks2labels[task] == 2:\n",
    "            average = 'binary'\n",
    "        else:\n",
    "            average = 'macro'\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels[task], preds[task].argmax(-1), average=average)\n",
    "        acc = accuracy_score(labels[task], preds[task].argmax(-1))\n",
    "        res.update({\n",
    "            f'accuracy_{task}': acc,\n",
    "            f'f1_{task}': f1,\n",
    "            f'precision_{task}': precision,\n",
    "            f'recall_{task}': recall\n",
    "        })\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f93722",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e052dc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "my_training_args = MyTrainingArgs(selected_tasks=list(tasks2labels.keys()),\n",
    "                             base_model_name='bert-base-uncased',\n",
    "                             freeze_bert=False,\n",
    "                             use_pooler=False,\n",
    "                             num_epoch=5,\n",
    "                             data_limit=30000,\n",
    "                            )\n",
    "\n",
    "hg_training_args = TrainingArguments(\n",
    "    output_dir=my_training_args.model_folder,   # output directory\n",
    "    num_train_epochs=my_training_args.num_epoch,     # total number of training epochs\n",
    "    per_device_train_batch_size=my_training_args.batch_size,  # batch size per device during training\n",
    "    per_device_eval_batch_size=my_training_args.batch_size,   # batch size for evaluation\n",
    "    warmup_steps=my_training_args.num_warmup_steps,    # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir=f\"{my_training_args.model_folder}/logs\",  # directory for storing logs\n",
    "    logging_first_step = True, \n",
    "    evaluation_strategy=\"steps\",     # evaluate each `logging_steps`\n",
    "    save_total_limit = 1,\n",
    "    save_strategy = 'epoch',\n",
    "#     load_best_model_at_end=True, # decide on loss\n",
    ")\n",
    "\n",
    "model = init_model(my_training_args)\n",
    "freeze_model(model, my_training_args.freeze_bert)\n",
    "\n",
    "train_dataset = MyDataset(my_training_args, 'train')\n",
    "val_dataset = MyDataset(my_training_args, 'valid')\n",
    "\n",
    "trainer = MyTrainer(\n",
    "    model=model,   # the instantiated Transformers model to be trained\n",
    "    args=hg_training_args,                  # training arguments, defined above\n",
    "    tokenizer=model.tokenizer, \n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=val_dataset,          # evaluation dataset\n",
    "    compute_metrics=compute_metrics,     # the callback that computes metrics of interest\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd2779f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 30000\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 4690\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4690' max='4690' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4690/4690 18:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Country</th>\n",
       "      <th>F1 Country</th>\n",
       "      <th>Precision Country</th>\n",
       "      <th>Recall Country</th>\n",
       "      <th>Accuracy Politics</th>\n",
       "      <th>F1 Politics</th>\n",
       "      <th>Precision Politics</th>\n",
       "      <th>Recall Politics</th>\n",
       "      <th>Accuracy Tod</th>\n",
       "      <th>F1 Tod</th>\n",
       "      <th>Precision Tod</th>\n",
       "      <th>Recall Tod</th>\n",
       "      <th>Accuracy Age</th>\n",
       "      <th>F1 Age</th>\n",
       "      <th>Precision Age</th>\n",
       "      <th>Recall Age</th>\n",
       "      <th>Accuracy Education</th>\n",
       "      <th>F1 Education</th>\n",
       "      <th>Precision Education</th>\n",
       "      <th>Recall Education</th>\n",
       "      <th>Accuracy Ethnic</th>\n",
       "      <th>F1 Ethnic</th>\n",
       "      <th>Precision Ethnic</th>\n",
       "      <th>Recall Ethnic</th>\n",
       "      <th>Accuracy Gender</th>\n",
       "      <th>F1 Gender</th>\n",
       "      <th>Precision Gender</th>\n",
       "      <th>Recall Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.465700</td>\n",
       "      <td>6.712320</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.471178</td>\n",
       "      <td>0.338772</td>\n",
       "      <td>0.317624</td>\n",
       "      <td>0.376160</td>\n",
       "      <td>0.448622</td>\n",
       "      <td>0.207172</td>\n",
       "      <td>0.432388</td>\n",
       "      <td>0.256449</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.163771</td>\n",
       "      <td>0.201873</td>\n",
       "      <td>0.175018</td>\n",
       "      <td>0.337093</td>\n",
       "      <td>0.165237</td>\n",
       "      <td>0.312272</td>\n",
       "      <td>0.186655</td>\n",
       "      <td>0.828070</td>\n",
       "      <td>0.182579</td>\n",
       "      <td>0.178509</td>\n",
       "      <td>0.188811</td>\n",
       "      <td>0.736090</td>\n",
       "      <td>0.443897</td>\n",
       "      <td>0.513352</td>\n",
       "      <td>0.441870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.604200</td>\n",
       "      <td>6.594169</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.490727</td>\n",
       "      <td>0.355664</td>\n",
       "      <td>0.390922</td>\n",
       "      <td>0.391111</td>\n",
       "      <td>0.431830</td>\n",
       "      <td>0.235156</td>\n",
       "      <td>0.234724</td>\n",
       "      <td>0.264786</td>\n",
       "      <td>0.434085</td>\n",
       "      <td>0.188127</td>\n",
       "      <td>0.240019</td>\n",
       "      <td>0.187776</td>\n",
       "      <td>0.416040</td>\n",
       "      <td>0.196126</td>\n",
       "      <td>0.251324</td>\n",
       "      <td>0.196373</td>\n",
       "      <td>0.828321</td>\n",
       "      <td>0.204089</td>\n",
       "      <td>0.296138</td>\n",
       "      <td>0.201432</td>\n",
       "      <td>0.737343</td>\n",
       "      <td>0.441228</td>\n",
       "      <td>0.523945</td>\n",
       "      <td>0.440119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>6.355700</td>\n",
       "      <td>6.534550</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.489724</td>\n",
       "      <td>0.383332</td>\n",
       "      <td>0.468841</td>\n",
       "      <td>0.401730</td>\n",
       "      <td>0.450376</td>\n",
       "      <td>0.218197</td>\n",
       "      <td>0.314425</td>\n",
       "      <td>0.262195</td>\n",
       "      <td>0.438847</td>\n",
       "      <td>0.204605</td>\n",
       "      <td>0.234889</td>\n",
       "      <td>0.204669</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.218343</td>\n",
       "      <td>0.263148</td>\n",
       "      <td>0.207410</td>\n",
       "      <td>0.831328</td>\n",
       "      <td>0.217990</td>\n",
       "      <td>0.379092</td>\n",
       "      <td>0.210724</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.455421</td>\n",
       "      <td>0.495026</td>\n",
       "      <td>0.451151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>6.198000</td>\n",
       "      <td>6.552981</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.329146</td>\n",
       "      <td>0.325063</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.513283</td>\n",
       "      <td>0.427695</td>\n",
       "      <td>0.476989</td>\n",
       "      <td>0.432176</td>\n",
       "      <td>0.448120</td>\n",
       "      <td>0.239641</td>\n",
       "      <td>0.324544</td>\n",
       "      <td>0.269985</td>\n",
       "      <td>0.449875</td>\n",
       "      <td>0.217161</td>\n",
       "      <td>0.243137</td>\n",
       "      <td>0.213642</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>0.225031</td>\n",
       "      <td>0.268267</td>\n",
       "      <td>0.215740</td>\n",
       "      <td>0.831830</td>\n",
       "      <td>0.221282</td>\n",
       "      <td>0.320010</td>\n",
       "      <td>0.213328</td>\n",
       "      <td>0.739599</td>\n",
       "      <td>0.462612</td>\n",
       "      <td>0.491339</td>\n",
       "      <td>0.457825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>5.756800</td>\n",
       "      <td>6.531356</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.335879</td>\n",
       "      <td>0.491809</td>\n",
       "      <td>0.336684</td>\n",
       "      <td>0.515288</td>\n",
       "      <td>0.429238</td>\n",
       "      <td>0.491544</td>\n",
       "      <td>0.434767</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.225795</td>\n",
       "      <td>0.316301</td>\n",
       "      <td>0.265657</td>\n",
       "      <td>0.453383</td>\n",
       "      <td>0.210460</td>\n",
       "      <td>0.250206</td>\n",
       "      <td>0.209222</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.231064</td>\n",
       "      <td>0.293924</td>\n",
       "      <td>0.224936</td>\n",
       "      <td>0.829073</td>\n",
       "      <td>0.235061</td>\n",
       "      <td>0.385206</td>\n",
       "      <td>0.222489</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>0.464859</td>\n",
       "      <td>0.502547</td>\n",
       "      <td>0.459645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>5.421500</td>\n",
       "      <td>6.768310</td>\n",
       "      <td>0.975689</td>\n",
       "      <td>0.349031</td>\n",
       "      <td>0.575305</td>\n",
       "      <td>0.343557</td>\n",
       "      <td>0.518797</td>\n",
       "      <td>0.425691</td>\n",
       "      <td>0.490425</td>\n",
       "      <td>0.433170</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.230828</td>\n",
       "      <td>0.299303</td>\n",
       "      <td>0.266513</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.236233</td>\n",
       "      <td>0.216365</td>\n",
       "      <td>0.417794</td>\n",
       "      <td>0.232732</td>\n",
       "      <td>0.301486</td>\n",
       "      <td>0.230848</td>\n",
       "      <td>0.827569</td>\n",
       "      <td>0.238431</td>\n",
       "      <td>0.356211</td>\n",
       "      <td>0.223541</td>\n",
       "      <td>0.737093</td>\n",
       "      <td>0.462652</td>\n",
       "      <td>0.486474</td>\n",
       "      <td>0.458139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>4.972600</td>\n",
       "      <td>6.846441</td>\n",
       "      <td>0.975940</td>\n",
       "      <td>0.361321</td>\n",
       "      <td>0.563562</td>\n",
       "      <td>0.350344</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.455003</td>\n",
       "      <td>0.463876</td>\n",
       "      <td>0.452660</td>\n",
       "      <td>0.442356</td>\n",
       "      <td>0.263891</td>\n",
       "      <td>0.357665</td>\n",
       "      <td>0.279240</td>\n",
       "      <td>0.449123</td>\n",
       "      <td>0.226067</td>\n",
       "      <td>0.233774</td>\n",
       "      <td>0.226387</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>0.241904</td>\n",
       "      <td>0.289828</td>\n",
       "      <td>0.233589</td>\n",
       "      <td>0.828070</td>\n",
       "      <td>0.242996</td>\n",
       "      <td>0.338047</td>\n",
       "      <td>0.226461</td>\n",
       "      <td>0.740602</td>\n",
       "      <td>0.462699</td>\n",
       "      <td>0.492899</td>\n",
       "      <td>0.457873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>4.645300</td>\n",
       "      <td>7.032868</td>\n",
       "      <td>0.975188</td>\n",
       "      <td>0.348560</td>\n",
       "      <td>0.491968</td>\n",
       "      <td>0.343386</td>\n",
       "      <td>0.517544</td>\n",
       "      <td>0.451317</td>\n",
       "      <td>0.470335</td>\n",
       "      <td>0.449970</td>\n",
       "      <td>0.425815</td>\n",
       "      <td>0.264964</td>\n",
       "      <td>0.306352</td>\n",
       "      <td>0.278487</td>\n",
       "      <td>0.442857</td>\n",
       "      <td>0.222537</td>\n",
       "      <td>0.229282</td>\n",
       "      <td>0.220794</td>\n",
       "      <td>0.425564</td>\n",
       "      <td>0.241917</td>\n",
       "      <td>0.294418</td>\n",
       "      <td>0.232075</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.252534</td>\n",
       "      <td>0.378623</td>\n",
       "      <td>0.232904</td>\n",
       "      <td>0.734837</td>\n",
       "      <td>0.464048</td>\n",
       "      <td>0.481542</td>\n",
       "      <td>0.459938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>4.320900</td>\n",
       "      <td>7.108984</td>\n",
       "      <td>0.975689</td>\n",
       "      <td>0.355117</td>\n",
       "      <td>0.547607</td>\n",
       "      <td>0.346908</td>\n",
       "      <td>0.511779</td>\n",
       "      <td>0.455131</td>\n",
       "      <td>0.464497</td>\n",
       "      <td>0.452666</td>\n",
       "      <td>0.433083</td>\n",
       "      <td>0.262308</td>\n",
       "      <td>0.329649</td>\n",
       "      <td>0.277303</td>\n",
       "      <td>0.443358</td>\n",
       "      <td>0.225579</td>\n",
       "      <td>0.230294</td>\n",
       "      <td>0.225131</td>\n",
       "      <td>0.415789</td>\n",
       "      <td>0.237092</td>\n",
       "      <td>0.279466</td>\n",
       "      <td>0.231582</td>\n",
       "      <td>0.827820</td>\n",
       "      <td>0.250089</td>\n",
       "      <td>0.381450</td>\n",
       "      <td>0.231965</td>\n",
       "      <td>0.733584</td>\n",
       "      <td>0.462331</td>\n",
       "      <td>0.481048</td>\n",
       "      <td>0.458213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938\n",
      "Configuration saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876\n",
      "Configuration saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-938] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814\n",
      "Configuration saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-1876] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752\n",
      "Configuration saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-2814] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3990\n",
      "  Batch size = 32\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jz17d/anaconda3/envs/torch/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-4690\n",
      "Configuration saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-4690/config.json\n",
      "Model weights saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-4690/pytorch_model.bin\n",
      "tokenizer config file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-4690/tokenizer_config.json\n",
      "Special tokens file saved in /scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-4690/special_tokens_map.json\n",
      "Deleting older checkpoint [/scratch/data_jz17d/result/country+politics+tod+age+education+ethnic+gender/20220919-15:01:59/checkpoint-3752] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4690, training_loss=5.691822536159426, metrics={'train_runtime': 1120.7916, 'train_samples_per_second': 133.834, 'train_steps_per_second': 4.185, 'total_flos': 2206427450800320.0, 'train_loss': 5.691822536159426, 'epoch': 5.0})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4cc66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c4d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f70b788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1863edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcb156f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be896cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273d55e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90dac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a608965",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "923cbd92",
   "metadata": {},
   "source": [
    "## bertology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa453ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entropy(p):\n",
    "#     \"\"\" Compute the entropy of a probability distribution \"\"\"\n",
    "#     plogp = p * torch.log(p)\n",
    "#     plogp[p == 0] = 0\n",
    "#     return -plogp.sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f7bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_heads_importance(\n",
    "#     model, eval_dataloader, training_args, diagnose_per_step=False, diagnose_normalize=True, compute_entropy=True, compute_importance=True, head_mask=None, \n",
    "#     dont_normalize_importance_by_layer = True, dont_normalize_global_importance=True\n",
    "# ):\n",
    "#     \"\"\" This method shows how to compute:\n",
    "#         - head attention entropy\n",
    "#         - head importance scores according to http://arxiv.org/abs/1905.10650\n",
    "#     \"\"\"\n",
    "#     model_folder = training_args.model_folder\n",
    "    \n",
    "#     # Prepare our tensors\n",
    "#     n_layers, n_heads = model.basemodel.config.num_hidden_layers, model.basemodel.config.num_attention_heads\n",
    "#     head_importance = torch.zeros(n_layers, n_heads).to(device)\n",
    "#     attn_entropy = torch.zeros(n_layers, n_heads).to(device)\n",
    "\n",
    "#     if head_mask is None:\n",
    "#         head_mask = torch.ones(n_layers, n_heads).to(device)\n",
    "#     head_mask.requires_grad_(requires_grad=True)\n",
    "#     preds = None\n",
    "#     labels = None\n",
    "#     tot_tokens = 0.0\n",
    "#     if diagnose_per_step:\n",
    "#         entropy_per_step = None\n",
    "#         importance_per_step = None\n",
    "\n",
    "#     for step, batch in enumerate(tqdm(eval_dataloader, desc=\"Iteration\")):\n",
    "#         i_task, batch = batch\n",
    "#         label_ids = batch['label'].to(device)\n",
    "#         size = len(label_ids)\n",
    "#         del batch['label']\n",
    "#         batch = model.tokenizer(**batch, return_tensors='pt', padding=True, truncation=True, max_length=64).to(device)\n",
    "#         input_ids, input_mask, segment_ids = batch['input_ids'], batch['attention_mask'], batch['token_type_ids']\n",
    "        \n",
    "#         # Do a forward pass (not with torch.no_grad() since we need gradients for importance score - see below)\n",
    "#         outputs = model(i_task=i_task,\n",
    "#             input_ids=input_ids, token_type_ids=segment_ids, attention_mask=input_mask, label=label_ids, head_mask=head_mask, \n",
    "#             output_attentions = True, \n",
    "#         )\n",
    "#         loss, logits, all_attentions = (\n",
    "#             outputs.loss,\n",
    "#             outputs.logits,\n",
    "#             outputs.attentions,\n",
    "#         )  # Loss and logits are the first, attention the last\n",
    "#         loss.backward()  # Backpropagate to populate the gradients in the head mask\n",
    "        \n",
    "#         batch_entropy = torch.zeros(n_layers, n_heads).to(device) \n",
    "#         if compute_entropy:\n",
    "#             for layer, attn in enumerate(all_attentions):\n",
    "#                 masked_entropy = entropy(attn.detach()) * input_mask.float().unsqueeze(1)\n",
    "#                 batch_entropy[layer] += masked_entropy.sum(-1).sum(0).detach()\n",
    "#                 attn_entropy[layer] += masked_entropy.sum(-1).sum(0).detach()\n",
    "\n",
    "#         if compute_importance:\n",
    "#             batch_importance = head_mask.grad.abs().detach()\n",
    "#             head_importance += batch_importance\n",
    "\n",
    "#         # Also store our logits/labels if we want to compute metrics afterwards\n",
    "#         if preds is None:\n",
    "#             preds = logits.detach().cpu().numpy()\n",
    "#             labels = label_ids.detach().cpu().numpy()\n",
    "#         else:\n",
    "#             preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)\n",
    "#             labels = np.append(labels, label_ids.detach().cpu().numpy(), axis=0)\n",
    "        \n",
    "#         batch_num_tokens = input_mask.float().detach().sum().item()\n",
    "#         tot_tokens += batch_num_tokens\n",
    "        \n",
    "#         if diagnose_per_step:\n",
    "#             if diagnose_normalize:\n",
    "#                 batch_entropy = batch_entropy.detach().cpu().unsqueeze(0).numpy()/batch_num_tokens\n",
    "#                 batch_importance = batch_importance.cpu().unsqueeze(0).numpy()/batch_num_tokens\n",
    "                \n",
    "#             else:\n",
    "#                 batch_entropy = batch_entropy.detach().cpu().unsqueeze(0).numpy()\n",
    "#                 batch_importance = batch_importance.detach().cpu().unsqueeze(0).numpy()\n",
    "                \n",
    "#             if entropy_per_step is None:\n",
    "#                 entropy_per_step = batch_entropy\n",
    "#             else:\n",
    "#                 entropy_per_step = np.append(entropy_per_step, batch_entropy, axis=0)\n",
    "#             if importance_per_step is None:\n",
    "#                 importance_per_step = batch_importance\n",
    "#             else:\n",
    "#                 importance_per_step = np.append(importance_per_step, batch_importance, axis=0)\n",
    "    \n",
    "#     # Normalize\n",
    "#     attn_entropy /= tot_tokens\n",
    "#     head_importance /= tot_tokens\n",
    "#     # Layerwise importance normalization\n",
    "#     if not dont_normalize_importance_by_layer:\n",
    "#         exponent = 2\n",
    "#         norm_by_layer = torch.pow(torch.pow(head_importance, exponent).sum(-1), 1 / exponent)\n",
    "#         head_importance /= norm_by_layer.unsqueeze(-1) + 1e-20\n",
    "\n",
    "#     if not dont_normalize_global_importance:\n",
    "#         head_importance = (head_importance - head_importance.min()) / (head_importance.max() - head_importance.min())\n",
    "\n",
    "#     # save matrices\n",
    "#     np.save(os.path.join(model_folder, \"attn_entropy.npy\"), attn_entropy.detach().cpu().numpy())\n",
    "#     np.save(os.path.join(model_folder, \"head_importance.npy\"), head_importance.detach().cpu().numpy())\n",
    "\n",
    "#     head_ranks = torch.zeros(head_importance.numel(), dtype=torch.long, device=device)\n",
    "#     head_ranks[head_importance.view(-1).sort(descending=True)[1]] = torch.arange(\n",
    "#         head_importance.numel(), device=device\n",
    "#     )\n",
    "#     head_ranks = head_ranks.view_as(head_importance)\n",
    "    \n",
    "#     plt.figure(figsize = (9,4))\n",
    "#     plt.subplot(1,2,1)\n",
    "#     plt.title('attn_entropy')\n",
    "#     plt.imshow(attn_entropy.detach().cpu().numpy())\n",
    "#     plt.colorbar()\n",
    "#     plt.subplot(1,2,2)\n",
    "#     plt.title('head_importance')\n",
    "#     plt.imshow(head_importance.detach().cpu().numpy())\n",
    "#     plt.colorbar()\n",
    "#     plt.show()\n",
    "    \n",
    "#     if diagnose_per_step:\n",
    "#         return attn_entropy, head_importance, preds, labels, entropy_per_step, importance_per_step\n",
    "    \n",
    "#     return attn_entropy, head_importance, preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad3c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def imshow(torch_mat):\n",
    "#     plt.imshow(torch_mat.detach().cpu().numpy())\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267e3c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_dataloader = MultiTaskTestDataLoader(training_args, split='dev')\n",
    "# attn_entropy, head_importance, preds, labels = compute_heads_importance(model, eval_dataloader, training_args)\n",
    "\n",
    "# imshow(attn_entropy)\n",
    "# imshow(head_importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
